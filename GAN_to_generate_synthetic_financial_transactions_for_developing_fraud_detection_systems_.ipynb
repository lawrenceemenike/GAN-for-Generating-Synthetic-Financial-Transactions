{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RU6GZZqNTpcX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Optional for data visualization (later stages)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Fraud_dataset.csv')\n",
        "df.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sztS6cVYUCjm",
        "outputId": "a915d424-72c9-49ca-f13b-d2baceb977c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
              "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
              "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
              "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
              "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
              "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
              "\n",
              "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
              "0  M1979787155             0.0             0.0      0.0             0.0  \n",
              "1  M2044282225             0.0             0.0      0.0             0.0  \n",
              "2   C553264065             0.0             0.0      1.0             0.0  \n",
              "3    C38997010         21182.0             0.0      1.0             0.0  \n",
              "4  M1230701703             0.0             0.0      0.0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9436c93c-0432-4eee-aba2-939ad2214d03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>type</th>\n",
              "      <th>amount</th>\n",
              "      <th>nameOrig</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>nameDest</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>newbalanceDest</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>9839.64</td>\n",
              "      <td>C1231006815</td>\n",
              "      <td>170136.0</td>\n",
              "      <td>160296.36</td>\n",
              "      <td>M1979787155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>1864.28</td>\n",
              "      <td>C1666544295</td>\n",
              "      <td>21249.0</td>\n",
              "      <td>19384.72</td>\n",
              "      <td>M2044282225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TRANSFER</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C1305486145</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C553264065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CASH_OUT</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C840083671</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C38997010</td>\n",
              "      <td>21182.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>11668.14</td>\n",
              "      <td>C2048537720</td>\n",
              "      <td>41554.0</td>\n",
              "      <td>29885.86</td>\n",
              "      <td>M1230701703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9436c93c-0432-4eee-aba2-939ad2214d03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9436c93c-0432-4eee-aba2-939ad2214d03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9436c93c-0432-4eee-aba2-939ad2214d03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab595879-1fda-469f-88c6-f758c623a57d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab595879-1fda-469f-88c6-f758c623a57d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab595879-1fda-469f-88c6-f758c623a57d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15121,\n  \"fields\": [\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"TRANSFER\",\n          \"CASH_IN\",\n          \"CASH_OUT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 282708.8444499201,\n        \"min\": 2.39,\n        \"max\": 10000000.0,\n        \"num_unique_values\": 15053,\n        \"samples\": [\n          922.93,\n          142268.91,\n          672102.16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nameOrig\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15121,\n        \"samples\": [\n          \"C484886039\",\n          \"C367660195\",\n          \"C1127174687\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldbalanceOrg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1965267.893580551,\n        \"min\": 0.0,\n        \"max\": 12900000.0,\n        \"num_unique_values\": 10573,\n        \"samples\": [\n          27404.0,\n          157.0,\n          136507.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newbalanceOrig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2007504.5229249496,\n        \"min\": 0.0,\n        \"max\": 13000000.0,\n        \"num_unique_values\": 8446,\n        \"samples\": [\n          4505975.39,\n          97245.12,\n          26852.33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nameDest\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10103,\n        \"samples\": [\n          \"M144467413\",\n          \"M1010350904\",\n          \"M403831180\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldbalanceDest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2512250.478983635,\n        \"min\": 0.0,\n        \"max\": 20900000.0,\n        \"num_unique_values\": 6161,\n        \"samples\": [\n          11342.0,\n          645878.76,\n          134148.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newbalanceDest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3158826.415947836,\n        \"min\": 0.0,\n        \"max\": 25300000.0,\n        \"num_unique_values\": 2339,\n        \"samples\": [\n          117634.01,\n          5635.8,\n          1982491.06\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isFraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0720965481794461,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isFlaggedFraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kqYQgMnZHLw",
        "outputId": "5fdecb4c-b7cc-4c84-b96b-76b3e0c90888"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15121 entries, 0 to 15120\n",
            "Data columns (total 11 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   step            15121 non-null  int64  \n",
            " 1   type            15121 non-null  object \n",
            " 2   amount          15121 non-null  float64\n",
            " 3   nameOrig        15121 non-null  object \n",
            " 4   oldbalanceOrg   15121 non-null  float64\n",
            " 5   newbalanceOrig  15121 non-null  float64\n",
            " 6   nameDest        15121 non-null  object \n",
            " 7   oldbalanceDest  15120 non-null  float64\n",
            " 8   newbalanceDest  15120 non-null  float64\n",
            " 9   isFraud         15120 non-null  float64\n",
            " 10  isFlaggedFraud  15120 non-null  float64\n",
            "dtypes: float64(7), int64(1), object(3)\n",
            "memory usage: 1.3+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "Hi-sCwpwaU7C",
        "outputId": "6f77c6d8-8898-4b9f-f6a7-9a2d135b2fd7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               step        amount  oldbalanceOrg  newbalanceOrig  \\\n",
              "count  15121.000000  1.512100e+04   1.512100e+04    1.512100e+04   \n",
              "mean       5.208386  1.141586e+05   7.519870e+05    7.676741e+05   \n",
              "std        2.488843  2.827088e+05   1.965268e+06    2.007505e+06   \n",
              "min        1.000000  2.390000e+00   0.000000e+00    0.000000e+00   \n",
              "25%        3.000000  4.687140e+03   0.000000e+00    0.000000e+00   \n",
              "50%        7.000000  1.312560e+04   2.012500e+04    7.241380e+03   \n",
              "75%        7.000000  1.246170e+05   1.253520e+05    1.187286e+05   \n",
              "max        8.000000  1.000000e+07   1.290000e+07    1.300000e+07   \n",
              "\n",
              "       oldbalanceDest  newbalanceDest       isFraud  isFlaggedFraud  \n",
              "count    1.512000e+04    1.512000e+04  15120.000000         15120.0  \n",
              "mean     8.278360e+05    1.153106e+06      0.005225             0.0  \n",
              "std      2.512250e+06    3.158826e+06      0.072097             0.0  \n",
              "min      0.000000e+00    0.000000e+00      0.000000             0.0  \n",
              "25%      0.000000e+00    0.000000e+00      0.000000             0.0  \n",
              "50%      0.000000e+00    0.000000e+00      0.000000             0.0  \n",
              "75%      2.547435e+05    2.835928e+05      0.000000             0.0  \n",
              "max      2.090000e+07    2.530000e+07      1.000000             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbb23280-eb67-4060-bee3-b731cac492ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>amount</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>newbalanceDest</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>15121.000000</td>\n",
              "      <td>1.512100e+04</td>\n",
              "      <td>1.512100e+04</td>\n",
              "      <td>1.512100e+04</td>\n",
              "      <td>1.512000e+04</td>\n",
              "      <td>1.512000e+04</td>\n",
              "      <td>15120.000000</td>\n",
              "      <td>15120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.208386</td>\n",
              "      <td>1.141586e+05</td>\n",
              "      <td>7.519870e+05</td>\n",
              "      <td>7.676741e+05</td>\n",
              "      <td>8.278360e+05</td>\n",
              "      <td>1.153106e+06</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.488843</td>\n",
              "      <td>2.827088e+05</td>\n",
              "      <td>1.965268e+06</td>\n",
              "      <td>2.007505e+06</td>\n",
              "      <td>2.512250e+06</td>\n",
              "      <td>3.158826e+06</td>\n",
              "      <td>0.072097</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.390000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.687140e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.312560e+04</td>\n",
              "      <td>2.012500e+04</td>\n",
              "      <td>7.241380e+03</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.246170e+05</td>\n",
              "      <td>1.253520e+05</td>\n",
              "      <td>1.187286e+05</td>\n",
              "      <td>2.547435e+05</td>\n",
              "      <td>2.835928e+05</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>8.000000</td>\n",
              "      <td>1.000000e+07</td>\n",
              "      <td>1.290000e+07</td>\n",
              "      <td>1.300000e+07</td>\n",
              "      <td>2.090000e+07</td>\n",
              "      <td>2.530000e+07</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbb23280-eb67-4060-bee3-b731cac492ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cbb23280-eb67-4060-bee3-b731cac492ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cbb23280-eb67-4060-bee3-b731cac492ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-90d0f442-7afc-4f29-9765-8bb15e0f2b43\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90d0f442-7afc-4f29-9765-8bb15e0f2b43')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-90d0f442-7afc-4f29-9765-8bb15e0f2b43 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"step\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5344.379428251015,\n        \"min\": 1.0,\n        \"max\": 15121.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15121.0,\n          5.208385688777197,\n          7.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"amount\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3508854.8125954503,\n        \"min\": 2.39,\n        \"max\": 10000000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          114158.59391574633,\n          13125.6,\n          15121.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldbalanceOrg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4467925.833327364,\n        \"min\": 0.0,\n        \"max\": 12900000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15121.0,\n          751987.018754712,\n          125352.02\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newbalanceOrig\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4503456.143655656,\n        \"min\": 0.0,\n        \"max\": 13000000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          15121.0,\n          767674.0529587991,\n          118728.65\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oldbalanceDest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7258292.123430075,\n        \"min\": 0.0,\n        \"max\": 20900000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          15120.0,\n          827835.9891369047,\n          20900000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"newbalanceDest\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8780234.723447269,\n        \"min\": 0.0,\n        \"max\": 25300000.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          15120.0,\n          1153106.2801421958,\n          25300000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isFraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5345.672864038131,\n        \"min\": 0.0,\n        \"max\": 15120.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.005224867724867725,\n          1.0,\n          0.0720965481794461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isFlaggedFraud\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5345.7272657703,\n        \"min\": 0.0,\n        \"max\": 15120.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          15120.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['type'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1dWthquab2p",
        "outputId": "9e5310f5-99e2-4cb8-d95c-b4838022d513"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['PAYMENT', 'TRANSFER', 'CASH_OUT', 'DEBIT', 'CASH_IN'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: a script to plot a stacked bar chat showing which 'type' had the highest amount\n",
        "\n",
        "df_type = df.groupby('type')['amount'].sum().sort_values(ascending=False)\n",
        "\n",
        "colors_list = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue']\n",
        "\n",
        "df_type.plot(kind='bar', stacked=True, rot=0, color=colors_list)\n",
        "\n",
        "plt.title('Total Amount by Type')\n",
        "plt.xlabel('Type')\n",
        "plt.ylabel('Amount')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "FCjSobZvb96X",
        "outputId": "91d53c37-a8e4-44c7-ae53-dac4288e30db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze transaction type distribution\n",
        "print(\"Transaction Type Distribution:\")\n",
        "type_counts = df['type'].value_counts()\n",
        "print(type_counts)\n",
        "\n",
        "# Plot the distribution as a bar chart\n",
        "plt.figure(figsize=(8, 6))\n",
        "type_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title(\"Distribution of Transaction Types\")\n",
        "plt.xlabel(\"Transaction Type\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n",
        "\n",
        "# Analyze fraud by transaction type\n",
        "fraud_by_type = df.groupby('type')['isFraud'].mean() * 100  # Calculate percentage\n",
        "\n",
        "print(\"\\nPercentage of Fraudulent Transactions by Type:\")\n",
        "print(fraud_by_type)\n",
        "\n",
        "# Plot fraud percentage by transaction type\n",
        "plt.figure(figsize=(8, 6))\n",
        "fraud_by_type.plot(kind='bar', color='coral')\n",
        "plt.title(\"Percentage of Fraudulent Transactions by Type\")\n",
        "plt.xlabel(\"Transaction Type\")\n",
        "plt.ylabel(\"Percentage (%)\")\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-cQl2Y5ScTVn",
        "outputId": "5ea6935b-410b-48be-b695-e1905c561cc8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transaction Type Distribution:\n",
            "type\n",
            "PAYMENT     8341\n",
            "CASH_IN     2527\n",
            "CASH_OUT    2311\n",
            "TRANSFER    1524\n",
            "DEBIT        418\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Percentage of Fraudulent Transactions by Type:\n",
            "type\n",
            "CASH_IN     0.000000\n",
            "CASH_OUT    1.774124\n",
            "DEBIT       0.000000\n",
            "PAYMENT     0.000000\n",
            "TRANSFER    2.493438\n",
            "Name: isFraud, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABTuklEQVR4nO3deXhMZ//H8c9EZBISIZYETSXW2Kmd1q62UqW2X1Uorba0dq1WCaqxPCitUi1SRRFq62Lfautjr50iljaxS8SSkJzfH70yjzEJGU3E4f26rrnauc99zvmeZSYfZ+45YzEMwxAAAABgQi4ZXQAAAADwsAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizADLU8uXLVa5cObm7u8tisejq1asZXdK/Urt2bdWuXfuh5u3UqZMCAgLStB6kj39znNNbp06d5OnpmdFlAI8MYRZPjLCwMFksFtvD3d1dRYsWVY8ePXTu3LmMLu9fO3jwoEJCQhQREZHRpaSZS5cuqU2bNvLw8NCkSZP0/fffK2vWrMn2vff43v348MMPH3Hl5pXa8ygiIiLF/X3v40k6J+/2JL7m0kJISEiqzovHNezjyeOa0QUAaW3YsGEKDAzUrVu3tGnTJk2ePFm//PKL9u/fryxZsmR0eQ/t4MGDGjp0qGrXrv3EXL3bvn27rl27puHDh6t+/fqpmifp+N6tVKlS6VHeEym151Hu3Ln1/fff27WNHTtWZ8+e1fjx4x36Ponut69WrlyZMUU9Blq2bKnChQvbnsfGxuqdd97RK6+8opYtW9rafX19M6I8PIUIs3jiNG7cWBUrVpQkde3aVTlz5tS4ceO0ZMkStW/f/l8t+8aNG6YOxI+b8+fPS5KyZ8+e6nnuPr4PcuvWLbm5ucnFhQ+hnJU1a1Z16NDBrm3u3Lm6cuWKQ/vdDMPQrVu35OHhkd4lZig3N7eMLiHDlClTRmXKlLE9v3jxot555x2VKVPmvucGkF54h8cTr27dupKkkydP2tpmzZqlChUqyMPDQz4+PmrXrp3OnDljN1/t2rVVqlQp7dy5UzVr1lSWLFn00UcfSfonJIWEhKho0aJyd3dX3rx51bJlSx0/ftw2f2Jioj7//HOVLFlS7u7u8vX1Vbdu3XTlyhW79QQEBOill17Spk2bVLlyZbm7u6tgwYKaOXOmrU9YWJhat24tSapTp47tY7z169dLkpYsWaKmTZsqX758slqtKlSokIYPH66EhASH/TFp0iQVLFhQHh4eqly5sn777bdkx//FxcVpyJAhKly4sKxWq/z9/TVgwADFxcWlar+Hh4fb9nGuXLnUoUMH/fXXX3b7Nzg4WJJUqVIlWSwWderUKVXLTs769etlsVg0d+5cDRo0SPnz51eWLFkUExOjy5cvq1+/fipdurQ8PT2VLVs2NW7cWHv37rVbRtJQhns/Vk5adtL+TjJ16lQVKlTIbl/ey9ll3utRnkcPI2m9K1asUMWKFeXh4aGvv/5akjRjxgzVrVtXefLkkdVqVYkSJTR58uQUl3G/2iXp9u3bGjp0qIoUKSJ3d3flzJlTzz//vFatWmXr88cff6hTp04qWLCg3N3d5efnpzfeeEOXLl1yWO9ff/2lLl262F43gYGBeueddxQfH//AfZXca+b8+fPq0qWLfH195e7urrJly+q7776z65M0fOM///mP7fyxWq2qVKmStm/fbtc3KipKnTt31jPPPCOr1aq8efPq5ZdfTvWwhxMnTqhhw4bKmjWr8uXLp2HDhskwDEn//KMjICBAL7/8ssN8t27dkre3t7p165aq9SS3XovF4nAFX5K2bNkii8WiH374QdL/hiwcPnxYbdq0UbZs2ZQzZ0717NlTt27dcpg/Ne/dePpwZRZPvKSAmTNnTknSiBEj9Mknn6hNmzbq2rWrLly4oC+++EI1a9bU7t277a4SXrp0SY0bN1a7du3UoUMH+fr6KiEhQS+99JLWrFmjdu3aqWfPnrp27ZpWrVql/fv3q1ChQpKkbt26KSwsTJ07d9b777+vkydP6ssvv9Tu3bu1efNmZc6c2baeP//8U6+++qq6dOmi4OBgTZ8+XZ06dVKFChVUsmRJ1axZU++//74mTpyojz76SMWLF5ck23/DwsLk6empPn36yNPTU2vXrtXgwYMVExOjMWPG2NYzefJk9ejRQy+88IJ69+6tiIgItWjRQjly5NAzzzxj65eYmKjmzZtr06ZNeuutt1S8eHHt27dP48eP19GjR7V48eL77vOk7a5UqZJCQ0N17tw5TZgwQZs3b7bt448//ljFihXT1KlTbUMHkvbd/URHR+vixYt2bbly5bL9//Dhw+Xm5qZ+/fopLi5Obm5uOnjwoBYvXqzWrVsrMDBQ586d09dff61atWrp4MGDypcv3wPXe69p06apW7duql69unr16qUTJ06oefPm8vHxkb+/v9PLS8mjPI8e1pEjR9S+fXt169ZNb775pooVKybpn/OtZMmSat68uVxdXbVs2TK9++67SkxMVPfu3e2W8aDapX+CT2hoqLp27arKlSsrJiZGO3bs0K5du9SgQQNJ0qpVq3TixAl17txZfn5+OnDggKZOnaoDBw5o27ZtslgskqS///5blStX1tWrV/XWW28pKChIf/31lxYsWKAbN244va9u3ryp2rVr688//1SPHj0UGBio8PBwderUSVevXlXPnj3t+s+ZM0fXrl1Tt27dZLFYNHr0aLVs2VInTpywHdNWrVrpwIEDeu+99xQQEKDz589r1apVOn369AOHGiUkJKhRo0aqWrWqRo8ereXLl2vIkCG6c+eOhg0bJovFog4dOmj06NG6fPmyfHx8bPMuW7ZMMTExD32VtWDBgqpRo4Zmz56t3r17202bPXu2vLy8HEJ0mzZtFBAQoNDQUG3btk0TJ07UlStX7P5B48x7N54yBvCEmDFjhiHJWL16tXHhwgXjzJkzxty5c42cOXMaHh4extmzZ42IiAgjU6ZMxogRI+zm3bdvn+Hq6mrXXqtWLUOSMWXKFLu+06dPNyQZ48aNc6ghMTHRMAzD+O233wxJxuzZs+2mL1++3KG9QIEChiRj48aNtrbz588bVqvV6Nu3r60tPDzckGSsW7fOYb03btxwaOvWrZuRJUsW49atW4ZhGEZcXJyRM2dOo1KlSsbt27dt/cLCwgxJRq1atWxt33//veHi4mL89ttvdsucMmWKIcnYvHmzw/qSxMfHG3ny5DFKlSpl3Lx509b+008/GZKMwYMH29qSjtn27dtTXN69fZN7GIZhrFu3zpBkFCxY0GF/3Lp1y0hISLBrO3nypGG1Wo1hw4Y5rOPkyZN2fZOWnbTvk7axXLlyRlxcnK3f1KlTHfZlapdpGIYRHBxsFChQwPb8UZ9HD9K0aVO7+u5e7/Llyx36J3deNmzY0ChYsGCyy3hQ7WXLljWaNm163xqTW+cPP/zgsPyOHTsaLi4uyZ57Sa/j++2rWrVq2R3nzz//3JBkzJo1y9YWHx9vVKtWzfD09DRiYmIMw/jnvJNk5MyZ07h8+bKt75IlSwxJxrJlywzDMIwrV64YkowxY8bcd3uTExwcbEgy3nvvPbttatq0qeHm5mZcuHDBMAzDOHLkiCHJmDx5st38zZs3NwICAmz74UEuXLhgSDKGDBlia/v6668NScahQ4dsbfHx8UauXLmM4OBgW9uQIUMMSUbz5s3tlvnuu+8akoy9e/cahmE49d6Npw/DDPDEqV+/vnLnzi1/f3+1a9dOnp6eWrRokfLnz68ff/xRiYmJatOmjS5evGh7+Pn5qUiRIlq3bp3dsqxWqzp37mzXtnDhQuXKlUvvvfeew7qTrvqEh4fL29tbDRo0sFtPhQoV5Onp6bCeEiVK6IUXXrA9z507t4oVK6YTJ06kapvvHp947do1Xbx4US+88IJu3Lihw4cPS5J27NihS5cu6c0335Sr6/8+lHnttdeUI0cOu+WFh4erePHiCgoKsqs/acjGvfXfbceOHTp//rzeffddubu729qbNm2qoKAg/fzzz6nappRMmjRJq1atsnvcLTg42GG8ptVqtY2bTUhI0KVLl+Tp6alixYpp165dTteQtI1vv/223djJTp06ydvb+yG2KnmP+jx6WIGBgWrYsKFD+93HIemKeq1atXTixAlFR0fb9U1N7dmzZ9eBAwd07NixFGu5e523bt3SxYsXVbVqVUmyHevExEQtXrxYzZo1S3b8ddLr2Bm//PKL/Pz87MblZ86cWe+//75iY2O1YcMGu/5t27a1e90lbXvS9np4eMjNzU3r1693GFKSWj169LD9v8ViUY8ePRQfH6/Vq1dLkooWLaoqVapo9uzZtn6XL1/Wr7/+qtdee+2h9kOSNm3ayN3d3W7ZK1as0MWLF5O94nvvlfqk99dffvlFkpx+78bThWEGeOJMmjRJRYsWlaurq3x9fVWsWDFbkDl27JgMw1CRIkWSnffuj2wlKX/+/A5f9Dh+/LiKFStmFwjvdezYMUVHRytPnjzJTk/64lOSZ5991qFPjhw5Uv1H7MCBAxo0aJDWrl2rmJgYu2lJoeHUqVOSZPctZElydXV1+Mjy2LFjOnToUIrfUr+3/rslrSfpo+a7BQUFadOmTfffmAeoXLnyfb8Adu+dDqR/wsuECRP01Vdf6eTJk3ZjiZOGnzgjaRvvPY8yZ86sggULOr28lDzq8+hhJbfPJWnz5s0aMmSItm7dqhs3bthNi46Otgv+qal92LBhevnll1W0aFGVKlVKjRo10uuvv273ZaTLly9r6NChmjt3rsP+SXotXLhwQTExMWl6F4xTp06pSJEiDl82TBqWkHTOJLl3e5OCbdL2Wq1WjRo1Sn379pWvr6+qVq2ql156SR07dpSfn98D63FxcXE4F4sWLSpJdmNuO3bsqB49eujUqVMqUKCAwsPDdfv2bb3++uup2OqUZc+eXc2aNdOcOXM0fPhwSf8MMcifP7/tH8V3u/e1VKhQIbm4uNhqdfa9G08XwiyeOPcLO4mJibJYLPr111+VKVMmh+n33mj8Yb+RnZiYqDx58thdlbjbvSExuVok2b6scT9Xr15VrVq1lC1bNg0bNkyFChWSu7u7du3apQ8++ECJiYkPVX/p0qU1bty4ZKen5ZjQtJbcMfvss8/0ySef6I033tDw4cPl4+MjFxcX9erVy27/pHQlKrkv0qXWv1nmozyP/o3k9vnx48dVr149BQUFady4cfL395ebm5t++eUXjR8/3uG8TE3tNWvW1PHjx7VkyRKtXLlS3377rcaPH68pU6aoa9eukv65Irhlyxb1799f5cqVk6enpxITE9WoUaOHei2kl9Rsb69evdSsWTMtXrxYK1as0CeffKLQ0FCtXbtW5cuXT5M62rVrp969e2v27Nn66KOPNGvWLFWsWDHZf4w6q2PHjgoPD9eWLVtUunRpLV26VO+++26q7i5y7+vG2fduPF0Is3iqFCpUSIZhKDAw0HaV4mGW8fvvv+v27dspXg0oVKiQVq9erRo1aqTZLYpSCkXr16/XpUuX9OOPP6pmzZq29rvv3iBJBQoUkPTPF23q1Klja79z544iIiLsrm4VKlRIe/fuVb169Zz+qDFpPUeOHHG4AnPkyBHb9EdpwYIFqlOnjqZNm2bXfvXqVbsvjyVdHbv3V8juvaqWtA3Hjh2z28bbt2/r5MmTKlu2rNPLTM6jPI/S2rJlyxQXF6elS5faXYX8tx8H+/j4qHPnzurcubNiY2NVs2ZNhYSEqGvXrrpy5YrWrFmjoUOHavDgwbZ57h2WkDt3bmXLlk379++/77qc2VcFChTQH3/8ocTERLuwljTM52HP+0KFCqlv377q27evjh07pnLlymns2LGaNWvWfedLTEzUiRMn7N7njh49Kkl2n8T4+PioadOmmj17tl577TVt3rxZn3/++UPVeq9GjRopd+7cmj17tqpUqaIbN26keMX32LFjdlf4//zzTyUmJtpqTYv3bjy5GDOLp0rLli2VKVMmDR061OFqlWEYyd6+516tWrXSxYsX9eWXXzpMS1pmmzZtlJCQYPt47W537tx5qJ9sTfplrHvnTbpKcff2xMfH66uvvrLrV7FiReXMmVPffPON7ty5Y2ufPXu2w8fQbdq00V9//aVvvvnGoY6bN2/q+vXrKdZZsWJF5cmTR1OmTLG7jdevv/6qQ4cOqWnTpg/Y0rSXKVMmh+MdHh5ud6swSba7KWzcuNHWlpCQoKlTp9r1q1ixonLnzq0pU6YoPj7e1h4WFuZwfFK7zOQ8yvMorSV3XkZHR2vGjBkPvcx7X5+enp4qXLiw7TxLbp2SHMKZi4uLWrRooWXLlmnHjh0O60ma35l91aRJE0VFRWnevHm2tjt37uiLL76Qp6enatWq9cBl3O3GjRsOt6YqVKiQvLy8Un17vLvfowzD0JdffqnMmTOrXr16dv1ef/11HTx4UP3791emTJnUrl07p2pNiaurq9q3b6/58+crLCxMpUuXtvtH890mTZpk9/yLL76Q9M99paW0ee/Gk4srs3iqFCpUSJ9++qkGDhxouy2Vl5eXTp48qUWLFumtt95Sv3797ruMjh07aubMmerTp4/++9//6oUXXtD169e1evVqvfvuu3r55ZdVq1YtdevWTaGhodqzZ49efPFFZc6cWceOHVN4eLgmTJigV1991anay5Urp0yZMmnUqFGKjo6W1WpV3bp1Vb16deXIkUPBwcF6//33ZbFY9P333zu84bu5uSkkJETvvfee6tatqzZt2igiIkJhYWEqVKiQ3VWo119/XfPnz9fbb7+tdevWqUaNGkpISNDhw4c1f/582z1Fk5M5c2aNGjVKnTt3Vq1atdS+fXvbrbkCAgIcbtXzKLz00ksaNmyYOnfurOrVq2vfvn2aPXu2w5jCkiVLqmrVqho4cKDtdkVz5861C//SP9v46aefqlu3bqpbt67atm2rkydPasaMGQ+9zOQ8yvMopXG5D+vFF1+Um5ubmjVrpm7duik2NlbffPON8uTJo8jIyIdaZokSJVS7dm1VqFBBPj4+2rFjhxYsWGD7olO2bNlUs2ZNjR49Wrdv31b+/Pm1cuVKh08ppH+GnqxcuVK1atWy3X4uMjJS4eHh2rRpk7Jnz+7Uvnrrrbf09ddfq1OnTtq5c6cCAgK0YMEC25VOLy8vp7b16NGjqlevntq0aaMSJUrI1dVVixYt0rlz51IVNt3d3bV8+XIFBwerSpUq+vXXX/Xzzz/ro48+chie0rRpU+XMmVPh4eFq3Lhxmp4LHTt21MSJE7Vu3TqNGjUqxX4nT55U8+bN1ahRI23dulWzZs3S//3f/9k+5UiL9248wR7tzROA9OPMbZ4WLlxoPP/880bWrFmNrFmzGkFBQUb37t2NI0eO2PrUqlXLKFmyZLLz37hxw/j444+NwMBAI3PmzIafn5/x6quvGsePH7frN3XqVKNChQqGh4eH4eXlZZQuXdoYMGCA8ffff9v6FChQINnbDd176x/DMIxvvvnGKFiwoJEpUya7WwZt3rzZqFq1quHh4WHky5fPGDBggLFixYpkbys0ceJEo0CBAobVajUqV65sbN682ahQoYLRqFEju37x8fHGqFGjjJIlSxpWq9XIkSOHUaFCBWPo0KFGdHT0g3axMW/ePKN8+fKG1Wo1fHx8jNdee804e/asXZ+HuTVXSn2TbnUVHh7uMO3WrVtG3759jbx58xoeHh5GjRo1jK1btya7j48fP27Ur1/fsFqthq+vr/HRRx8Zq1atSnZffvXVV0ZgYKBhtVqNihUrGhs3bvxXy7z31lxJHtV59CAp3ZorpdtlLV261ChTpozh7u5uBAQEGKNGjbLd2u7uW5WltvZPP/3UqFy5spE9e3bDw8PDCAoKMkaMGGHEx8fb+pw9e9Z45ZVXjOzZsxve3t5G69atjb///tvh1lGGYRinTp0yOnbsaOTOnduwWq1GwYIFje7du9vdbi2lfZXcfj137pzRuXNnI1euXIabm5tRunRpY8aMGXZ9km7Nldwtt+6u8eLFi0b37t2NoKAgI2vWrIa3t7dRpUoVY/78+cnu67sFBwcbWbNmNY4fP268+OKLRpYsWQxfX19jyJAhDreoS5J0K6w5c+Y8cPn3Su7WXHcrWbKk4eLi4vD6N4z/3Zrr4MGDxquvvmp4eXkZOXLkMHr06GF3a78kqXnvxtPHYhjp/M0AAI+1xMRE5c6dWy1btkx2WAGAJ1/v3r01bdo0RUVFpflPdpcvX14+Pj5as2aNw7SQkBANHTpUFy5csBu/DjiDMbPAU+TWrVsOww9mzpypy5cvO/w0J4Cnw61btzRr1iy1atUqzYPsjh07tGfPHnXs2DFNlwvcjTGzwFNk27Zt6t27t1q3bq2cOXNq165dmjZtmkqVKmX7HXoAT4fz589r9erVWrBggS5duuTwk7v/xv79+7Vz506NHTtWefPmVdu2bdNs2cC9CLPAUyQgIED+/v6aOHGi7ctIHTt21MiRIx1+HALAk+3gwYN67bXXlCdPHk2cOFHlypVLs2UvWLBAw4YNU7FixfTDDz/Y/RogkNYYMwsAAADTYswsAAAATIswCwAAANN66sbMJiYm6u+//5aXl9cj+1lHAAAApJ5hGLp27Zry5ctn9xPRyXnqwuzff/8tf3//jC4DAAAAD3DmzBk988wz9+3z1IXZpJ8UPHPmjLJly5bB1QAAAOBeMTEx8vf3T9VPQT91YTZpaEG2bNkIswAAAI+x1AwJ5QtgAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEwrQ8NsaGioKlWqJC8vL+XJk0ctWrTQkSNH7jtPWFiYLBaL3cPd3f0RVQwAAIDHSYaG2Q0bNqh79+7atm2bVq1apdu3b+vFF1/U9evX7ztftmzZFBkZaXucOnXqEVUMAACAx4lrRq58+fLlds/DwsKUJ08e7dy5UzVr1kxxPovFIj8/v/QuDwAAAI+5x2rMbHR0tCTJx8fnvv1iY2NVoEAB+fv76+WXX9aBAwdS7BsXF6eYmBi7BwAAAJ4Mj02YTUxMVK9evVSjRg2VKlUqxX7FihXT9OnTtWTJEs2aNUuJiYmqXr26zp49m2z/0NBQeXt72x7+/v7ptQkAAAB4xCyGYRgZXYQkvfPOO/r111+1adMmPfPMM6me7/bt2ypevLjat2+v4cOHO0yPi4tTXFyc7XlMTIz8/f0VHR2tbNmypUntAADgCRfySkZXkDFCFmXIamNiYuTt7Z2qvJahY2aT9OjRQz/99JM2btzoVJCVpMyZM6t8+fL6888/k51utVpltVrTokwAAAA8ZjJ0mIFhGOrRo4cWLVqktWvXKjAw0OllJCQkaN++fcqbN286VAgAAIDHWYZeme3evbvmzJmjJUuWyMvLS1FRUZIkb29veXh4SJI6duyo/PnzKzQ0VJI0bNgwVa1aVYULF9bVq1c1ZswYnTp1Sl27ds2w7QAAAEDGyNAwO3nyZElS7dq17dpnzJihTp06SZJOnz4tF5f/XUC+cuWK3nzzTUVFRSlHjhyqUKGCtmzZohIlSjyqsgEAAPCYeGy+APaoODOgGAAAQBJfAHvEnMlrj82tuQAAAABnEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpZWiYDQ0NVaVKleTl5aU8efKoRYsWOnLkyAPnCw8PV1BQkNzd3VW6dGn98ssvj6BaAAAAPG4yNMxu2LBB3bt317Zt27Rq1Srdvn1bL774oq5fv57iPFu2bFH79u3VpUsX7d69Wy1atFCLFi20f//+R1g5AAAAHgcWwzCMjC4iyYULF5QnTx5t2LBBNWvWTLZP27Ztdf36df3000+2tqpVq6pcuXKaMmXKA9cRExMjb29vRUdHK1u2bGlWOwAAeIKFvJLRFWSMkEUZslpn8tpjNWY2OjpakuTj45Nin61bt6p+/fp2bQ0bNtTWrVuT7R8XF6eYmBi7BwAAAJ4Mj02YTUxMVK9evVSjRg2VKlUqxX5RUVHy9fW1a/P19VVUVFSy/UNDQ+Xt7W17+Pv7p2ndAAAAyDiPTZjt3r279u/fr7lz56bpcgcOHKjo6Gjb48yZM2m6fAAAAGQc14wuQJJ69Oihn376SRs3btQzzzxz375+fn46d+6cXdu5c+fk5+eXbH+r1Sqr1ZpmtQIAAODxkaFXZg3DUI8ePbRo0SKtXbtWgYGBD5ynWrVqWrNmjV3bqlWrVK1atfQqEwAAAI+pDL0y2717d82ZM0dLliyRl5eXbdyrt7e3PDw8JEkdO3ZU/vz5FRoaKknq2bOnatWqpbFjx6pp06aaO3euduzYoalTp2bYdgAAACBjZOiV2cmTJys6Olq1a9dW3rx5bY958+bZ+pw+fVqRkZG259WrV9ecOXM0depUlS1bVgsWLNDixYvv+6UxAAAAPJky9Mpsam5xu379eoe21q1bq3Xr1ulQEQAAAMzksbmbAQAAAOAswiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAt14wuAHiihbyS0RVkjJBFGV0BAOApwZVZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKbl6uwMcXFx+v3333Xq1CnduHFDuXPnVvny5RUYGJge9QEAAAApSnWY3bx5syZMmKBly5bp9u3b8vb2loeHhy5fvqy4uDgVLFhQb731lt5++215eXmlZ80AAACApFQOM2jevLnatm2rgIAArVy5UteuXdOlS5d09uxZ3bhxQ8eOHdOgQYO0Zs0aFS1aVKtWrUrvugEAAIDUXZlt2rSpFi5cqMyZMyc7vWDBgipYsKCCg4N18OBBRUZGpmmRAAAAQHJSFWa7deuW6gWWKFFCJUqUeOiCAAAAgNRy+gtgd9u/f782bNighIQE1ahRQxUqVEirugAAAIAHeuhbc02aNEn16tXThg0btG7dOtWtW1cjRoxIy9oAAACA+0r1ldkzZ87I39/f9vzLL7/UgQMHlCtXLknS1q1b1bx5c3388cdpXyUAAACQjFRfma1fv74mTJggwzAkSTlz5tTy5csVFxena9euafXq1cqdO3e6FQoAAADcK9Vhdvv27Tpy5IiqVKmiPXv2aOrUqRo/frw8PDyUPXt2zZs3T99991161goAAADYSfUwg2zZsumrr77Sli1b1KlTJ9WtW1e//fabEhISlJCQoOzZs6djmQAAAIAjp78AVr16de3YsUM5cuRQ+fLltXHjRoIsAAAAMkSqr8zeuXNHU6dO1aFDh1S2bFl99NFHatu2rd5++22FhYXpyy+/lK+vb3rWCgAAANhJ9ZXZLl266Msvv1TWrFk1Y8YM9e7dW0WLFtXatWvVqFEjVatWTZMnT3Zq5Rs3blSzZs2UL18+WSwWLV68+L79169fL4vF4vCIiopyar0AAAB4MqQ6zC5ZskQLFy7UyJEjtWrVKv3888+2aV26dNG2bdv022+/ObXy69evq2zZspo0aZJT8x05ckSRkZG2R548eZyaHwAAAE+GVA8z8PX11cqVK1WoUCGtXbtWOXPmtJueJ08ezZkzx6mVN27cWI0bN3ZqnqR1MU4XAAAAqb4y++WXX2rEiBHy8PDQ22+/rc8//zwdy7q/cuXKKW/evGrQoIE2b958375xcXGKiYmxewAAAODJkOow26BBA507d05RUVE6e/asqlevnp51JStv3ryaMmWKFi5cqIULF8rf31+1a9fWrl27UpwnNDRU3t7etsfdv2IGAAAAc0v1MANJslgsGforX8WKFVOxYsVsz6tXr67jx49r/Pjx+v7775OdZ+DAgerTp4/teUxMDIEWAADgCZGqK7ONGjXStm3bHtjv2rVrGjVqlNNf6Po3KleurD///DPF6VarVdmyZbN7AAAA4MmQqiuzrVu3VqtWreTt7a1mzZqpYsWKypcvn9zd3XXlyhUdPHhQmzZt0i+//KKmTZtqzJgx6V23zZ49e5Q3b95Htj4AAAA8PlIVZrt06aIOHTooPDxc8+bN09SpUxUdHS3pn6EHJUqUUMOGDbV9+3YVL1481SuPjY21u6p68uRJ7dmzRz4+Pnr22Wc1cOBA/fXXX5o5c6Yk6fPPP1dgYKBKliypW7du6dtvv9XatWu1cuVKZ7YZAAAAT4hUj5m1Wq3q0KGDOnToIEmKjo7WzZs3lTNnTmXOnPmhVr5jxw7VqVPH9jxpbGtwcLDCwsIUGRmp06dP26bHx8erb9+++uuvv5QlSxaVKVNGq1evtlsGAAAAnh4WwzCMjC7iUYqJiZG3t7eio6MZP4v0F/JKRleQMUIWZXQFAJC2eD9/pJzJa6m+NRcAAADwuCHMAgAAwLQIswAAADAtwiwAAABM66HC7NWrV/Xtt99q4MCBunz5siRp165d+uuvv9K0OAAAAOB+nPo5W0n6448/VL9+fXl7eysiIkJvvvmmfHx89OOPP+r06dO2e8ICAAAA6c3pK7N9+vRRp06ddOzYMbm7u9vamzRpoo0bN6ZpcQAAAMD9OB1mt2/frm7dujm058+fX1FRUWlSFAAAAJAaTodZq9WqmJgYh/ajR48qd+7caVIUAAAAkBpOh9nmzZtr2LBhun37tiTJYrHo9OnT+uCDD9SqVas0LxAAAABIidNhduzYsYqNjVWePHl08+ZN1apVS4ULF5aXl5dGjBiRHjUCAAAAyXL6bgbe3t5atWqVNm3apD/++EOxsbF67rnnVL9+/fSoDwAAAEiR02E2yfPPP6/nn38+LWsBAAAAnOJ0mJ04cWKy7RaLRe7u7ipcuLBq1qypTJky/eviAAAAgPtxOsyOHz9eFy5c0I0bN5QjRw5J0pUrV5QlSxZ5enrq/PnzKliwoNatWyd/f/80LxgAAABI4vQXwD777DNVqlRJx44d06VLl3Tp0iUdPXpUVapU0YQJE3T69Gn5+fmpd+/e6VEvAAAAYOP0ldlBgwZp4cKFKlSokK2tcOHC+s9//qNWrVrpxIkTGj16NLfpAgAAQLpz+spsZGSk7ty549B+584d2y+A5cuXT9euXfv31QEAAAD34XSYrVOnjrp166bdu3fb2nbv3q133nlHdevWlSTt27dPgYGBaVclAAAAkAynw+y0adPk4+OjChUqyGq1ymq1qmLFivLx8dG0adMkSZ6enho7dmyaFwsAAADczekxs35+flq1apUOHz6so0ePSpKKFSumYsWK2frUqVMn7SoEAAAAUvDQP5oQFBSkoKCgtKwFAAAAcMpDhdmzZ89q6dKlOn36tOLj4+2mjRs3Lk0KAwAAAB7E6TC7Zs0aNW/eXAULFtThw4dVqlQpRUREyDAMPffcc+lRIwAAAJAsp78ANnDgQPXr10/79u2Tu7u7Fi5cqDNnzqhWrVpq3bp1etQIAAAAJMvpMHvo0CF17NhRkuTq6qqbN2/K09NTw4YN06hRo9K8QAAAACAlTofZrFmz2sbJ5s2bV8ePH7dNu3jxYtpVBgAAADyA02Nmq1atqk2bNql48eJq0qSJ+vbtq3379unHH39U1apV06NGAAAAIFlOh9lx48YpNjZWkjR06FDFxsZq3rx5KlKkCHcyAAAAwCPldJgtWLCg7f+zZs2qKVOmpGlBAAAAQGo5PWa2YMGCunTpkkP71atX7YIuAAAAkN6cDrMRERFKSEhwaI+Li9Nff/2VJkUBAAAAqZHqYQZLly61/f+KFSvk7e1te56QkKA1a9YoICAgTYsDAAAA7ifVYbZFixaSJIvFouDgYLtpmTNnVkBAgMaOHZumxQEAAAD3k+owm5iYKEkKDAzU9u3blStXrnQrCgAAAEgNp+9mcPLkyfSoAwAAAHCa02FWktasWaM1a9bo/Pnztiu2SaZPn54mhQEAAAAP4nSYHTp0qIYNG6aKFSsqb968slgs6VEXAAAA8EBOh9kpU6YoLCxMr7/+enrUAwAAAKSa0/eZjY+PV/Xq1dOjFgAAAMApTofZrl27as6cOelRCwAAAOAUp4cZ3Lp1S1OnTtXq1atVpkwZZc6c2W76uHHj0qw4AAAA4H6cDrN//PGHypUrJ0nav3+/3TS+DAYAAIBHyekwu27duvSoAwAAAHCa02Nmk/z5559asWKFbt68KUkyDCPNigIAAABSw+kwe+nSJdWrV09FixZVkyZNFBkZKUnq0qWL+vbtm+YFAgAAAClxOsz27t1bmTNn1unTp5UlSxZbe9u2bbV8+fI0LQ4AAAC4H6fHzK5cuVIrVqzQM888Y9depEgRnTp1Ks0KAwAAAB7E6Suz169ft7sim+Ty5cuyWq1pUhQAAACQGk6H2RdeeEEzZ860PbdYLEpMTNTo0aNVp06dNC0OAAAAuB+nhxmMHj1a9erV044dOxQfH68BAwbowIEDunz5sjZv3pweNQIAAADJcvrKbKlSpXT06FE9//zzevnll3X9+nW1bNlSu3fvVqFChdKjRgAAACBZTl+ZlSRvb299/PHHaV0LAAAA4BSnr8zOmDFD4eHhDu3h4eH67rvv0qQoAAAAIDWcDrOhoaHKlSuXQ3uePHn02WefpUlRAAAAQGo4HWZPnz6twMBAh/YCBQro9OnTaVIUAAAAkBpOh9k8efLojz/+cGjfu3evcubMmSZFAQAAAKnhdJht37693n//fa1bt04JCQlKSEjQ2rVr1bNnT7Vr1y49agQAAACS5fTdDIYPH66IiAjVq1dPrq7/zJ6YmKiOHTsyZhYAAACPlFNh1jAMRUVFKSwsTJ9++qn27NkjDw8PlS5dWgUKFEivGgEAAIBkOR1mCxcurAMHDqhIkSIqUqRIetUFAAAAPJBTY2ZdXFxUpEgRXbp0Kb3qAQAAAFLN6S+AjRw5Uv3799f+/fvTox4AAAAg1Zz+AljHjh1148YNlS1bVm5ubvLw8LCbfvny5TQrDgAAALgfp8Ps559/ng5lAAAAAM5zOswGBwenRx0AAACA05weMytJx48f16BBg9S+fXudP39ekvTrr7/qwIEDaVocAAAAcD9Oh9kNGzaodOnS+v333/Xjjz8qNjZW0j8/ZztkyJA0LxAAAABIidNh9sMPP9Snn36qVatWyc3NzdZet25dbdu2LU2LAwAAAO7H6TC7b98+vfLKKw7tefLk0cWLF9OkKAAAACA1nA6z2bNnV2RkpEP77t27lT9//jQpCgAAAEgNp8Nsu3bt9MEHHygqKkoWi0WJiYnavHmz+vXrp44dO6ZHjQAAAECynA6zn332mYKCguTv76/Y2FiVKFFCNWvWVPXq1TVo0KD0qBEAAABIltP3mXVzc9M333yjwYMHa9++fYqNjVX58uVVpEiR9KgPAAAASFGqw2xiYqLGjBmjpUuXKj4+XvXq1dOQIUMcfs4WAAAAeFRSPcxgxIgR+uijj+Tp6an8+fNrwoQJ6t69e3rWBgAAANxXqsPszJkz9dVXX2nFihVavHixli1bptmzZysxMTE96wMAAABSlOowe/r0aTVp0sT2vH79+rJYLPr7778feuUbN25Us2bNlC9fPlksFi1evPiB86xfv17PPfecrFarChcurLCwsIdePwAAAMwt1WH2zp07cnd3t2vLnDmzbt++/dArv379usqWLatJkyalqv/JkyfVtGlT1alTR3v27FGvXr3UtWtXrVix4qFrAAAAgHml+gtghmGoU6dOslqttrZbt27p7bffVtasWW1tP/74Y6pX3rhxYzVu3DjV/adMmaLAwECNHTtWklS8eHFt2rRJ48ePV8OGDVO9HAAAADwZUh1mg4ODHdo6dOiQpsU8yNatW1W/fn27toYNG6pXr14pzhMXF6e4uDjb85iYmPQqDwAAAI9YqsPsjBkz0rOOVImKipKvr69dm6+vr2JiYnTz5s1kbxMWGhqqoUOHPqoSAQAA8Ag5/QtgZjNw4EBFR0fbHmfOnMnokgAAAJBGnP4FsIzk5+enc+fO2bWdO3dO2bJlS/HHG6xWq904XwAAADw5THVltlq1alqzZo1d26pVq1StWrUMqggAAAAZKUPDbGxsrPbs2aM9e/ZI+ufWW3v27NHp06cl/TNEoGPHjrb+b7/9tk6cOKEBAwbo8OHD+uqrrzR//nz17t07I8oHAABABsvQMLtjxw6VL19e5cuXlyT16dNH5cuX1+DBgyVJkZGRtmArSYGBgfr555+1atUqlS1bVmPHjtW3337LbbkAAACeUhk6ZrZ27doyDCPF6cn9ulft2rW1e/fudKwKAAAAZmGqMbMAAADA3QizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMK3HIsxOmjRJAQEBcnd3V5UqVfTf//43xb5hYWGyWCx2D3d390dYLQAAAB4XGR5m582bpz59+mjIkCHatWuXypYtq4YNG+r8+fMpzpMtWzZFRkbaHqdOnXqEFQMAAOBxkeFhdty4cXrzzTfVuXNnlShRQlOmTFGWLFk0ffr0FOexWCzy8/OzPXx9fVPsGxcXp5iYGLsHAAAAngwZGmbj4+O1c+dO1a9f39bm4uKi+vXra+vWrSnOFxsbqwIFCsjf318vv/yyDhw4kGLf0NBQeXt72x7+/v5pug0AAADIOBkaZi9evKiEhASHK6u+vr6KiopKdp5ixYpp+vTpWrJkiWbNmqXExERVr15dZ8+eTbb/wIEDFR0dbXucOXMmzbcDAAAAGcM1owtwVrVq1VStWjXb8+rVq6t48eL6+uuvNXz4cIf+VqtVVqv1UZYIAACARyRDr8zmypVLmTJl0rlz5+zaz507Jz8/v1QtI3PmzCpfvrz+/PPP9CgRAAAAj7EMDbNubm6qUKGC1qxZY2tLTEzUmjVr7K6+3k9CQoL27dunvHnzpleZAAAAeExl+DCDPn36KDg4WBUrVlTlypX1+eef6/r16+rcubMkqWPHjsqfP79CQ0MlScOGDVPVqlVVuHBhXb16VWPGjNGpU6fUtWvXjNwMAAAAZIAMD7Nt27bVhQsXNHjwYEVFRalcuXJavny57Uthp0+flovL/y4gX7lyRW+++aaioqKUI0cOVahQQVu2bFGJEiUyahMAAACQQSyGYRgZXcSjFBMTI29vb0VHRytbtmwZXQ6edCGvZHQFGSNkUUZXAABpi/fzR8qZvJbhP5oAAAAAPCzCLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMK3HIsxOmjRJAQEBcnd3V5UqVfTf//73vv3Dw8MVFBQkd3d3lS5dWr/88ssjqhQAAACPkwwPs/PmzVOfPn00ZMgQ7dq1S2XLllXDhg11/vz5ZPtv2bJF7du3V5cuXbR79261aNFCLVq00P79+x9x5QAAAMhoGR5mx40bpzfffFOdO3dWiRIlNGXKFGXJkkXTp09Ptv+ECRPUqFEj9e/fX8WLF9fw4cP13HPP6csvv3zElQMAACCjuWbkyuPj47Vz504NHDjQ1ubi4qL69etr69atyc6zdetW9enTx66tYcOGWrx4cbL94+LiFBcXZ3seHR0tSYqJifmX1QOpEHc7oyvIGLy+ADxpeD9/xKv9Z72GYTywb4aG2YsXLyohIUG+vr527b6+vjp8+HCy80RFRSXbPyoqKtn+oaGhGjp0qEO7v7//Q1YN4IFGemd0BQCAtJDB7+fXrl2Tt/f9a8jQMPsoDBw40O5KbmJioi5fvqycOXPKYrFkYGWPVkxMjPz9/XXmzBlly5Yto8tBOuN4P1043k8XjvfT5Wk93oZh6Nq1a8qXL98D+2ZomM2VK5cyZcqkc+fO2bWfO3dOfn5+yc7j5+fnVH+r1Sqr1WrXlj179ocv2uSyZcv2VL0YnnYc76cLx/vpwvF+ujyNx/tBV2STZOgXwNzc3FShQgWtWbPG1paYmKg1a9aoWrVqyc5TrVo1u/6StGrVqhT7AwAA4MmV4cMM+vTpo+DgYFWsWFGVK1fW559/ruvXr6tz586SpI4dOyp//vwKDQ2VJPXs2VO1atXS2LFj1bRpU82dO1c7duzQ1KlTM3IzAAAAkAEyPMy2bdtWFy5c0ODBgxUVFaVy5cpp+fLlti95nT59Wi4u/7uAXL16dc2ZM0eDBg3SRx99pCJFimjx4sUqVapURm2CKVitVg0ZMsRhyAWeTBzvpwvH++nC8X66cLwfzGKk5p4HAAAAwGMow380AQAAAHhYhFkAAACYFmEWAAAApkWYBQAAgGkRZjNYVFSU3nvvPRUsWFBWq1X+/v5q1qyZw710Q0NDlSlTJo0ZM8ZhGQkJCRo5cqSCgoLk4eEhHx8fValSRd9++62tT6dOndSiRQuHedevXy+LxaKrV68+sNZ7+yY9L1mypBISEuz6Zs+eXWFhYQ9c5pPITMc0aV3jx49X6dKl5e7urhw5cqhx48bavHmzXb+QkBCVK1fOYf6IiAhZLBbt2bNHnTp1ksViSfEREBCQqpqeFnfvr8yZM8vX11cNGjTQ9OnTlZiYaOsXEBCQ7P4cOXKkpP8dg6SHm5ubChcurE8//dTud83vPoYpLTPp0alTp0e5K0zr7mOYtN+HDRumO3fu2Po0bNhQmTJl0vbt2yVJcXFxKlmypN566y2H5Q0YMECBgYG6du2awsLCZLFYVLx4cYd+4eHhDq+ppP73Ptzd3R3qTTp3kixevNj2q5i8jnXf7bdYLAoJCXF43fn4+KhWrVr67bffkl1mt27dlClTJoWHhztMCwkJkcVi0dtvv23XvmfPHlksFkVERNjaFi1apKpVq8rb21teXl4qWbKkevXqZZue0nmQ9PfDmfMk6b0pMDBQAwYM0K1bt/7FXk0/hNkMFBERoQoVKmjt2rUaM2aM9u3bp+XLl6tOnTrq3r27Xd/p06drwIABmj59usNyhg4dqvHjx2v48OE6ePCg1q1bp7feeivVYebfOnHihGbOnPlI1vW4M9sxNQxD7dq107Bhw9SzZ08dOnRI69evl7+/v2rXrq3Fixc7tbwJEyYoMjLS9pCkGTNm2J4n/THH/zRq1EiRkZGKiIjQr7/+qjp16qhnz5566aWX7ALRsGHD7PZtZGSk3nvvPbtlrV69WpGRkTp27JiGDh2qESNGJHt+SdL27dtty1m4cKEk6ciRI7a2CRMmpN9GP2GSjuGxY8fUt29fhYSE2P6Revr0aW3ZskU9evSwHQur1aqZM2cqLCxMK1assC1n27ZtGj9+vMLCwuTl5SVJypo1q86fP6+tW7farXPatGl69tlnHWrJli2bw3ly6tQpuz7u7u4aNWqUrly5kuz28DqW3fZ//vnnDvu1X79+tr5Jr7uNGzcqX758eumllxx+qfTGjRuaO3duiu/50j/HZdq0aTp27FiKda1Zs0Zt27ZVq1at9N///lc7d+7UiBEjdPv2bbt+yZ0Hr7322n2n33ueJJ3XJ06c0Pjx4/X1119ryJAhqd6Hj5SBDNO4cWMjf/78RmxsrMO0K1eu2P5//fr1Rv78+Y34+HgjX758xubNm+36li1b1ggJCbnvuoKDg42XX37ZoX3dunWGJLv1peTevknP+/fvb/j7+xu3bt2y9fX29jZmzJjxwGU+acx2TOfOnWtIMpYuXeowrWXLlkbOnDlt2zJkyBCjbNmyDv1OnjxpSDJ2797tME2SsWjRogfW8bRK6RiuWbPGkGR88803hmEYRoECBYzx48enuJyUjkG9evWMd9991/Y8pWPozDkDe8kdwwYNGhhVq1Y1DMMwQkJCjHbt2hmHDh0yvL29jRs3btj6hYSEGPnz5zeuXLli3Lx50wgKCjJ69+5tmz5jxgzD29vb6NGjh9G1a1db+5kzZwyr1Wp8+OGHRoECBRz6P6jel156yQgKCjL69+9va1+0aJGRUiR42l/HKe3X5F53f/zxhyHJWLJkiV3fsLAwo2rVqsbVq1eNLFmyGKdPn7abnvTabNCggdG6dWtb++7duw1JxsmTJw3DMIyePXsatWvXfqh6UzvdMJI/r1u2bGmUL1/+vvNlFK7MZpDLly9r+fLl6t69u7JmzeowPXv27Lb/nzZtmtq3b6/MmTOrffv2mjZtml1fPz8/rV27VhcuXEjvspPVq1cv3blzR1988UWGrP9xYcZjOmfOHBUtWlTNmjVzmNa3b19dunRJq1atStca4Khu3boqW7asfvzxx4dexo4dO7Rz505VqVIlDStDanh4eCg+Pl6GYWjGjBnq0KGDgoKCVLhwYS1YsMDW7+OPP5afn5/ef/99DRo0SBaLRZ999pnD8t544w3Nnz9fN27ckPTPx8SNGjWy/biQszJlyqTPPvtMX3zxhc6ePftwGwkHN2/etH1K6ebmZjdt2rRp6tChg7y9vdW4ceMUh+GNHDlSCxcu1I4dO5Kd7ufnpwMHDmj//v1pWvuD7N+/X1u2bHHYrscFYTaD/PnnnzIMQ0FBQfftFxMTowULFqhDhw6SpA4dOmj+/PmKjY219Rk3bpwuXLggPz8/lSlTRm+//bZ+/fVXh2X99NNP8vT0tHs0btz4X29LlixZNGTIEIWGhio6OvpfL8+szHhMjx49mux4PEm29qNHj6Z6eUg7QUFBduPkPvjgA4djfe/YvOrVq8vT01Nubm6qVKmS2rRpo44dOz7iyp9ehmFo9erVWrFiherWravVq1frxo0batiwoaR/Xut3/8PV1dVVM2fOVHh4uL744gvNnDnTbtxikvLly6tgwYJasGCBDMNQWFiY3njjjWRriI6OTtV7wiuvvKJy5co9vh8bm0jS6y5r1qz6z3/+owoVKqhevXq26ceOHdO2bdvUtm1bSf+cBzNmzLAbz57kueeeU5s2bfTBBx8ku6733ntPlSpVUunSpRUQEKB27dpp+vTpiouLs+t373ng5+d33+nJnSdJf1/c3d1VunRpnT9/Xv3793+ofZTeCLMZJLmTODk//PCDChUqpLJly0qSypUrpwIFCmjevHm2PiVKlND+/fu1bds2vfHGGzp//ryaNWumrl272i2rTp062rNnj93j7i8U/RtdunRRzpw5NWrUqDRZnhmZ9Zimtm48WoZh2L6QI0n9+/d3ONYVK1a0m2fevHnas2eP9u7dq/nz52vJkiX68MMPH3XpT527/+g3btxYbdu2VUhIiKZPn662bdvK1fWfX45v3769Nm/erOPHj9vmLVGihFq1aqUGDRo4HM+7vfHGG5oxY4Y2bNig69evq0mTJsn28/LySvV7wqhRo/Tdd9/p0KFD/2LrMW/ePO3evVsLFy5U4cKFFRYWpsyZM9umT58+XQ0bNlSuXLkkSU2aNFF0dLTWrl2b7PI+/fRT/fbbb1q5cqXDtKxZs+rnn3/Wn3/+qUGDBsnT01N9+/ZV5cqVbVfuJcfzYMuWLXbLSc15kvT35ffff1dwcLA6d+6sVq1aPfR+Sk+uGV3A06pIkSKyWCw6fPjwfftNmzZNBw4csL0ZSlJiYqKmT5+uLl262NpcXFxUqVIlVapUSb169dKsWbP0+uuv6+OPP1ZgYKCkf14EhQsXtlt+Wn3E5OrqqhEjRqhTp07q0aNHmizTbMx4TIsWLZriH7Kk9qJFi0r65wsDyV15T/pSmre3d6rXiwc7dOiQ7ThLUq5cuRyO9b38/f1tfYoXL67jx4/rk08+UUhISLJX/JA26tSpo8mTJ8vNzU358uWTq6urLl++rEWLFun27duaPHmyrW9CQoKmT5+uESNG2NpcXV3t3g+S89prr2nAgAEKCQnR66+/nmJ/FxeXB54nSWrWrKmGDRtq4MCB3L3iX/D391eRIkVUpEgR3blzR6+88or2798vq9WqhIQEfffdd4qKirI7Zknnwd1XcJMUKlRIb775pj788EOHIWh39ylUqJC6du2qjz/+WEWLFtW8efPUuXNnSQ8+D1Jzntz992X69OkqW7aspk2bZvd36nHBldkM4uPjo4YNG2rSpEm6fv26w/SrV69q37592rFjh9avX2/3r6f169dr69at9w1NJUqUkKRkl51eWrdurZIlS2ro0KGPbJ2PEzMe03bt2unYsWNatmyZw7SxY8cqZ86catCggSSpWLFiOnv2rMO3dHft2iV3d/dkv1mNh7N27Vrt27fvX18FyZQpk+7cuaP4+Pg0qgzJSfqj/+yzz9oCy+zZs/XMM89o7969dq/1sWPHKiwszOF2hg/i4+Oj5s2ba8OGDSkOMXgYI0eO1LJlyxzuloCH8+qrr8rV1VVfffWVJOmXX37RtWvXtHv3brvz4IcfftCPP/6Y4h1qBg8erKNHj2ru3LkPXGdAQICyZMmSrn/vXVxc9NFHH2nQoEG6efNmuq3nYXFlNgNNmjRJNWrUUOXKlTVs2DCVKVNGd+7c0apVqzR58mQ1bNhQlStXVs2aNR3mrVSpkqZNm6YxY8bo1VdfVY0aNVS9enX5+fnp5MmTGjhwoIoWLfrA8ZtpbeTIkbbxYU8jsx3Tdu3aKTw8XMHBwRozZozq1aunmJgYTZo0SUuXLlV4eLjty2wNGzZUsWLF1L59e3366afy8/PTrl27NGjQIPXs2VOZMmVKs7qeJnFxcYqKilJCQoLOnTun5cuXKzQ0VC+99JLdeNdr164pKirKbt4sWbIoW7ZstueXLl1SVFSU7ty5o3379mnChAmqU6eOXR88GtOmTdOrr76qUqVK2bX7+/tr4MCBWr58uZo2berUMsPCwvTVV18pZ86cKfYxDMPhPJGkPHnyyMXF8fpV6dKl9dprr2nixIlO1YLkWSwWvf/++woJCVG3bt00bdo0NW3a1DasLEmJEiXUu3dvzZ492+G2jZLk6+urPn36ONyHPCQkRDdu3FCTJk1UoEABXb16VRMnTtTt27dtFx5Sw9nzRPrnglX//v01adIku1uTPQ64MpuBChYsqF27dqlOnTrq27evSpUqpQYNGmjNmjWaMGGCZs2aleKVmVatWmnmzJm6ffu2GjZsqGXLlqlZs2YqWrSogoODFRQUpJUrVz7wo6u0VrduXdWtW9fu/phPE7MdU4vFovnz5+ujjz7S+PHjVaxYMb3wwgs6deqU1q9fb/ejDK6urlq5cqWeffZZtW/fXqVKldKQIUPUs2dPDR8+PM1qetosX75cefPmVUBAgBo1aqR169Zp4sSJWrJkid0/EAYPHqy8efPaPQYMGGC3rPr169uW9dZbb6lJkyZ2Y7HxaOzcuVN79+5N9rXu7e2tevXqpfjx8f14eHjcN8hK/3zB9N7zJG/evDp//nyK8wwbNszuRzrw7wQHB+v27dv64osv9PPPPyd7Hri4uOiVV16573nQr18/eXp62rXVqlVLJ06cUMeOHRUUFKTGjRsrKipKK1euVLFixVJd48OcJ66ururRo4dGjx79SD/1TQ2Lwbc/AAAAYFJcmQUAAIBpEWZh07hxY4f7ziU9kruRNx5/HFMAwJOOYQaw+euvv1L8lqKPj498fHwecUX4tzimAIAnHWEWAAAApsUwAwAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQB4Qqxfv14WiyXF33sHgCcRYRbAE81isdz3ERISktElPpTatWurV69edm3Vq1dXZGSkvL290229T+r+BGBeafcj7wDwGIqMjLT9/7x58zR48GAdOXLE1nb3b58bhqGEhAS5uprzrdHNzU1+fn7pug5n9icAPApcmQXwRPPz87M9vL29ZbFYbM8PHz4sLy8v/frrr6pQoYKsVqs2bdqk48eP6+WXX5avr688PT1VqVIlrV692m65AQEB+uyzz/TGG2/Iy8tLzz77rKZOnWqbHh8frx49eihv3rxyd3dXgQIFFBoaaps+btw4lS5dWlmzZpW/v7/effddxcbG2q1j8+bNql27trJkyaIcOXKoYcOGunLlijp16qQNGzZowoQJtiuiERERyQ4zWLhwoUqWLCmr1aqAgACNHTvWqe1I7f708vJS0aJFtXz5crv+ixcvVtasWXXt2jVFRETIYrFo7ty5ql69utzd3VWqVClt2LDBbp79+/fbfr3O19dXr7/+ui5evHj/Aw3gqUWYBfDU+/DDDzVy5EgdOnRIZcqUUWxsrJo0aaI1a9Zo9+7datSokZo1a6bTp0/bzTd27FhVrFhRu3fv1rvvvqt33nnHdpVy4sSJWrp0qebPn68jR45o9uzZCggIsM3r4uKiiRMn6sCBA/ruu++0du1aDRgwwDZ9z549qlevnkqUKKGtW7dq06ZNatasmRISEjRhwgRVq1ZNb775piIjIxUZGSl/f3+H7dq5c6fatGmjdu3aad++fQoJCdEnn3yisLCwVG9HamXNmlXt2rXTjBkz7NpnzJihV199VV5eXra2/v37q2/fvtq9e7eqVaumZs2a6dKlS5Kkq1evqm7duipfvrx27Nih5cuX69y5c2rTpo1T9QB4ihgA8JSYMWOG4e3tbXu+bt06Q5KxePHiB85bsmRJ44svvrA9L1CggNGhQwfb88TERCNPnjzG5MmTDcMwjPfee8+oW7eukZiYmKrawsPDjZw5c9qet2/f3qhRo0aK/WvVqmX07NnTri1pe65cuWIYhmH83//9n9GgQQO7Pv379zdKlCiR6u24n3v35++//25kypTJ+Pvvvw3DMIxz584Zrq6uxvr16w3DMIyTJ08akoyRI0fa5rl9+7bxzDPPGKNGjTIMwzCGDx9uvPjii3brOXPmjCHJOHLkyANrAvD04cosgKdexYoV7Z7HxsaqX79+Kl68uLJnzy5PT08dOnTI4cpsmTJlbP+f9HH7+fPnJUmdOnXSnj17VKxYMb3//vtauXKl3byrV69WvXr1lD9/fnl5een111/XpUuXdOPGDUn/uzL7bxw6dEg1atSwa6tRo4aOHTumhISEVG2HMypXrqySJUvqu+++kyTNmjVLBQoUUM2aNe36VatWzfb/rq6uqlixog4dOiRJ2rt3r9atWydPT0/bIygoSJJ0/Phxp2sC8OQjzAJ46mXNmtXueb9+/bRo0SJ99tln+u2337Rnzx6VLl1a8fHxdv0yZ85s99xisSgxMVGS9Nxzz+nkyZMaPny4bt68qTZt2ujVV1+VJEVEROill15SmTJltHDhQu3cuVOTJk2SJNs6PDw80mVbk3O/7XBW165dbcMYZsyYoc6dO8tisaR6/tjYWDVr1kx79uyxexw7dswhFAOARJgFAAebN29Wp06d9Morr6h06dLy8/NTRESE08vJli2b2rZtq2+++Ubz5s3TwoULdfnyZe3cuVOJiYkaO3asqlatqqJFi+rvv/+2m7dMmTJas2ZNist2c3Ozu7qanOLFi2vz5s0O21a0aFFlypTJ6e1JjQ4dOujUqVOaOHGiDh48qODgYIc+27Zts/3/nTt3tHPnThUvXlzSP/8IOHDggAICAlS4cGG7x73/6AAAiTALAA6KFCmiH3/8UXv27NHevXv1f//3f05fqRw3bpx++OEHHT58WEePHlV4eLj8/PyUPXt2FS5cWLdv39YXX3yhEydO6Pvvv9eUKVPs5h84cKC2b9+ud999V3/88YcOHz6syZMn277VHxAQoN9//10RERG6ePFisvX17dtXa9as0fDhw3X06FF99913+vLLL9WvX7+H3zkPkCNHDrVs2VL9+/fXiy++qGeeecahz6RJk7Ro0SIdPnxY3bt315UrV/TGG29Ikrp3767Lly+rffv22r59u44fP64VK1aoc+fODwzvAJ5OhFkAuMe4ceOUI0cOVa9eXc2aNVPDhg313HPPObUMLy8vjR49WhUrVlSlSpUUERGhX375RS4uLipbtqzGjRunUaNGqVSpUpo9e7bdbbskqWjRolq5cqX27t2rypUrq1q1alqyZIntHrj9+vVTpkyZVKJECeXOndthPK/0z1XO+fPna+7cuSpVqpQGDx6sYcOGqVOnTg+9b1KjS5cuio+PtwXUe40cOVIjR45U2bJltWnTJi1dulS5cuWSJOXLl0+bN29WQkKCXnzxRZUuXVq9evVS9uzZ5eLCnywAjiyGYRgZXQQA4Mnx/fffq3fv3vr777/l5uZma4+IiFBgYKB2796tcuXKZVyBAJ4o5vyZGwDAY+fGjRuKjIzUyJEj1a1bN7sgCwDphc9sAABpYvTo0QoKCpKfn58GDhyY0eUAeEowzAAAAACmxZVZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWv8PpXtPry6P5VQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze transaction amount distribution\n",
        "print(\"\\nTransaction Amount Distribution:\")\n",
        "print(df['amount'].describe())  # Get summary statistics\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(df['amount'], bins=50, edgecolor='black')  # Create histogram with 50 bins\n",
        "plt.title(\"Distribution of Transaction Amounts\")\n",
        "plt.xlabel(\"Transaction Amount\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)  # Add grid lines for better readability\n",
        "plt.show()\n",
        "\n",
        "# Analyze fraudulent vs. legitimate transaction amounts\n",
        "fraudulent_amounts = df[df['isFraud'] == 1]['amount']\n",
        "legitimate_amounts = df[df['isFraud'] == 0]['amount']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot([fraudulent_amounts, legitimate_amounts], labels=['Fraudulent', 'Legitimate'], notch=True)\n",
        "plt.title(\"Distribution of Transaction Amounts (Fraudulent vs. Legitimate)\")\n",
        "plt.xlabel(\"Transaction Category\")\n",
        "plt.ylabel(\"Transaction Amount\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hjf4YAnke69N",
        "outputId": "d8be8a31-7398-4044-b0de-b6296d87afc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Transaction Amount Distribution:\n",
            "count    1.512100e+04\n",
            "mean     1.141586e+05\n",
            "std      2.827088e+05\n",
            "min      2.390000e+00\n",
            "25%      4.687140e+03\n",
            "50%      1.312560e+04\n",
            "75%      1.246170e+05\n",
            "max      1.000000e+07\n",
            "Name: amount, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze balance distributions (old/new for origin and destination)\n",
        "balance_features = ['oldbalanceOrg', 'newbalanceOrg', 'oldbalanceDest', 'newbalanceDest']\n",
        "\n",
        "\n",
        "# Analyze impact of balance on fraud (average balance before and after)\n",
        "fraudulent = df[df['isFraud'] == 1]\n",
        "legitimate = df[df['isFraud'] == 0]\n",
        "\n",
        "avg_balance_before_fraud = fraudulent[['oldbalanceOrg', 'oldbalanceDest']].mean(axis=1)\n",
        "avg_balance_after_fraud = fraudulent[['newbalanceOrig', 'newbalanceDest']].mean(axis=1)\n",
        "avg_balance_before_legitimate = legitimate[['oldbalanceOrg', 'oldbalanceDest']].mean(axis=1)\n",
        "avg_balance_after_legitimate = legitimate[['newbalanceOrig', 'newbalanceDest']].mean(axis=1)\n",
        "\n",
        "# Plot average balance comparison (before and after) for fraud\n",
        "fraud_balance_labels = ['Before Fraud', 'After Fraud']\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(fraud_balance_labels, [avg_balance_before_fraud.mean(), avg_balance_after_fraud.mean()], color=['skyblue', 'coral'])\n",
        "plt.title(\"Average Balance (Fraudulent Transactions)\")\n",
        "plt.xlabel(\"Transaction Stage\")\n",
        "plt.ylabel(\"Average Balance\")\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels for readability\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Plot average balance comparison (before and after) for legitimate\n",
        "legitimate_balance_labels = ['Before', 'After']\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(legitimate_balance_labels, [avg_balance_before_legitimate.mean(), avg_balance_after_legitimate.mean()], color=['lightgreen', 'lightblue'])\n",
        "plt.title(\"Average Balance (Legitimate Transactions)\")\n",
        "plt.xlabel(\"Transaction Stage\")\n",
        "plt.ylabel(\"Average Balance\")\n",
        "plt.xticks(rotation=0)  # Rotate x-axis labels for readability\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WAgPHRmfnabt",
        "outputId": "4630d129-130a-4a7e-c54d-2dbfb8fb176d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAIjCAYAAADFk0cVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbYUlEQVR4nO3dZ3QVVf/28eukk0onQUINUqRJaAGkGQnSEQS8EQICKkWBiAi3CgQLitIUBRQF1ChFEBWkxCAi5RYMVaRJEQVChxBK6jwveDJ/DgmQgSQnku9nrazF7Nkz8zslk4s5e/axGYZhCAAAAECWOTm6AAAAAODfhhANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDSDfmjNnjmw2mw4fPuzoUrLFwIED9cgjjzi6DMvGjh0rm812R9vea6/hvexuXufsNHLkSNWvX9/RZeAeQIgG8pAPP/xQNpuNE3wmypYtK5vNZv54eHioYsWKevHFF3X27FlHl+dwhw4d0qxZs/Tf//7XbDt8+LDdc3b9T4MGDRxY7b/L5cuXNXbsWK1Zs+a2fW98n97sZ86cOTletyNYea4cZejQodq+fbu+++47R5eCfzkXRxcA4P9ERUWpbNmy2rRpk/78808FBQU5uqQ8pVatWnrhhRckSVevXlVsbKymTJmin3/+WZs2bXJwdY41depUlStXTs2bN8+w7oknnlDr1q3t2ooVK5Zbpf3rXb58WZGRkZKkZs2a3bLvlClTlJCQYC7/8MMP+uqrrzR58mQVLVrUbG/YsGGO1Opot3quXnnlFY0cOdIBVdnz9/dXhw4d9O6776p9+/aOLgf/YoRoII84dOiQNmzYoMWLF+uZZ55RVFSUxowZk6s1pKWlKSkpSR4eHrl63Ky677779OSTT5rL/fr1k7e3t959913t379fFStWdGB1jpOcnKyoqCg9++yzma6vXbu23fN2K3n9PZDXdezY0W45Li5OX331lTp27KiyZcvedLtLly7Jy8srZ4tzMBcXF7m45I3Y0bVrVz3++OM6ePCgypcv7+hy8C/FcA4gj4iKilKhQoXUpk0bdenSRVFRUea65ORkFS5cWH369MmwXXx8vDw8PDR8+HCzLTExUWPGjFFQUJDc3d0VGBioESNGKDEx0W5bm82mwYMHKyoqSg888IDc3d21YsUKSdK7776rhg0bqkiRIipQoICCg4P19ddfZzj+lStX9Pzzz6to0aLy8fFR+/btdfToUdlsNo0dO9au79GjR/XUU0+pRIkScnd31wMPPKBPP/30bp42+fv7S5LdH+cdO3aod+/eKl++vDw8POTv76+nnnpKZ86cue3+vv32W7Vp00YlS5aUu7u7KlSooNdee02pqal2/Zo1a6Zq1arpjz/+UPPmzeXp6an77rtPEyZMyLDPq1evauzYsbr//vvl4eGhgIAAPfbYYzpw4IDZJy0tTVOmTNEDDzwgDw8PlShRQs8884zOnTt325rXrVun06dPKzQ09LZ9b3S374H0ISOZDU/I7D2wbt061a1bVx4eHqpQoYJmzpyZYTur+8zM8uXL9dBDD8nLy0s+Pj5q06aNdu3aZdend+/e8vb21tGjR9WxY0d5e3urWLFiGj58uPl6Hz582LxqHxkZaQ7HyEoNN5N+3AMHDqh169by8fFRjx49JEm//PKLHn/8cZUuXdr83R02bJiuXLliufZ08+bNU3BwsHx8fOTr66vq1atr6tSp5vqzZ89q+PDhql69ury9veXr66tHH31U27dvz1D7rd7Lt3uuMhsTnZKSotdee00VKlSQu7u7ypYtq//+978ZzlVly5ZV27ZttW7dOtWrV08eHh4qX768PvvsM7t+ycnJioyMVMWKFeXh4aEiRYqocePGio6OtuuX/rvy7bff3vK1Am4lb/yXEICioqL02GOPyc3NTU888YSmT5+uzZs3q27dunJ1dVWnTp20ePFizZw5U25ubuZ2S5YsUWJiorp37y7pWhhr37691q1bp6efflpVqlTRzp07NXnyZO3bt09LliyxO+7q1au1YMECDR48WEWLFjWvlk2dOlXt27dXjx49lJSUpHnz5unxxx/X0qVL1aZNG3P73r17a8GCBerZs6caNGign3/+2W59uhMnTqhBgwZmaCtWrJiWL1+uvn37Kj4+XkOHDr3tc5ScnKzTp09LuvbHfOvWrZo0aZKaNGmicuXKmf2io6N18OBB9enTR/7+/tq1a5c++ugj7dq1S//73/9ueXPTnDlz5O3trYiICHl7e2v16tUaPXq04uPj9c4779j1PXfunFq1aqXHHntMXbt21ddff62XXnpJ1atX16OPPipJSk1NVdu2bRUTE6Pu3btryJAhunjxoqKjo/X777+rQoUKkqRnnnlGc+bMUZ8+ffT888/r0KFDmjZtmrZu3ar169fL1dX1pjVv2LBBNptNDz74YKbrL1++bD5v6fz8/Mx93u17IKt27typli1bqlixYho7dqxSUlI0ZswYlShRwvK+buXzzz9XeHi4wsLC9Pbbb+vy5cuaPn26GjdurK1bt9pdEU5NTVVYWJjq16+vd999Vz/++KMmTpyoChUqaMCAASpWrJimT5+uAQMGqFOnTnrsscckSTVq1LirGlNSUhQWFqbGjRvr3XfflaenpyRp4cKFunz5sgYMGKAiRYpo06ZNev/99/XPP/9o4cKFdvu4Xe3Std+FJ554Qg8//LDefvttSdLu3bu1fv16DRkyRJJ08OBBLVmyRI8//rjKlSunEydOaObMmWratKn++OMPlSxZ0jzerd7LoaGhlp+rfv36ae7cuerSpYteeOEF/frrrxo/frx2796tb775xq7vn3/+qS5duqhv374KDw/Xp59+qt69eys4OFgPPPCApGtBffz48erXr5/q1aun+Ph4/fbbb9qyZYvdTbd+fn6qUKGC1q9fr2HDht3x64h8zgDgcL/99pshyYiOjjYMwzDS0tKMUqVKGUOGDDH7rFy50pBkfP/993bbtm7d2ihfvry5/PnnnxtOTk7GL7/8YtdvxowZhiRj/fr1Zpskw8nJydi1a1eGmi5fvmy3nJSUZFSrVs1o0aKF2RYbG2tIMoYOHWrXt3fv3oYkY8yYMWZb3759jYCAAOP06dN2fbt37274+fllON6NypQpY0jK8NOoUaMM+8xsX1999ZUhyVi7dq3ZNnv2bEOScejQoVtu+8wzzxienp7G1atXzbamTZsakozPPvvMbEtMTDT8/f2Nzp07m22ffvqpIcmYNGlShv2mpaUZhmEYv/zyiyHJiIqKslu/YsWKTNtv9OSTTxpFihTJ0H7o0KFMnzNJxk8//WQYxt2/B9KPMXv27Azb3/ge6Nixo+Hh4WH89ddfZtsff/xhODs7G9f/ObKyzxtfw4sXLxoFCxY0+vfvb7ddXFyc4efnZ9ceHh5uSDLGjRtn1/fBBx80goODzeVTp05lOG5WvfPOOxneY+nHHTlyZIb+mb3/xo8fb9hsNrvnLau1DxkyxPD19TVSUlJuWuPVq1eN1NRUu7ZDhw4Z7u7udvvPynv5Vs/VmDFj7F7nbdu2GZKMfv362fUbPny4IclYvXq12Zb++3/97+/JkycNd3d344UXXjDbatasabRp0+amj/V6LVu2NKpUqZKlvkBmGM4B5AFRUVEqUaKEeVOYzWZTt27dNG/ePPOj2RYtWqho0aKaP3++ud25c+cUHR2tbt26mW0LFy5UlSpVVLlyZZ0+fdr8adGihSTpp59+sjt206ZNVbVq1Qw1FShQwO44Fy5c0EMPPaQtW7aY7ekf+w8cONBu2+eee85u2TAMLVq0SO3atZNhGHZ1hYWF6cKFC3b7vZn69esrOjpa0dHRWrp0qd544w3t2rVL7du3t/u4+/rar169qtOnT5uzUdzuONdve/HiRZ0+fVoPPfSQLl++rD179tj19fb2thtr7Obmpnr16ungwYNm26JFi1S0aNEMz4kk84r4woUL5efnp0ceecTuuQkODpa3t3eG1+xGZ86cUaFChW66/umnnzaft/SfmjVrmuvv5j2QVampqVq5cqU6duyo0qVLm+1VqlRRWFiY5f3dTHR0tM6fP68nnnjC7rl0dnZW/fr1M30ubxxL/tBDD9m9hjkl/Wrx9a5/zi9duqTTp0+rYcOGMgxDW7duzdD/drUXLFhQly5dyjCc4Xru7u5ycroWB1JTU3XmzBl5e3urUqVKdq91Vt7LVvzwww+SpIiICLv29JuHly1bZtdetWpVPfTQQ+ZysWLFVKlSpQyPd9euXdq/f/9tj1+oUKEMn9AAVjCcA3Cw1NRUzZs3T82bN9ehQ4fM9vr162vixImKiYlRy5Yt5eLios6dO+vLL79UYmKi3N3dtXjxYiUnJ9uF6P3792v37t03nX3h5MmTdsvXD4O43tKlS/X6669r27ZtduMTr/9j+ddff8nJySnDPm6cVeTUqVM6f/68PvroI3300UdZqiszRYsWtRv326ZNG1WqVEldunTRrFmzzD/uZ8+eVWRkpObNm5dhvxcuXLjlMXbt2qVXXnlFq1evVnx8/C23LVWqVIbwUKhQIe3YscNcPnDggCpVqnTLG6r279+vCxcuqHjx4pmuz8pzYxjGTddVrFjxluOl7+Y9kFWnTp3SlStXMr35s1KlSmagulvp4Sn9P4038vX1tVv28PDI8LtSqFChLI1FvxsuLi4qVapUhvYjR45o9OjR+u677zLUcOP7Lyu1Dxw4UAsWLNCjjz6q++67Ty1btlTXrl3VqlUrs09aWpqmTp2qDz/8UIcOHbIbU12kSBHz31l5L1uRfv648Xzh7++vggUL6q+//rJrv/4/X+lufLzjxo1Thw4ddP/996tatWpq1aqVevbsmemQEsMw8sS81fj3IkQDDrZ69WodP35c8+bN07x58zKsj4qKUsuWLSVJ3bt318yZM7V8+XJ17NhRCxYsUOXKle2uKqalpal69eqaNGlSpscLDAy0W77+yle6X375Re3bt1eTJk304YcfKiAgQK6urpo9e7a+/PJLy48xLS1NkvTkk08qPDw80z53Osb04YcfliStXbvWDNFdu3bVhg0b9OKLL6pWrVry9vZWWlqaWrVqZdaSmfPnz6tp06by9fXVuHHjVKFCBXl4eGjLli166aWXMmzr7Oyc6X5uFWgzk5aWpuLFi9vdTHq9201HV6RIkbsKfXfzHrhZCLnx5jYr7maf6a/R559/bt50er0bA+DNXsOcdv3V33Spqal65JFHdPbsWb300kuqXLmyvLy8dPToUfXu3TvL77/rFS9eXNu2bdPKlSu1fPlyLV++XLNnz1avXr00d+5cSdKbb76pV199VU899ZRee+01FS5cWE5OTho6dOgtf1+yS1aDbFZ+35o0aaIDBw7o22+/1apVqzRr1ixNnjxZM2bMUL9+/ey2O3funN20g4BVhGjAwaKiolS8eHF98MEHGdYtXrxY33zzjWbMmKECBQqoSZMmCggI0Pz589W4cWOtXr1aL7/8st02FSpU0Pbt2/Xwww/f8VWWRYsWycPDQytXrpS7u7vZPnv2bLt+ZcqUUVpamg4dOmR3hfHPP/+061esWDH5+PgoNTX1jmaQuJWUlBRJMufmPXfunGJiYhQZGanRo0eb/bLy8e6aNWt05swZLV68WE2aNDHbr/+EwKoKFSro119/VXJy8k1vDqxQoYJ+/PFHNWrUKNNAezuVK1dWVFSULly4ID8/vzuu9XpZfQ+kDyM5f/68XfuNVxGLFSumAgUKZPo67N279472mZn0GzWLFy+ebe+13LpauXPnTu3bt09z585Vr169zPZbDcXICjc3N7Vr107t2rVTWlqaBg4cqJkzZ+rVV19VUFCQvv76azVv3lyffPKJ3Xbnz5+3C5lZeS9bea7Szx/79+9XlSpVzPYTJ07o/PnzKlOmjMVHek36TEZ9+vRRQkKCmjRporFjx2YI0YcOHbK7AAFYxZhowIGuXLmixYsXq23bturSpUuGn8GDB+vixYvmN2s5OTmpS5cu+v777/X5558rJSXFbiiHdO0q7NGjR/Xxxx9nerxLly7dti5nZ2fZbDa7K3+HDx/OMLNH+ljWDz/80K79/fffz7C/zp07a9GiRfr9998zHO/UqVO3relmvv/+e0ky/ximX6268WrwlClTbruvzLZNSkrK8Pis6Ny5s06fPq1p06ZlWJd+nK5duyo1NVWvvfZahj4pKSkZwuSNQkJCZBiGYmNj77jOG2X1PeDr66uiRYtq7dq1du03PmfOzs4KCwvTkiVLdOTIEbN99+7dWrly5R3tMzNhYWHy9fXVm2++qeTk5Azr7+S9lj5zxu1eh7uV2fvPMAy76eisunFaRycnJ/NTn/QhOs7Ozhl+XxYuXKijR4/atWXlvWzluUr/AqAbfzfTP0W7kxlgbny83t7eCgoKyjBl3oULF3TgwIF79ktvkDu4Eg040HfffaeLFy/e9FuzGjRooGLFiikqKsoMy926ddP777+vMWPGqHr16nZXcCSpZ8+eWrBggZ599ln99NNPatSokVJTU7Vnzx4tWLBAK1euVJ06dW5ZV5s2bTRp0iS1atVK//nPf3Ty5El98MEHCgoKshvvGxwcrM6dO2vKlCk6c+aMOcXdvn37JNlflXrrrbf0008/qX79+urfv7+qVq2qs2fPasuWLfrxxx+z9NXdR48e1RdffCHpWrjdvn27Zs6caXezk6+vr5o0aaIJEyYoOTlZ9913n1atWpWlq8kNGzZUoUKFFB4erueff142m02ff/655eEZ1+vVq5c+++wzRUREaNOmTXrooYd06dIl/fjjjxo4cKA6dOigpk2b6plnntH48eO1bds2tWzZUq6urtq/f78WLlyoqVOnqkuXLjc9RuPGjVWkSBH9+OOPNx0LbFVW3wPStWnK3nrrLfXr10916tTR2rVrzffA9SIjI7VixQo99NBDGjhwoFJSUvT+++/rgQceuON93sjX11fTp09Xz549Vbt2bXXv3l3FihXTkSNHtGzZMjVq1CjTEHgrBQoUUNWqVTV//nzdf//9Kly4sKpVq6Zq1apZ2s/tVK5cWRUqVNDw4cN19OhR+fr6atGiRXc1VKdfv346e/asWrRooVKlSumvv/7S+++/r1q1apnnjrZt22rcuHHq06ePGjZsqJ07dyoqKirDl5Bk5b1s5bmqWbOmwsPD9dFHH5lDqTZt2qS5c+eqY8eOmX775u1UrVpVzZo1U3BwsAoXLqzffvtNX3/9tQYPHmzX78cff5RhGOrQoYPlYwCmXJ8PBICpXbt2hoeHh3Hp0qWb9undu7fh6upqTuOWlpZmBAYGGpKM119/PdNtkpKSjLffftt44IEHDHd3d6NQoUJGcHCwERkZaVy4cMHsJ8kYNGhQpvv45JNPjIoVKxru7u5G5cqVjdmzZ2eYosowDOPSpUvGoEGDjMKFCxve3t5Gx44djb179xqSjLfeesuu74kTJ4xBgwYZgYGBhqurq+Hv7288/PDDxkcffXTb5+rGKe6cnJyM4sWLG0888YTx559/2vX9559/jE6dOhkFCxY0/Pz8jMcff9w4duzYbadHMwzDWL9+vdGgQQOjQIECRsmSJY0RI0aY0wumTwtnGNemuHvggQcy1BkeHm6UKVPGru3y5cvGyy+/bJQrV8583F26dDEOHDhg1++jjz4ygoODjQIFChg+Pj5G9erVjREjRhjHjh277fPz/PPPG0FBQXZt6VPFvfPOOzfdLjveA5cvXzb69u1r+Pn5GT4+PkbXrl2NkydPZjrV2c8//2wEBwcbbm5uRvny5Y0ZM2bc1T4zew0NwzB++uknIywszPDz8zM8PDyMChUqGL179zZ+++03s094eLjh5eWV4XFnVs+GDRvMujN7XDdzsynuMjuuYVyb8i80NNTw9vY2ihYtavTv39/Yvn17hin/slr7119/bbRs2dIoXry44ebmZpQuXdp45plnjOPHj5t9rl69arzwwgtGQECAUaBAAaNRo0bGxo0bjaZNmxpNmza1239W3ss3e64ye16Tk5ONyMhIc3+BgYHGqFGj7KaTNIxrv/+ZTV13Y42vv/66Ua9ePaNgwYJGgQIFjMqVKxtvvPGGkZSUZLddt27djMaNG2fYH2CFzTDu4hILAGRi27ZtevDBB/XFF1+Y38SGnHXw4EFVrlxZy5cvN2+2BJBRXFycypUrp3nz5nElGneFMdEA7sqNX0csXRvj6OTkZHdzHnJW+fLl1bdvX7311luOLgXI06ZMmaLq1asToHHXuBIN4K5ERkYqNjZWzZs3l4uLizmN1tNPP62ZM2c6ujwAAHIEIRrAXYmOjlZkZKT++OMPJSQkqHTp0urZs6defvnlbPtSBgAA8hpCNAAAAGARY6IBAAAAiwjRAAAAgEUMWMxFaWlpOnbsmHx8fHLta2QBAACQdYZh6OLFiypZsqScnG5+vZkQnYuOHTumwMBAR5cBAACA2/j7779VqlSpm64nROciHx8fSddeFF9fXwdXg3tRcnKyVq1aZX5tNADcSzjHITfEx8crMDDQzG03Q4jORelDOHx9fQnRyBHJycny9PSUr68vf2AA3HM4xyE33W7oLTcWAgAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFLo4uADnrra2nHV0CcpFTWooqSZq844zSnPj1zk9GPljU0SUAQL7ClWgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYFGeCdFvvfWWbDabhg4darZdvXpVgwYNUpEiReTt7a3OnTvrxIkTdtsdOXJEbdq0kaenp4oXL64XX3xRKSkpdn3WrFmj2rVry93dXUFBQZozZ06G43/wwQcqW7asPDw8VL9+fW3atMlufVZqAQAAQP6QJ0L05s2bNXPmTNWoUcOufdiwYfr++++1cOFC/fzzzzp27Jgee+wxc31qaqratGmjpKQkbdiwQXPnztWcOXM0evRos8+hQ4fUpk0bNW/eXNu2bdPQoUPVr18/rVy50uwzf/58RUREaMyYMdqyZYtq1qypsLAwnTx5Msu1AAAAIP9weIhOSEhQjx499PHHH6tQoUJm+4ULF/TJJ59o0qRJatGihYKDgzV79mxt2LBB//vf/yRJq1at0h9//KEvvvhCtWrV0qOPPqrXXntNH3zwgZKSkiRJM2bMULly5TRx4kRVqVJFgwcPVpcuXTR58mTzWJMmTVL//v3Vp08fVa1aVTNmzJCnp6c+/fTTLNcCAACA/MPF0QUMGjRIbdq0UWhoqF5//XWzPTY2VsnJyQoNDTXbKleurNKlS2vjxo1q0KCBNm7cqOrVq6tEiRJmn7CwMA0YMEC7du3Sgw8+qI0bN9rtI71P+rCRpKQkxcbGatSoUeZ6JycnhYaGauPGjVmuJTOJiYlKTEw0l+Pj4yVJycnJSk5OtvpU3RGntJTbd8I9I/315nXPf3LrnAI4Uvr7nPc7clJW318ODdHz5s3Tli1btHnz5gzr4uLi5ObmpoIFC9q1lyhRQnFxcWaf6wN0+vr0dbfqEx8frytXrujcuXNKTU3NtM+ePXuyXEtmxo8fr8jIyAztq1atkqen5023y06VcuUoyGsqHot1dAnIZT/84+gKgNwTHR3t6BJwD7t8+XKW+jksRP/9998aMmSIoqOj5eHh4agyctSoUaMUERFhLsfHxyswMFAtW7aUr69vrtQweceZXDkO8gantBRVPBar/SWDlebk8A+akIuG1Sji6BKAHJecnKzo6Gg98sgjcnV1dXQ5uEeljxy4HYf9lY2NjdXJkydVu3Ztsy01NVVr167VtGnTtHLlSiUlJen8+fN2V4BPnDghf39/SZK/v3+GWTTSZ8y4vs+Ns2icOHFCvr6+KlCggJydneXs7Jxpn+v3cbtaMuPu7i53d/cM7a6urrn2y0+Qyp/SnFx47fMZAgXyk9z8O4r8J6vvLYfdWPjwww9r586d2rZtm/lTp04d9ejRw/y3q6urYmJizG327t2rI0eOKCQkRJIUEhKinTt32s2iER0dLV9fX1WtWtXsc/0+0vuk78PNzU3BwcF2fdLS0hQTE2P2CQ4Ovm0tAAAAyD8cdqnKx8dH1apVs2vz8vJSkSJFzPa+ffsqIiJChQsXlq+vr5577jmFhISYN/K1bNlSVatWVc+ePTVhwgTFxcXplVde0aBBg8wrwM8++6ymTZumESNG6KmnntLq1au1YMECLVu2zDxuRESEwsPDVadOHdWrV09TpkzRpUuX1KdPH0mSn5/fbWsBAABA/pGnP++dPHmynJyc1LlzZyUmJiosLEwffvihud7Z2VlLly7VgAEDFBISIi8vL4WHh2vcuHFmn3LlymnZsmUaNmyYpk6dqlKlSmnWrFkKCwsz+3Tr1k2nTp3S6NGjFRcXp1q1amnFihV2NxverhYAAADkHzbDMAxHF5FfxMfHy8/PTxcuXMi1Gwvf2no6V46DvMEpLUWV/vlVe0vVZ0x0PjPywaKOLgHIccnJyfrhhx/UunVrxkQjx2Q1rzn8y1YAAACAfxtCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAscnF0AQAA3LGxnRxdAXKTk6tUs4c0voeUluzoapCbxn7j6Aoy4Eo0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABY5NERPnz5dNWrUkK+vr3x9fRUSEqLly5eb669evapBgwapSJEi8vb2VufOnXXixAm7fRw5ckRt2rSRp6enihcvrhdffFEpKSl2fdasWaPatWvL3d1dQUFBmjNnToZaPvjgA5UtW1YeHh6qX7++Nm3aZLc+K7UAAAAgf3BoiC5VqpTeeustxcbG6rffflOLFi3UoUMH7dq1S5I0bNgwff/991q4cKF+/vlnHTt2TI899pi5fWpqqtq0aaOkpCRt2LBBc+fO1Zw5czR69Gizz6FDh9SmTRs1b95c27Zt09ChQ9WvXz+tXLnS7DN//nxFRERozJgx2rJli2rWrKmwsDCdPHnS7HO7WgAAAJB/2AzDMBxdxPUKFy6sd955R126dFGxYsX05ZdfqkuXLpKkPXv2qEqVKtq4caMaNGig5cuXq23btjp27JhKlCghSZoxY4ZeeuklnTp1Sm5ubnrppZe0bNky/f777+YxunfvrvPnz2vFihWSpPr166tu3bqaNm2aJCktLU2BgYF67rnnNHLkSF24cOG2tWRFfHy8/Pz8dOHCBfn6+mbbc3Yrb209nSvHQd7glJaiSv/8qr2l6ivNycXR5SAXjXywqKNLcIyxnRxdAXJRspOrfqjZQ623R8k1LdnR5SA3jf0m1w6V1byWZ/7KpqamauHChbp06ZJCQkIUGxur5ORkhYaGmn0qV66s0qVLm8F148aNql69uhmgJSksLEwDBgzQrl279OCDD2rjxo12+0jvM3ToUElSUlKSYmNjNWrUKHO9k5OTQkNDtXHjRknKUi2ZSUxMVGJiorkcHx8vSUpOTlZycu788julpdy+E+4Z6a83r3v+k1vnlDzHydXRFSAXJf//iwPJXCTIf3LxHJfV86nD34U7d+5USEiIrl69Km9vb33zzTeqWrWqtm3bJjc3NxUsWNCuf4kSJRQXFydJiouLswvQ6evT192qT3x8vK5cuaJz584pNTU10z579uwx93G7WjIzfvx4RUZGZmhftWqVPD09b7pddqqUK0dBXlPxWKyjS0Au++EfR1fgIDV7OLoCOEB09W6OLgG57Ycfcu1Qly9fzlI/h4foSpUqadu2bbpw4YK+/vprhYeH6+eff3Z0Wdli1KhRioiIMJfj4+MVGBioli1b5tpwjsk7zuTKcZA3OKWlqOKxWO0vGcxwjnxmWI0iji7BMcYTovOTZCcXRVfvpkd2zpcrn7jlL6Oicu1Q6SMHbsfhf2Xd3NwUFBQkSQoODtbmzZs1depUdevWTUlJSTp//rzdFeATJ07I399fkuTv759hFo30GTOu73PjLBonTpyQr6+vChQoIGdnZzk7O2fa5/p93K6WzLi7u8vd3T1Du6urq1xdc+cjSIJU/pTm5MJrn8/k1jklz2FcbL7kmpbCmOj8JhfPcVk9n+a5eaLT0tKUmJio4OBgubq6KiYmxly3d+9eHTlyRCEhIZKkkJAQ7dy5024WjejoaPn6+qpq1apmn+v3kd4nfR9ubm4KDg6265OWlqaYmBizT1ZqAQAAQP7h0EtVo0aN0qOPPqrSpUvr4sWL+vLLL7VmzRqtXLlSfn5+6tu3ryIiIlS4cGH5+vrqueeeU0hIiHkjX8uWLVW1alX17NlTEyZMUFxcnF555RUNGjTIvAL87LPPatq0aRoxYoSeeuoprV69WgsWLNCyZcvMOiIiIhQeHq46deqoXr16mjJlii5duqQ+ffpIUpZqAQAAQP7h0BB98uRJ9erVS8ePH5efn59q1KihlStX6pFHHpEkTZ48WU5OTurcubMSExMVFhamDz/80Nze2dlZS5cu1YABAxQSEiIvLy+Fh4dr3LhxZp9y5cpp2bJlGjZsmKZOnapSpUpp1qxZCgsLM/t069ZNp06d0ujRoxUXF6datWppxYoVdjcb3q4WAAAA5B95bp7oexnzRCOnMU90/sU80cgPmCc6H8uD80TnuTHRAAAAQF5HiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACL7ihEnz9/XrNmzdKoUaN09uxZSdKWLVt09OjRbC0OAAAAyItcrG6wY8cOhYaGys/PT4cPH1b//v1VuHBhLV68WEeOHNFnn32WE3UCAAAAeYblK9ERERHq3bu39u/fLw8PD7O9devWWrt2bbYWBwAAAORFlkP05s2b9cwzz2Rov++++xQXF5ctRQEAAAB5meUQ7e7urvj4+Azt+/btU7FixbKlKAAAACAvsxyi27dvr3Hjxik5OVmSZLPZdOTIEb300kvq3LlzthcIAAAA5DWWQ/TEiROVkJCg4sWL68qVK2ratKmCgoLk4+OjN954IydqBAAAAPIUy7Nz+Pn5KTo6WuvXr9f27duVkJCg2rVrKzQ0NCfqAwAAAPIcyyE6XaNGjdSoUaPsrAUAAAD4V7A8nOP555/Xe++9l6F92rRpGjp0aHbUBAAAAORplkP0okWLMr0C3bBhQ3399dfZUhQAAACQl1kO0WfOnJGfn1+Gdl9fX50+fTpbigIAAADyMsshOigoSCtWrMjQvnz5cpUvXz5bigIAAADyMss3FkZERGjw4ME6deqUWrRoIUmKiYnRxIkTNWXKlOyuDwAAAMhzLIfop556SomJiXrjjTf02muvSZLKli2r6dOnq1evXtleIAAAAJDX3NEUdwMGDNCAAQN06tQpFShQQN7e3tldFwAAAJBn3fE80ZJUrFix7KoDAAAA+NewfGPhiRMn1LNnT5UsWVIuLi5ydna2+wEAAADudZavRPfu3VtHjhzRq6++qoCAANlstpyoCwAAAMizLIfodevW6ZdfflGtWrVyoBwAAAAg77M8nCMwMFCGYeRELQAAAMC/guUQPWXKFI0cOVKHDx/OgXIAAACAvM/ycI5u3brp8uXLqlChgjw9PeXq6mq3/uzZs9lWHAAAAJAXWQ7RfCshAAAA8jvLITo8PDwn6gAAAAD+Ne7qy1auXr2qpKQkuzZfX9+7KggAAADI6yzfWHjp0iUNHjxYxYsXl5eXlwoVKmT3AwAAANzrLIfoESNGaPXq1Zo+fbrc3d01a9YsRUZGqmTJkvrss89yokYAAAAgT7E8nOP777/XZ599pmbNmqlPnz566KGHFBQUpDJlyigqKko9evTIiToBAACAPMPyleizZ8+qfPnykq6Nf06f0q5x48Zau3Zt9lYHAAAA5EGWQ3T58uV16NAhSVLlypW1YMECSdeuUBcsWDBbiwMAAADyIsshuk+fPtq+fbskaeTIkfrggw/k4eGhYcOG6cUXX8z2AgEAAIC8xvKY6GHDhpn/Dg0N1Z49exQbG6ugoCDVqFEjW4sDAAAA8qK7midaksqUKaMyZcpkRy0AAADAv0KWQvR7772X5R0+//zzd1wMAAAA8G+QpRA9efLkLO3MZrMRogEAAHDPy1KITp+NAwAAAMAdzM4BAAAA5Hd3dGPhP//8o++++05HjhxRUlKS3bpJkyZlS2EAAABAXmU5RMfExKh9+/YqX7689uzZo2rVqunw4cMyDEO1a9fOiRoBAACAPMXycI5Ro0Zp+PDh2rlzpzw8PLRo0SL9/fffatq0qR5//PGcqBEAAADIUyyH6N27d6tXr16SJBcXF125ckXe3t4aN26c3n777WwvEAAAAMhrLIdoLy8vcxx0QECADhw4YK47ffp09lUGAAAA5FGWx0Q3aNBA69atU5UqVdS6dWu98MIL2rlzpxYvXqwGDRrkRI0AAABAnmI5RE+aNEkJCQmSpMjISCUkJGj+/PmqWLEiM3MAAAAgX7AcosuXL2/+28vLSzNmzMjWggAAAIC87q6/bOXgwYPatWuX0tLSsqMeAAAAIM/LcohOTk7WmDFj1K5dO73xxhtKTU3VE088oYoVK6pGjRrmfNEAAADAvS7LIXrkyJGaPn26/P399emnn+qxxx7T1q1b9eWXX2revHlycXHRyy+/nJO1AgAAAHlClsdEf/3115ozZ45at26tffv2qXLlylq2bJkeffRRSVLx4sXVo0ePHCsUAAAAyCuyfCX62LFjqlmzpiTp/vvvl7u7u4KCgsz1999/v+Li4rK/QgAAACCPyXKITk1Nlaurq7ns4uIiZ2fn/9uRk5MMw8je6gAAAIA8yNIUdytXrpSfn58kKS0tTTExMfr9998lSefPn8/24gAAAIC8yFKIDg8Pt1t+5pln7JZtNtvdVwQAAADkcVkO0cwDDQAAAFxz11+2AgAAAOQ3hGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYdEch+vz585o1a5ZGjRqls2fPSpK2bNmio0ePZmtxAAAAQF5kaZ5oSdqxY4dCQ0Pl5+enw4cPq3///ipcuLAWL16sI0eO6LPPPsuJOgEAAIA8w/KV6IiICPXu3Vv79++Xh4eH2d66dWutXbs2W4sDAAAA8iLLIXrz5s0ZvqlQku677z7FxcVlS1EAAABAXmY5RLu7uys+Pj5D+759+1SsWLFsKQoAAADIyyyH6Pbt22vcuHFKTk6WJNlsNh05ckQvvfSSOnfunO0FAgAAAHmN5RA9ceJEJSQkqHjx4rpy5YqaNm2qoKAg+fj46I033siJGgEAAIA8xfLsHH5+foqOjta6deu0Y8cOJSQkqHbt2goNDc2J+gAAAIA8x3KITte4cWM1btw4O2sBAAAA/hUsh+j33nsv03abzSYPDw8FBQWpSZMmcnZ2vuviAAAAgLzIcoiePHmyTp06pcuXL6tQoUKSpHPnzsnT01Pe3t46efKkypcvr59++kmBgYHZXjAAAADgaJZvLHzzzTdVt25d7d+/X2fOnNGZM2e0b98+1a9fX1OnTtWRI0fk7++vYcOG5US9AAAAgMNZvhL9yiuvaNGiRapQoYLZFhQUpHfffVedO3fWwYMHNWHCBKa7AwAAwD3L8pXo48ePKyUlJUN7SkqK+Y2FJUuW1MWLF+++OgAAACAPshyimzdvrmeeeUZbt24127Zu3aoBAwaoRYsWkqSdO3eqXLly2VclAAAAkIdYDtGffPKJChcurODgYLm7u8vd3V116tRR4cKF9cknn0iSvL29NXHixGwvFgAAAMgLLI+J9vf3V3R0tPbs2aN9+/ZJkipVqqRKlSqZfZo3b559FQIAAAB5zB1/2UrlypVVuXLl7KwFAAAA+Fe4oxD9zz//6LvvvtORI0eUlJRkt27SpEnZUhgAAACQV1keEx0TE6NKlSpp+vTpmjhxon766SfNnj1bn376qbZt22ZpX+PHj1fdunXl4+Oj4sWLq2PHjtq7d69dn6tXr2rQoEEqUqSIvL291blzZ504ccKuz5EjR9SmTRt5enqqePHievHFFzPMILJmzRrVrl1b7u7uCgoK0pw5czLU88EHH6hs2bLy8PBQ/fr1tWnTJsu1AAAA4N5nOUSPGjVKw4cP186dO+Xh4aFFixbp77//VtOmTfX4449b2tfPP/+sQYMG6X//+5+io6OVnJysli1b6tKlS2afYcOG6fvvv9fChQv1888/69ixY3rsscfM9ampqWrTpo2SkpK0YcMGzZ07V3PmzNHo0aPNPocOHVKbNm3UvHlzbdu2TUOHDlW/fv20cuVKs8/8+fMVERGhMWPGaMuWLapZs6bCwsJ08uTJLNcCAACA/MFmGIZhZQMfHx9t27ZNFSpUUKFChbRu3To98MAD2r59uzp06KDDhw/fcTGnTp1S8eLF9fPPP6tJkya6cOGCihUrpi+//FJdunSRJO3Zs0dVqlTRxo0b1aBBAy1fvlxt27bVsWPHVKJECUnSjBkz9NJLL+nUqVNyc3PTSy+9pGXLlun33383j9W9e3edP39eK1askCTVr19fdevW1bRp0yRJaWlpCgwM1HPPPaeRI0dmqZbbiY+Pl5+fny5cuCBfX987fp6seGvr6Vw5DvIGp7QUVfrnV+0tVV9pTnd8ywP+hUY+WNTRJTjG2E6OrgC5KNnJVT/U7KHW26Pkmpbs6HKQm8Z+k2uHympes/xX1svLyxwHHRAQoAMHDuiBBx6QJJ0+fXeB7cKFC5KkwoULS5JiY2OVnJys0NBQs0/lypVVunRpM7hu3LhR1atXNwO0JIWFhWnAgAHatWuXHnzwQW3cuNFuH+l9hg4dKklKSkpSbGysRo0aZa53cnJSaGioNm7cmOVabpSYmKjExERzOT4+XpKUnJys5OTc+eV3Ssv4xTi4d6W/3rzu+U9unVPyHCdXR1eAXJT8/y8OJHORIP/JxXNcVs+nlt+FDRo00Lp161SlShW1bt1aL7zwgnbu3KnFixdn6WrszaSlpWno0KFq1KiRqlWrJkmKi4uTm5ubChYsaNe3RIkS5rcjxsXF2QXo9PXp627VJz4+XleuXNG5c+eUmpqaaZ89e/ZkuZYbjR8/XpGRkRnaV61aJU9Pz5s9Fdmq0u274B5U8Viso0tALvvhH0dX4CA1ezi6AjhAdPVuji4Bue2HH3LtUJcvX85SP8shetKkSUpISJAkRUZGKiEhQfPnz1fFihXvamaOQYMG6ffff9e6devueB95zahRoxQREWEux8fHKzAwUC1btsy14RyTd5zJleMgb3BKS1HFY7HaXzKY4Rz5zLAaRRxdgmOMJ0TnJ8lOLoqu3k2P7JwvVz5xy19GReXaodJHDtyOpb+yqamp+ueff1SjRg1J14Z2zJgxw3p1Nxg8eLCWLl2qtWvXqlSpUma7v7+/kpKSdP78ebsrwCdOnJC/v7/Z58ZZNNJnzLi+z42zaJw4cUK+vr4qUKCAnJ2d5ezsnGmf6/dxu1pulP6NjjdydXWVq2vufARJkMqf0pxceO3zmdw6p+Q5jIvNl1zTUhgTnd/k4jkuq+dTS7NzODs7q2XLljp37twdFXUjwzA0ePBgffPNN1q9erXKlStntz44OFiurq6KiYkx2/bu3asjR44oJCREkhQSEqKdO3fazaIRHR0tX19fVa1a1exz/T7S+6Tvw83NTcHBwXZ90tLSFBMTY/bJSi0AAADIHyxfqqpWrZoOHjyYIfDeiUGDBunLL7/Ut99+Kx8fH3NssZ+fnwoUKCA/Pz/17dtXERERKly4sHx9ffXcc88pJCTEHH/dsmVLVa1aVT179tSECRMUFxenV155RYMGDTKvAj/77LOaNm2aRowYoaeeekqrV6/WggULtGzZMrOWiIgIhYeHq06dOqpXr56mTJmiS5cuqU+fPmZNt6sFAAAA+YPlEP36669r+PDheu211xQcHCwvLy+79VbG+k6fPl2S1KxZM7v22bNnq3fv3pKkyZMny8nJSZ07d1ZiYqLCwsL04Ycfmn2dnZ21dOlSDRgwQCEhIfLy8lJ4eLjGjRtn9ilXrpyWLVumYcOGaerUqSpVqpRmzZqlsLAws0+3bt106tQpjR49WnFxcapVq5ZWrFhhd7Ph7WoBAABA/mB5nmgnp/8bAWKz2cx/G4Yhm82m1NTU7KvuHsM80chpzBOdfzFPNPID5onOx+6FeaJ/+umnuyoMAAAA+LezHKKbNm2aE3UAAAAA/xqWZudI98svv+jJJ59Uw4YNdfToUUnS559/fk/N8QwAAADcjOUQvWjRIoWFhalAgQLasmWL+bXWFy5c0JtvvpntBQIAAAB5jeUQ/frrr2vGjBn6+OOP7SajbtSokbZs2ZKtxQEAAAB5keUQvXfvXjVp0iRDu5+fn86fP58dNQEAAAB5muUQ7e/vrz///DND+7p161S+fPlsKQoAAADIyyyH6P79+2vIkCH69ddfZbPZdOzYMUVFRWn48OEaMGBATtQIAAAA5CmWp7gbOXKk0tLS9PDDD+vy5ctq0qSJ3N3dNXz4cD333HM5USMAAACQp1gO0TabTS+//LJefPFF/fnnn0pISFDVqlXl7e2dE/UBAAAAeY7l4RxffPGFLl++LDc3N1WtWlX16tUjQAMAACBfsRyihw0bpuLFi+s///mPfvjhB6WmpuZEXQAAAECeZTlEHz9+XPPmzZPNZlPXrl0VEBCgQYMGacOGDTlRHwAAAJDnWA7RLi4uatu2raKionTy5ElNnjxZhw8fVvPmzVWhQoWcqBEAAADIUyzfWHg9T09PhYWF6dy5c/rrr7+0e/fu7KoLAAAAyLMsX4mWpMuXLysqKkqtW7fWfffdpylTpqhTp07atWtXdtcHAAAA5DmWr0R3795dS5culaenp7p27apXX31VISEhOVEbAAAAkCdZDtHOzs5asGCBwsLC5OzsbLfu999/V7Vq1bKtOAAAACAvshyio6Ki7JYvXryor776SrNmzVJsbCxT3gEAAOCed0djoiVp7dq1Cg8PV0BAgN599121aNFC//vf/7KzNgAAACBPsnQlOi4uTnPmzNEnn3yi+Ph4de3aVYmJiVqyZImqVq2aUzUCAAAAeUqWr0S3a9dOlSpV0o4dOzRlyhQdO3ZM77//fk7WBgAAAORJWb4SvXz5cj3//PMaMGCAKlasmJM1AQAAAHlalq9Er1u3ThcvXlRwcLDq16+vadOm6fTp0zlZGwAAAJAnZTlEN2jQQB9//LGOHz+uZ555RvPmzVPJkiWVlpam6OhoXbx4MSfrBAAAAPIMy7NzeHl56amnntK6deu0c+dOvfDCC3rrrbdUvHhxtW/fPidqBAAAAPKUO57iTpIqVaqkCRMm6J9//tFXX32VXTUBAAAAedpdheh0zs7O6tixo7777rvs2B0AAACQp2VLiAYAAADyE0I0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEUODdFr165Vu3btVLJkSdlsNi1ZssRuvWEYGj16tAICAlSgQAGFhoZq//79dn3Onj2rHj16yNfXVwULFlTfvn2VkJBg12fHjh166KGH5OHhocDAQE2YMCFDLQsXLlTlypXl4eGh6tWr64cffrBcCwAAAPIHh4boS5cuqWbNmvrggw8yXT9hwgS99957mjFjhn799Vd5eXkpLCxMV69eNfv06NFDu3btUnR0tJYuXaq1a9fq6aefNtfHx8erZcuWKlOmjGJjY/XOO+9o7Nix+uijj8w+GzZs0BNPPKG+fftq69at6tixozp27Kjff//dUi0AAADIH2yGYRiOLkKSbDabvvnmG3Xs2FHStSu/JUuW1AsvvKDhw4dLki5cuKASJUpozpw56t69u3bv3q2qVatq8+bNqlOnjiRpxYoVat26tf755x+VLFlS06dP18svv6y4uDi5ublJkkaOHKklS5Zoz549kqRu3brp0qVLWrp0qVlPgwYNVKtWLc2YMSNLtWRFfHy8/Pz8dOHCBfn6+mbL83Y7b209nSvHQd7glJaiSv/8qr2l6ivNycXR5SAXjXywqKNLcIyxnRxdAXJRspOrfqjZQ623R8k1LdnR5SA3jf0m1w6V1byWZ//KHjp0SHFxcQoNDTXb/Pz8VL9+fW3cuFHdu3fXxo0bVbBgQTNAS1JoaKicnJz066+/qlOnTtq4caOaNGliBmhJCgsL09tvv61z586pUKFC2rhxoyIiIuyOHxYWZg4vyUotmUlMTFRiYqK5HB8fL0lKTk5WcnLu/PI7paXkynGQN6S/3rzu+U9unVPyHCdXR1eAXJT8/y8OJHORIP/JxXNcVs+nefZdGBcXJ0kqUaKEXXuJEiXMdXFxcSpevLjdehcXFxUuXNiuT7ly5TLsI31doUKFFBcXd9vj3K6WzIwfP16RkZEZ2letWiVPT8+bbpedKuXKUZDXVDwW6+gSkMt++MfRFThIzR6OrgAOEF29m6NLQG674V61nHT58uUs9cuzIfpeMGrUKLsr3PHx8QoMDFTLli1zbTjH5B1ncuU4yBuc0lJU8Vis9pcMZjhHPjOsRhFHl+AY4wnR+Umyk4uiq3fTIzvny5VP3PKXUVG5dqj0kQO3k2f/yvr7+0uSTpw4oYCAALP9xIkTqlWrltnn5MmTdtulpKTo7Nmz5vb+/v46ceKEXZ/05dv1uX797WrJjLu7u9zd3TO0u7q6ytU1dz6CJEjlT2lOLrz2+UxunVPyHMbF5kuuaSmMic5vcvEcl9XzaZ6dJ7pcuXLy9/dXTEyM2RYfH69ff/1VISEhkqSQkBCdP39esbH/99H16tWrlZaWpvr165t91q5daze+JTo6WpUqVVKhQoXMPtcfJ71P+nGyUgsAAADyD4eG6ISEBG3btk3btm2TdO0Gvm3btunIkSOy2WwaOnSoXn/9dX333XfauXOnevXqpZIlS5ozeFSpUkWtWrVS//79tWnTJq1fv16DBw9W9+7dVbJkSUnSf/7zH7m5ualv377atWuX5s+fr6lTp9oNsxgyZIhWrFihiRMnas+ePRo7dqx+++03DR48WJKyVAsAAADyD4d+3vvbb7+pefPm5nJ6sA0PD9ecOXM0YsQIXbp0SU8//bTOnz+vxo0ba8WKFfLw8DC3iYqK0uDBg/Xwww/LyclJnTt31nvvvWeu9/Pz06pVqzRo0CAFBweraNGiGj16tN1c0g0bNtSXX36pV155Rf/9739VsWJFLVmyRNWqVTP7ZKUWAAAA5A95Zp7o/IB5opHTmCc6/2KeaOQHzBOdj+XBeaLz7JhoAAAAIK8iRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEWffDBBypbtqw8PDxUv359bdq0ydElAQAAIJcRoi2YP3++IiIiNGbMGG3ZskU1a9ZUWFiYTp486ejSAAAAkIsI0RZMmjRJ/fv3V58+fVS1alXNmDFDnp6e+vTTTx1dGgAAAHKRi6ML+LdISkpSbGysRo0aZbY5OTkpNDRUGzduzHSbxMREJSYmmssXLlyQJJ09e1bJyck5W/D/lxR/LleOg7zBKS1Fly9fVlL8OaU58eudn5w5Y3N0CY6R5OgCkJuSnQxdvnxZZ5IMuaY5uhrkqjNncu1QFy9elCQZhnHLfvyVzaLTp08rNTVVJUqUsGsvUaKE9uzZk+k248ePV2RkZIb2cuXK5UiNAPKvMY4uAMg1Xzu6ADjC+CW5fsiLFy/Kz8/vpusJ0Tlo1KhRioiIMJfT0tJ09uxZFSlSRDZbPr1qhBwVHx+vwMBA/f333/L19XV0OQCQrTjHITcYhqGLFy+qZMmSt+xHiM6iokWLytnZWSdOnLBrP3HihPz9/TPdxt3dXe7u7nZtBQsWzKkSAZOvry9/YADcszjHIafd6gp0Om4szCI3NzcFBwcrJibGbEtLS1NMTIxCQkIcWBkAAAByG1eiLYiIiFB4eLjq1KmjevXqacqUKbp06ZL69Onj6NIAAACQiwjRFnTr1k2nTp3S6NGjFRcXp1q1amnFihUZbjYEHMXd3V1jxozJMIwIAO4FnOOQl9iM283fAQAAAMAOY6IBAAAAiwjRAAAAgEWEaAAAAMAiQjSQy8aOHasSJUrIZrNpyZIlji7HYXr37q2OHTs6ugwAd8kwDD399NMqXLiwbDabtm3b5uiSclWzZs00dOhQR5cBByBEA1nQu3dv2Ww286dIkSJq1aqVduzYYWk/u3fvVmRkpGbOnKnjx4/r0UcfzaGKM3fj40j/+fPPP3O1DgD/Lhs3bpSzs7PatGmTYd2KFSs0Z84cLV26VMePH1e1atVy/CJBs2bNMj2XpaSk5NgxgRsRooEsatWqlY4fP67jx48rJiZGLi4uatu2raV9HDhwQJLUoUMH+fv73/E0TcnJyXe0nWT/ONJ/ypUrl6FfUlLSHR8DwL3lk08+0XPPPae1a9fq2LFjdusOHDiggIAANWzYUP7+/nJxyb7Zc291ruvfv3+Gc1lmx+ZchpxCiAayyN3dXf7+/vL391etWrU0cuRI/f333zp16pTZ5++//1bXrl1VsGBBFS5cWB06dNDhw4clXRvG0a5dO0mSk5OTbDabpGvffDlu3DiVKlVK7u7u5vzj6Q4fPiybzab58+eradOm8vDwUFRUlCRp1qxZqlKlijw8PFS5cmV9+OGHlh5H+o+zs7OaNWumwYMHa+jQoSpatKjCwsIkSZMmTVL16tXl5eWlwMBADRw4UAkJCeb+xo4dq1q1atkdY8qUKSpbtqy5nJqaqoiICBUsWFBFihTRiBEjxOyawL9DQkKC5s+frwEDBqhNmzaaM2eOua5379567rnndOTIEdlsNpUtW9b83e/UqZPZlu7bb79V7dq15eHhofLlyysyMtLu6rHNZtP06dPVvn17eXl56Y033rhpXZ6enhnOZZJUtmxZvfbaa+rVq5d8fX319NNPS5Jeeukl3X///fL09FT58uX16quv2oX0zIaYDR06VM2aNTOXL126pF69esnb21sBAQGaOHGixWcT9xJCNHAHEhIS9MUXXygoKEhFihSRdO2KSVhYmHx8fPTLL79o/fr18vb2VqtWrZSUlKThw4dr9uzZkmReNZGkqVOnauLEiXr33Xe1Y8cOhYWFqX379tq/f7/dMUeOHKkhQ4Zo9+7dCgsLU1RUlEaPHq033nhDu3fv1ptvvqlXX31Vc+fOvePHNXfuXLm5uWn9+vWaMWOGpGuB/7333tOuXbs0d+5crV69WiNGjLC034kTJ2rOnDn69NNPtW7dOp09e1bffPPNHdcJIPcsWLBAlStXVqVKlfTkk0/q008/Nf8TPHXqVPMiwPHjx7V582Zt3rxZkjR79myzTZJ++eUX9erVS0OGDNEff/yhmTNnas6cORmC8tixY9WpUyft3LlTTz311B3V/O6776pmzZraunWrXn31VUmSj4+P5syZoz/++ENTp07Vxx9/rMmTJ1va74svvqiff/5Z3377rVatWqU1a9Zoy5Ytd1Qj7gEGgNsKDw83nJ2dDS8vL8PLy8uQZAQEBBixsbFmn88//9yoVKmSkZaWZrYlJiYaBQoUMFauXGkYhmF88803xo2/diVLljTeeOMNu7a6desaAwcONAzDMA4dOmRIMqZMmWLXp0KFCsaXX35p1/baa68ZISEhWX4cXl5eRpcuXQzDMIymTZsaDz744G2fi4ULFxpFihQxl8eMGWPUrFnTrs/kyZONMmXKmMsBAQHGhAkTzOXk5GSjVKlSRocOHW57PACO1bBhQ/P8k5ycbBQtWtT46aefzPU3/r4bhmFIMr755hu7tocffth488037do+//xzIyAgwG67oUOH3rampk2bGq6urnbnsoiICMMwDKNMmTJGx44db7uPd955xwgODjaXw8PDM5yThgwZYjRt2tQwDMO4ePGi4ebmZixYsMBcf+bMGaNAgQLGkCFDbns83Hv42m8gi5o3b67p06dLks6dO6cPP/xQjz76qDZt2qQyZcpo+/bt+vPPP+Xj42O33dWrV82x0DeKj4/XsWPH1KhRI7v2Ro0aafv27XZtderUMf996dIlHThwQH379lX//v3N9pSUFPn5+WX5cUiSl5eX+e/g4OAM/X/88UeNHz9ee/bsUXx8vFJSUnT16lVdvnxZnp6etzyWJF24cEHHjx9X/fr1zTYXFxfVqVOHIR1AHrd3715t2rTJ/OTIxcVF3bp10yeffGI3zCErtm/frvXr19tdeU5NTc1wPrn+XHcrPXr00Msvv2wuFyxY0Px3ZvuYP3++3nvvPR04cEAJCQlKSUmRr69vlus/cOCAkpKS7M5lhQsXVqVKlbK8D9xbCNFAFnl5eSkoKMhcnjVrlvz8/PTxxx/r9ddfV0JCgoKDg83xytcrVqxYthw/XfqY5I8//tjuhC5Jzs7Ot93P9Y/jZseQro3Hbtu2rQYMGKA33nhDhQsX1rp169S3b18lJSXJ09NTTk5OGcLw3dz4CCDv+OSTT5SSkqKSJUuabYZhyN3dXdOmTbvtf9qvl5CQoMjISD322GMZ1nl4eJj/vvE8dDN+fn5ZPpdt3LhRPXr0UGRkpMLCwuTn56d58+bZjWnmXAarCNHAHbLZbHJyctKVK1ckSbVr19b8+fNVvHjxLF/d8PX1VcmSJbV+/Xo1bdrUbF+/fr3q1at30+1KlCihkiVL6uDBg+rRo8fdPZBbiI2NVVpamiZOnCgnp2u3UCxYsMCuT7FixRQXFyfDMMybJa+fJ9bPz08BAQH69ddf1aRJE0nXrpjHxsaqdu3aOVY7gLuTkpKizz77TBMnTlTLli3t1nXs2FFfffWVnn322Uy3dXV1VWpqql1b7dq1tXfv3psG35y0YcMGlSlTxu7K9V9//WXXp1ixYvr999/t2rZt2yZXV1dJUoUKFeTq6qpff/1VpUuXlnTtU8l9+/bZnb+RfxCigSxKTExUXFycpGsnzmnTpikhIcGccaNHjx5655131KFDB/NGm7/++kuLFy/WiBEjVKpUqUz3++KLL2rMmDGqUKGCatWqpdmzZ2vbtm2ZXtG+XmRkpJ5//nn5+fmpVatWSkxM1G+//aZz584pIiIiWx5zUFCQkpOT9f7776tdu3Z2Nxyma9asmU6dOqUJEyaoS5cuWrFihZYvX273H4khQ4borbfeUsWKFVW5cmVNmjRJ58+fz5YaAeSMpUuX6ty5c+rbt2+GK86dO3fWJ598ctMQXbZsWcXExKhRo0Zyd3dXoUKFNHr0aLVt21alS5dWly5d5OTkpO3bt+v333/X66+/nqOPpWLFijpy5IjmzZununXratmyZRlubm7RooXeeecdffbZZwoJCdEXX3yh33//XQ8++KAkydvbW3379tWLL76oIkWKqHjx4nr55ZfNCwzIf3jlgSxasWKFAgICFBAQoPr162vz5s1auHChOS7Q09NTa9euVenSpfXYY4+pSpUq6tu3r65evXrLK9PPP/+8IiIi9MILL6h69epasWKFvvvuO1WsWPGW9fTr10+zZs3S7NmzVb16dTVt2lRz5szJdM7nO1WzZk1NmjRJb7/9tqpVq6aoqCiNHz/erk+VKlX04Ycf6oMPPlDNmjW1adMmDR8+3K7PCy+8oJ49eyo8PFwhISHy8fFRp06dsq1OANnvk08+UWhoaKZDNjp37qzffvvtpl84NXHiREVHRyswMNAMoWFhYVq6dKlWrVqlunXrqkGDBpo8ebLKlCmTo49Dktq3b69hw4Zp8ODBqlWrljZs2GDO2pEuLCxMr776qkaMGKG6devq4sWL6tWrl12fd955Rw899JDatWun0NBQNW7cONN7SZA/2Azu7AEAAAAs4Uo0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNADAsjVr1shms/H17QDyLUI0AGQTm812y5+xY8c6usQ70qxZMw0dOtSurWHDhjp+/HimXwmdnU6dOqUBAwaodOnScnd3l7+/v8LCwrR+/Xqzj81m05IlS3K0DgC4kYujCwCAe8Xx48fNf8+fP1+jR4/W3r17zTZvb2/z34ZhKDU1VS4u/87TsJubm/z9/XP8OJ07d1ZSUpLmzp2r8uXL68SJE4qJidGZM2dy/NgAcCtciQaAbOLv72/++Pn5yWazmct79uyRj4+Pli9fruDgYLm7u2vdunU6cOCAOnTooBIlSsjb21t169bVjz/+aLffsmXL6s0339RTTz0lHx8flS5dWh999JG5PikpSYMHD1ZAQIA8PDxUpkwZjR8/3lw/adIkVa9eXV5eXgoMDNTAgQOVkJBgd4z169erWbNm8vT0VKFChRQWFqZz586pd+/e+vnnnzV16lTzivrhw4czHc6xaNEiPfDAA3J3d1fZsmU1ceJES4/jRufPn9cvv/yit99+W82bN1eZMmVUr149jRo1Su3btzf3KUmdOnWSzWYzl7PyvB4/flxt2rRRgQIFVK5cOX355ZcqW7aspkyZYldDv379VKxYMfn6+qpFixbavn37TWsGkH8QogEgF40cOVJvvfWWdu/erRo1aighIUGtW7dWTEyMtm7dqlatWqldu3Y6cuSI3XYTJ05UnTp1tHXrVg0cOFADBgwwr3K/9957+u6777RgwQLt3btXUVFRZpiUJCcnJ7333nvatWuX5s6dq9WrV2vEiBHm+m3btunhhx9W1apVtXHjRq1bt07t2rVTamqqpk6dqpCQEPXv31/Hjx/X8ePHFRgYmOFxxcbGqmvXrurevbt27typsWPH6tVXX9WcOXOy/Dhu5O3tLW9vby1ZskSJiYmZ9tm8ebMkafbs2Tp+/Li5nJXntVevXjp27JjWrFmjRYsW6aOPPtLJkyft9v/444/r5MmTWr58uWJjY1W7dm09/PDDOnv2bKb1AMhHDABAtps9e7bh5+dnLv/000+GJGPJkiW33faBBx4w3n//fXO5TJkyxpNPPmkup6WlGcWLFzemT59uGIZhPPfcc0aLFi2MtLS0LNW2cOFCo0iRIubyE088YTRq1Oim/Zs2bWoMGTLEri398Zw7d84wDMP4z3/+YzzyyCN2fV588UWjatWqWX4cmfn666+NQoUKGR4eHkbDhg2NUaNGGdu3b7frI8n45ptvbrqPdNc/r7t37zYkGZs3bzbX79+/35BkTJ482TAMw/jll18MX19f4+rVq3b7qVChgjFz5szbHg/AvY0r0QCQi+rUqWO3nJCQoOHDh6tKlSoqWLCgvL29tXv37gxXomvUqGH+O32YSPpV0969e2vbtm2qVKmSnn/+ea1atcpu2x9//FEPP/yw7rvvPvn4+Khnz546c+aMLl++LOn/rkTfjd27d6tRo0Z2bY0aNdL+/fuVmpqapceRmc6dO+vYsWP67rvv1KpVK61Zs0a1a9fOcIX7Rrd7Xvfu3SsXFxfVrl3b3CYoKEiFChUyl7dv366EhAQVKVLEvCru7e2tQ4cO6cCBA1l6XgDcu/6dd7QAwL+Ul5eX3fLw4cMVHR2td999V0FBQSpQoIC6dOmipKQku36urq52yzabTWlpaZKk2rVr69ChQ1q+fLl+/PFHde3aVaGhofr66691+PBhtW3bVgMGDNAbb7yhwoULa926derbt6+SkpLk6empAgUK5OyDzuLjuBkPDw898sgjeuSRR/Tqq6+qX79+GjNmjHr37n3TbbL6vN5KQkKCAgICtGbNmgzrChYsmOX9ALg3EaIBwIHWr1+v3r17q1OnTpKuBbfDhw9b3o+vr6+6deumbt26qUuXLmrVqpXOnj2r2NhYpaWlaeLEiXJyuvbh44IFC+y2rVGjhmJiYhQZGZnpvt3c3OyuJmemSpUqdtPOpT+2+++/X87OzpYfz61UrVrVbko7V1fXDPXd7nmtVKmSUlJStHXrVgUHB0uS/vzzT507d87sU7t2bcXFxcnFxcVujDkASNxYCAAOVbFiRS1evFjbtm3T9u3b9Z///Oe2V2ZvNGnSJH311Vfas2eP9u3bp4ULF8rf318FCxZUUFCQkpOT9f777+vgwYP6/PPPNWPGDLvtR40apc2bN2vgwIHasWOH9uzZo+nTp+v06dOSrs2A8euvv+rw4cM6ffp0pvW98MILiomJ0WuvvaZ9+/Zp7ty5mjZtmoYPH37Hz82ZM2fUokULffHFF9qxY4cOHTqkhQsXasKECerQoYPZr2zZsoqJiVFcXJwZgm/3vFauXFmhoaF6+umntWnTJm3dulVPP/20ChQoIJvNJkkKDQ1VSEiIOnbsqFWrVunw4cPasGGDXn75Zf322293/LgA3BsI0QDgQJMmTVKhQoXUsGFDtWvXTmFhYXbjdLPCx8dHEyZMUJ06dVS3bl0dPnxYP/zwg5ycnFSzZk1NmjRJb7/9tqpVq6aoqCi76e8k6f7779eqVau0fft21atXTyEhIfr222/NOayHDx8uZ2dnVa1aVcWKFcswXlu6dtV2wYIFmjdvnqpVq6bRo0dr3LhxtxxycTve3t6qX7++Jk+erCZNmqhatWp69dVX1b9/f02bNs3sN3HiREVHRyswMFAPPvigpKw9r5999plKlCihJk2aqFOnTurfv798fHzk4eEh6dpQkx9++EFNmjRRnz59dP/996t79+7666+/VKJEiTt+XADuDTbDMAxHFwEAgKP9888/CgwMNG/EBIBbIUQDAPKl1atXKyEhQdWrV9fx48c1YsQIHT16VPv27ctwAyQA3IgbCwEA+VJycrL++9//6uDBg/Lx8VHDhg0VFRVFgAaQJVyJBgAAACzixkIAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARf8PjtxbR1kcFtsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAIjCAYAAAAQgZNYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUSElEQVR4nO3deVhU5f//8dewOIgIbmwaioprmgvmWm6RmKZZrm0upZlmamSL9UnFMttEW7VyS6Pcs+WjJpJmLp8s98xdkVJQcUNEAeH8/vDHfB1BZRQYjzwf18Wlc899znmfheE1Z+5zxmIYhiEAAADAhFycXQAAAABwowizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAJxu5syZslgsiouLc3Yp+WLw4MG6//77nV2GQ9t11apVslgsWrVqVYHXBecaM2aMLBaLs8vQq6++qiZNmji7DNwGCLNALj777DNZLBZeaHMRHBwsi8Vi+/Hw8FC1atX00ksv6eTJk84uz+kOHjyoqVOn6rXXXrO1xcXFyWKx6IMPPnBiZZd89tlnmjlzprPLsPP3339rzJgx+fpm5srj9Go/t9q2yC+pqakaM2bMLf3mZPjw4dq6dat++OEHZ5cCk7MYhmE4uwjgVtOiRQsdOXJEcXFx2rt3r0JCQpxd0i0jODhYpUuX1osvvihJunDhgjZu3KipU6eqQYMG2rBhg8PznDlzpvr166eDBw8qODg4nysuXMOHD9fSpUu1e/duW1tcXJwqV66s999/XyNGjCi0WjIzM5WRkSGr1Wo7E1enTh2VK1cuR8jJyspSenq6ihUrJheXwj3PsWDBAnXv3l0rV65U69at82WeixcvVkpKiu3xkiVL9O2332rixIkqV66crb158+aqUqVKvizzVpKUlCRfX1+NHj1aY8aMsXvu4sWLunjxojw8PJxT3GV69uyphIQErV692tmlwMTcnF0AcKs5ePCg1q1bp0WLFmngwIGKjo7W6NGjC7WG7GBxK/yxyU2FChX0xBNP2B73799fXl5e+uCDD7R3715Vq1bNidU5T0ZGhqKjo/Xss886uxRJkqurq1xdXfPU18XF5ZY93m5Ely5d7B4nJibq22+/VZcuXa75huncuXMqUaJEwRbnZG5ubnJzuzX+/Pfo0UPdu3fXgQMHbss3FSgcDDMArhAdHa3SpUurY8eO6tatm6Kjo23PZWRkqEyZMurXr1+O6ZKTk+Xh4WF35i0tLU2jR49WSEiIrFargoKC9PLLLystLc1uWovFoiFDhig6Olp33nmnrFarli1bJkn64IMP1Lx5c5UtW1bFixdXaGioFixYkGP558+f19ChQ1WuXDmVLFlSnTt31uHDh2WxWHKcmTl8+LCeeuop+fv7y2q16s4779T06dNvZrMpICBAkuz+SG7btk19+/ZVlSpV5OHhoYCAAD311FM6ceLEdef3/fffq2PHjipfvrysVquqVq2qN998U5mZmXb9WrdurTp16ujvv/9WmzZt5OnpqQoVKui9997LMc8LFy5ozJgxql69ujw8PBQYGKhHHnlE+/fvt/XJysrSpEmTdOedd8rDw0P+/v4aOHCgTp06dd2a16xZo6SkJIWFhV23b27yerzkdV9fOWY2ODhYO3bs0K+//mr7mD37TGhuY2azt+22bdvUqlUreXp6KiQkxHb8/frrr2rSpImKFy+uGjVqaMWKFXZ1Hjp0SIMHD1aNGjVUvHhxlS1bVt27d7cbTjBz5kx1795dktSmTRtbXZfXsXTpUt17770qUaKESpYsqY4dO2rHjh03tI0v17dvX3l5eWn//v3q0KGDSpYsqccff1yS9Ntvv6l79+6qWLGibV+88MILOn/+fK7zOHz4sLp06SIvLy/5+vpqxIgROY7VOXPmKDQ0VCVLlpS3t7fq1q2rDz/80Pb8yZMnNWLECNWtW1deXl7y9vbWAw88oK1bt+ao/VrHclxcnHx9fSVJkZGRtm2afWzkNmb24sWLevPNN1W1alVZrVYFBwfrtddey3HsBQcH68EHH9SaNWvUuHFjeXh4qEqVKpo1a5Zdv4yMDEVGRqpatWry8PBQ2bJldc899ygmJsauX/bvyvfff3/NfQVcy63x1gy4hURHR+uRRx5RsWLF9Oijj2ry5Mn6448/dPfdd8vd3V0PP/ywFi1apM8//1zFihWzTbd48WKlpaWpV69eki6Fos6dO2vNmjV65plnVKtWLW3fvl0TJ07Unj17tHjxYrvl/vLLL5o3b56GDBmicuXK2c4effjhh+rcubMef/xxpaena86cOerevbt++ukndezY0TZ93759NW/ePD355JNq2rSpfv31V7vnsx09elRNmza1BWhfX18tXbpUTz/9tJKTkzV8+PDrbqOMjAwlJSVJuvRHdfPmzYqKilLLli1VuXJlW7+YmBgdOHBA/fr1U0BAgHbs2KEvvvhCO3bs0P/+979rXoQyc+ZMeXl5KSIiQl5eXvrll180atQoJScn6/3337fre+rUKbVv316PPPKIevTooQULFuiVV15R3bp19cADD0i69JH7gw8+qNjYWPXq1UvDhg3T2bNnFRMTo7/++ktVq1aVJA0cONA27GHo0KE6ePCgPvnkE23evFlr166Vu7v7VWtet26dLBaLGjRocN1teCVHjpe87usrTZo0Sc8//7y8vLz0+uuvS5L8/f2vOc2pU6f04IMPqlevXurevbsmT56sXr16KTo6WsOHD9ezzz6rxx57TO+//766deumf/75RyVLlpQk/fHHH1q3bp169eqlO+64Q3FxcZo8ebJat26tv//+W56enmrZsqWGDh2qjz76SK+99ppq1aolSbZ/Z8+erT59+ig8PFzvvvuuUlNTNXnyZN1zzz3avHnzTQ9LuXjxosLDw3XPPffogw8+kKenpyRp/vz5Sk1N1aBBg1S2bFlt2LBBH3/8sf7991/Nnz/fbh6ZmZkKDw9XkyZN9MEHH2jFihWaMGGCqlatqkGDBkm69Lvw6KOP6r777tO7774rSdq5c6fWrl2rYcOGSZIOHDigxYsXq3v37qpcubKOHj2qzz//XK1atdLff/+t8uXL25Z3rWM5LCxMkydP1qBBg/Twww/rkUcekSTdddddV90O/fv311dffaVu3brpxRdf1O+//67x48dr586d+u677+z67tu3T926ddPTTz+tPn36aPr06erbt69CQ0N15513SroUmMePH6/+/furcePGSk5O1p9//qlNmzbZXRzp4+OjqlWrau3atXrhhRdueD+iiDMA2Pz555+GJCMmJsYwDMPIysoy7rjjDmPYsGG2Pj///LMhyfjxxx/tpu3QoYNRpUoV2+PZs2cbLi4uxm+//WbXb8qUKYYkY+3atbY2SYaLi4uxY8eOHDWlpqbaPU5PTzfq1KljtG3b1ta2ceNGQ5IxfPhwu759+/Y1JBmjR4+2tT399NNGYGCgkZSUZNe3V69eho+PT47lXalSpUqGpBw/LVq0yDHP3Ob17bffGpKM1atX29pmzJhhSDIOHjx4zWkHDhxoeHp6GhcuXLC1tWrVypBkzJo1y9aWlpZmBAQEGF27drW1TZ8+3ZBkREVF5ZhvVlaWYRiG8dtvvxmSjOjoaLvnly1blmv7lZ544gmjbNmyOdoPHjxoSDLef//9q06b1+PFkX2d23a98847jVatWuVY/sqVKw1JxsqVK21t2dv2m2++sbXt2rXLdrz+73//s7Vn/17MmDHD1pbbPly/fn2O/TV//vwcyzYMwzh79qxRqlQpY8CAAXbtiYmJho+PT472a3n//fdzbIs+ffoYkoxXX301R//cah8/frxhsViMQ4cO5ZjH2LFj7fo2aNDACA0NtT0eNmyY4e3tbVy8ePGqNV64cMHIzMy0azt48KBhtVrt5p+XY/n48eM5jodso0ePNi7/879lyxZDktG/f3+7fiNGjDAkGb/88outLfv3//Lf32PHjhlWq9V48cUXbW316tUzOnbseNV1vVy7du2MWrVq5akvkBuGGQCXiY6Olr+/v9q0aSPp0sf/PXv21Jw5c2wfGbZt21blypXT3LlzbdOdOnVKMTEx6tmzp61t/vz5qlWrlmrWrKmkpCTbT9u2bSVJK1eutFt2q1atVLt27Rw1FS9e3G45Z86c0b333qtNmzbZ2rOHJAwePNhu2ueff97usWEYWrhwoTp16iTDMOzqCg8P15kzZ+zmezVNmjRRTEyMYmJi9NNPP2ncuHHasWOHOnfubPcx7OW1X7hwQUlJSWratKkkXXc5l0979uxZJSUl6d5771Vqaqp27dpl19fLy8tuDG+xYsXUuHFjHThwwNa2cOFClStXLsc2kWQ7Qzx//nz5+Pjo/vvvt9s2oaGh8vLyyrHPrnTixAmVLl36mn2uJq/HS173dX7x8vKyfdogSTVq1FCpUqVUq1Ytu7t9ZP//8m1++T7MyMjQiRMnFBISolKlSuXpOIuJidHp06f16KOP2m0TV1dXNWnS5Lr7I6+yz55e7vLaz507p6SkJDVv3lyGYWjz5s05+l85Tvree++12xalSpXSuXPncnzMfjmr1Wq7+C4zM1MnTpyQl5eXatSoYbe98nIsO2LJkiWSpIiICLv27Is8//vf/9q1165dW/fee6/tsa+vr2rUqJFjfXfs2KG9e/ded/mlS5e2fdID3IgiHWZXr16tTp06qXz58rJYLDk+9s0LwzD0wQcfqHr16rJarapQoYLGjRuX/8WiwGVmZmrOnDlq06aNDh48qH379mnfvn1q0qSJjh49qtjYWEmXxoR27dpV33//vW082aJFi5SRkWEXZvfu3asdO3bI19fX7qd69eqSpGPHjtkt//KP5y/3008/qWnTpvLw8FCZMmXk6+uryZMn68yZM7Y+hw4dkouLS455XHkXhuPHj+v06dP64osvctSVPQ74yrpyU65cOYWFhSksLEwdO3bUa6+9pqlTp2rdunWaOnWqrd/Jkyc1bNgw+fv7q3jx4vL19bXVeHn9udmxY4cefvhh+fj4yNvbW76+vrbAeuW0d9xxR44/4qVLl7Yb57p//37VqFHjmhe+7N27V2fOnJGfn1+O7ZOSkpKnbWPc4A1i8nq85HVf55fctq2Pj4+CgoJytEmy2+bnz5/XqFGjFBQUJKvVqnLlysnX11enT5++7v6XZAtCbdu2zbFdli9fnqf9cT1ubm664447crTHx8erb9++KlOmjG0cbKtWrSTlPP48PDxsY1SzXXn8DR48WNWrV9cDDzygO+64Q0899ZTtjUm2rKwsTZw4UdWqVbPbXtu2bbNbZl6OZUdkH1NXHkMBAQEqVaqUDh06ZNdesWLFHPO4cn3Hjh2r06dPq3r16qpbt65eeuklbdu2LdflG4ZxS9z3FuZVpMfMnjt3TvXq1dNTTz1lG1PkqGHDhmn58uX64IMPVLduXZ08eZJ7bZrUL7/8ooSEBM2ZM0dz5szJ8Xx0dLTatWsnSerVq5c+//xzLV26VF26dNG8efNUs2ZN1atXz9Y/KytLdevWVVRUVK7LuzIMXH4mKNtvv/2mzp07q2XLlvrss88UGBgod3d3zZgxQ998843D65iVlSVJeuKJJ9SnT59c+1xrXN213HfffZIuvUnMPmPUo0cPrVu3Ti+99JLq168vLy8vZWVlqX379rZacnP69Gm1atVK3t7eGjt2rKpWrSoPDw9t2rRJr7zySo5pr3bFvqPBMisrS35+fnYX/V3uysBypbJly+bpQrGrLduR46WwXG3b5mWbP//885oxY4aGDx+uZs2aycfHRxaLRb169brm/s+W3Wf27Nm2Cwwvlx9h7vKzodkyMzN1//336+TJk3rllVdUs2ZNlShRQocPH1bfvn3zfPxdzs/PT1u2bNHPP/+spUuXaunSpZoxY4Z69+6tr776SpL09ttv64033tBTTz2lN998U2XKlJGLi4uGDx+ep+11s/IaKPOy71u2bKn9+/fr+++/1/LlyzV16lRNnDhRU6ZMUf/+/e2mO3XqlN3t0gBHFekw+8ADD9guDslNWlqaXn/9dX377bc6ffq06tSpo3fffdd29e/OnTs1efJk/fXXX6pRo4akq59dw60vOjpafn5++vTTT3M8t2jRIn333XeaMmWKihcvrpYtWyowMFBz587VPffco19++cV2QU22qlWrauvWrbrvvvtu+KzDwoUL5eHhoZ9//llWq9XWPmPGDLt+lSpVUlZWlg4ePGh3W6x9+/bZ9fP19VXJkiWVmZl5w1fcX83FixclyXZvz1OnTik2NlaRkZEaNWqUrV9ePnZctWqVTpw4oUWLFqlly5a29oMHD95wfVWrVtXvv/+ujIyMq17EVbVqVa1YsUItWrTI9c3F9dSsWVPR0dE6c+aM7UylI/Xl5XjJ676+msI8A7ZgwQL16dNHEyZMsLVduHBBp0+fzlNN2Rfl+fn55fvxei3bt2/Xnj179NVXX6l379629msNEciLYsWKqVOnTurUqZOysrI0ePBgff7553rjjTdsd4lo06aNpk2bZjfd6dOn7cJeXo5lR/Zz9jG1d+9e24V30qWLRU+fPq1KlSo5uKaXZN/5pV+/fkpJSVHLli01ZsyYHGH24MGDdicCAEcV6WEG1zNkyBCtX79ec+bM0bZt29S9e3e1b9/e9sf4xx9/VJUqVfTTTz+pcuXKCg4OVv/+/Tkza0Lnz5/XokWL9OCDD6pbt245foYMGaKzZ8/avqnGxcVF3bp1048//qjZs2fr4sWLdkMMpEtnJQ8fPqwvv/wy1+WdO3fuunW5urrKYrHY3eInLi4ux5CY8PBwSZe+3elyH3/8cY75de3aVQsXLtRff/2VY3nHjx+/bk1X8+OPP0qS7Y9S9tmbK8+OTpo06brzym3a9PT0HOvniK5duyopKUmffPJJjueyl9OjRw9lZmbqzTffzNHn4sWLOULYlZo1aybDMLRx40aH68vr8ZLXfX01JUqUuO565BdXV9cc+//jjz/Occuq7Pu6XllXeHi4vL299fbbbysjIyPH/G/meL2W3I4/wzDsbqPlqCtvR+fi4mL7FCR7uFJu22v+/Pk6fPiwXVtejuXsuzLkZV936NBBUs7fzexPCfJyp4wrXbm+Xl5eCgkJyXGrrzNnzmj//v1q3ry5w8sAshXpM7PXEh8frxkzZig+Pt52O5QRI0Zo2bJlmjFjht5++20dOHBAhw4d0vz58zVr1ixlZmbqhRdeULdu3fTLL784eQ3giB9++EFnz55V586dc32+adOm8vX1VXR0tC209uzZUx9//LFGjx6tunXr2p3RkKQnn3xS8+bN07PPPquVK1eqRYsWyszM1K5duzRv3jz9/PPPatSo0TXr6tixo6KiotS+fXs99thjOnbsmD799FOFhITYjT8LDQ1V165dNWnSJJ04ccJ2u6Y9e/ZIsj9L884772jlypVq0qSJBgwYoNq1a+vkyZPatGmTVqxYkac3Y4cPH9bXX38t6VLI3Lp1qz7//HO7i1K8vb3VsmVLvffee8rIyFCFChW0fPnyPJ1dbd68uUqXLq0+ffpo6NChslgsmj179g2PR5Wk3r17a9asWYqIiNCGDRt077336ty5c1qxYoUGDx6shx56SK1atdLAgQM1fvx4bdmyRe3atZO7u7v27t2r+fPn68MPP1S3bt2uuox77rlHZcuW1YoVK2wXbl0uNjZWFy5cyNHepUuXPB8vjuzr3ISGhmry5Ml66623FBISIj8/v1xrzQ8PPvigZs+eLR8fH9WuXVvr16/XihUrVLZsWbt+9evXl6urq959912dOXNGVqtVbdu2lZ+fnyZPnqwnn3xSDRs2VK9eveTr66v4+Hj997//VYsWLXINdDerZs2aqlq1qkaMGKHDhw/L29tbCxcuvOEhJJJsJzratm2rO+64Q4cOHdLHH3+s+vXr2147HnzwQY0dO1b9+vVT8+bNtX37dkVHR+f4MoG8HMvFixdX7dq1NXfuXFWvXl1lypRRnTp1VKdOnRy11atXT3369NEXX3xhG+KzYcMGffXVV+rSpYvtglhH1K5dW61bt1ZoaKjKlCmjP//8UwsWLNCQIUPs+q1YsUKGYeihhx5yeBmATeHePOHWJcn47rvvbI9/+uknQ5JRokQJux83NzejR48ehmEYxoABAwxJxu7du23TZd82Z9euXYW9CrgJnTp1Mjw8PIxz585dtU/fvn0Nd3d32+2nsrKyjKCgIEOS8dZbb+U6TXp6uvHuu+8ad955p2G1Wo3SpUsboaGhRmRkpHHmzBlbP0nGc889l+s8pk2bZlSrVs2wWq1GzZo1jRkzZuS4tY5hGMa5c+eM5557zihTpozh5eVldOnSxdi9e7chyXjnnXfs+h49etR47rnnjKCgIMPd3d0ICAgw7rvvPuOLL7647ra68tZcLi4uhp+fn/Hoo48a+/bts+v777//Gg8//LBRqlQpw8fHx+jevbtx5MiRPN1Cau3atUbTpk2N4sWLG+XLlzdefvll2+2frrx91J133pmjzj59+hiVKlWya0tNTTVef/11o3Llyrb17tatm7F//367fl988YURGhpqFC9e3ChZsqRRt25d4+WXXzaOHDly3e0zdOhQIyQkxK4t+9ZcV/uZPXu2YRh5P17yuq9z266JiYlGx44djZIlSxqSbLfputqtuXLbtpUqVcr1tktXHsenTp0y+vXrZ5QrV87w8vIywsPDjV27dhmVKlUy+vTpYzftl19+aVSpUsVwdXXNUcfKlSuN8PBww8fHx/Dw8DCqVq1q9O3b1/jzzz+vuh+udLVbc5UoUSLX/n///bcRFhZmeHl5GeXKlTMGDBhgbN26Ncftx642jyt/RxcsWGC0a9fO8PPzM4oVK2ZUrFjRGDhwoJGQkGDrc+HCBePFF180AgMDjeLFixstWrQw1q9fb7Rq1SrH7dTyciyvW7fOCA0NNYoVK2b3O5fb60dGRoYRGRlpm19QUJAxcuRIu9vgGcbV9/2VNb711ltG48aNjVKlShnFixc3atasaYwbN85IT0+3m65nz57GPffck2N+gCMshnETpzpuIxaLRd99953tKxDnzp2rxx9/XDt27Mgx2N3Ly0sBAQEaPXp0jo+/zp8/L09PTy1fvtzuxtCAM2zZskUNGjTQ119/bftmIxSsAwcOqGbNmlq6dKntorjCwL6G2SQmJqpy5cqaM2cOZ2ZxUxgzexUNGjRQZmamjh07ppCQELuf7KtqW7RooYsXL9p9FWb2R303OmAeuFFXfs2mdGkMnIuLi91FVChYVapU0dNPP6133nmnwJbBvsbtYNKkSapbty5BFjetSJ+ZTUlJsV0B3KBBA0VFRalNmzYqU6aMKlasqCeeeEJr167VhAkT1KBBAx0/flyxsbG666671LFjR2VlZenuu++Wl5eXJk2apKysLD333HPy9vbW8uXLnbx2KGoiIyO1ceNGtWnTRm5ubrbb/zzzzDP6/PPPnV0e8hH7GgD+T5EOs6tWrcp1YHufPn00c+ZMZWRk6K233tKsWbN0+PBhlStXTk2bNlVkZKTq1q0rSTpy5Iief/55LV++XCVKlNADDzygCRMmqEyZMoW9OijiYmJiFBkZqb///lspKSmqWLGinnzySb3++uv5dnN13BrY1wDwf4p0mAUAAIC5MWYWAAAApkWYBQAAgGkVucFVWVlZOnLkiEqWLFmoX+sIAACAvDEMQ2fPnlX58uXl4nLtc69FLsweOXJEQUFBzi4DAAAA1/HPP//ojjvuuGYfp4bZ1atX6/3339fGjRuVkJBg96UFV7Nq1SpFRERox44dCgoK0n/+8x/17ds3z8ssWbKkpEsbx9vb+yaqB64uIyNDy5cvt30dKgDcTniNQ0FLTk5WUFCQLbddi1PD7Llz51SvXj099dRTeuSRR67b/+DBg+rYsaOeffZZRUdHKzY2Vv3791dgYKDCw8PztMzsoQXe3t6EWRSYjIwMeXp6ytvbmxd6ALcdXuNQWPIyJNSpYfaBBx7QAw88kOf+U6ZMUeXKlTVhwgRJUq1atbRmzRpNnDgxz2EWAAAAtw9TjZldv369wsLC7NrCw8M1fPjwq06TlpamtLQ02+Pk5GRJl95VZmRkFEidQPaxxTEG4HbEaxwKmiPHlqnCbGJiovz9/e3a/P39lZycrPPnz6t48eI5phk/frwiIyNztC9fvlyenp4FVisgXfqmJgC4XfEah4KSmpqa576mCrM3YuTIkYqIiLA9zh5Q3K5dO8bMosBkZGQoJiZG999/P+PJANx2eI1DQcv+JD0vTBVmAwICdPToUbu2o0ePytvbO9ezspJktVpltVpztLu7u/MLiALHcQbgdsZrHAqKI8eVqb4BrFmzZoqNjbVri4mJUbNmzZxUEQAAAJzJqWE2JSVFW7Zs0ZYtWyRduvXWli1bFB8fL+nSEIHevXvb+j/77LM6cOCAXn75Ze3atUufffaZ5s2bpxdeeMEZ5QMAAMDJnBpm//zzTzVo0EANGjSQJEVERKhBgwYaNWqUJCkhIcEWbCWpcuXK+u9//6uYmBjVq1dPEyZM0NSpU7ktFwAAQBHl1DGzrVu3lmEYV31+5syZuU6zefPmAqwKAAAAZmGqMbMAAADA5QizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC2nfp0tAOD2sGh3grNLQGHKzJSrpB/3HpVcXZ1dDQrJIzUCnV1CrjgzCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANNyepj99NNPFRwcLA8PDzVp0kQbNmy4Zv9JkyapRo0aKl68uIKCgvTCCy/owoULhVQtAAAAbiVODbNz585VRESERo8erU2bNqlevXoKDw/XsWPHcu3/zTff6NVXX9Xo0aO1c+dOTZs2TXPnztVrr71WyJUDAADgVuDUMBsVFaUBAwaoX79+ql27tqZMmSJPT09Nnz491/7r1q1TixYt9Nhjjyk4OFjt2rXTo48+et2zuQAAALg9uTlrwenp6dq4caNGjhxpa3NxcVFYWJjWr1+f6zTNmzfX119/rQ0bNqhx48Y6cOCAlixZoieffPKqy0lLS1NaWprtcXJysiQpIyNDGRkZ+bQ2gL3sY4tjDEVGZqazK0Bhyt7f7PcipTD/pjmyLKeF2aSkJGVmZsrf39+u3d/fX7t27cp1mscee0xJSUm65557ZBiGLl68qGefffaawwzGjx+vyMjIHO3Lly+Xp6fnza0EcB0xMTHOLgEoFK7OLgBO4Xpgi7NLQCFasrfwlpWamprnvk4Lszdi1apVevvtt/XZZ5+pSZMm2rdvn4YNG6Y333xTb7zxRq7TjBw5UhEREbbHycnJCgoKUrt27eTt7V1YpaOIycjIUExMjO6//365u7s7uxygwP2496izS0BhysyU64EtyqxSX3LlrUxR0ama//U75ZPsT9Lzwmlhtly5cnJ1ddXRo/YvgEePHlVAQECu07zxxht68skn1b9/f0lS3bp1de7cOT3zzDN6/fXX5eKScwiw1WqV1WrN0e7u7k7IQIHjOEORQaApmlxd2fdFSGH+PXNkWU67AKxYsWIKDQ1VbGysrS0rK0uxsbFq1qxZrtOkpqbmCKyu//+XyDCMgisWAAAAtySnDjOIiIhQnz591KhRIzVu3FiTJk3SuXPn1K9fP0lS7969VaFCBY0fP16S1KlTJ0VFRalBgwa2YQZvvPGGOnXqZAu1t6IPT33o7BJQyCwXLaqkSpp8erIMN95oFRXDSg9zdgkAUOQ4Ncz27NlTx48f16hRo5SYmKj69etr2bJltovC4uPj7c7E/uc//5HFYtF//vMfHT58WL6+vurUqZPGjRvnrFUAAACAE1mMIvb5fHJysnx8fHTmzJlCuwCMM7NFj+WiRZXWVdKh5oc4M1uEFOUzs4t2Jzi7BBSmzEy57t2ozGqhjJktQh6pEVhoy3Ikrzn962wBAACAG0WYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBaNxRmT58+ralTp2rkyJE6efKkJGnTpk06fPhwvhYHAAAAXIuboxNs27ZNYWFh8vHxUVxcnAYMGKAyZcpo0aJFio+P16xZswqiTgAAACAHh8/MRkREqG/fvtq7d688PDxs7R06dNDq1avztTgAAADgWhwOs3/88YcGDhyYo71ChQpKTEzMl6IAAACAvHA4zFqtViUnJ+do37Nnj3x9ffOlKAAAACAvHA6znTt31tixY5WRkSFJslgsio+P1yuvvKKuXbvme4EAAADA1TgcZidMmKCUlBT5+fnp/PnzatWqlUJCQlSyZEmNGzeuIGoEAAAAcuXw3Qx8fHwUExOjtWvXauvWrUpJSVHDhg0VFhZWEPUBAAAAV+VwmM3WokULtWjRIj9rAQAAABzi8DCDoUOH6qOPPsrR/sknn2j48OH5URMAAACQJw6H2YULF+Z6RrZ58+ZasGCBwwV8+umnCg4OloeHh5o0aaINGzZcs//p06f13HPPKTAwUFarVdWrV9eSJUscXi4AAADMz+FhBidOnJCPj0+Odm9vbyUlJTk0r7lz5yoiIkJTpkxRkyZNNGnSJIWHh2v37t3y8/PL0T89PV3333+//Pz8tGDBAlWoUEGHDh1SqVKlHF0NAAAA3AYcPjMbEhKiZcuW5WhfunSpqlSp4tC8oqKiNGDAAPXr10+1a9fWlClT5OnpqenTp+faf/r06Tp58qQWL16sFi1aKDg4WK1atVK9evUcXQ0AAADcBhw+MxsREaEhQ4bo+PHjatu2rSQpNjZWEyZM0KRJk/I8n/T0dG3cuFEjR460tbm4uCgsLEzr16/PdZoffvhBzZo103PPPafvv/9evr6+euyxx/TKK6/I1dU112nS0tKUlpZme5z9hQ8ZGRm2e+UWNMtFS6EsB7eO7H3Ovi9aCus15ZaUmensClCYsvc3+71IKczXOEeW5XCYfeqpp5SWlqZx48bpzTfflCQFBwdr8uTJ6t27d57nk5SUpMzMTPn7+9u1+/v7a9euXblOc+DAAf3yyy96/PHHtWTJEu3bt0+DBw9WRkaGRo8enes048ePV2RkZI725cuXy9PTM8/13oxKqlQoy8Gtp+KGis4uAYVoiYru+P3cTyfgdud6YIuzS0AhWrK38JaVmpqa574WwzCMG13Q8ePHVbx4cXl5eTk87ZEjR1ShQgWtW7dOzZo1s7W//PLL+vXXX/X777/nmKZ69eq6cOGCDh48aDsTGxUVpffff18JCQm5Lie3M7NBQUFKSkqSt7e3w3XfiMmnJxfKcnDrsFy0qOKGiopvHC/D7YZ/xWAyg0oNcnYJTvPj3qPOLgGFKTNTrge2KLNKfekqn4zi9tOpmv/1O+WT5ORklStXTmfOnLluXrvh+8xKkq+v7w1PW65cObm6uuroUfsXwKNHjyogICDXaQIDA+Xu7m43pKBWrVpKTExUenq6ihUrlmMaq9Uqq9Wao93d3V3u7u43XL8jCDNFl+FmsP+LkMJ6TbklEWiKJldX9n0RUpivcY4sy+ELwI4ePaonn3xS5cuXl5ubm1xdXe1+8qpYsWIKDQ1VbGysrS0rK0uxsbF2Z2ov16JFC+3bt09ZWVm2tj179igwMDDXIAsAAIDbm8NnZvv27av4+Hi98cYbCgwMlMVy4xe4REREqE+fPmrUqJEaN26sSZMm6dy5c+rXr58kqXfv3qpQoYLGjx8vSRo0aJA++eQTDRs2TM8//7z27t2rt99+W0OHDr3hGgAAAGBeDofZNWvW6LffflP9+vVveuE9e/bU8ePHNWrUKCUmJqp+/fpatmyZ7aKw+Ph4ubj838njoKAg/fzzz3rhhRd01113qUKFCho2bJheeeWVm64FAAAA5uNwmA0KCtJNXDOWw5AhQzRkyJBcn1u1alWOtmbNmul///tfvi0fAAAA5uXwmNlJkybp1VdfVVxcXAGUAwAAAOSdw2dme/bsqdTUVFWtWlWenp45rjY7efJkvhUHAAAAXIvDYdaRb/kCAAAACpLDYbZPnz4FUQcAAADgsJv60oQLFy4oPT3drq2wvlULAAAAcPgCsHPnzmnIkCHy8/NTiRIlVLp0absfAAAAoLA4HGZffvll/fLLL5o8ebKsVqumTp2qyMhIlS9fXrNmzSqIGgEAAIBcOTzM4Mcff9SsWbPUunVr9evXT/fee69CQkJUqVIlRUdH6/HHHy+IOgEAAIAcHD4ze/LkSVWpUkXSpfGx2bfiuueee7R69er8rQ4AAAC4BofDbJUqVXTw4EFJUs2aNTVv3jxJl87YlipVKl+LAwAAAK7F4TDbr18/bd26VZL06quv6tNPP5WHh4deeOEFvfTSS/leIAAAAHA1Do+ZfeGFF2z/DwsL065du7Rx40aFhITorrvuytfiAAAAgGu5qfvMSlKlSpVUqVKl/KgFAAAAcEiewuxHH32U5xkOHTr0hosBAAAAHJGnMDtx4sQ8zcxisRBmAQAAUGjyFGaz714AAAAA3EocvpsBAAAAcKu4oQvA/v33X/3www+Kj49Xenq63XNRUVH5UhgAAABwPQ6H2djYWHXu3FlVqlTRrl27VKdOHcXFxckwDDVs2LAgagQAAABy5fAwg5EjR2rEiBHavn27PDw8tHDhQv3zzz9q1aqVunfvXhA1AgAAALlyOMzu3LlTvXv3liS5ubnp/Pnz8vLy0tixY/Xuu+/me4EAAADA1TgcZkuUKGEbJxsYGKj9+/fbnktKSsq/ygAAAIDrcHjMbNOmTbVmzRrVqlVLHTp00Isvvqjt27dr0aJFatq0aUHUCAAAAOTK4TAbFRWllJQUSVJkZKRSUlI0d+5cVatWjTsZAAAAoFA5HGarVKli+3+JEiU0ZcqUfC0IAAAAyKub/tKEAwcOaMeOHcrKysqPegAAAIA8y3OYzcjI0OjRo9WpUyeNGzdOmZmZevTRR1WtWjXdddddtvvNAgAAAIUlz2H21Vdf1eTJkxUQEKDp06frkUce0ebNm/XNN99ozpw5cnNz0+uvv16QtQIAAAB28jxmdsGCBZo5c6Y6dOigPXv2qGbNmvrvf/+rBx54QJLk5+enxx9/vMAKBQAAAK6U5zOzR44cUb169SRJ1atXl9VqVUhIiO356tWrKzExMf8rBAAAAK4iz2E2MzNT7u7utsdubm5ydXX9vxm5uMgwjPytDgAAALgGh27N9fPPP8vHx0eSlJWVpdjYWP3111+SpNOnT+d7cQAAAMC1OBRm+/TpY/d44MCBdo8tFsvNVwQAAADkUZ7DLPeRBQAAwK3mpr80AQAAAHAWwiwAAABMizALAAAA0yLMAgAAwLQIswAAADCtGwqzp0+f1tSpUzVy5EidPHlSkrRp0yYdPnw4X4sDAAAArsWh+8xK0rZt2xQWFiYfHx/FxcVpwIABKlOmjBYtWqT4+HjNmjWrIOoEAAAAcnD4zGxERIT69u2rvXv3ysPDw9beoUMHrV69Ol+LAwAAAK7F4TD7xx9/5PjmL0mqUKGCEhMT86UoAAAAIC8cDrNWq1XJyck52vfs2SNfX998KQoAAADIC4fDbOfOnTV27FhlZGRIkiwWi+Lj4/XKK6+oa9eu+V4gAAAAcDUOh9kJEyYoJSVFfn5+On/+vFq1aqWQkBCVLFlS48aNK4gaAQAAgFw5fDcDHx8fxcTEaM2aNdq2bZtSUlLUsGFDhYWFFUR9AAAAwFU5HGaz3XPPPbrnnnvysxYAAADAIQ6H2Y8++ijXdovFIg8PD4WEhKhly5ZydXW96eIAAACAa3E4zE6cOFHHjx9XamqqSpcuLUk6deqUPD095eXlpWPHjqlKlSpauXKlgoKC8r1gAAAAIJvDF4C9/fbbuvvuu7V3716dOHFCJ06c0J49e9SkSRN9+OGHio+PV0BAgF544YWCqBcAAACwcfjM7H/+8x8tXLhQVatWtbWFhITogw8+UNeuXXXgwAG999573KYLAAAABc7hM7MJCQm6ePFijvaLFy/avgGsfPnyOnv27M1XBwAAAFyDw2G2TZs2GjhwoDZv3mxr27x5swYNGqS2bdtKkrZv367KlSvnX5UAAABALhwOs9OmTVOZMmUUGhoqq9Uqq9WqRo0aqUyZMpo2bZokycvLSxMmTMj3YgEAAIDLOTxmNiAgQDExMdq1a5f27NkjSapRo4Zq1Khh69OmTZv8qxAAAAC4ihv+0oSaNWuqZs2a+VkLAAAA4JAbCrP//vuvfvjhB8XHxys9Pd3uuaioqHwpDAAAALgeh8NsbGysOnfurCpVqmjXrl2qU6eO4uLiZBiGGjZsWBA1AgAAALly+AKwkSNHasSIEdq+fbs8PDy0cOFC/fPPP2rVqpW6d+9eEDUCAAAAuXI4zO7cuVO9e/eWJLm5uen8+fPy8vLS2LFj9e677+Z7gQAAAMDVOBxmS5QoYRsnGxgYqP3799ueS0pKyr/KAAAAgOtweMxs06ZNtWbNGtWqVUsdOnTQiy++qO3bt2vRokVq2rRpQdQIAAAA5MrhMBsVFaWUlBRJUmRkpFJSUjR37lxVq1aNOxkAAACgUDkUZjMzM/Xvv//qrrvuknRpyMGUKVMKpDAAAADgehwaM+vq6qp27drp1KlTBVUPAAAAkGcOXwBWp04dHThwoCBqAQAAABzicJh96623NGLECP30009KSEhQcnKy3Q8AAABQWBy+AKxDhw6SpM6dO8tisdjaDcOQxWJRZmZm/lUHAAAAXIPDYXblypUFUQcAAADgMIfDbKtWrQqiDgAAAMBhDo+ZlaTffvtNTzzxhJo3b67Dhw9LkmbPnq01a9bka3EAAADAtTgcZhcuXKjw8HAVL15cmzZtUlpamiTpzJkzevvtt/O9QAAAAOBqbuhuBlOmTNGXX34pd3d3W3uLFi20adOmfC0OAAAAuBaHw+zu3bvVsmXLHO0+Pj46ffp0ftQEAAAA5InDYTYgIED79u3L0b5mzRpVqVIlX4oCAAAA8sLhMDtgwAANGzZMv//+uywWi44cOaLo6GiNGDFCgwYNKogaAQAAgFw5fGuuV199VVlZWbrvvvuUmpqqli1bymq1asSIEXr++ecLokYAAAAgVw6HWYvFotdff10vvfSS9u3bp5SUFNWuXVteXl4FUR8AAABwVQ4PM/j666+VmpqqYsWKqXbt2mrcuDFBFgAAAE7hcJh94YUX5Ofnp8cee0xLlixRZmbmTRfx6aefKjg4WB4eHmrSpIk2bNiQp+nmzJkji8WiLl263HQNAAAAMB+Hw2xCQoItRPbo0UOBgYF67rnntG7duhsqYO7cuYqIiNDo0aO1adMm1atXT+Hh4Tp27Ng1p4uLi9OIESN077333tByAQAAYH4Oh1k3Nzc9+OCDio6O1rFjxzRx4kTFxcWpTZs2qlq1qsMFREVFacCAAerXr59q166tKVOmyNPTU9OnT7/qNJmZmXr88ccVGRnJ7cAAAACKMIcvALucp6enwsPDderUKR06dEg7d+50aPr09HRt3LhRI0eOtLW5uLgoLCxM69evv+p0Y8eOlZ+fn55++mn99ttv11xGWlqa7St3JSk5OVmSlJGRoYyMDIfqvVGWi5ZCWQ5uHdn7nH1ftBTWa8otKR+GnMFEsvc3+71IKczXOEeWdUNhNjU1Vd99952io6MVGxuroKAgPfroo1qwYIFD80lKSlJmZqb8/f3t2v39/bVr165cp1mzZo2mTZumLVu25GkZ48ePV2RkZI725cuXy9PT06F6b1QlVSqU5eDWU3FDRWeXgEK0REucXYLTuDq7ADiF64Etzi4BhWjJ3sJbVmpqap77Ohxme/XqpZ9++kmenp7q0aOH3njjDTVr1szR2dyQs2fP6sknn9SXX36pcuXK5WmakSNHKiIiwvY4OTlZQUFBateunby9vQuqVDuTT08ulOXg1mG5aFHFDRUV3zhehpvh7HJQSAaVKrpfHPPj3qPOLgGFKTNTrge2KLNKfcmVtzJFRadq/tfvlE+yP0nPC4fDrKurq+bNm6fw8HC5XnEA//XXX6pTp06e51WuXDm5urrq6FH7F8GjR48qICAgR//9+/crLi5OnTp1srVlZWVJujSWd/fu3TnG7VqtVlmt1hzzcnd3l7u7e55rvRmEmaLLcDPY/0VIYb2m3JIINEWTqyv7vggpzNc4R5bl8AVg0dHR6tChgy3Inj17Vl988YUaN26sevXqOTSvYsWKKTQ0VLGxsba2rKwsxcbG5nq2t2bNmtq+fbu2bNli++ncubPatGmjLVu2KCgoyNHVAQAAgInd8AVgq1ev1rRp07Rw4UKVL19ejzzyiD799FOH5xMREaE+ffqoUaNGaty4sSZNmqRz586pX79+kqTevXurQoUKGj9+vDw8PHKc+S1VqpQkOXRGGAAAALcHh8JsYmKiZs6cqWnTpik5OVk9evRQWlqaFi9erNq1a99QAT179tTx48c1atQoJSYmqn79+lq2bJntorD4+Hi5uDh8AhkAAABFQJ7DbKdOnbR69Wp17NhRkyZNUvv27eXq6qopU6bcdBFDhgzRkCFDcn1u1apV15x25syZN718AAAAmFOew+zSpUs1dOhQDRo0SNWqVSvImgAAAIA8yfPn92vWrNHZs2cVGhqqJk2a6JNPPlFSUlJB1gYAAABcU57DbNOmTfXll18qISFBAwcO1Jw5c1S+fHllZWUpJiZGZ8+eLcg6AQAAgBwcvrKqRIkSeuqpp7RmzRpt375dL774ot555x35+fmpc+fOBVEjAAAAkKubuk1AjRo19N577+nff//Vt99+m181AQAAAHmSL/e8cnV1VZcuXfTDDz/kx+wAAACAPOEGrgAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABM65YIs59++qmCg4Pl4eGhJk2aaMOGDVft++WXX+ree+9V6dKlVbp0aYWFhV2zPwAAAG5fTg+zc+fOVUREhEaPHq1NmzapXr16Cg8P17Fjx3Ltv2rVKj366KNauXKl1q9fr6CgILVr106HDx8u5MoBAADgbE4Ps1FRURowYID69eun2rVra8qUKfL09NT06dNz7R8dHa3Bgwerfv36qlmzpqZOnaqsrCzFxsYWcuUAAABwNjdnLjw9PV0bN27UyJEjbW0uLi4KCwvT+vXr8zSP1NRUZWRkqEyZMrk+n5aWprS0NNvj5ORkSVJGRoYyMjJuovq8s1y0FMpycOvI3ufs+6KlsF5TbkmZmc6uAIUpe3+z34uUwnyNc2RZTg2zSUlJyszMlL+/v127v7+/du3alad5vPLKKypfvrzCwsJyfX78+PGKjIzM0b58+XJ5eno6XvQNqKRKhbIc3Hoqbqjo7BJQiJZoibNLcBpXZxcAp3A9sMXZJaAQLdlbeMtKTU3Nc1+nhtmb9c4772jOnDlatWqVPDw8cu0zcuRIRURE2B4nJyfbxtl6e3sXSp2TT08ulOXg1mG5aFHFDRUV3zhehpvh7HJQSAaVGuTsEpzmx71HnV0CClNmplwPbFFmlfqSK29liopO1fyv3ymfZH+SnhdODbPlypWTq6urjh61fxE8evSoAgICrjntBx98oHfeeUcrVqzQXXfdddV+VqtVVqs1R7u7u7vc3d1vrHAHEWaKLsPNYP8XIYX1mnJLItAUTa6u7PsipDBf4xxZllMvACtWrJhCQ0PtLt7KvpirWbNmV53uvffe05tvvqlly5apUaNGhVEqAAAAbkFOH2YQERGhPn36qFGjRmrcuLEmTZqkc+fOqV+/fpKk3r17q0KFCho/frwk6d1339WoUaP0zTffKDg4WImJiZIkLy8veXl5OW09AAAAUPicHmZ79uyp48ePa9SoUUpMTFT9+vW1bNky20Vh8fHxcnH5vxPIkydPVnp6urp162Y3n9GjR2vMmDGFWToAAACczOlhVpKGDBmiIUOG5PrcqlWr7B7HxcUVfEEAAAAwBad/aQIAAABwowizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtG6JMPvpp58qODhYHh4eatKkiTZs2HDN/vPnz1fNmjXl4eGhunXrasmSJYVUKQAAAG4lTg+zc+fOVUREhEaPHq1NmzapXr16Cg8P17Fjx3Ltv27dOj366KN6+umntXnzZnXp0kVdunTRX3/9VciVAwAAwNmcHmajoqI0YMAA9evXT7Vr19aUKVPk6emp6dOn59r/ww8/VPv27fXSSy+pVq1aevPNN9WwYUN98sknhVw5AAAAnM3NmQtPT0/Xxo0bNXLkSFubi4uLwsLCtH79+lynWb9+vSIiIuzawsPDtXjx4lz7p6WlKS0tzfb4zJkzkqSTJ08qIyPjJtcgb9LOpF2/E24vF6XU1FRdOHXByb9lKEwnsk44uwSnST1z2tkloDBlZso1NVWZZ05Lrq7OrgaF5MSJYoW2rLNnz0qSDMO4bl+n/plNSkpSZmam/P397dr9/f21a9euXKdJTEzMtX9iYmKu/cePH6/IyMgc7ZUrV77BqgEgd6/oFWeXAAC3lbNnz8rHx+eafW77c0YjR460O5OblZWlkydPqmzZsrJYLE6sDLez5ORkBQUF6Z9//pG3t7ezywGAfMVrHAqaYRg6e/asypcvf92+Tg2z5cqVk6urq44ePWrXfvToUQUEBOQ6TUBAgEP9rVarrFarXVupUqVuvGjAAd7e3rzQA7ht8RqHgnS9M7LZnHoBWLFixRQaGqrY2FhbW1ZWlmJjY9WsWbNcp2nWrJldf0mKiYm5an8AAADcvpw+zCAiIkJ9+vRRo0aN1LhxY02aNEnnzp1Tv379JEm9e/dWhQoVNH78eEnSsGHD1KpVK02YMEEdO3bUnDlz9Oeff+qLL75w5moAAADACZweZnv27Knjx49r1KhRSkxMVP369bVs2TLbRV7x8fFycfm/E8jNmzfXN998o//85z967bXXVK1aNS1evFh16tRx1ioAOVitVo0ePTrHEBcAuB3wGodbicXIyz0PAAAAgFuQ0780AQAAALhRhFkAAACYFmEWAAAApkWYBfLJmDFj5O/vL4vFctWvVwYAszAMQ88884zKlCkji8WiLVu2OLskIFeEWRR5ffv2lcVisf2ULVtW7du317Zt2/I8j507dyoyMlKff/65EhIS9MADDxRgxQCQf9avXy9XV1d17NjRrn3ZsmWaOXOmfvrpJyUkJKhOnTq8WcctiTALSGrfvr0SEhKUkJCg2NhYubm56cEHH8zz9Pv375ckPfTQQwoICLjh29VkZGTc0HQAcKOmTZum559/XqtXr9aRI0ds7fv371dgYKCaN2+ugIAAubnl3908ea1DfiLMArp0z8SAgAAFBASofv36evXVV/XPP//o+PHjkqR//vlHPXr0UKlSpVSmTBk99NBDiouLk3RpeEGnTp0kSS4uLrJYLJIufZvd2LFjdccdd8hqtdruoZwtLi5OFotFc+fOVatWreTh4aHo6GhJ0tSpU1WrVi15eHioZs2a+uyzzwpxawAoKlJSUjR37lwNGjRIHTt21MyZMyVd+sTq+eefV3x8vCwWi4KDgxUcHCxJevjhh21t2b7//ns1bNhQHh4eqlKliiIjI3Xx4kXb8xaLRZMnT1bnzp1VokQJjRs3rhDXErc9Ayji+vTpYzz00EO2x2fPnjUGDhxohISEGJmZmUZ6erpRq1Yt46mnnjK2bdtm/P3338Zjjz1m1KhRw0hLSzPOnj1rzJgxw5BkJCQkGAkJCYZhGEZUVJTh7e1tfPvtt8auXbuMl19+2XB3dzf27NljGIZhHDx40JBkBAcHGwsXLjQOHDhgHDlyxPj666+NwMBAW9vChQuNMmXKGDNnznTG5gFwG5s2bZrRqFEjwzAM48cffzSqVq1qZGVlGadPnzbGjh1r3HHHHUZCQoJx7Ngx49ixY4YkY8aMGbY2wzCM1atXG97e3sbMmTON/fv3G8uXLzeCg4ONMWPG2JYjyfDz8zOmT59u7N+/3zh06JBT1he3J8Isirw+ffoYrq6uRokSJYwSJUoYkozAwEBj48aNhmEYxuzZs40aNWoYWVlZtmnS0tKM4sWLGz///LNhGIbx3XffGVe+Nyxfvrwxbtw4u7a7777bGDx4sGEY/xdmJ02aZNenatWqxjfffGPX9uabbxrNmjXLnxUGgP+vefPmttegjIwMo1y5csbKlSsNwzCMiRMnGpUqVbLrL8n47rvv7Nruu+8+4+2337Zrmz17thEYGGg33fDhw/O9fsAwDMPpX2cL3AratGmjyZMnS5JOnTqlzz77TA888IA2bNigrVu3at++fSpZsqTdNBcuXLCNlb1ScnKyjhw5ohYtWti1t2jRQlu3brVra9Soke3/586d0/79+/X0009rwIABtvaLFy/Kx8fnptYRAC63e/dubdiwQd99950kyc3NTT179tS0adPUunXrPM9n69atWrt2rd3QgczMTF24cEGpqany9PSUZP9aB+QnwiwgqUSJEgoJCbE9njp1qnx8fPTll18qJSVFoaGhtvGsl/P19c2XZWdLSUmRJH355Zdq0qSJXT9XV9ebXhYAZJs2bZouXryo8uXL29oMw5DVatUnn3yS5/mkpKQoMjJSjzzySI7nPDw8bP+//LUOyE+EWSAXFotFLi4uOn/+vBo2bKi5c+fKz89P3t7eeZre29tb5cuX19q1a9WqVStb+9q1a9W4ceOrTufv76/y5cvrwIEDevzxx296PQAgNxcvXtSsWbM0YcIEtWvXzu65Ll266Ntvv811Ond3d2VmZtq1NWzYULt377Y7IQAUJsIsICktLU2JiYmSLg0z+OSTT5SSkqJOnTqpcePGev/99/XQQw/Z7k5w6NAhLVq0SC+//LLuuOOOXOf50ksvafTo0apatarq16+vGTNmaMuWLbme4b1cZGSkhg4dKh8fH7Vv315paWn6888/derUKUVEROT7ugMoen766SedOnVKTz/9dI4hTF27dtW0adNyfUMdHBys2NhYtWjRQlarVaVLl9aoUaP04IMPqmLFiurWrZtcXFy0detW/fXXX3rrrbcKa5VQhHFrLkCXbg4eGBiowMBANWnSRH/88Yfmz5+v1q1by9PTU6tXr1bFihX1yCOPqFatWnr66ad14cKFa56pHTp0qCIiIvTiiy+qbt26WrZsmX744QdVq1btmrX0799fU6dO1YwZM1S3bl21atVKM2fOVOXKlfN7tQEUUdOmTVNYWFiuY/G7du2qP//8U8nJyTmemzBhgmJiYhQUFKQGDRpIksLDw/XTTz9p+fLluvvuu9W0aVNNnDhRlSpVKvD1ACTJYhiG4ewiAAAAgBvBmVkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAMKlVq1bJYrHo9OnTzi4FAJyGMAvgtmKxWK75M2bMGGeXeENat26t4cOH27U1b95cCQkJuX4laX46fvy4Bg0apIoVK8pqtSogIEDh4eFau3atrY/FYtHixYsLtA4AyI2bswsAgPyUkJBg+//cuXM1atQo7d6929bm5eVl+79hGMrMzJSbmzlfCosVK6aAgIACX07Xrl2Vnp6ur776SlWqVNHRo0cVGxurEydOFPiyAeB6ODML4LYSEBBg+/Hx8ZHFYrE93rVrl0qWLKmlS5cqNDRUVqtVa9as0f79+/XQQw/J399fXl5euvvuu7VixQq7+QYHB+vtt9/WU089pZIlS6pixYr64osvbM+np6dryJAhCgwMlIeHhypVqqTx48fbno+KilLdunVVokQJBQUFafDgwUpJSbFbxtq1a9W6dWt5enqqdOnSCg8P16lTp9S3b1/9+uuv+vDDD21nmOPi4nIdZrBw4ULdeeedslqtCg4O1oQJExxajyudPn1av/32m9599121adNGlSpVUuPGjTVy5Eh17tzZNk9Jevjhh2WxWGyP87JdExIS1LFjRxUvXlyVK1fWN998o+DgYE2aNMmuhv79+8vX11fe3t5q27attm7detWaARQthFkARc6rr76qd955Rzt37tRdd92llJQUdejQQbGxsdq8ebPat2+vTp06KT4+3m66CRMmqFGjRtq8ebMGDx6sQYMG2c76fvTRR/rhhx80b9487d69W9HR0bZQJ0kuLi766KOPtGPHDn311Vf65Zdf9PLLL9ue37Jli+677z7Vrl1b69ev15o1a9SpUydlZmbqww8/VLNmzTRgwAAlJCQoISFBQUFBOdZr48aN6tGjh3r16qXt27drzJgxeuONNzRz5sw8r8eVvLy85OXlpcWLFystLS3XPn/88YckacaMGUpISLA9zst27d27t44cOaJVq1Zp4cKF+uKLL3Ts2DG7+Xfv3l3Hjh3T0qVLtXHjRjVs2FD33XefTp48mWs9AIoYAwBuUzNmzDB8fHxsj1euXGlIMhYvXnzdae+8807j448/tj2uVKmS8cQTT9geZ2VlGX5+fsbkyZMNwzCM559/3mjbtq2RlZWVp9rmz59vlC1b1vb40UcfNVq0aHHV/q1atTKGDRtm15a9PqdOnTIMwzAee+wx4/7777fr89JLLxm1a9fO83rkZsGCBUbp0qUNDw8Po3nz5sbIkSONrVu32vWRZHz33XdXnUe2y7frzp07DUnGH3/8YXt+7969hiRj4sSJhmEYxm+//WZ4e3sbFy5csJtP1apVjc8///y6ywNw++PMLIAip1GjRnaPU1JSNGLECNWqVUulSpWSl5eXdu7cmePM7F133WX7f/bwheyziH379tWWLVtUo0YNDR06VMuXL7ebdsWKFbrvvvtUoUIFlSxZUk8++aROnDih1NRUSf93ZvZm7Ny5Uy1atLBra9Gihfbu3avMzMw8rUduunbtqiNHjuiHH35Q+/bttWrVKjVs2DDHGd8rXW+77t69W25ubmrYsKFtmpCQEJUuXdr2eOvWrUpJSVHZsmVtZ4m9vLx08OBB7d+/P0/bBcDtzZxXPQDATShRooTd4xEjRigmJkYffPCBQkJCVLx4cXXr1k3p6el2/dzd3e0eWywWZWVlSZIaNmyogwcPaunSpVqxYoV69OihsLAwLViwQHFxcXrwwQc1aNAgjRs3TmXKlNGaNWv09NNPKz09XZ6enipevHjBrnQe1+NqPDw8dP/99+v+++/XG2+8of79+2v06NHq27fvVafJ63a9lpSUFAUGBmrVqlU5nitVqlSe5wPg9kWYBVDkrV27Vn379tXDDz8s6VKAiouLc3g+3t7e6tmzp3r27Klu3bqpffv2OnnypDZu3KisrCxNmDBBLi6XPhCbN2+e3bR33XWXYmNjFRkZmeu8ixUrZnd2NTe1atWyu11W9rpVr15drq6uDq/PtdSuXdvuVlzu7u456rvedq1Ro4YuXryozZs3KzQ0VJK0b98+nTp1ytanYcOGSkxMlJubm90YZADIxjADAEVetWrVtGjRIm3ZskVbt27VY489dt0zlVeKiorSt99+q127dmnPnj2aP3++AgICVKpUKYWEhCgjI0Mff/yxDhw4oNmzZ2vKlCl2048cOVJ//PGHBg8erG3btmnXrl2aPHmykpKSJF26Y8Dvv/+uuLg4JSUl5Vrfiy++qNjYWL355pvas2ePvvrqK33yyScaMWLEDW+bEydOqG3btvr666+1bds2HTx4UPPnz9d7772nhx56yNYvODhYsbGxSkxMtIXR623XmjVrKiwsTM8884w2bNigzZs365lnnlHx4sVlsVgkSWFhYWrWrJm6dOmi5cuXKy4uTuvWrdPrr7+uP//884bXC8DtgzALoMiLiopS6dKl1bx5c3Xq1Enh4eF24zjzomTJknrvvffUqFEj3X333YqLi9OSJUvk4uKievXqKSoqSu+++67q1Kmj6Ohou9t2SVL16tW1fPlybd26VY0bN1azZs30/fff2+6BO2LECLm6uqp27dry9fXNMZ5XunQWc968eZozZ47q1KmjUaNGaezYsdccCnA9Xl5eatKkiSZOnKiWLVuqTp06euONNzRgwAB98skntn4TJkxQTEyMgoKC1KBBA0l5266zZs2Sv7+/WrZsqYcfflgDBgxQyZIl5eHhIenSEIglS5aoZcuW6tevn6pXr65evXrp0KFD8vf3v+H1AnD7sBiGYTi7CAAAJOnff/9VUFCQ7YI5ALgewiwAwGl++eUXpaSkqG7dukpISNDLL7+sw4cPa8+ePTkuVAOA3HABGADAaTIyMvTaa6/pwIEDKlmypJo3b67o6GiCLIA848wsAAAATIsLwAAAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGn9P/HUauSi/2BLAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "source": [
        "for feature in balance_features:\n",
        "  if feature in df.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(df[feature], bins=50, edgecolor='black')  # Create histogram with 50 bins\n",
        "    plt.title(f\"Distribution of {feature}\")\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "  else:\n",
        "    print(f\"The column '{feature}' does not exist in the DataFrame.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "878rgOWup5aa",
        "outputId": "932bad34-b95b-4306-a83e-dd9cc9ace896"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The column 'newbalanceOrg' does not exist in the DataFrame.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values in relevant columns\n",
        "print(df['isFraud'].isnull().sum())\n",
        "print(df['isFlaggedFraud'].isnull().sum())\n",
        "\n",
        "# Check if \"isFlaggedFraud\" exists\n",
        "if 'isFlaggedFraud' in df.columns:\n",
        "  # Calculate confusion matrix\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "\n",
        "  # Count actual fraud cases (positive class)\n",
        "  actual_fraud = df[df['isFraud'] == 1].shape[0]\n",
        "\n",
        "  # Create confusion matrix\n",
        "  confusion_matrix_result = confusion_matrix(df['isFraud'], df['isFlaggedFraud'])\n",
        "\n",
        "  # Calculate precision, recall (assuming \"isFraud\" is the positive class)\n",
        "  true_positives = confusion_matrix_result[1, 1]\n",
        "  false_positives = confusion_matrix_result[0, 1]\n",
        "  false_negatives = confusion_matrix_result[1, 0]\n",
        "\n",
        "  # Precision - How many flagged frauds were actually fraudulent?\n",
        "  precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "\n",
        "  # Recall - How many actual frauds were flagged?\n",
        "  recall = true_positives / actual_fraud if actual_fraud > 0 else 0\n",
        "\n",
        "  print(\"\\nAnalysis of 'isFlaggedFraud' Feature:\")\n",
        "  print(confusion_matrix_result)\n",
        "\n",
        "  print(f\"\\nPrecision (Flagged Fraud that is Actual Fraud): {precision:.4f}\")\n",
        "  print(f\"Recall (Actual Fraud that is Flagged): {recall:.4f}\")\n",
        "else:\n",
        "  print(\"\\n'isFlaggedFraud' feature not found in the dataset.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "t-xrO29TpsWP",
        "outputId": "ec985c13-de97-42dd-bc8c-0943b6cbc7e2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py:380: RuntimeWarning: invalid value encountered in cast\n",
            "  if xp.any(data != data.astype(int)):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Input y_true contains NaN.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d20ca9a7fcf0>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# Create confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mconfusion_matrix_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isFraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'isFlaggedFraud'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0;31m# Calculate precision, recall (assuming \"isFraud\" is the positive class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \"\"\"\n\u001b[0;32m--> 317\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m     86\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input y_true contains NaN."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['isFlaggedFraud'], inplace=True)"
      ],
      "metadata": {
        "id": "u7HQimILsVJl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['isFlaggedFraud'])"
      ],
      "metadata": {
        "id": "o87cr7PtrD1V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "source": [
        "df['isFlaggedFraud'].fillna(0, inplace=True)  # Replace missing values with 0"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "d2OwKbxpsZO9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def handle_missing_values(df, method='drop'):\n",
        "  \"\"\"\n",
        "  This function handles missing values in a DataFrame.\n",
        "\n",
        "  Args:\n",
        "      data (pandas.DataFrame): The DataFrame containing the data.\n",
        "      method (str, optional): The method for handling missing values.\n",
        "                              Options are 'drop' (default) or 'impute'.\n",
        "\n",
        "  Returns:\n",
        "      pandas.DataFrame: The DataFrame with missing values handled.\n",
        "  \"\"\"\n",
        "  if method == 'drop':\n",
        "    # Drop rows with missing values\n",
        "    return df.dropna()\n",
        "  elif method == 'impute':\n",
        "    # Impute missing values (using median for this example)\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    imputer = SimpleImputer(strategy='median')\n",
        "    df = pd.DataFrame(imputer.fit_transform(df))\n",
        "    df.columns = list(df)  # Set column names after imputation\n",
        "    return df\n",
        "  else:\n",
        "    raise ValueError(\"Invalid method. Choose 'drop' or 'impute'.\")\n",
        "\n",
        "# Example usage (replace 'column1', 'column2' with your actual columns)\n",
        "missing_value_cols = ['column1', 'column2']  # Columns to handle\n",
        "data_preprocessed = handle_missing_values(df.copy(), method='drop')  # Copy data to avoid modifying original\n",
        "\n",
        "# Alternatively, for imputation:\n",
        "# data_preprocessed = handle_missing_values(data.copy(), method='impute')\n",
        "\n",
        "# Print results (optional)\n",
        "print(f\"Original data shape: {df.shape}\")\n",
        "print(f\"Preprocessed data shape (after handling missing values): {data_preprocessed.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkY6H55nsMBs",
        "outputId": "b793e157-ed56-44cc-cd4a-8c040c36acc0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data shape: (15120, 11)\n",
            "Preprocessed data shape (after handling missing values): (15120, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# List of categorical columns to encode\n",
        "categorical_columns = ['type', 'nameOrig', 'nameDest']\n",
        "\n",
        "# Apply LabelEncoder to each categorical column\n",
        "for col in categorical_columns:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Display the first few rows of the dataframe to check the encoding\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cBwTxA1vtbl",
        "outputId": "c959292b-6511-406e-c6a9-3cb5138720d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   step  type    amount  nameOrig  oldbalanceOrg  newbalanceOrig  nameDest  \\\n",
            "0     1     3   9839.64      1741       170136.0       160296.36      5970   \n",
            "1     1     3   1864.28      5240        21249.0        19384.72      6263   \n",
            "2     1     4    181.00      2350          181.0            0.00      1369   \n",
            "3     1     1    181.00     13863          181.0            0.00      1211   \n",
            "4     1     3  11668.14      8252        41554.0        29885.86      2723   \n",
            "\n",
            "   oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
            "0             0.0             0.0      0.0             0.0  \n",
            "1             0.0             0.0      0.0             0.0  \n",
            "2             0.0             0.0      1.0             0.0  \n",
            "3         21182.0             0.0      1.0             0.0  \n",
            "4             0.0             0.0      0.0             0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "jOC9h2lIyRDJ",
        "outputId": "fb1bc7a1-0f1c-4bbb-bff0-8bbda18d50b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
              "0     1   PAYMENT   9839.64  C1231006815      170136.00       160296.36   \n",
              "1     1   PAYMENT   1864.28  C1666544295       21249.00        19384.72   \n",
              "2     1  TRANSFER    181.00  C1305486145         181.00            0.00   \n",
              "3     1  CASH_OUT    181.00   C840083671         181.00            0.00   \n",
              "4     1   PAYMENT  11668.14  C2048537720       41554.00        29885.86   \n",
              "5     1   PAYMENT   7817.71    C90045638       53860.00        46042.29   \n",
              "6     1   PAYMENT   7107.77   C154988899      183195.00       176087.23   \n",
              "7     1   PAYMENT   7861.64  C1912850431      176087.23       168225.59   \n",
              "8     1   PAYMENT   4024.36  C1265012928        2671.00            0.00   \n",
              "9     1     DEBIT   5337.77   C712410124       41720.00        36382.23   \n",
              "\n",
              "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
              "0  M1979787155             0.0            0.00      0.0             0.0  \n",
              "1  M2044282225             0.0            0.00      0.0             0.0  \n",
              "2   C553264065             0.0            0.00      1.0             0.0  \n",
              "3    C38997010         21182.0            0.00      1.0             0.0  \n",
              "4  M1230701703             0.0            0.00      0.0             0.0  \n",
              "5   M573487274             0.0            0.00      0.0             0.0  \n",
              "6   M408069119             0.0            0.00      0.0             0.0  \n",
              "7   M633326333             0.0            0.00      0.0             0.0  \n",
              "8  M1176932104             0.0            0.00      0.0             0.0  \n",
              "9   C195600860         41898.0        40348.79      0.0             0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5adb3631-c08e-475d-81c9-b178f6af8246\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>step</th>\n",
              "      <th>type</th>\n",
              "      <th>amount</th>\n",
              "      <th>nameOrig</th>\n",
              "      <th>oldbalanceOrg</th>\n",
              "      <th>newbalanceOrig</th>\n",
              "      <th>nameDest</th>\n",
              "      <th>oldbalanceDest</th>\n",
              "      <th>newbalanceDest</th>\n",
              "      <th>isFraud</th>\n",
              "      <th>isFlaggedFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>9839.64</td>\n",
              "      <td>C1231006815</td>\n",
              "      <td>170136.00</td>\n",
              "      <td>160296.36</td>\n",
              "      <td>M1979787155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>1864.28</td>\n",
              "      <td>C1666544295</td>\n",
              "      <td>21249.00</td>\n",
              "      <td>19384.72</td>\n",
              "      <td>M2044282225</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>TRANSFER</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C1305486145</td>\n",
              "      <td>181.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C553264065</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>CASH_OUT</td>\n",
              "      <td>181.00</td>\n",
              "      <td>C840083671</td>\n",
              "      <td>181.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>C38997010</td>\n",
              "      <td>21182.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>11668.14</td>\n",
              "      <td>C2048537720</td>\n",
              "      <td>41554.00</td>\n",
              "      <td>29885.86</td>\n",
              "      <td>M1230701703</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>7817.71</td>\n",
              "      <td>C90045638</td>\n",
              "      <td>53860.00</td>\n",
              "      <td>46042.29</td>\n",
              "      <td>M573487274</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>7107.77</td>\n",
              "      <td>C154988899</td>\n",
              "      <td>183195.00</td>\n",
              "      <td>176087.23</td>\n",
              "      <td>M408069119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>7861.64</td>\n",
              "      <td>C1912850431</td>\n",
              "      <td>176087.23</td>\n",
              "      <td>168225.59</td>\n",
              "      <td>M633326333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>PAYMENT</td>\n",
              "      <td>4024.36</td>\n",
              "      <td>C1265012928</td>\n",
              "      <td>2671.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>M1176932104</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>DEBIT</td>\n",
              "      <td>5337.77</td>\n",
              "      <td>C712410124</td>\n",
              "      <td>41720.00</td>\n",
              "      <td>36382.23</td>\n",
              "      <td>C195600860</td>\n",
              "      <td>41898.0</td>\n",
              "      <td>40348.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5adb3631-c08e-475d-81c9-b178f6af8246')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5adb3631-c08e-475d-81c9-b178f6af8246 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5adb3631-c08e-475d-81c9-b178f6af8246');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a026f36-5992-43ef-9cf0-e6ffb7accd28\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a026f36-5992-43ef-9cf0-e6ffb7accd28')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a026f36-5992-43ef-9cf0-e6ffb7accd28 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.Sigmoid()  # Changed to Sigmoid for output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # Output a probability\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define input dimensions\n",
        "    input_dim = 100  # Dimension of the noise vector for the generator\n",
        "    output_dim = 9  # Dimension of the generated transaction (excluding 'isFraud' and 'isFlaggedFraud')\n",
        "\n",
        "    # Create instances of the Generator and Discriminator\n",
        "    generator = Generator(input_dim, output_dim)\n",
        "    discriminator = Discriminator(output_dim)\n",
        "\n",
        "    # Print the architectures\n",
        "    print(\"Generator Architecture:\\n\", generator)\n",
        "    print(\"\\nDiscriminator Architecture:\\n\", discriminator)\n",
        "\n",
        "    # Example input\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNHwf5sKy_RS",
        "outputId": "9e7989a7-3845-48b7-f413-df0bbd53344e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Architecture:\n",
            " Generator(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=512, out_features=9, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n",
            "\n",
            "Discriminator Architecture:\n",
            " Discriminator(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=9, out_features=512, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.2)\n",
            "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (3): LeakyReLU(negative_slope=0.2)\n",
            "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (5): LeakyReLU(negative_slope=0.2)\n",
            "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
            "    (7): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # Output a probability\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Function to initialize the weights of the networks\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "lr = 0.0002\n",
        "num_epochs = 100\n",
        "input_dim = 100  # Dimension of the noise vector for the generator\n",
        "output_dim = df.shape[1]  # Dimension of the generated transaction (excluding 'isFraud' and 'isFlaggedFraud')\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df.values)\n",
        "dataset = TensorDataset(torch.tensor(df_scaled, dtype=torch.float32))\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create instances of the Generator and Discriminator\n",
        "generator = Generator(input_dim, output_dim)\n",
        "discriminator = Discriminator(output_dim)\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training the GAN\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        # Train Discriminator\n",
        "        real_data = data[0]\n",
        "        batch_size = real_data.size(0)\n",
        "        labels_real = torch.ones(batch_size, 1)\n",
        "        labels_fake = torch.zeros(batch_size, 1)\n",
        "\n",
        "        # Real data\n",
        "        outputs = discriminator(real_data)\n",
        "        d_loss_real = criterion(outputs, labels_real)\n",
        "\n",
        "        # Fake data\n",
        "        noise = torch.randn(batch_size, input_dim)\n",
        "        fake_data = generator(noise)\n",
        "        outputs = discriminator(fake_data.detach())\n",
        "        d_loss_fake = criterion(outputs, labels_fake)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        outputs = discriminator(fake_data)\n",
        "        g_loss = criterion(outputs, labels_real)  # We want the generator to fool the discriminator\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Logging\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
        "\n",
        "# Save the trained models\n",
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNl0Hi0WEIHP",
        "outputId": "93fda489-b9ad-4cdb-92ab-a4db9618216f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch [32/100], Step [3800/7382], D Loss: 1.3874, G Loss: 0.7438\n",
            "Epoch [32/100], Step [3900/7382], D Loss: 1.3877, G Loss: 0.6822\n",
            "Epoch [32/100], Step [4000/7382], D Loss: 1.3821, G Loss: 0.6971\n",
            "Epoch [32/100], Step [4100/7382], D Loss: 1.3556, G Loss: 0.7201\n",
            "Epoch [32/100], Step [4200/7382], D Loss: 1.3887, G Loss: 0.6982\n",
            "Epoch [32/100], Step [4300/7382], D Loss: 1.3613, G Loss: 0.7025\n",
            "Epoch [32/100], Step [4400/7382], D Loss: 1.3745, G Loss: 0.7370\n",
            "Epoch [32/100], Step [4500/7382], D Loss: 1.3450, G Loss: 0.7500\n",
            "Epoch [32/100], Step [4600/7382], D Loss: 1.3434, G Loss: 0.7573\n",
            "Epoch [32/100], Step [4700/7382], D Loss: 1.3690, G Loss: 0.7346\n",
            "Epoch [32/100], Step [4800/7382], D Loss: 1.3515, G Loss: 0.7462\n",
            "Epoch [32/100], Step [4900/7382], D Loss: 1.3957, G Loss: 0.7240\n",
            "Epoch [32/100], Step [5000/7382], D Loss: 1.3720, G Loss: 0.7701\n",
            "Epoch [32/100], Step [5100/7382], D Loss: 1.3876, G Loss: 0.7205\n",
            "Epoch [32/100], Step [5200/7382], D Loss: 1.3808, G Loss: 0.6858\n",
            "Epoch [32/100], Step [5300/7382], D Loss: 1.3789, G Loss: 0.7401\n",
            "Epoch [32/100], Step [5400/7382], D Loss: 1.3398, G Loss: 0.7386\n",
            "Epoch [32/100], Step [5500/7382], D Loss: 1.3864, G Loss: 0.7706\n",
            "Epoch [32/100], Step [5600/7382], D Loss: 1.3763, G Loss: 0.7132\n",
            "Epoch [32/100], Step [5700/7382], D Loss: 1.3922, G Loss: 0.7091\n",
            "Epoch [32/100], Step [5800/7382], D Loss: 1.3684, G Loss: 0.7013\n",
            "Epoch [32/100], Step [5900/7382], D Loss: 1.3391, G Loss: 0.7390\n",
            "Epoch [32/100], Step [6000/7382], D Loss: 1.3694, G Loss: 0.7135\n",
            "Epoch [32/100], Step [6100/7382], D Loss: 1.3508, G Loss: 0.7658\n",
            "Epoch [32/100], Step [6200/7382], D Loss: 1.3774, G Loss: 0.7919\n",
            "Epoch [32/100], Step [6300/7382], D Loss: 1.3535, G Loss: 0.7029\n",
            "Epoch [32/100], Step [6400/7382], D Loss: 1.3545, G Loss: 0.7473\n",
            "Epoch [32/100], Step [6500/7382], D Loss: 1.3584, G Loss: 0.7444\n",
            "Epoch [32/100], Step [6600/7382], D Loss: 1.3792, G Loss: 0.7144\n",
            "Epoch [32/100], Step [6700/7382], D Loss: 1.3705, G Loss: 0.7285\n",
            "Epoch [32/100], Step [6800/7382], D Loss: 1.4078, G Loss: 0.7259\n",
            "Epoch [32/100], Step [6900/7382], D Loss: 1.3116, G Loss: 0.8051\n",
            "Epoch [32/100], Step [7000/7382], D Loss: 1.3846, G Loss: 0.7123\n",
            "Epoch [32/100], Step [7100/7382], D Loss: 1.3828, G Loss: 0.6881\n",
            "Epoch [32/100], Step [7200/7382], D Loss: 1.3680, G Loss: 0.7222\n",
            "Epoch [32/100], Step [7300/7382], D Loss: 1.3657, G Loss: 0.7476\n",
            "Epoch [33/100], Step [100/7382], D Loss: 1.3863, G Loss: 0.7321\n",
            "Epoch [33/100], Step [200/7382], D Loss: 1.3420, G Loss: 0.7456\n",
            "Epoch [33/100], Step [300/7382], D Loss: 1.3789, G Loss: 0.7151\n",
            "Epoch [33/100], Step [400/7382], D Loss: 1.3515, G Loss: 0.7774\n",
            "Epoch [33/100], Step [500/7382], D Loss: 1.3683, G Loss: 0.7077\n",
            "Epoch [33/100], Step [600/7382], D Loss: 1.3826, G Loss: 0.7209\n",
            "Epoch [33/100], Step [700/7382], D Loss: 1.3889, G Loss: 0.7151\n",
            "Epoch [33/100], Step [800/7382], D Loss: 1.3560, G Loss: 0.7710\n",
            "Epoch [33/100], Step [900/7382], D Loss: 1.3665, G Loss: 0.7142\n",
            "Epoch [33/100], Step [1000/7382], D Loss: 1.3748, G Loss: 0.6996\n",
            "Epoch [33/100], Step [1100/7382], D Loss: 1.3824, G Loss: 0.7168\n",
            "Epoch [33/100], Step [1200/7382], D Loss: 1.3546, G Loss: 0.7200\n",
            "Epoch [33/100], Step [1300/7382], D Loss: 1.3927, G Loss: 0.6892\n",
            "Epoch [33/100], Step [1400/7382], D Loss: 1.3953, G Loss: 0.7192\n",
            "Epoch [33/100], Step [1500/7382], D Loss: 1.3591, G Loss: 0.6851\n",
            "Epoch [33/100], Step [1600/7382], D Loss: 1.3675, G Loss: 0.7184\n",
            "Epoch [33/100], Step [1700/7382], D Loss: 1.3797, G Loss: 0.7315\n",
            "Epoch [33/100], Step [1800/7382], D Loss: 1.3832, G Loss: 0.6969\n",
            "Epoch [33/100], Step [1900/7382], D Loss: 1.3773, G Loss: 0.7246\n",
            "Epoch [33/100], Step [2000/7382], D Loss: 1.3631, G Loss: 0.7174\n",
            "Epoch [33/100], Step [2100/7382], D Loss: 1.3910, G Loss: 0.7039\n",
            "Epoch [33/100], Step [2200/7382], D Loss: 1.4030, G Loss: 0.7018\n",
            "Epoch [33/100], Step [2300/7382], D Loss: 1.3566, G Loss: 0.7168\n",
            "Epoch [33/100], Step [2400/7382], D Loss: 1.3862, G Loss: 0.6952\n",
            "Epoch [33/100], Step [2500/7382], D Loss: 1.3453, G Loss: 0.7550\n",
            "Epoch [33/100], Step [2600/7382], D Loss: 1.3878, G Loss: 0.6985\n",
            "Epoch [33/100], Step [2700/7382], D Loss: 1.3768, G Loss: 0.7386\n",
            "Epoch [33/100], Step [2800/7382], D Loss: 1.3583, G Loss: 0.7460\n",
            "Epoch [33/100], Step [2900/7382], D Loss: 1.3762, G Loss: 0.7538\n",
            "Epoch [33/100], Step [3000/7382], D Loss: 1.3681, G Loss: 0.6991\n",
            "Epoch [33/100], Step [3100/7382], D Loss: 1.3777, G Loss: 0.6931\n",
            "Epoch [33/100], Step [3200/7382], D Loss: 1.3317, G Loss: 0.7298\n",
            "Epoch [33/100], Step [3300/7382], D Loss: 1.2960, G Loss: 0.7827\n",
            "Epoch [33/100], Step [3400/7382], D Loss: 1.3773, G Loss: 0.7155\n",
            "Epoch [33/100], Step [3500/7382], D Loss: 1.3725, G Loss: 0.7063\n",
            "Epoch [33/100], Step [3600/7382], D Loss: 1.3488, G Loss: 0.7000\n",
            "Epoch [33/100], Step [3700/7382], D Loss: 1.3473, G Loss: 0.7817\n",
            "Epoch [33/100], Step [3800/7382], D Loss: 1.3492, G Loss: 0.7778\n",
            "Epoch [33/100], Step [3900/7382], D Loss: 1.3622, G Loss: 0.7209\n",
            "Epoch [33/100], Step [4000/7382], D Loss: 1.3527, G Loss: 0.7464\n",
            "Epoch [33/100], Step [4100/7382], D Loss: 1.3796, G Loss: 0.7308\n",
            "Epoch [33/100], Step [4200/7382], D Loss: 1.3817, G Loss: 0.7358\n",
            "Epoch [33/100], Step [4300/7382], D Loss: 1.3475, G Loss: 0.7822\n",
            "Epoch [33/100], Step [4400/7382], D Loss: 1.3970, G Loss: 0.6957\n",
            "Epoch [33/100], Step [4500/7382], D Loss: 1.3768, G Loss: 0.7076\n",
            "Epoch [33/100], Step [4600/7382], D Loss: 1.3753, G Loss: 0.7475\n",
            "Epoch [33/100], Step [4700/7382], D Loss: 1.3744, G Loss: 0.7221\n",
            "Epoch [33/100], Step [4800/7382], D Loss: 1.3574, G Loss: 0.7283\n",
            "Epoch [33/100], Step [4900/7382], D Loss: 1.3914, G Loss: 0.7126\n",
            "Epoch [33/100], Step [5000/7382], D Loss: 1.3511, G Loss: 0.7552\n",
            "Epoch [33/100], Step [5100/7382], D Loss: 1.2661, G Loss: 0.8578\n",
            "Epoch [33/100], Step [5200/7382], D Loss: 1.3622, G Loss: 0.7333\n",
            "Epoch [33/100], Step [5300/7382], D Loss: 1.3597, G Loss: 0.7789\n",
            "Epoch [33/100], Step [5400/7382], D Loss: 1.4039, G Loss: 0.6943\n",
            "Epoch [33/100], Step [5500/7382], D Loss: 1.3616, G Loss: 0.7267\n",
            "Epoch [33/100], Step [5600/7382], D Loss: 1.3731, G Loss: 0.7111\n",
            "Epoch [33/100], Step [5700/7382], D Loss: 1.3250, G Loss: 0.7705\n",
            "Epoch [33/100], Step [5800/7382], D Loss: 1.3705, G Loss: 0.7117\n",
            "Epoch [33/100], Step [5900/7382], D Loss: 1.3917, G Loss: 0.7481\n",
            "Epoch [33/100], Step [6000/7382], D Loss: 1.3649, G Loss: 0.7174\n",
            "Epoch [33/100], Step [6100/7382], D Loss: 1.3598, G Loss: 0.7093\n",
            "Epoch [33/100], Step [6200/7382], D Loss: 1.3666, G Loss: 0.7240\n",
            "Epoch [33/100], Step [6300/7382], D Loss: 1.3456, G Loss: 0.7237\n",
            "Epoch [33/100], Step [6400/7382], D Loss: 1.3574, G Loss: 0.7518\n",
            "Epoch [33/100], Step [6500/7382], D Loss: 1.3696, G Loss: 0.7334\n",
            "Epoch [33/100], Step [6600/7382], D Loss: 1.3557, G Loss: 0.7131\n",
            "Epoch [33/100], Step [6700/7382], D Loss: 1.3282, G Loss: 0.7730\n",
            "Epoch [33/100], Step [6800/7382], D Loss: 1.3583, G Loss: 0.7506\n",
            "Epoch [33/100], Step [6900/7382], D Loss: 1.3779, G Loss: 0.7679\n",
            "Epoch [33/100], Step [7000/7382], D Loss: 1.3485, G Loss: 0.7333\n",
            "Epoch [33/100], Step [7100/7382], D Loss: 1.3871, G Loss: 0.7575\n",
            "Epoch [33/100], Step [7200/7382], D Loss: 1.3962, G Loss: 0.7479\n",
            "Epoch [33/100], Step [7300/7382], D Loss: 1.3891, G Loss: 0.7200\n",
            "Epoch [34/100], Step [100/7382], D Loss: 1.2955, G Loss: 0.7795\n",
            "Epoch [34/100], Step [200/7382], D Loss: 1.2963, G Loss: 0.8110\n",
            "Epoch [34/100], Step [300/7382], D Loss: 1.3775, G Loss: 0.7351\n",
            "Epoch [34/100], Step [400/7382], D Loss: 1.3530, G Loss: 0.7688\n",
            "Epoch [34/100], Step [500/7382], D Loss: 1.3883, G Loss: 0.6989\n",
            "Epoch [34/100], Step [600/7382], D Loss: 1.3532, G Loss: 0.7057\n",
            "Epoch [34/100], Step [700/7382], D Loss: 1.3448, G Loss: 0.7269\n",
            "Epoch [34/100], Step [800/7382], D Loss: 1.3826, G Loss: 0.7301\n",
            "Epoch [34/100], Step [900/7382], D Loss: 1.3185, G Loss: 0.7563\n",
            "Epoch [34/100], Step [1000/7382], D Loss: 1.3611, G Loss: 0.7363\n",
            "Epoch [34/100], Step [1100/7382], D Loss: 1.3888, G Loss: 0.6821\n",
            "Epoch [34/100], Step [1200/7382], D Loss: 1.3627, G Loss: 0.7273\n",
            "Epoch [34/100], Step [1300/7382], D Loss: 1.3671, G Loss: 0.7208\n",
            "Epoch [34/100], Step [1400/7382], D Loss: 1.3538, G Loss: 0.7452\n",
            "Epoch [34/100], Step [1500/7382], D Loss: 1.3798, G Loss: 0.7368\n",
            "Epoch [34/100], Step [1600/7382], D Loss: 1.4058, G Loss: 0.7339\n",
            "Epoch [34/100], Step [1700/7382], D Loss: 1.3873, G Loss: 0.7238\n",
            "Epoch [34/100], Step [1800/7382], D Loss: 1.3986, G Loss: 0.6977\n",
            "Epoch [34/100], Step [1900/7382], D Loss: 1.3206, G Loss: 0.7672\n",
            "Epoch [34/100], Step [2000/7382], D Loss: 1.3707, G Loss: 0.7295\n",
            "Epoch [34/100], Step [2100/7382], D Loss: 1.3627, G Loss: 0.7578\n",
            "Epoch [34/100], Step [2200/7382], D Loss: 1.3810, G Loss: 0.7408\n",
            "Epoch [34/100], Step [2300/7382], D Loss: 1.3871, G Loss: 0.6929\n",
            "Epoch [34/100], Step [2400/7382], D Loss: 1.3711, G Loss: 0.7092\n",
            "Epoch [34/100], Step [2500/7382], D Loss: 1.3741, G Loss: 0.7168\n",
            "Epoch [34/100], Step [2600/7382], D Loss: 1.3675, G Loss: 0.7510\n",
            "Epoch [34/100], Step [2700/7382], D Loss: 1.4032, G Loss: 0.6900\n",
            "Epoch [34/100], Step [2800/7382], D Loss: 1.3855, G Loss: 0.6850\n",
            "Epoch [34/100], Step [2900/7382], D Loss: 1.3989, G Loss: 0.7014\n",
            "Epoch [34/100], Step [3000/7382], D Loss: 1.3629, G Loss: 0.7086\n",
            "Epoch [34/100], Step [3100/7382], D Loss: 1.3828, G Loss: 0.7303\n",
            "Epoch [34/100], Step [3200/7382], D Loss: 1.3408, G Loss: 0.7519\n",
            "Epoch [34/100], Step [3300/7382], D Loss: 1.3526, G Loss: 0.7861\n",
            "Epoch [34/100], Step [3400/7382], D Loss: 1.3386, G Loss: 0.7748\n",
            "Epoch [34/100], Step [3500/7382], D Loss: 1.3772, G Loss: 0.7208\n",
            "Epoch [34/100], Step [3600/7382], D Loss: 1.4220, G Loss: 0.7043\n",
            "Epoch [34/100], Step [3700/7382], D Loss: 1.3812, G Loss: 0.6942\n",
            "Epoch [34/100], Step [3800/7382], D Loss: 1.3468, G Loss: 0.8316\n",
            "Epoch [34/100], Step [3900/7382], D Loss: 1.3421, G Loss: 0.7571\n",
            "Epoch [34/100], Step [4000/7382], D Loss: 1.3517, G Loss: 0.7600\n",
            "Epoch [34/100], Step [4100/7382], D Loss: 1.3858, G Loss: 0.6951\n",
            "Epoch [34/100], Step [4200/7382], D Loss: 1.4101, G Loss: 0.7642\n",
            "Epoch [34/100], Step [4300/7382], D Loss: 1.3740, G Loss: 0.7256\n",
            "Epoch [34/100], Step [4400/7382], D Loss: 1.3350, G Loss: 0.7341\n",
            "Epoch [34/100], Step [4500/7382], D Loss: 1.3706, G Loss: 0.7588\n",
            "Epoch [34/100], Step [4600/7382], D Loss: 1.3209, G Loss: 0.7462\n",
            "Epoch [34/100], Step [4700/7382], D Loss: 1.3557, G Loss: 0.7428\n",
            "Epoch [34/100], Step [4800/7382], D Loss: 1.3700, G Loss: 0.7088\n",
            "Epoch [34/100], Step [4900/7382], D Loss: 1.3557, G Loss: 0.7732\n",
            "Epoch [34/100], Step [5000/7382], D Loss: 1.3848, G Loss: 0.7617\n",
            "Epoch [34/100], Step [5100/7382], D Loss: 1.3814, G Loss: 0.7355\n",
            "Epoch [34/100], Step [5200/7382], D Loss: 1.3655, G Loss: 0.6885\n",
            "Epoch [34/100], Step [5300/7382], D Loss: 1.3451, G Loss: 0.7639\n",
            "Epoch [34/100], Step [5400/7382], D Loss: 1.3960, G Loss: 0.7696\n",
            "Epoch [34/100], Step [5500/7382], D Loss: 1.3771, G Loss: 0.7189\n",
            "Epoch [34/100], Step [5600/7382], D Loss: 1.3809, G Loss: 0.7024\n",
            "Epoch [34/100], Step [5700/7382], D Loss: 1.3616, G Loss: 0.7541\n",
            "Epoch [34/100], Step [5800/7382], D Loss: 1.3519, G Loss: 0.7121\n",
            "Epoch [34/100], Step [5900/7382], D Loss: 1.3594, G Loss: 0.7090\n",
            "Epoch [34/100], Step [6000/7382], D Loss: 1.3656, G Loss: 0.7727\n",
            "Epoch [34/100], Step [6100/7382], D Loss: 1.3671, G Loss: 0.7177\n",
            "Epoch [34/100], Step [6200/7382], D Loss: 1.3578, G Loss: 0.7405\n",
            "Epoch [34/100], Step [6300/7382], D Loss: 1.3729, G Loss: 0.7155\n",
            "Epoch [34/100], Step [6400/7382], D Loss: 1.3823, G Loss: 0.7142\n",
            "Epoch [34/100], Step [6500/7382], D Loss: 1.3964, G Loss: 0.7218\n",
            "Epoch [34/100], Step [6600/7382], D Loss: 1.3943, G Loss: 0.7289\n",
            "Epoch [34/100], Step [6700/7382], D Loss: 1.3578, G Loss: 0.7103\n",
            "Epoch [34/100], Step [6800/7382], D Loss: 1.3635, G Loss: 0.7191\n",
            "Epoch [34/100], Step [6900/7382], D Loss: 1.3807, G Loss: 0.7284\n",
            "Epoch [34/100], Step [7000/7382], D Loss: 1.3821, G Loss: 0.7432\n",
            "Epoch [34/100], Step [7100/7382], D Loss: 1.3787, G Loss: 0.7404\n",
            "Epoch [34/100], Step [7200/7382], D Loss: 1.3870, G Loss: 0.7396\n",
            "Epoch [34/100], Step [7300/7382], D Loss: 1.3588, G Loss: 0.7474\n",
            "Epoch [35/100], Step [100/7382], D Loss: 1.4662, G Loss: 0.7049\n",
            "Epoch [35/100], Step [200/7382], D Loss: 1.3352, G Loss: 0.8393\n",
            "Epoch [35/100], Step [300/7382], D Loss: 1.4075, G Loss: 0.6900\n",
            "Epoch [35/100], Step [400/7382], D Loss: 1.3718, G Loss: 0.6803\n",
            "Epoch [35/100], Step [500/7382], D Loss: 1.3400, G Loss: 0.7596\n",
            "Epoch [35/100], Step [600/7382], D Loss: 1.3874, G Loss: 0.7204\n",
            "Epoch [35/100], Step [700/7382], D Loss: 1.3160, G Loss: 0.7497\n",
            "Epoch [35/100], Step [800/7382], D Loss: 1.3829, G Loss: 0.6906\n",
            "Epoch [35/100], Step [900/7382], D Loss: 1.3515, G Loss: 0.7327\n",
            "Epoch [35/100], Step [1000/7382], D Loss: 1.3769, G Loss: 0.7315\n",
            "Epoch [35/100], Step [1100/7382], D Loss: 1.3356, G Loss: 0.7757\n",
            "Epoch [35/100], Step [1200/7382], D Loss: 1.3766, G Loss: 0.7308\n",
            "Epoch [35/100], Step [1300/7382], D Loss: 1.3863, G Loss: 0.7092\n",
            "Epoch [35/100], Step [1400/7382], D Loss: 1.3736, G Loss: 0.7088\n",
            "Epoch [35/100], Step [1500/7382], D Loss: 1.3641, G Loss: 0.7101\n",
            "Epoch [35/100], Step [1600/7382], D Loss: 1.3630, G Loss: 0.7228\n",
            "Epoch [35/100], Step [1700/7382], D Loss: 1.3650, G Loss: 0.7641\n",
            "Epoch [35/100], Step [1800/7382], D Loss: 1.3625, G Loss: 0.7409\n",
            "Epoch [35/100], Step [1900/7382], D Loss: 1.3495, G Loss: 0.8177\n",
            "Epoch [35/100], Step [2000/7382], D Loss: 1.3751, G Loss: 0.7405\n",
            "Epoch [35/100], Step [2100/7382], D Loss: 1.3646, G Loss: 0.7217\n",
            "Epoch [35/100], Step [2200/7382], D Loss: 1.3655, G Loss: 0.7051\n",
            "Epoch [35/100], Step [2300/7382], D Loss: 1.3789, G Loss: 0.7438\n",
            "Epoch [35/100], Step [2400/7382], D Loss: 1.4001, G Loss: 0.7020\n",
            "Epoch [35/100], Step [2500/7382], D Loss: 1.3943, G Loss: 0.7156\n",
            "Epoch [35/100], Step [2600/7382], D Loss: 1.3660, G Loss: 0.6941\n",
            "Epoch [35/100], Step [2700/7382], D Loss: 1.3372, G Loss: 0.7597\n",
            "Epoch [35/100], Step [2800/7382], D Loss: 1.3683, G Loss: 0.7274\n",
            "Epoch [35/100], Step [2900/7382], D Loss: 1.3746, G Loss: 0.7683\n",
            "Epoch [35/100], Step [3000/7382], D Loss: 1.3575, G Loss: 0.7264\n",
            "Epoch [35/100], Step [3100/7382], D Loss: 1.3691, G Loss: 0.7334\n",
            "Epoch [35/100], Step [3200/7382], D Loss: 1.3400, G Loss: 0.7707\n",
            "Epoch [35/100], Step [3300/7382], D Loss: 1.3713, G Loss: 0.7724\n",
            "Epoch [35/100], Step [3400/7382], D Loss: 1.4419, G Loss: 0.6765\n",
            "Epoch [35/100], Step [3500/7382], D Loss: 1.3421, G Loss: 0.7239\n",
            "Epoch [35/100], Step [3600/7382], D Loss: 1.3593, G Loss: 0.7704\n",
            "Epoch [35/100], Step [3700/7382], D Loss: 1.3890, G Loss: 0.7231\n",
            "Epoch [35/100], Step [3800/7382], D Loss: 1.3624, G Loss: 0.7635\n",
            "Epoch [35/100], Step [3900/7382], D Loss: 1.3489, G Loss: 0.7503\n",
            "Epoch [35/100], Step [4000/7382], D Loss: 1.3914, G Loss: 0.7054\n",
            "Epoch [35/100], Step [4100/7382], D Loss: 1.3732, G Loss: 0.7841\n",
            "Epoch [35/100], Step [4200/7382], D Loss: 1.3762, G Loss: 0.7094\n",
            "Epoch [35/100], Step [4300/7382], D Loss: 1.3266, G Loss: 0.7955\n",
            "Epoch [35/100], Step [4400/7382], D Loss: 1.3326, G Loss: 0.8383\n",
            "Epoch [35/100], Step [4500/7382], D Loss: 1.3928, G Loss: 0.7179\n",
            "Epoch [35/100], Step [4600/7382], D Loss: 1.3669, G Loss: 0.7526\n",
            "Epoch [35/100], Step [4700/7382], D Loss: 1.3695, G Loss: 0.7593\n",
            "Epoch [35/100], Step [4800/7382], D Loss: 1.3869, G Loss: 0.6924\n",
            "Epoch [35/100], Step [4900/7382], D Loss: 1.4073, G Loss: 0.7008\n",
            "Epoch [35/100], Step [5000/7382], D Loss: 1.3625, G Loss: 0.7221\n",
            "Epoch [35/100], Step [5100/7382], D Loss: 1.3788, G Loss: 0.7008\n",
            "Epoch [35/100], Step [5200/7382], D Loss: 1.3996, G Loss: 0.6849\n",
            "Epoch [35/100], Step [5300/7382], D Loss: 1.3856, G Loss: 0.7130\n",
            "Epoch [35/100], Step [5400/7382], D Loss: 1.3772, G Loss: 0.7141\n",
            "Epoch [35/100], Step [5500/7382], D Loss: 1.3778, G Loss: 0.7030\n",
            "Epoch [35/100], Step [5600/7382], D Loss: 1.3457, G Loss: 0.7580\n",
            "Epoch [35/100], Step [5700/7382], D Loss: 1.3932, G Loss: 0.7219\n",
            "Epoch [35/100], Step [5800/7382], D Loss: 1.3714, G Loss: 0.7471\n",
            "Epoch [35/100], Step [5900/7382], D Loss: 1.3684, G Loss: 0.7897\n",
            "Epoch [35/100], Step [6000/7382], D Loss: 1.3379, G Loss: 0.7565\n",
            "Epoch [35/100], Step [6100/7382], D Loss: 1.3725, G Loss: 0.8581\n",
            "Epoch [35/100], Step [6200/7382], D Loss: 1.3680, G Loss: 0.7129\n",
            "Epoch [35/100], Step [6300/7382], D Loss: 1.3687, G Loss: 0.7068\n",
            "Epoch [35/100], Step [6400/7382], D Loss: 1.3456, G Loss: 0.7050\n",
            "Epoch [35/100], Step [6500/7382], D Loss: 1.3796, G Loss: 0.7149\n",
            "Epoch [35/100], Step [6600/7382], D Loss: 1.3795, G Loss: 0.7348\n",
            "Epoch [35/100], Step [6700/7382], D Loss: 1.3727, G Loss: 0.7220\n",
            "Epoch [35/100], Step [6800/7382], D Loss: 1.3747, G Loss: 0.7487\n",
            "Epoch [35/100], Step [6900/7382], D Loss: 1.3581, G Loss: 0.7371\n",
            "Epoch [35/100], Step [7000/7382], D Loss: 1.3899, G Loss: 0.7602\n",
            "Epoch [35/100], Step [7100/7382], D Loss: 1.3282, G Loss: 0.7717\n",
            "Epoch [35/100], Step [7200/7382], D Loss: 1.3775, G Loss: 0.7212\n",
            "Epoch [35/100], Step [7300/7382], D Loss: 1.3618, G Loss: 0.7033\n",
            "Epoch [36/100], Step [100/7382], D Loss: 1.3502, G Loss: 0.7585\n",
            "Epoch [36/100], Step [200/7382], D Loss: 1.3171, G Loss: 0.7529\n",
            "Epoch [36/100], Step [300/7382], D Loss: 1.3644, G Loss: 0.7345\n",
            "Epoch [36/100], Step [400/7382], D Loss: 1.3548, G Loss: 0.7641\n",
            "Epoch [36/100], Step [500/7382], D Loss: 1.3851, G Loss: 0.7189\n",
            "Epoch [36/100], Step [600/7382], D Loss: 1.3791, G Loss: 0.7210\n",
            "Epoch [36/100], Step [700/7382], D Loss: 1.3441, G Loss: 0.8081\n",
            "Epoch [36/100], Step [800/7382], D Loss: 1.3634, G Loss: 0.7112\n",
            "Epoch [36/100], Step [900/7382], D Loss: 1.4578, G Loss: 0.6835\n",
            "Epoch [36/100], Step [1000/7382], D Loss: 1.3541, G Loss: 0.7262\n",
            "Epoch [36/100], Step [1100/7382], D Loss: 1.3555, G Loss: 0.7795\n",
            "Epoch [36/100], Step [1200/7382], D Loss: 1.3372, G Loss: 0.7371\n",
            "Epoch [36/100], Step [1300/7382], D Loss: 1.3628, G Loss: 0.7475\n",
            "Epoch [36/100], Step [1400/7382], D Loss: 1.3714, G Loss: 0.7468\n",
            "Epoch [36/100], Step [1500/7382], D Loss: 1.4120, G Loss: 0.7244\n",
            "Epoch [36/100], Step [1600/7382], D Loss: 1.3653, G Loss: 0.7715\n",
            "Epoch [36/100], Step [1700/7382], D Loss: 1.3554, G Loss: 0.7067\n",
            "Epoch [36/100], Step [1800/7382], D Loss: 1.4063, G Loss: 0.6802\n",
            "Epoch [36/100], Step [1900/7382], D Loss: 1.3692, G Loss: 0.7464\n",
            "Epoch [36/100], Step [2000/7382], D Loss: 1.3991, G Loss: 0.7285\n",
            "Epoch [36/100], Step [2100/7382], D Loss: 1.4124, G Loss: 0.7743\n",
            "Epoch [36/100], Step [2200/7382], D Loss: 1.3800, G Loss: 0.7225\n",
            "Epoch [36/100], Step [2300/7382], D Loss: 1.3400, G Loss: 0.7630\n",
            "Epoch [36/100], Step [2400/7382], D Loss: 1.3645, G Loss: 0.7596\n",
            "Epoch [36/100], Step [2500/7382], D Loss: 1.4130, G Loss: 0.6826\n",
            "Epoch [36/100], Step [2600/7382], D Loss: 1.3618, G Loss: 0.7097\n",
            "Epoch [36/100], Step [2700/7382], D Loss: 1.4130, G Loss: 0.6653\n",
            "Epoch [36/100], Step [2800/7382], D Loss: 1.4099, G Loss: 0.6920\n",
            "Epoch [36/100], Step [2900/7382], D Loss: 1.3919, G Loss: 0.6985\n",
            "Epoch [36/100], Step [3000/7382], D Loss: 1.3871, G Loss: 0.7314\n",
            "Epoch [36/100], Step [3100/7382], D Loss: 1.3633, G Loss: 0.7430\n",
            "Epoch [36/100], Step [3200/7382], D Loss: 1.3865, G Loss: 0.7111\n",
            "Epoch [36/100], Step [3300/7382], D Loss: 1.3973, G Loss: 0.6973\n",
            "Epoch [36/100], Step [3400/7382], D Loss: 1.3741, G Loss: 0.7471\n",
            "Epoch [36/100], Step [3500/7382], D Loss: 1.3934, G Loss: 0.7073\n",
            "Epoch [36/100], Step [3600/7382], D Loss: 1.3536, G Loss: 0.7399\n",
            "Epoch [36/100], Step [3700/7382], D Loss: 1.3949, G Loss: 0.6920\n",
            "Epoch [36/100], Step [3800/7382], D Loss: 1.3756, G Loss: 0.7417\n",
            "Epoch [36/100], Step [3900/7382], D Loss: 1.3637, G Loss: 0.7343\n",
            "Epoch [36/100], Step [4000/7382], D Loss: 1.3446, G Loss: 0.8272\n",
            "Epoch [36/100], Step [4100/7382], D Loss: 1.3879, G Loss: 0.7159\n",
            "Epoch [36/100], Step [4200/7382], D Loss: 1.3751, G Loss: 0.7255\n",
            "Epoch [36/100], Step [4300/7382], D Loss: 1.3656, G Loss: 0.7285\n",
            "Epoch [36/100], Step [4400/7382], D Loss: 1.3783, G Loss: 0.7355\n",
            "Epoch [36/100], Step [4500/7382], D Loss: 1.3432, G Loss: 0.7384\n",
            "Epoch [36/100], Step [4600/7382], D Loss: 1.3952, G Loss: 0.6894\n",
            "Epoch [36/100], Step [4700/7382], D Loss: 1.3463, G Loss: 0.7614\n",
            "Epoch [36/100], Step [4800/7382], D Loss: 1.3812, G Loss: 0.7662\n",
            "Epoch [36/100], Step [4900/7382], D Loss: 1.4018, G Loss: 0.7084\n",
            "Epoch [36/100], Step [5000/7382], D Loss: 1.3644, G Loss: 0.7735\n",
            "Epoch [36/100], Step [5100/7382], D Loss: 1.4054, G Loss: 0.7196\n",
            "Epoch [36/100], Step [5200/7382], D Loss: 1.3824, G Loss: 0.7573\n",
            "Epoch [36/100], Step [5300/7382], D Loss: 1.3615, G Loss: 0.7323\n",
            "Epoch [36/100], Step [5400/7382], D Loss: 1.4000, G Loss: 0.7067\n",
            "Epoch [36/100], Step [5500/7382], D Loss: 1.3646, G Loss: 0.7511\n",
            "Epoch [36/100], Step [5600/7382], D Loss: 1.3712, G Loss: 0.6967\n",
            "Epoch [36/100], Step [5700/7382], D Loss: 1.3468, G Loss: 0.6664\n",
            "Epoch [36/100], Step [5800/7382], D Loss: 1.3822, G Loss: 0.7029\n",
            "Epoch [36/100], Step [5900/7382], D Loss: 1.3873, G Loss: 0.6968\n",
            "Epoch [36/100], Step [6000/7382], D Loss: 1.3935, G Loss: 0.6967\n",
            "Epoch [36/100], Step [6100/7382], D Loss: 1.3219, G Loss: 0.8188\n",
            "Epoch [36/100], Step [6200/7382], D Loss: 1.3696, G Loss: 0.7501\n",
            "Epoch [36/100], Step [6300/7382], D Loss: 1.3486, G Loss: 0.7528\n",
            "Epoch [36/100], Step [6400/7382], D Loss: 1.3449, G Loss: 0.7457\n",
            "Epoch [36/100], Step [6500/7382], D Loss: 1.3766, G Loss: 0.6822\n",
            "Epoch [36/100], Step [6600/7382], D Loss: 1.3729, G Loss: 0.7526\n",
            "Epoch [36/100], Step [6700/7382], D Loss: 1.3705, G Loss: 0.7125\n",
            "Epoch [36/100], Step [6800/7382], D Loss: 1.3353, G Loss: 0.7566\n",
            "Epoch [36/100], Step [6900/7382], D Loss: 1.3484, G Loss: 0.7363\n",
            "Epoch [36/100], Step [7000/7382], D Loss: 1.3220, G Loss: 0.7509\n",
            "Epoch [36/100], Step [7100/7382], D Loss: 1.3735, G Loss: 0.7280\n",
            "Epoch [36/100], Step [7200/7382], D Loss: 1.3931, G Loss: 0.7114\n",
            "Epoch [36/100], Step [7300/7382], D Loss: 1.3314, G Loss: 0.7549\n",
            "Epoch [37/100], Step [100/7382], D Loss: 1.3395, G Loss: 0.7590\n",
            "Epoch [37/100], Step [200/7382], D Loss: 1.3392, G Loss: 0.7567\n",
            "Epoch [37/100], Step [300/7382], D Loss: 1.3387, G Loss: 0.7908\n",
            "Epoch [37/100], Step [400/7382], D Loss: 1.3273, G Loss: 0.7917\n",
            "Epoch [37/100], Step [500/7382], D Loss: 1.3107, G Loss: 0.7821\n",
            "Epoch [37/100], Step [600/7382], D Loss: 1.3367, G Loss: 0.7857\n",
            "Epoch [37/100], Step [700/7382], D Loss: 1.3495, G Loss: 0.8009\n",
            "Epoch [37/100], Step [800/7382], D Loss: 1.3615, G Loss: 0.7362\n",
            "Epoch [37/100], Step [900/7382], D Loss: 1.3888, G Loss: 0.7077\n",
            "Epoch [37/100], Step [1000/7382], D Loss: 1.4354, G Loss: 0.6643\n",
            "Epoch [37/100], Step [1100/7382], D Loss: 1.4090, G Loss: 0.7327\n",
            "Epoch [37/100], Step [1200/7382], D Loss: 1.3918, G Loss: 0.7612\n",
            "Epoch [37/100], Step [1300/7382], D Loss: 1.3549, G Loss: 0.7604\n",
            "Epoch [37/100], Step [1400/7382], D Loss: 1.3352, G Loss: 0.7439\n",
            "Epoch [37/100], Step [1500/7382], D Loss: 1.3647, G Loss: 0.7373\n",
            "Epoch [37/100], Step [1600/7382], D Loss: 1.3504, G Loss: 0.7673\n",
            "Epoch [37/100], Step [1700/7382], D Loss: 1.3859, G Loss: 0.7881\n",
            "Epoch [37/100], Step [1800/7382], D Loss: 1.3404, G Loss: 0.7931\n",
            "Epoch [37/100], Step [1900/7382], D Loss: 1.3834, G Loss: 0.7207\n",
            "Epoch [37/100], Step [2000/7382], D Loss: 1.3148, G Loss: 0.7547\n",
            "Epoch [37/100], Step [2100/7382], D Loss: 1.3784, G Loss: 0.7328\n",
            "Epoch [37/100], Step [2200/7382], D Loss: 1.3075, G Loss: 0.7729\n",
            "Epoch [37/100], Step [2300/7382], D Loss: 1.3133, G Loss: 0.7650\n",
            "Epoch [37/100], Step [2400/7382], D Loss: 1.2570, G Loss: 0.8892\n",
            "Epoch [37/100], Step [2500/7382], D Loss: 1.2966, G Loss: 0.7681\n",
            "Epoch [37/100], Step [2600/7382], D Loss: 1.2861, G Loss: 0.8670\n",
            "Epoch [37/100], Step [2700/7382], D Loss: 1.2903, G Loss: 0.9057\n",
            "Epoch [37/100], Step [2800/7382], D Loss: 1.3366, G Loss: 0.8081\n",
            "Epoch [37/100], Step [2900/7382], D Loss: 1.3691, G Loss: 0.7391\n",
            "Epoch [37/100], Step [3000/7382], D Loss: 1.3756, G Loss: 0.7828\n",
            "Epoch [37/100], Step [3100/7382], D Loss: 1.3466, G Loss: 0.7627\n",
            "Epoch [37/100], Step [3200/7382], D Loss: 1.2955, G Loss: 0.7996\n",
            "Epoch [37/100], Step [3300/7382], D Loss: 1.3349, G Loss: 0.8193\n",
            "Epoch [37/100], Step [3400/7382], D Loss: 1.2874, G Loss: 0.8337\n",
            "Epoch [37/100], Step [3500/7382], D Loss: 1.2799, G Loss: 0.7870\n",
            "Epoch [37/100], Step [3600/7382], D Loss: 1.3636, G Loss: 0.7810\n",
            "Epoch [37/100], Step [3700/7382], D Loss: 1.3476, G Loss: 0.7944\n",
            "Epoch [37/100], Step [3800/7382], D Loss: 1.3668, G Loss: 0.7512\n",
            "Epoch [37/100], Step [3900/7382], D Loss: 1.3552, G Loss: 0.7344\n",
            "Epoch [37/100], Step [4000/7382], D Loss: 1.3588, G Loss: 0.7128\n",
            "Epoch [37/100], Step [4100/7382], D Loss: 1.3592, G Loss: 0.7743\n",
            "Epoch [37/100], Step [4200/7382], D Loss: 1.3633, G Loss: 0.7150\n",
            "Epoch [37/100], Step [4300/7382], D Loss: 1.3504, G Loss: 0.7631\n",
            "Epoch [37/100], Step [4400/7382], D Loss: 1.3467, G Loss: 0.7252\n",
            "Epoch [37/100], Step [4500/7382], D Loss: 1.3965, G Loss: 0.6975\n",
            "Epoch [37/100], Step [4600/7382], D Loss: 1.3869, G Loss: 0.7602\n",
            "Epoch [37/100], Step [4700/7382], D Loss: 1.3613, G Loss: 0.7347\n",
            "Epoch [37/100], Step [4800/7382], D Loss: 1.3462, G Loss: 0.7545\n",
            "Epoch [37/100], Step [4900/7382], D Loss: 1.3486, G Loss: 0.7876\n",
            "Epoch [37/100], Step [5000/7382], D Loss: 1.4151, G Loss: 0.7100\n",
            "Epoch [37/100], Step [5100/7382], D Loss: 1.3662, G Loss: 0.7166\n",
            "Epoch [37/100], Step [5200/7382], D Loss: 1.3648, G Loss: 0.7154\n",
            "Epoch [37/100], Step [5300/7382], D Loss: 1.3740, G Loss: 0.7345\n",
            "Epoch [37/100], Step [5400/7382], D Loss: 1.3906, G Loss: 0.7214\n",
            "Epoch [37/100], Step [5500/7382], D Loss: 1.3569, G Loss: 0.7210\n",
            "Epoch [37/100], Step [5600/7382], D Loss: 1.3660, G Loss: 0.7174\n",
            "Epoch [37/100], Step [5700/7382], D Loss: 1.3784, G Loss: 0.7184\n",
            "Epoch [37/100], Step [5800/7382], D Loss: 1.3839, G Loss: 0.7784\n",
            "Epoch [37/100], Step [5900/7382], D Loss: 1.3984, G Loss: 0.7675\n",
            "Epoch [37/100], Step [6000/7382], D Loss: 1.2875, G Loss: 0.8237\n",
            "Epoch [37/100], Step [6100/7382], D Loss: 1.3391, G Loss: 0.8043\n",
            "Epoch [37/100], Step [6200/7382], D Loss: 1.3258, G Loss: 0.8119\n",
            "Epoch [37/100], Step [6300/7382], D Loss: 1.3721, G Loss: 0.7394\n",
            "Epoch [37/100], Step [6400/7382], D Loss: 1.3488, G Loss: 0.8119\n",
            "Epoch [37/100], Step [6500/7382], D Loss: 1.3062, G Loss: 0.7982\n",
            "Epoch [37/100], Step [6600/7382], D Loss: 1.4340, G Loss: 0.7287\n",
            "Epoch [37/100], Step [6700/7382], D Loss: 1.2806, G Loss: 0.8231\n",
            "Epoch [37/100], Step [6800/7382], D Loss: 1.3583, G Loss: 0.7124\n",
            "Epoch [37/100], Step [6900/7382], D Loss: 1.3565, G Loss: 0.7255\n",
            "Epoch [37/100], Step [7000/7382], D Loss: 1.3729, G Loss: 0.7552\n",
            "Epoch [37/100], Step [7100/7382], D Loss: 1.3645, G Loss: 0.7907\n",
            "Epoch [37/100], Step [7200/7382], D Loss: 1.4275, G Loss: 0.7542\n",
            "Epoch [37/100], Step [7300/7382], D Loss: 1.3645, G Loss: 0.7752\n",
            "Epoch [38/100], Step [100/7382], D Loss: 1.3550, G Loss: 0.7413\n",
            "Epoch [38/100], Step [200/7382], D Loss: 1.3586, G Loss: 0.7708\n",
            "Epoch [38/100], Step [300/7382], D Loss: 1.4030, G Loss: 0.7039\n",
            "Epoch [38/100], Step [400/7382], D Loss: 1.3674, G Loss: 0.7480\n",
            "Epoch [38/100], Step [500/7382], D Loss: 1.3582, G Loss: 0.7581\n",
            "Epoch [38/100], Step [600/7382], D Loss: 1.3270, G Loss: 0.8012\n",
            "Epoch [38/100], Step [700/7382], D Loss: 1.3760, G Loss: 0.7158\n",
            "Epoch [38/100], Step [800/7382], D Loss: 1.3159, G Loss: 0.7705\n",
            "Epoch [38/100], Step [900/7382], D Loss: 1.3410, G Loss: 0.7897\n",
            "Epoch [38/100], Step [1000/7382], D Loss: 1.3898, G Loss: 0.6948\n",
            "Epoch [38/100], Step [1100/7382], D Loss: 1.3381, G Loss: 0.8413\n",
            "Epoch [38/100], Step [1200/7382], D Loss: 1.3911, G Loss: 0.7120\n",
            "Epoch [38/100], Step [1300/7382], D Loss: 1.3475, G Loss: 0.7583\n",
            "Epoch [38/100], Step [1400/7382], D Loss: 1.4132, G Loss: 0.7288\n",
            "Epoch [38/100], Step [1500/7382], D Loss: 1.3426, G Loss: 0.7589\n",
            "Epoch [38/100], Step [1600/7382], D Loss: 1.3746, G Loss: 0.7635\n",
            "Epoch [38/100], Step [1700/7382], D Loss: 1.3531, G Loss: 0.7509\n",
            "Epoch [38/100], Step [1800/7382], D Loss: 1.3625, G Loss: 0.7559\n",
            "Epoch [38/100], Step [1900/7382], D Loss: 1.3455, G Loss: 0.7540\n",
            "Epoch [38/100], Step [2000/7382], D Loss: 1.3451, G Loss: 0.7428\n",
            "Epoch [38/100], Step [2100/7382], D Loss: 1.3794, G Loss: 0.7501\n",
            "Epoch [38/100], Step [2200/7382], D Loss: 1.3469, G Loss: 0.8348\n",
            "Epoch [38/100], Step [2300/7382], D Loss: 1.3827, G Loss: 0.7336\n",
            "Epoch [38/100], Step [2400/7382], D Loss: 1.3220, G Loss: 0.7649\n",
            "Epoch [38/100], Step [2500/7382], D Loss: 1.3315, G Loss: 0.7333\n",
            "Epoch [38/100], Step [2600/7382], D Loss: 1.3632, G Loss: 0.7550\n",
            "Epoch [38/100], Step [2700/7382], D Loss: 1.4044, G Loss: 0.7669\n",
            "Epoch [38/100], Step [2800/7382], D Loss: 1.3390, G Loss: 0.7111\n",
            "Epoch [38/100], Step [2900/7382], D Loss: 1.3734, G Loss: 0.7240\n",
            "Epoch [38/100], Step [3000/7382], D Loss: 1.3599, G Loss: 0.7634\n",
            "Epoch [38/100], Step [3100/7382], D Loss: 1.3640, G Loss: 0.7104\n",
            "Epoch [38/100], Step [3200/7382], D Loss: 1.4182, G Loss: 0.6960\n",
            "Epoch [38/100], Step [3300/7382], D Loss: 1.3602, G Loss: 0.8281\n",
            "Epoch [38/100], Step [3400/7382], D Loss: 1.4043, G Loss: 0.7263\n",
            "Epoch [38/100], Step [3500/7382], D Loss: 1.3778, G Loss: 0.7477\n",
            "Epoch [38/100], Step [3600/7382], D Loss: 1.3619, G Loss: 0.7304\n",
            "Epoch [38/100], Step [3700/7382], D Loss: 1.3633, G Loss: 0.7470\n",
            "Epoch [38/100], Step [3800/7382], D Loss: 1.3694, G Loss: 0.7265\n",
            "Epoch [38/100], Step [3900/7382], D Loss: 1.3484, G Loss: 0.7323\n",
            "Epoch [38/100], Step [4000/7382], D Loss: 1.3844, G Loss: 0.7274\n",
            "Epoch [38/100], Step [4100/7382], D Loss: 1.3520, G Loss: 0.7271\n",
            "Epoch [38/100], Step [4200/7382], D Loss: 1.3743, G Loss: 0.7036\n",
            "Epoch [38/100], Step [4300/7382], D Loss: 1.3999, G Loss: 0.7597\n",
            "Epoch [38/100], Step [4400/7382], D Loss: 1.3751, G Loss: 0.7920\n",
            "Epoch [38/100], Step [4500/7382], D Loss: 1.3718, G Loss: 0.8109\n",
            "Epoch [38/100], Step [4600/7382], D Loss: 1.3855, G Loss: 0.7362\n",
            "Epoch [38/100], Step [4700/7382], D Loss: 1.3717, G Loss: 0.7430\n",
            "Epoch [38/100], Step [4800/7382], D Loss: 1.3503, G Loss: 0.7773\n",
            "Epoch [38/100], Step [4900/7382], D Loss: 1.3535, G Loss: 0.7487\n",
            "Epoch [38/100], Step [5000/7382], D Loss: 1.3664, G Loss: 0.7318\n",
            "Epoch [38/100], Step [5100/7382], D Loss: 1.3513, G Loss: 0.7455\n",
            "Epoch [38/100], Step [5200/7382], D Loss: 1.3472, G Loss: 0.7124\n",
            "Epoch [38/100], Step [5300/7382], D Loss: 1.3913, G Loss: 0.7116\n",
            "Epoch [38/100], Step [5400/7382], D Loss: 1.3781, G Loss: 0.6985\n",
            "Epoch [38/100], Step [5500/7382], D Loss: 1.3609, G Loss: 0.7479\n",
            "Epoch [38/100], Step [5600/7382], D Loss: 1.3820, G Loss: 0.7575\n",
            "Epoch [38/100], Step [5700/7382], D Loss: 1.3763, G Loss: 0.6775\n",
            "Epoch [38/100], Step [5800/7382], D Loss: 1.3811, G Loss: 0.6978\n",
            "Epoch [38/100], Step [5900/7382], D Loss: 1.3618, G Loss: 0.7493\n",
            "Epoch [38/100], Step [6000/7382], D Loss: 1.3361, G Loss: 0.7767\n",
            "Epoch [38/100], Step [6100/7382], D Loss: 1.3588, G Loss: 0.7247\n",
            "Epoch [38/100], Step [6200/7382], D Loss: 1.3482, G Loss: 0.7117\n",
            "Epoch [38/100], Step [6300/7382], D Loss: 1.4051, G Loss: 0.6937\n",
            "Epoch [38/100], Step [6400/7382], D Loss: 1.3777, G Loss: 0.7180\n",
            "Epoch [38/100], Step [6500/7382], D Loss: 1.3327, G Loss: 0.7606\n",
            "Epoch [38/100], Step [6600/7382], D Loss: 1.3492, G Loss: 0.7536\n",
            "Epoch [38/100], Step [6700/7382], D Loss: 1.3153, G Loss: 0.8075\n",
            "Epoch [38/100], Step [6800/7382], D Loss: 1.3856, G Loss: 0.7013\n",
            "Epoch [38/100], Step [6900/7382], D Loss: 1.3956, G Loss: 0.7387\n",
            "Epoch [38/100], Step [7000/7382], D Loss: 1.3758, G Loss: 0.7628\n",
            "Epoch [38/100], Step [7100/7382], D Loss: 1.3979, G Loss: 0.7275\n",
            "Epoch [38/100], Step [7200/7382], D Loss: 1.3473, G Loss: 0.7310\n",
            "Epoch [38/100], Step [7300/7382], D Loss: 1.3813, G Loss: 0.7605\n",
            "Epoch [39/100], Step [100/7382], D Loss: 1.3422, G Loss: 0.7431\n",
            "Epoch [39/100], Step [200/7382], D Loss: 1.3418, G Loss: 0.7952\n",
            "Epoch [39/100], Step [300/7382], D Loss: 1.3468, G Loss: 0.7395\n",
            "Epoch [39/100], Step [400/7382], D Loss: 1.3743, G Loss: 0.7620\n",
            "Epoch [39/100], Step [500/7382], D Loss: 1.3880, G Loss: 0.7319\n",
            "Epoch [39/100], Step [600/7382], D Loss: 1.3558, G Loss: 0.7702\n",
            "Epoch [39/100], Step [700/7382], D Loss: 1.3419, G Loss: 0.7150\n",
            "Epoch [39/100], Step [800/7382], D Loss: 1.3356, G Loss: 0.7561\n",
            "Epoch [39/100], Step [900/7382], D Loss: 1.3525, G Loss: 0.7546\n",
            "Epoch [39/100], Step [1000/7382], D Loss: 1.3665, G Loss: 0.7285\n",
            "Epoch [39/100], Step [1100/7382], D Loss: 1.4152, G Loss: 0.7501\n",
            "Epoch [39/100], Step [1200/7382], D Loss: 1.3249, G Loss: 0.7833\n",
            "Epoch [39/100], Step [1300/7382], D Loss: 1.3554, G Loss: 0.7667\n",
            "Epoch [39/100], Step [1400/7382], D Loss: 1.3191, G Loss: 0.7846\n",
            "Epoch [39/100], Step [1500/7382], D Loss: 1.4334, G Loss: 0.8054\n",
            "Epoch [39/100], Step [1600/7382], D Loss: 1.3264, G Loss: 0.7903\n",
            "Epoch [39/100], Step [1700/7382], D Loss: 1.3296, G Loss: 0.7904\n",
            "Epoch [39/100], Step [1800/7382], D Loss: 1.3260, G Loss: 0.7497\n",
            "Epoch [39/100], Step [1900/7382], D Loss: 1.4473, G Loss: 0.7776\n",
            "Epoch [39/100], Step [2000/7382], D Loss: 1.3788, G Loss: 0.7108\n",
            "Epoch [39/100], Step [2100/7382], D Loss: 1.3064, G Loss: 0.8186\n",
            "Epoch [39/100], Step [2200/7382], D Loss: 1.3434, G Loss: 0.7864\n",
            "Epoch [39/100], Step [2300/7382], D Loss: 1.3578, G Loss: 0.7722\n",
            "Epoch [39/100], Step [2400/7382], D Loss: 1.2949, G Loss: 0.8337\n",
            "Epoch [39/100], Step [2500/7382], D Loss: 1.3213, G Loss: 0.7678\n",
            "Epoch [39/100], Step [2600/7382], D Loss: 1.3179, G Loss: 0.8395\n",
            "Epoch [39/100], Step [2700/7382], D Loss: 1.2962, G Loss: 0.7950\n",
            "Epoch [39/100], Step [2800/7382], D Loss: 1.3565, G Loss: 0.7748\n",
            "Epoch [39/100], Step [2900/7382], D Loss: 1.2392, G Loss: 0.8095\n",
            "Epoch [39/100], Step [3000/7382], D Loss: 1.2370, G Loss: 1.0227\n",
            "Epoch [39/100], Step [3100/7382], D Loss: 1.3453, G Loss: 0.7667\n",
            "Epoch [39/100], Step [3200/7382], D Loss: 1.3935, G Loss: 0.8717\n",
            "Epoch [39/100], Step [3300/7382], D Loss: 1.2745, G Loss: 0.8924\n",
            "Epoch [39/100], Step [3400/7382], D Loss: 1.3485, G Loss: 0.7936\n",
            "Epoch [39/100], Step [3500/7382], D Loss: 1.2855, G Loss: 0.9161\n",
            "Epoch [39/100], Step [3600/7382], D Loss: 1.2679, G Loss: 0.8020\n",
            "Epoch [39/100], Step [3700/7382], D Loss: 1.3460, G Loss: 0.7966\n",
            "Epoch [39/100], Step [3800/7382], D Loss: 1.3339, G Loss: 0.7689\n",
            "Epoch [39/100], Step [3900/7382], D Loss: 1.3009, G Loss: 0.8980\n",
            "Epoch [39/100], Step [4000/7382], D Loss: 1.2617, G Loss: 0.9034\n",
            "Epoch [39/100], Step [4100/7382], D Loss: 1.2305, G Loss: 0.9607\n",
            "Epoch [39/100], Step [4200/7382], D Loss: 1.3277, G Loss: 0.7433\n",
            "Epoch [39/100], Step [4300/7382], D Loss: 1.3053, G Loss: 0.7906\n",
            "Epoch [39/100], Step [4400/7382], D Loss: 1.2932, G Loss: 0.8028\n",
            "Epoch [39/100], Step [4500/7382], D Loss: 1.3590, G Loss: 0.7875\n",
            "Epoch [39/100], Step [4600/7382], D Loss: 1.3032, G Loss: 0.8112\n",
            "Epoch [39/100], Step [4700/7382], D Loss: 1.3254, G Loss: 0.7770\n",
            "Epoch [39/100], Step [4800/7382], D Loss: 1.3487, G Loss: 0.7941\n",
            "Epoch [39/100], Step [4900/7382], D Loss: 1.3537, G Loss: 0.7559\n",
            "Epoch [39/100], Step [5000/7382], D Loss: 1.3124, G Loss: 0.8474\n",
            "Epoch [39/100], Step [5100/7382], D Loss: 1.3241, G Loss: 0.8522\n",
            "Epoch [39/100], Step [5200/7382], D Loss: 1.3066, G Loss: 0.7914\n",
            "Epoch [39/100], Step [5300/7382], D Loss: 1.3062, G Loss: 0.8588\n",
            "Epoch [39/100], Step [5400/7382], D Loss: 1.3183, G Loss: 0.7948\n",
            "Epoch [39/100], Step [5500/7382], D Loss: 1.3139, G Loss: 0.8307\n",
            "Epoch [39/100], Step [5600/7382], D Loss: 1.3801, G Loss: 0.8188\n",
            "Epoch [39/100], Step [5700/7382], D Loss: 1.2938, G Loss: 0.7719\n",
            "Epoch [39/100], Step [5800/7382], D Loss: 1.3634, G Loss: 0.7492\n",
            "Epoch [39/100], Step [5900/7382], D Loss: 1.3293, G Loss: 0.7527\n",
            "Epoch [39/100], Step [6000/7382], D Loss: 1.3151, G Loss: 0.7892\n",
            "Epoch [39/100], Step [6100/7382], D Loss: 1.3438, G Loss: 0.7708\n",
            "Epoch [39/100], Step [6200/7382], D Loss: 1.3771, G Loss: 0.7671\n",
            "Epoch [39/100], Step [6300/7382], D Loss: 1.3521, G Loss: 0.8096\n",
            "Epoch [39/100], Step [6400/7382], D Loss: 1.3689, G Loss: 0.7729\n",
            "Epoch [39/100], Step [6500/7382], D Loss: 1.3178, G Loss: 0.7631\n",
            "Epoch [39/100], Step [6600/7382], D Loss: 1.3841, G Loss: 0.7677\n",
            "Epoch [39/100], Step [6700/7382], D Loss: 1.3612, G Loss: 0.7069\n",
            "Epoch [39/100], Step [6800/7382], D Loss: 1.3661, G Loss: 0.7524\n",
            "Epoch [39/100], Step [6900/7382], D Loss: 1.3518, G Loss: 0.7306\n",
            "Epoch [39/100], Step [7000/7382], D Loss: 1.3685, G Loss: 0.7733\n",
            "Epoch [39/100], Step [7100/7382], D Loss: 1.3725, G Loss: 0.7167\n",
            "Epoch [39/100], Step [7200/7382], D Loss: 1.3729, G Loss: 0.7847\n",
            "Epoch [39/100], Step [7300/7382], D Loss: 1.3809, G Loss: 0.7205\n",
            "Epoch [40/100], Step [100/7382], D Loss: 1.4021, G Loss: 0.6945\n",
            "Epoch [40/100], Step [200/7382], D Loss: 1.3599, G Loss: 0.7387\n",
            "Epoch [40/100], Step [300/7382], D Loss: 1.4001, G Loss: 0.7340\n",
            "Epoch [40/100], Step [400/7382], D Loss: 1.4049, G Loss: 0.7257\n",
            "Epoch [40/100], Step [500/7382], D Loss: 1.3530, G Loss: 0.7306\n",
            "Epoch [40/100], Step [600/7382], D Loss: 1.3433, G Loss: 0.7849\n",
            "Epoch [40/100], Step [700/7382], D Loss: 1.3990, G Loss: 0.7335\n",
            "Epoch [40/100], Step [800/7382], D Loss: 1.3415, G Loss: 0.7640\n",
            "Epoch [40/100], Step [900/7382], D Loss: 1.3997, G Loss: 0.7253\n",
            "Epoch [40/100], Step [1000/7382], D Loss: 1.3412, G Loss: 0.7481\n",
            "Epoch [40/100], Step [1100/7382], D Loss: 1.3705, G Loss: 0.7298\n",
            "Epoch [40/100], Step [1200/7382], D Loss: 1.3852, G Loss: 0.7113\n",
            "Epoch [40/100], Step [1300/7382], D Loss: 1.3559, G Loss: 0.7253\n",
            "Epoch [40/100], Step [1400/7382], D Loss: 1.3695, G Loss: 0.7534\n",
            "Epoch [40/100], Step [1500/7382], D Loss: 1.3742, G Loss: 0.7412\n",
            "Epoch [40/100], Step [1600/7382], D Loss: 1.3852, G Loss: 0.7372\n",
            "Epoch [40/100], Step [1700/7382], D Loss: 1.3583, G Loss: 0.7262\n",
            "Epoch [40/100], Step [1800/7382], D Loss: 1.3381, G Loss: 0.7586\n",
            "Epoch [40/100], Step [1900/7382], D Loss: 1.3509, G Loss: 0.7509\n",
            "Epoch [40/100], Step [2000/7382], D Loss: 1.3797, G Loss: 0.7215\n",
            "Epoch [40/100], Step [2100/7382], D Loss: 1.3229, G Loss: 0.8022\n",
            "Epoch [40/100], Step [2200/7382], D Loss: 1.3291, G Loss: 0.7429\n",
            "Epoch [40/100], Step [2300/7382], D Loss: 1.3611, G Loss: 0.7554\n",
            "Epoch [40/100], Step [2400/7382], D Loss: 1.2888, G Loss: 0.8116\n",
            "Epoch [40/100], Step [2500/7382], D Loss: 1.3803, G Loss: 0.7401\n",
            "Epoch [40/100], Step [2600/7382], D Loss: 1.3411, G Loss: 0.7044\n",
            "Epoch [40/100], Step [2700/7382], D Loss: 1.2828, G Loss: 0.7894\n",
            "Epoch [40/100], Step [2800/7382], D Loss: 1.3636, G Loss: 0.7470\n",
            "Epoch [40/100], Step [2900/7382], D Loss: 1.3679, G Loss: 0.7151\n",
            "Epoch [40/100], Step [3000/7382], D Loss: 1.3984, G Loss: 0.7110\n",
            "Epoch [40/100], Step [3100/7382], D Loss: 1.3340, G Loss: 0.7651\n",
            "Epoch [40/100], Step [3200/7382], D Loss: 1.3712, G Loss: 0.7165\n",
            "Epoch [40/100], Step [3300/7382], D Loss: 1.3148, G Loss: 0.8137\n",
            "Epoch [40/100], Step [3400/7382], D Loss: 1.3154, G Loss: 0.7941\n",
            "Epoch [40/100], Step [3500/7382], D Loss: 1.3546, G Loss: 0.7993\n",
            "Epoch [40/100], Step [3600/7382], D Loss: 1.3156, G Loss: 0.8076\n",
            "Epoch [40/100], Step [3700/7382], D Loss: 1.3667, G Loss: 0.7213\n",
            "Epoch [40/100], Step [3800/7382], D Loss: 1.3784, G Loss: 0.7014\n",
            "Epoch [40/100], Step [3900/7382], D Loss: 1.3069, G Loss: 0.8138\n",
            "Epoch [40/100], Step [4000/7382], D Loss: 1.3567, G Loss: 0.7959\n",
            "Epoch [40/100], Step [4100/7382], D Loss: 1.3914, G Loss: 0.7645\n",
            "Epoch [40/100], Step [4200/7382], D Loss: 1.3605, G Loss: 0.7104\n",
            "Epoch [40/100], Step [4300/7382], D Loss: 1.2935, G Loss: 0.9099\n",
            "Epoch [40/100], Step [4400/7382], D Loss: 1.3668, G Loss: 0.7569\n",
            "Epoch [40/100], Step [4500/7382], D Loss: 1.3161, G Loss: 0.7900\n",
            "Epoch [40/100], Step [4600/7382], D Loss: 1.3227, G Loss: 0.7727\n",
            "Epoch [40/100], Step [4700/7382], D Loss: 1.3538, G Loss: 0.8212\n",
            "Epoch [40/100], Step [4800/7382], D Loss: 1.3697, G Loss: 0.7792\n",
            "Epoch [40/100], Step [4900/7382], D Loss: 1.3781, G Loss: 0.7709\n",
            "Epoch [40/100], Step [5000/7382], D Loss: 1.3635, G Loss: 0.7354\n",
            "Epoch [40/100], Step [5100/7382], D Loss: 1.3089, G Loss: 0.8296\n",
            "Epoch [40/100], Step [5200/7382], D Loss: 1.3634, G Loss: 0.7951\n",
            "Epoch [40/100], Step [5300/7382], D Loss: 1.4187, G Loss: 0.7148\n",
            "Epoch [40/100], Step [5400/7382], D Loss: 1.3948, G Loss: 0.7044\n",
            "Epoch [40/100], Step [5500/7382], D Loss: 1.4069, G Loss: 0.7182\n",
            "Epoch [40/100], Step [5600/7382], D Loss: 1.3662, G Loss: 0.7970\n",
            "Epoch [40/100], Step [5700/7382], D Loss: 1.3700, G Loss: 0.7512\n",
            "Epoch [40/100], Step [5800/7382], D Loss: 1.3625, G Loss: 0.7079\n",
            "Epoch [40/100], Step [5900/7382], D Loss: 1.3696, G Loss: 0.7223\n",
            "Epoch [40/100], Step [6000/7382], D Loss: 1.4215, G Loss: 0.7333\n",
            "Epoch [40/100], Step [6100/7382], D Loss: 1.2930, G Loss: 0.7835\n",
            "Epoch [40/100], Step [6200/7382], D Loss: 1.3118, G Loss: 0.8094\n",
            "Epoch [40/100], Step [6300/7382], D Loss: 1.3484, G Loss: 0.7297\n",
            "Epoch [40/100], Step [6400/7382], D Loss: 1.3436, G Loss: 0.8413\n",
            "Epoch [40/100], Step [6500/7382], D Loss: 1.3812, G Loss: 0.6879\n",
            "Epoch [40/100], Step [6600/7382], D Loss: 1.3713, G Loss: 0.7520\n",
            "Epoch [40/100], Step [6700/7382], D Loss: 1.3820, G Loss: 0.8357\n",
            "Epoch [40/100], Step [6800/7382], D Loss: 1.3023, G Loss: 0.8370\n",
            "Epoch [40/100], Step [6900/7382], D Loss: 1.3835, G Loss: 0.7089\n",
            "Epoch [40/100], Step [7000/7382], D Loss: 1.3873, G Loss: 0.7492\n",
            "Epoch [40/100], Step [7100/7382], D Loss: 1.3348, G Loss: 0.7385\n",
            "Epoch [40/100], Step [7200/7382], D Loss: 1.4052, G Loss: 0.7187\n",
            "Epoch [40/100], Step [7300/7382], D Loss: 1.3597, G Loss: 0.7615\n",
            "Epoch [41/100], Step [100/7382], D Loss: 1.3531, G Loss: 0.7288\n",
            "Epoch [41/100], Step [200/7382], D Loss: 1.3250, G Loss: 0.7811\n",
            "Epoch [41/100], Step [300/7382], D Loss: 1.3366, G Loss: 0.7608\n",
            "Epoch [41/100], Step [400/7382], D Loss: 1.3777, G Loss: 0.7118\n",
            "Epoch [41/100], Step [500/7382], D Loss: 1.2857, G Loss: 0.7837\n",
            "Epoch [41/100], Step [600/7382], D Loss: 1.3481, G Loss: 0.7981\n",
            "Epoch [41/100], Step [700/7382], D Loss: 1.3034, G Loss: 0.8242\n",
            "Epoch [41/100], Step [800/7382], D Loss: 1.3915, G Loss: 0.7320\n",
            "Epoch [41/100], Step [900/7382], D Loss: 1.4023, G Loss: 0.7265\n",
            "Epoch [41/100], Step [1000/7382], D Loss: 1.3253, G Loss: 0.7473\n",
            "Epoch [41/100], Step [1100/7382], D Loss: 1.3459, G Loss: 0.7944\n",
            "Epoch [41/100], Step [1200/7382], D Loss: 1.3386, G Loss: 0.7902\n",
            "Epoch [41/100], Step [1300/7382], D Loss: 1.3799, G Loss: 0.7444\n",
            "Epoch [41/100], Step [1400/7382], D Loss: 1.3790, G Loss: 0.6948\n",
            "Epoch [41/100], Step [1500/7382], D Loss: 1.3580, G Loss: 0.7211\n",
            "Epoch [41/100], Step [1600/7382], D Loss: 1.3349, G Loss: 0.7256\n",
            "Epoch [41/100], Step [1700/7382], D Loss: 1.3319, G Loss: 0.7273\n",
            "Epoch [41/100], Step [1800/7382], D Loss: 1.3986, G Loss: 0.6859\n",
            "Epoch [41/100], Step [1900/7382], D Loss: 1.3528, G Loss: 0.7723\n",
            "Epoch [41/100], Step [2000/7382], D Loss: 1.3597, G Loss: 0.8102\n",
            "Epoch [41/100], Step [2100/7382], D Loss: 1.3311, G Loss: 0.7171\n",
            "Epoch [41/100], Step [2200/7382], D Loss: 1.3651, G Loss: 0.8172\n",
            "Epoch [41/100], Step [2300/7382], D Loss: 1.3943, G Loss: 0.7302\n",
            "Epoch [41/100], Step [2400/7382], D Loss: 1.3195, G Loss: 0.7528\n",
            "Epoch [41/100], Step [2500/7382], D Loss: 1.3702, G Loss: 0.7423\n",
            "Epoch [41/100], Step [2600/7382], D Loss: 1.3792, G Loss: 0.7835\n",
            "Epoch [41/100], Step [2700/7382], D Loss: 1.3662, G Loss: 0.7265\n",
            "Epoch [41/100], Step [2800/7382], D Loss: 1.3465, G Loss: 0.7732\n",
            "Epoch [41/100], Step [2900/7382], D Loss: 1.3804, G Loss: 0.7386\n",
            "Epoch [41/100], Step [3000/7382], D Loss: 1.3681, G Loss: 0.7191\n",
            "Epoch [41/100], Step [3100/7382], D Loss: 1.3667, G Loss: 0.7333\n",
            "Epoch [41/100], Step [3200/7382], D Loss: 1.3573, G Loss: 0.7361\n",
            "Epoch [41/100], Step [3300/7382], D Loss: 1.4009, G Loss: 0.7339\n",
            "Epoch [41/100], Step [3400/7382], D Loss: 1.3183, G Loss: 0.7728\n",
            "Epoch [41/100], Step [3500/7382], D Loss: 1.3633, G Loss: 0.7263\n",
            "Epoch [41/100], Step [3600/7382], D Loss: 1.3625, G Loss: 0.7257\n",
            "Epoch [41/100], Step [3700/7382], D Loss: 1.3709, G Loss: 0.7625\n",
            "Epoch [41/100], Step [3800/7382], D Loss: 1.3114, G Loss: 0.8462\n",
            "Epoch [41/100], Step [3900/7382], D Loss: 1.3352, G Loss: 0.7429\n",
            "Epoch [41/100], Step [4000/7382], D Loss: 1.4095, G Loss: 0.7164\n",
            "Epoch [41/100], Step [4100/7382], D Loss: 1.3620, G Loss: 0.8433\n",
            "Epoch [41/100], Step [4200/7382], D Loss: 1.3670, G Loss: 0.7978\n",
            "Epoch [41/100], Step [4300/7382], D Loss: 1.3793, G Loss: 0.7247\n",
            "Epoch [41/100], Step [4400/7382], D Loss: 1.3707, G Loss: 0.7810\n",
            "Epoch [41/100], Step [4500/7382], D Loss: 1.3418, G Loss: 0.7689\n",
            "Epoch [41/100], Step [4600/7382], D Loss: 1.3444, G Loss: 0.7694\n",
            "Epoch [41/100], Step [4700/7382], D Loss: 1.3653, G Loss: 0.7346\n",
            "Epoch [41/100], Step [4800/7382], D Loss: 1.3500, G Loss: 0.7913\n",
            "Epoch [41/100], Step [4900/7382], D Loss: 1.3466, G Loss: 0.7273\n",
            "Epoch [41/100], Step [5000/7382], D Loss: 1.3462, G Loss: 0.7806\n",
            "Epoch [41/100], Step [5100/7382], D Loss: 1.3360, G Loss: 0.8183\n",
            "Epoch [41/100], Step [5200/7382], D Loss: 1.3511, G Loss: 0.7096\n",
            "Epoch [41/100], Step [5300/7382], D Loss: 1.3396, G Loss: 0.7191\n",
            "Epoch [41/100], Step [5400/7382], D Loss: 1.2945, G Loss: 0.8246\n",
            "Epoch [41/100], Step [5500/7382], D Loss: 1.3854, G Loss: 0.6860\n",
            "Epoch [41/100], Step [5600/7382], D Loss: 1.3316, G Loss: 0.7787\n",
            "Epoch [41/100], Step [5700/7382], D Loss: 1.3818, G Loss: 0.7811\n",
            "Epoch [41/100], Step [5800/7382], D Loss: 1.3650, G Loss: 0.7461\n",
            "Epoch [41/100], Step [5900/7382], D Loss: 1.3658, G Loss: 0.7255\n",
            "Epoch [41/100], Step [6000/7382], D Loss: 1.4186, G Loss: 0.7463\n",
            "Epoch [41/100], Step [6100/7382], D Loss: 1.3774, G Loss: 0.7537\n",
            "Epoch [41/100], Step [6200/7382], D Loss: 1.3728, G Loss: 0.7235\n",
            "Epoch [41/100], Step [6300/7382], D Loss: 1.4318, G Loss: 0.7340\n",
            "Epoch [41/100], Step [6400/7382], D Loss: 1.3530, G Loss: 0.7795\n",
            "Epoch [41/100], Step [6500/7382], D Loss: 1.3262, G Loss: 0.8066\n",
            "Epoch [41/100], Step [6600/7382], D Loss: 1.3440, G Loss: 0.7283\n",
            "Epoch [41/100], Step [6700/7382], D Loss: 1.4254, G Loss: 0.7099\n",
            "Epoch [41/100], Step [6800/7382], D Loss: 1.3314, G Loss: 0.8128\n",
            "Epoch [41/100], Step [6900/7382], D Loss: 1.3486, G Loss: 0.7592\n",
            "Epoch [41/100], Step [7000/7382], D Loss: 1.3509, G Loss: 0.7429\n",
            "Epoch [41/100], Step [7100/7382], D Loss: 1.3973, G Loss: 0.7047\n",
            "Epoch [41/100], Step [7200/7382], D Loss: 1.3774, G Loss: 0.7122\n",
            "Epoch [41/100], Step [7300/7382], D Loss: 1.3148, G Loss: 0.7779\n",
            "Epoch [42/100], Step [100/7382], D Loss: 1.3541, G Loss: 0.7794\n",
            "Epoch [42/100], Step [200/7382], D Loss: 1.3849, G Loss: 0.6912\n",
            "Epoch [42/100], Step [300/7382], D Loss: 1.3269, G Loss: 0.7385\n",
            "Epoch [42/100], Step [400/7382], D Loss: 1.3869, G Loss: 0.6955\n",
            "Epoch [42/100], Step [500/7382], D Loss: 1.3577, G Loss: 0.7522\n",
            "Epoch [42/100], Step [600/7382], D Loss: 1.3769, G Loss: 0.7299\n",
            "Epoch [42/100], Step [700/7382], D Loss: 1.3690, G Loss: 0.6867\n",
            "Epoch [42/100], Step [800/7382], D Loss: 1.3212, G Loss: 0.7515\n",
            "Epoch [42/100], Step [900/7382], D Loss: 1.3602, G Loss: 0.7442\n",
            "Epoch [42/100], Step [1000/7382], D Loss: 1.3755, G Loss: 0.7331\n",
            "Epoch [42/100], Step [1100/7382], D Loss: 1.3592, G Loss: 0.7297\n",
            "Epoch [42/100], Step [1200/7382], D Loss: 1.3189, G Loss: 0.7871\n",
            "Epoch [42/100], Step [1300/7382], D Loss: 1.3874, G Loss: 0.7130\n",
            "Epoch [42/100], Step [1400/7382], D Loss: 1.3912, G Loss: 0.7040\n",
            "Epoch [42/100], Step [1500/7382], D Loss: 1.3689, G Loss: 0.7674\n",
            "Epoch [42/100], Step [1600/7382], D Loss: 1.3486, G Loss: 0.7741\n",
            "Epoch [42/100], Step [1700/7382], D Loss: 1.3203, G Loss: 0.7994\n",
            "Epoch [42/100], Step [1800/7382], D Loss: 1.3554, G Loss: 0.7410\n",
            "Epoch [42/100], Step [1900/7382], D Loss: 1.2969, G Loss: 0.8278\n",
            "Epoch [42/100], Step [2000/7382], D Loss: 1.3910, G Loss: 0.7544\n",
            "Epoch [42/100], Step [2100/7382], D Loss: 1.3481, G Loss: 0.7643\n",
            "Epoch [42/100], Step [2200/7382], D Loss: 1.3195, G Loss: 0.7981\n",
            "Epoch [42/100], Step [2300/7382], D Loss: 1.3397, G Loss: 0.7902\n",
            "Epoch [42/100], Step [2400/7382], D Loss: 1.3608, G Loss: 0.7295\n",
            "Epoch [42/100], Step [2500/7382], D Loss: 1.3959, G Loss: 0.7674\n",
            "Epoch [42/100], Step [2600/7382], D Loss: 1.3668, G Loss: 0.7580\n",
            "Epoch [42/100], Step [2700/7382], D Loss: 1.3080, G Loss: 0.7738\n",
            "Epoch [42/100], Step [2800/7382], D Loss: 1.3802, G Loss: 0.7222\n",
            "Epoch [42/100], Step [2900/7382], D Loss: 1.3253, G Loss: 0.7708\n",
            "Epoch [42/100], Step [3000/7382], D Loss: 1.3373, G Loss: 0.7716\n",
            "Epoch [42/100], Step [3100/7382], D Loss: 1.4269, G Loss: 0.8035\n",
            "Epoch [42/100], Step [3200/7382], D Loss: 1.3441, G Loss: 0.8104\n",
            "Epoch [42/100], Step [3300/7382], D Loss: 1.3637, G Loss: 0.7451\n",
            "Epoch [42/100], Step [3400/7382], D Loss: 1.2653, G Loss: 0.8218\n",
            "Epoch [42/100], Step [3500/7382], D Loss: 1.2673, G Loss: 0.9507\n",
            "Epoch [42/100], Step [3600/7382], D Loss: 1.1808, G Loss: 0.8532\n",
            "Epoch [42/100], Step [3700/7382], D Loss: 1.2849, G Loss: 0.7989\n",
            "Epoch [42/100], Step [3800/7382], D Loss: 1.3432, G Loss: 0.7733\n",
            "Epoch [42/100], Step [3900/7382], D Loss: 1.3532, G Loss: 0.7958\n",
            "Epoch [42/100], Step [4000/7382], D Loss: 1.2989, G Loss: 0.8239\n",
            "Epoch [42/100], Step [4100/7382], D Loss: 1.2401, G Loss: 0.8222\n",
            "Epoch [42/100], Step [4200/7382], D Loss: 1.3414, G Loss: 0.7747\n",
            "Epoch [42/100], Step [4300/7382], D Loss: 1.3446, G Loss: 0.7777\n",
            "Epoch [42/100], Step [4400/7382], D Loss: 1.3354, G Loss: 0.7850\n",
            "Epoch [42/100], Step [4500/7382], D Loss: 1.3687, G Loss: 0.7467\n",
            "Epoch [42/100], Step [4600/7382], D Loss: 1.3711, G Loss: 0.7770\n",
            "Epoch [42/100], Step [4700/7382], D Loss: 1.3145, G Loss: 0.8512\n",
            "Epoch [42/100], Step [4800/7382], D Loss: 1.3295, G Loss: 0.8131\n",
            "Epoch [42/100], Step [4900/7382], D Loss: 1.3594, G Loss: 0.7753\n",
            "Epoch [42/100], Step [5000/7382], D Loss: 1.3427, G Loss: 0.7338\n",
            "Epoch [42/100], Step [5100/7382], D Loss: 1.3131, G Loss: 0.7870\n",
            "Epoch [42/100], Step [5200/7382], D Loss: 1.3418, G Loss: 0.7785\n",
            "Epoch [42/100], Step [5300/7382], D Loss: 1.3625, G Loss: 0.8207\n",
            "Epoch [42/100], Step [5400/7382], D Loss: 1.3441, G Loss: 0.7450\n",
            "Epoch [42/100], Step [5500/7382], D Loss: 1.3028, G Loss: 0.8294\n",
            "Epoch [42/100], Step [5600/7382], D Loss: 1.2532, G Loss: 0.9228\n",
            "Epoch [42/100], Step [5700/7382], D Loss: 1.2782, G Loss: 0.8122\n",
            "Epoch [42/100], Step [5800/7382], D Loss: 1.3672, G Loss: 0.7821\n",
            "Epoch [42/100], Step [5900/7382], D Loss: 1.3911, G Loss: 0.7924\n",
            "Epoch [42/100], Step [6000/7382], D Loss: 1.2732, G Loss: 0.8019\n",
            "Epoch [42/100], Step [6100/7382], D Loss: 1.4458, G Loss: 0.7313\n",
            "Epoch [42/100], Step [6200/7382], D Loss: 1.2951, G Loss: 0.8106\n",
            "Epoch [42/100], Step [6300/7382], D Loss: 1.1943, G Loss: 0.9497\n",
            "Epoch [42/100], Step [6400/7382], D Loss: 1.2900, G Loss: 0.8093\n",
            "Epoch [42/100], Step [6500/7382], D Loss: 1.3738, G Loss: 0.7476\n",
            "Epoch [42/100], Step [6600/7382], D Loss: 1.3908, G Loss: 0.8117\n",
            "Epoch [42/100], Step [6700/7382], D Loss: 1.2889, G Loss: 0.8347\n",
            "Epoch [42/100], Step [6800/7382], D Loss: 1.2407, G Loss: 0.8741\n",
            "Epoch [42/100], Step [6900/7382], D Loss: 1.2882, G Loss: 0.8010\n",
            "Epoch [42/100], Step [7000/7382], D Loss: 1.3015, G Loss: 0.8115\n",
            "Epoch [42/100], Step [7100/7382], D Loss: 1.3373, G Loss: 0.8249\n",
            "Epoch [42/100], Step [7200/7382], D Loss: 1.3431, G Loss: 0.8064\n",
            "Epoch [42/100], Step [7300/7382], D Loss: 1.3215, G Loss: 0.7789\n",
            "Epoch [43/100], Step [100/7382], D Loss: 1.3025, G Loss: 0.7894\n",
            "Epoch [43/100], Step [200/7382], D Loss: 1.2382, G Loss: 0.8327\n",
            "Epoch [43/100], Step [300/7382], D Loss: 1.3088, G Loss: 0.8858\n",
            "Epoch [43/100], Step [400/7382], D Loss: 1.2879, G Loss: 0.8733\n",
            "Epoch [43/100], Step [500/7382], D Loss: 1.2875, G Loss: 0.8557\n",
            "Epoch [43/100], Step [600/7382], D Loss: 1.2838, G Loss: 0.8487\n",
            "Epoch [43/100], Step [700/7382], D Loss: 1.3597, G Loss: 0.7686\n",
            "Epoch [43/100], Step [800/7382], D Loss: 1.3080, G Loss: 0.8017\n",
            "Epoch [43/100], Step [900/7382], D Loss: 1.2782, G Loss: 0.8252\n",
            "Epoch [43/100], Step [1000/7382], D Loss: 1.3286, G Loss: 0.7938\n",
            "Epoch [43/100], Step [1100/7382], D Loss: 1.2996, G Loss: 0.7511\n",
            "Epoch [43/100], Step [1200/7382], D Loss: 1.2810, G Loss: 0.8039\n",
            "Epoch [43/100], Step [1300/7382], D Loss: 1.2937, G Loss: 0.7911\n",
            "Epoch [43/100], Step [1400/7382], D Loss: 1.2777, G Loss: 0.8066\n",
            "Epoch [43/100], Step [1500/7382], D Loss: 1.3689, G Loss: 0.7609\n",
            "Epoch [43/100], Step [1600/7382], D Loss: 1.2743, G Loss: 0.8249\n",
            "Epoch [43/100], Step [1700/7382], D Loss: 1.3391, G Loss: 0.7962\n",
            "Epoch [43/100], Step [1800/7382], D Loss: 1.3097, G Loss: 0.7910\n",
            "Epoch [43/100], Step [1900/7382], D Loss: 1.3776, G Loss: 0.7421\n",
            "Epoch [43/100], Step [2000/7382], D Loss: 1.3327, G Loss: 0.7642\n",
            "Epoch [43/100], Step [2100/7382], D Loss: 1.3717, G Loss: 0.7248\n",
            "Epoch [43/100], Step [2200/7382], D Loss: 1.3240, G Loss: 0.8486\n",
            "Epoch [43/100], Step [2300/7382], D Loss: 1.3275, G Loss: 0.7564\n",
            "Epoch [43/100], Step [2400/7382], D Loss: 1.4093, G Loss: 0.7580\n",
            "Epoch [43/100], Step [2500/7382], D Loss: 1.3838, G Loss: 0.7208\n",
            "Epoch [43/100], Step [2600/7382], D Loss: 1.3807, G Loss: 0.7247\n",
            "Epoch [43/100], Step [2700/7382], D Loss: 1.3258, G Loss: 0.7619\n",
            "Epoch [43/100], Step [2800/7382], D Loss: 1.4012, G Loss: 0.7017\n",
            "Epoch [43/100], Step [2900/7382], D Loss: 1.3713, G Loss: 0.7363\n",
            "Epoch [43/100], Step [3000/7382], D Loss: 1.3371, G Loss: 0.7497\n",
            "Epoch [43/100], Step [3100/7382], D Loss: 1.3550, G Loss: 0.7965\n",
            "Epoch [43/100], Step [3200/7382], D Loss: 1.3134, G Loss: 0.7844\n",
            "Epoch [43/100], Step [3300/7382], D Loss: 1.3437, G Loss: 0.7355\n",
            "Epoch [43/100], Step [3400/7382], D Loss: 1.3374, G Loss: 0.7488\n",
            "Epoch [43/100], Step [3500/7382], D Loss: 1.3864, G Loss: 0.7287\n",
            "Epoch [43/100], Step [3600/7382], D Loss: 1.3883, G Loss: 0.7223\n",
            "Epoch [43/100], Step [3700/7382], D Loss: 1.3729, G Loss: 0.7368\n",
            "Epoch [43/100], Step [3800/7382], D Loss: 1.3221, G Loss: 0.7711\n",
            "Epoch [43/100], Step [3900/7382], D Loss: 1.3525, G Loss: 0.7550\n",
            "Epoch [43/100], Step [4000/7382], D Loss: 1.3176, G Loss: 0.7754\n",
            "Epoch [43/100], Step [4100/7382], D Loss: 1.3704, G Loss: 0.7371\n",
            "Epoch [43/100], Step [4200/7382], D Loss: 1.3028, G Loss: 0.8324\n",
            "Epoch [43/100], Step [4300/7382], D Loss: 1.2779, G Loss: 0.8237\n",
            "Epoch [43/100], Step [4400/7382], D Loss: 1.3500, G Loss: 0.7833\n",
            "Epoch [43/100], Step [4500/7382], D Loss: 1.3266, G Loss: 0.7460\n",
            "Epoch [43/100], Step [4600/7382], D Loss: 1.3159, G Loss: 0.8350\n",
            "Epoch [43/100], Step [4700/7382], D Loss: 1.3540, G Loss: 0.7932\n",
            "Epoch [43/100], Step [4800/7382], D Loss: 1.3439, G Loss: 0.7362\n",
            "Epoch [43/100], Step [4900/7382], D Loss: 1.3482, G Loss: 0.8097\n",
            "Epoch [43/100], Step [5000/7382], D Loss: 1.3439, G Loss: 0.7606\n",
            "Epoch [43/100], Step [5100/7382], D Loss: 1.3965, G Loss: 0.6946\n",
            "Epoch [43/100], Step [5200/7382], D Loss: 1.4039, G Loss: 0.7964\n",
            "Epoch [43/100], Step [5300/7382], D Loss: 1.3523, G Loss: 0.7928\n",
            "Epoch [43/100], Step [5400/7382], D Loss: 1.3846, G Loss: 0.7467\n",
            "Epoch [43/100], Step [5500/7382], D Loss: 1.3580, G Loss: 0.7778\n",
            "Epoch [43/100], Step [5600/7382], D Loss: 1.2933, G Loss: 0.8237\n",
            "Epoch [43/100], Step [5700/7382], D Loss: 1.3509, G Loss: 0.7947\n",
            "Epoch [43/100], Step [5800/7382], D Loss: 1.2859, G Loss: 0.8165\n",
            "Epoch [43/100], Step [5900/7382], D Loss: 1.3259, G Loss: 0.7455\n",
            "Epoch [43/100], Step [6000/7382], D Loss: 1.3207, G Loss: 0.8092\n",
            "Epoch [43/100], Step [6100/7382], D Loss: 1.3282, G Loss: 0.7638\n",
            "Epoch [43/100], Step [6200/7382], D Loss: 1.3411, G Loss: 0.7830\n",
            "Epoch [43/100], Step [6300/7382], D Loss: 1.3729, G Loss: 0.7660\n",
            "Epoch [43/100], Step [6400/7382], D Loss: 1.3930, G Loss: 0.7386\n",
            "Epoch [43/100], Step [6500/7382], D Loss: 1.3489, G Loss: 0.7387\n",
            "Epoch [43/100], Step [6600/7382], D Loss: 1.3756, G Loss: 0.7405\n",
            "Epoch [43/100], Step [6700/7382], D Loss: 1.3862, G Loss: 0.7158\n",
            "Epoch [43/100], Step [6800/7382], D Loss: 1.3010, G Loss: 0.8165\n",
            "Epoch [43/100], Step [6900/7382], D Loss: 1.3835, G Loss: 0.7066\n",
            "Epoch [43/100], Step [7000/7382], D Loss: 1.3926, G Loss: 0.7642\n",
            "Epoch [43/100], Step [7100/7382], D Loss: 1.3786, G Loss: 0.7361\n",
            "Epoch [43/100], Step [7200/7382], D Loss: 1.3535, G Loss: 0.8399\n",
            "Epoch [43/100], Step [7300/7382], D Loss: 1.3729, G Loss: 0.8065\n",
            "Epoch [44/100], Step [100/7382], D Loss: 1.3563, G Loss: 0.7548\n",
            "Epoch [44/100], Step [200/7382], D Loss: 1.3767, G Loss: 0.7606\n",
            "Epoch [44/100], Step [300/7382], D Loss: 1.3249, G Loss: 0.8202\n",
            "Epoch [44/100], Step [400/7382], D Loss: 1.3486, G Loss: 0.7316\n",
            "Epoch [44/100], Step [500/7382], D Loss: 1.3674, G Loss: 0.7578\n",
            "Epoch [44/100], Step [600/7382], D Loss: 1.3282, G Loss: 0.8104\n",
            "Epoch [44/100], Step [700/7382], D Loss: 1.3729, G Loss: 0.7431\n",
            "Epoch [44/100], Step [800/7382], D Loss: 1.3614, G Loss: 0.7674\n",
            "Epoch [44/100], Step [900/7382], D Loss: 1.2954, G Loss: 0.7940\n",
            "Epoch [44/100], Step [1000/7382], D Loss: 1.3733, G Loss: 0.7088\n",
            "Epoch [44/100], Step [1100/7382], D Loss: 1.3583, G Loss: 0.7502\n",
            "Epoch [44/100], Step [1200/7382], D Loss: 1.3387, G Loss: 0.7794\n",
            "Epoch [44/100], Step [1300/7382], D Loss: 1.3818, G Loss: 0.6828\n",
            "Epoch [44/100], Step [1400/7382], D Loss: 1.3035, G Loss: 0.8481\n",
            "Epoch [44/100], Step [1500/7382], D Loss: 1.4027, G Loss: 0.7156\n",
            "Epoch [44/100], Step [1600/7382], D Loss: 1.3599, G Loss: 0.6999\n",
            "Epoch [44/100], Step [1700/7382], D Loss: 1.4045, G Loss: 0.7501\n",
            "Epoch [44/100], Step [1800/7382], D Loss: 1.3446, G Loss: 0.7311\n",
            "Epoch [44/100], Step [1900/7382], D Loss: 1.3284, G Loss: 0.7547\n",
            "Epoch [44/100], Step [2000/7382], D Loss: 1.3096, G Loss: 0.7670\n",
            "Epoch [44/100], Step [2100/7382], D Loss: 1.3279, G Loss: 0.7412\n",
            "Epoch [44/100], Step [2200/7382], D Loss: 1.3774, G Loss: 0.7417\n",
            "Epoch [44/100], Step [2300/7382], D Loss: 1.3441, G Loss: 0.7421\n",
            "Epoch [44/100], Step [2400/7382], D Loss: 1.2904, G Loss: 0.9216\n",
            "Epoch [44/100], Step [2500/7382], D Loss: 1.3500, G Loss: 0.7703\n",
            "Epoch [44/100], Step [2600/7382], D Loss: 1.3270, G Loss: 0.8325\n",
            "Epoch [44/100], Step [2700/7382], D Loss: 1.3842, G Loss: 0.7744\n",
            "Epoch [44/100], Step [2800/7382], D Loss: 1.3352, G Loss: 0.7765\n",
            "Epoch [44/100], Step [2900/7382], D Loss: 1.3884, G Loss: 0.7052\n",
            "Epoch [44/100], Step [3000/7382], D Loss: 1.3364, G Loss: 0.7847\n",
            "Epoch [44/100], Step [3100/7382], D Loss: 1.3525, G Loss: 0.8029\n",
            "Epoch [44/100], Step [3200/7382], D Loss: 1.3403, G Loss: 0.7562\n",
            "Epoch [44/100], Step [3300/7382], D Loss: 1.3145, G Loss: 0.7948\n",
            "Epoch [44/100], Step [3400/7382], D Loss: 1.3553, G Loss: 0.7367\n",
            "Epoch [44/100], Step [3500/7382], D Loss: 1.3379, G Loss: 0.7337\n",
            "Epoch [44/100], Step [3600/7382], D Loss: 1.3505, G Loss: 0.7716\n",
            "Epoch [44/100], Step [3700/7382], D Loss: 1.3414, G Loss: 0.7333\n",
            "Epoch [44/100], Step [3800/7382], D Loss: 1.2714, G Loss: 0.8274\n",
            "Epoch [44/100], Step [3900/7382], D Loss: 1.3743, G Loss: 0.7175\n",
            "Epoch [44/100], Step [4000/7382], D Loss: 1.2834, G Loss: 0.7771\n",
            "Epoch [44/100], Step [4100/7382], D Loss: 1.3545, G Loss: 0.7691\n",
            "Epoch [44/100], Step [4200/7382], D Loss: 1.3561, G Loss: 0.7635\n",
            "Epoch [44/100], Step [4300/7382], D Loss: 1.3098, G Loss: 0.8021\n",
            "Epoch [44/100], Step [4400/7382], D Loss: 1.3676, G Loss: 0.7322\n",
            "Epoch [44/100], Step [4500/7382], D Loss: 1.2821, G Loss: 0.7754\n",
            "Epoch [44/100], Step [4600/7382], D Loss: 1.3023, G Loss: 0.8305\n",
            "Epoch [44/100], Step [4700/7382], D Loss: 1.3117, G Loss: 0.7763\n",
            "Epoch [44/100], Step [4800/7382], D Loss: 1.4277, G Loss: 0.6994\n",
            "Epoch [44/100], Step [4900/7382], D Loss: 1.3854, G Loss: 0.7414\n",
            "Epoch [44/100], Step [5000/7382], D Loss: 1.3524, G Loss: 0.8027\n",
            "Epoch [44/100], Step [5100/7382], D Loss: 1.3652, G Loss: 0.7460\n",
            "Epoch [44/100], Step [5200/7382], D Loss: 1.3676, G Loss: 0.7196\n",
            "Epoch [44/100], Step [5300/7382], D Loss: 1.3633, G Loss: 0.7630\n",
            "Epoch [44/100], Step [5400/7382], D Loss: 1.3024, G Loss: 0.7826\n",
            "Epoch [44/100], Step [5500/7382], D Loss: 1.3808, G Loss: 0.7444\n",
            "Epoch [44/100], Step [5600/7382], D Loss: 1.3431, G Loss: 0.7364\n",
            "Epoch [44/100], Step [5700/7382], D Loss: 1.3529, G Loss: 0.7662\n",
            "Epoch [44/100], Step [5800/7382], D Loss: 1.3491, G Loss: 0.7376\n",
            "Epoch [44/100], Step [5900/7382], D Loss: 1.3742, G Loss: 0.7246\n",
            "Epoch [44/100], Step [6000/7382], D Loss: 1.3843, G Loss: 0.7741\n",
            "Epoch [44/100], Step [6100/7382], D Loss: 1.3973, G Loss: 0.7917\n",
            "Epoch [44/100], Step [6200/7382], D Loss: 1.3609, G Loss: 0.7176\n",
            "Epoch [44/100], Step [6300/7382], D Loss: 1.3908, G Loss: 0.7413\n",
            "Epoch [44/100], Step [6400/7382], D Loss: 1.3830, G Loss: 0.7375\n",
            "Epoch [44/100], Step [6500/7382], D Loss: 1.3381, G Loss: 0.7859\n",
            "Epoch [44/100], Step [6600/7382], D Loss: 1.3556, G Loss: 0.7353\n",
            "Epoch [44/100], Step [6700/7382], D Loss: 1.3389, G Loss: 0.8078\n",
            "Epoch [44/100], Step [6800/7382], D Loss: 1.3374, G Loss: 0.7641\n",
            "Epoch [44/100], Step [6900/7382], D Loss: 1.3368, G Loss: 0.8020\n",
            "Epoch [44/100], Step [7000/7382], D Loss: 1.3155, G Loss: 0.7983\n",
            "Epoch [44/100], Step [7100/7382], D Loss: 1.3332, G Loss: 0.7114\n",
            "Epoch [44/100], Step [7200/7382], D Loss: 1.4250, G Loss: 0.7302\n",
            "Epoch [44/100], Step [7300/7382], D Loss: 1.3560, G Loss: 0.7760\n",
            "Epoch [45/100], Step [100/7382], D Loss: 1.2891, G Loss: 0.8491\n",
            "Epoch [45/100], Step [200/7382], D Loss: 1.4094, G Loss: 0.7884\n",
            "Epoch [45/100], Step [300/7382], D Loss: 1.3142, G Loss: 0.8178\n",
            "Epoch [45/100], Step [400/7382], D Loss: 1.3512, G Loss: 0.7458\n",
            "Epoch [45/100], Step [500/7382], D Loss: 1.3201, G Loss: 0.8498\n",
            "Epoch [45/100], Step [600/7382], D Loss: 1.3313, G Loss: 0.7577\n",
            "Epoch [45/100], Step [700/7382], D Loss: 1.3742, G Loss: 0.7910\n",
            "Epoch [45/100], Step [800/7382], D Loss: 1.3760, G Loss: 0.7349\n",
            "Epoch [45/100], Step [900/7382], D Loss: 1.3331, G Loss: 0.7820\n",
            "Epoch [45/100], Step [1000/7382], D Loss: 1.3750, G Loss: 0.7271\n",
            "Epoch [45/100], Step [1100/7382], D Loss: 1.3432, G Loss: 0.8508\n",
            "Epoch [45/100], Step [1200/7382], D Loss: 1.3601, G Loss: 0.7124\n",
            "Epoch [45/100], Step [1300/7382], D Loss: 1.3256, G Loss: 0.8049\n",
            "Epoch [45/100], Step [1400/7382], D Loss: 1.3281, G Loss: 0.7885\n",
            "Epoch [45/100], Step [1500/7382], D Loss: 1.3503, G Loss: 0.8071\n",
            "Epoch [45/100], Step [1600/7382], D Loss: 1.3470, G Loss: 0.7463\n",
            "Epoch [45/100], Step [1700/7382], D Loss: 1.3624, G Loss: 0.7446\n",
            "Epoch [45/100], Step [1800/7382], D Loss: 1.3207, G Loss: 0.8086\n",
            "Epoch [45/100], Step [1900/7382], D Loss: 1.3294, G Loss: 0.7831\n",
            "Epoch [45/100], Step [2000/7382], D Loss: 1.3160, G Loss: 0.8288\n",
            "Epoch [45/100], Step [2100/7382], D Loss: 1.3053, G Loss: 0.8267\n",
            "Epoch [45/100], Step [2200/7382], D Loss: 1.3670, G Loss: 0.7313\n",
            "Epoch [45/100], Step [2300/7382], D Loss: 1.3623, G Loss: 0.7361\n",
            "Epoch [45/100], Step [2400/7382], D Loss: 1.3528, G Loss: 0.7252\n",
            "Epoch [45/100], Step [2500/7382], D Loss: 1.3558, G Loss: 0.7541\n",
            "Epoch [45/100], Step [2600/7382], D Loss: 1.2896, G Loss: 0.8660\n",
            "Epoch [45/100], Step [2700/7382], D Loss: 1.3747, G Loss: 0.7432\n",
            "Epoch [45/100], Step [2800/7382], D Loss: 1.3926, G Loss: 0.7451\n",
            "Epoch [45/100], Step [2900/7382], D Loss: 1.3423, G Loss: 0.7847\n",
            "Epoch [45/100], Step [3000/7382], D Loss: 1.3667, G Loss: 0.7539\n",
            "Epoch [45/100], Step [3100/7382], D Loss: 1.3757, G Loss: 0.7373\n",
            "Epoch [45/100], Step [3200/7382], D Loss: 1.3346, G Loss: 0.8144\n",
            "Epoch [45/100], Step [3300/7382], D Loss: 1.3665, G Loss: 0.7443\n",
            "Epoch [45/100], Step [3400/7382], D Loss: 1.3627, G Loss: 0.7582\n",
            "Epoch [45/100], Step [3500/7382], D Loss: 1.4104, G Loss: 0.7165\n",
            "Epoch [45/100], Step [3600/7382], D Loss: 1.3541, G Loss: 0.7940\n",
            "Epoch [45/100], Step [3700/7382], D Loss: 1.3675, G Loss: 0.7481\n",
            "Epoch [45/100], Step [3800/7382], D Loss: 1.3977, G Loss: 0.6916\n",
            "Epoch [45/100], Step [3900/7382], D Loss: 1.3912, G Loss: 0.7551\n",
            "Epoch [45/100], Step [4000/7382], D Loss: 1.3508, G Loss: 0.7586\n",
            "Epoch [45/100], Step [4100/7382], D Loss: 1.3680, G Loss: 0.7810\n",
            "Epoch [45/100], Step [4200/7382], D Loss: 1.3680, G Loss: 0.7859\n",
            "Epoch [45/100], Step [4300/7382], D Loss: 1.3832, G Loss: 0.7123\n",
            "Epoch [45/100], Step [4400/7382], D Loss: 1.3635, G Loss: 0.7822\n",
            "Epoch [45/100], Step [4500/7382], D Loss: 1.3575, G Loss: 0.7372\n",
            "Epoch [45/100], Step [4600/7382], D Loss: 1.3399, G Loss: 0.7463\n",
            "Epoch [45/100], Step [4700/7382], D Loss: 1.3729, G Loss: 0.7252\n",
            "Epoch [45/100], Step [4800/7382], D Loss: 1.3699, G Loss: 0.7107\n",
            "Epoch [45/100], Step [4900/7382], D Loss: 1.3622, G Loss: 0.7602\n",
            "Epoch [45/100], Step [5000/7382], D Loss: 1.3300, G Loss: 0.7860\n",
            "Epoch [45/100], Step [5100/7382], D Loss: 1.3746, G Loss: 0.7880\n",
            "Epoch [45/100], Step [5200/7382], D Loss: 1.3279, G Loss: 0.8968\n",
            "Epoch [45/100], Step [5300/7382], D Loss: 1.3582, G Loss: 0.8125\n",
            "Epoch [45/100], Step [5400/7382], D Loss: 1.3754, G Loss: 0.7599\n",
            "Epoch [45/100], Step [5500/7382], D Loss: 1.3248, G Loss: 0.7715\n",
            "Epoch [45/100], Step [5600/7382], D Loss: 1.3793, G Loss: 0.7746\n",
            "Epoch [45/100], Step [5700/7382], D Loss: 1.3593, G Loss: 0.8180\n",
            "Epoch [45/100], Step [5800/7382], D Loss: 1.3820, G Loss: 0.7788\n",
            "Epoch [45/100], Step [5900/7382], D Loss: 1.3711, G Loss: 0.7996\n",
            "Epoch [45/100], Step [6000/7382], D Loss: 1.3935, G Loss: 0.7670\n",
            "Epoch [45/100], Step [6100/7382], D Loss: 1.3795, G Loss: 0.6971\n",
            "Epoch [45/100], Step [6200/7382], D Loss: 1.4184, G Loss: 0.7081\n",
            "Epoch [45/100], Step [6300/7382], D Loss: 1.3685, G Loss: 0.7262\n",
            "Epoch [45/100], Step [6400/7382], D Loss: 1.3385, G Loss: 0.7473\n",
            "Epoch [45/100], Step [6500/7382], D Loss: 1.3978, G Loss: 0.7704\n",
            "Epoch [45/100], Step [6600/7382], D Loss: 1.3662, G Loss: 0.7450\n",
            "Epoch [45/100], Step [6700/7382], D Loss: 1.3055, G Loss: 0.8100\n",
            "Epoch [45/100], Step [6800/7382], D Loss: 1.2779, G Loss: 0.8476\n",
            "Epoch [45/100], Step [6900/7382], D Loss: 1.3171, G Loss: 0.7636\n",
            "Epoch [45/100], Step [7000/7382], D Loss: 1.3472, G Loss: 0.8095\n",
            "Epoch [45/100], Step [7100/7382], D Loss: 1.2692, G Loss: 0.8595\n",
            "Epoch [45/100], Step [7200/7382], D Loss: 1.3680, G Loss: 0.7575\n",
            "Epoch [45/100], Step [7300/7382], D Loss: 1.3132, G Loss: 0.8184\n",
            "Epoch [46/100], Step [100/7382], D Loss: 1.2748, G Loss: 0.8575\n",
            "Epoch [46/100], Step [200/7382], D Loss: 1.3466, G Loss: 0.7555\n",
            "Epoch [46/100], Step [300/7382], D Loss: 1.3881, G Loss: 0.7127\n",
            "Epoch [46/100], Step [400/7382], D Loss: 1.3756, G Loss: 0.7165\n",
            "Epoch [46/100], Step [500/7382], D Loss: 1.3714, G Loss: 0.7824\n",
            "Epoch [46/100], Step [600/7382], D Loss: 1.3281, G Loss: 0.8187\n",
            "Epoch [46/100], Step [700/7382], D Loss: 1.3364, G Loss: 0.7561\n",
            "Epoch [46/100], Step [800/7382], D Loss: 1.3740, G Loss: 0.7440\n",
            "Epoch [46/100], Step [900/7382], D Loss: 1.3856, G Loss: 0.8112\n",
            "Epoch [46/100], Step [1000/7382], D Loss: 1.2706, G Loss: 0.8166\n",
            "Epoch [46/100], Step [1100/7382], D Loss: 1.3861, G Loss: 0.7679\n",
            "Epoch [46/100], Step [1200/7382], D Loss: 1.2734, G Loss: 0.8689\n",
            "Epoch [46/100], Step [1300/7382], D Loss: 1.3841, G Loss: 0.7601\n",
            "Epoch [46/100], Step [1400/7382], D Loss: 1.4091, G Loss: 0.7364\n",
            "Epoch [46/100], Step [1500/7382], D Loss: 1.3425, G Loss: 0.7630\n",
            "Epoch [46/100], Step [1600/7382], D Loss: 1.3896, G Loss: 0.7271\n",
            "Epoch [46/100], Step [1700/7382], D Loss: 1.4129, G Loss: 0.7341\n",
            "Epoch [46/100], Step [1800/7382], D Loss: 1.3356, G Loss: 0.7505\n",
            "Epoch [46/100], Step [1900/7382], D Loss: 1.3696, G Loss: 0.7494\n",
            "Epoch [46/100], Step [2000/7382], D Loss: 1.3617, G Loss: 0.7392\n",
            "Epoch [46/100], Step [2100/7382], D Loss: 1.3399, G Loss: 0.7294\n",
            "Epoch [46/100], Step [2200/7382], D Loss: 1.3509, G Loss: 0.7803\n",
            "Epoch [46/100], Step [2300/7382], D Loss: 1.3112, G Loss: 0.8029\n",
            "Epoch [46/100], Step [2400/7382], D Loss: 1.3728, G Loss: 0.7172\n",
            "Epoch [46/100], Step [2500/7382], D Loss: 1.3736, G Loss: 0.7041\n",
            "Epoch [46/100], Step [2600/7382], D Loss: 1.3836, G Loss: 0.7403\n",
            "Epoch [46/100], Step [2700/7382], D Loss: 1.3592, G Loss: 0.7459\n",
            "Epoch [46/100], Step [2800/7382], D Loss: 1.3385, G Loss: 0.7460\n",
            "Epoch [46/100], Step [2900/7382], D Loss: 1.4115, G Loss: 0.7014\n",
            "Epoch [46/100], Step [3000/7382], D Loss: 1.3564, G Loss: 0.7180\n",
            "Epoch [46/100], Step [3100/7382], D Loss: 1.3601, G Loss: 0.7394\n",
            "Epoch [46/100], Step [3200/7382], D Loss: 1.3422, G Loss: 0.6941\n",
            "Epoch [46/100], Step [3300/7382], D Loss: 1.3142, G Loss: 0.7897\n",
            "Epoch [46/100], Step [3400/7382], D Loss: 1.3330, G Loss: 0.7541\n",
            "Epoch [46/100], Step [3500/7382], D Loss: 1.3675, G Loss: 0.7286\n",
            "Epoch [46/100], Step [3600/7382], D Loss: 1.3428, G Loss: 0.7340\n",
            "Epoch [46/100], Step [3700/7382], D Loss: 1.3996, G Loss: 0.7635\n",
            "Epoch [46/100], Step [3800/7382], D Loss: 1.3541, G Loss: 0.7551\n",
            "Epoch [46/100], Step [3900/7382], D Loss: 1.3499, G Loss: 0.7683\n",
            "Epoch [46/100], Step [4000/7382], D Loss: 1.3738, G Loss: 0.7373\n",
            "Epoch [46/100], Step [4100/7382], D Loss: 1.3213, G Loss: 0.7472\n",
            "Epoch [46/100], Step [4200/7382], D Loss: 1.3825, G Loss: 0.7957\n",
            "Epoch [46/100], Step [4300/7382], D Loss: 1.3447, G Loss: 0.8368\n",
            "Epoch [46/100], Step [4400/7382], D Loss: 1.3406, G Loss: 0.7543\n",
            "Epoch [46/100], Step [4500/7382], D Loss: 1.3731, G Loss: 0.7198\n",
            "Epoch [46/100], Step [4600/7382], D Loss: 1.3392, G Loss: 0.8331\n",
            "Epoch [46/100], Step [4700/7382], D Loss: 1.3750, G Loss: 0.7002\n",
            "Epoch [46/100], Step [4800/7382], D Loss: 1.3458, G Loss: 0.7216\n",
            "Epoch [46/100], Step [4900/7382], D Loss: 1.3646, G Loss: 0.7165\n",
            "Epoch [46/100], Step [5000/7382], D Loss: 1.3695, G Loss: 0.7375\n",
            "Epoch [46/100], Step [5100/7382], D Loss: 1.3646, G Loss: 0.7494\n",
            "Epoch [46/100], Step [5200/7382], D Loss: 1.3572, G Loss: 0.7911\n",
            "Epoch [46/100], Step [5300/7382], D Loss: 1.3649, G Loss: 0.7745\n",
            "Epoch [46/100], Step [5400/7382], D Loss: 1.2948, G Loss: 0.8503\n",
            "Epoch [46/100], Step [5500/7382], D Loss: 1.3633, G Loss: 0.7397\n",
            "Epoch [46/100], Step [5600/7382], D Loss: 1.4065, G Loss: 0.7047\n",
            "Epoch [46/100], Step [5700/7382], D Loss: 1.3392, G Loss: 0.7742\n",
            "Epoch [46/100], Step [5800/7382], D Loss: 1.3944, G Loss: 0.7082\n",
            "Epoch [46/100], Step [5900/7382], D Loss: 1.4063, G Loss: 0.7319\n",
            "Epoch [46/100], Step [6000/7382], D Loss: 1.3124, G Loss: 0.7820\n",
            "Epoch [46/100], Step [6100/7382], D Loss: 1.3190, G Loss: 0.7898\n",
            "Epoch [46/100], Step [6200/7382], D Loss: 1.3675, G Loss: 0.7271\n",
            "Epoch [46/100], Step [6300/7382], D Loss: 1.3410, G Loss: 0.7312\n",
            "Epoch [46/100], Step [6400/7382], D Loss: 1.3960, G Loss: 0.7560\n",
            "Epoch [46/100], Step [6500/7382], D Loss: 1.3650, G Loss: 0.7315\n",
            "Epoch [46/100], Step [6600/7382], D Loss: 1.3306, G Loss: 0.8001\n",
            "Epoch [46/100], Step [6700/7382], D Loss: 1.3103, G Loss: 0.8217\n",
            "Epoch [46/100], Step [6800/7382], D Loss: 1.2690, G Loss: 0.9022\n",
            "Epoch [46/100], Step [6900/7382], D Loss: 1.3463, G Loss: 0.7668\n",
            "Epoch [46/100], Step [7000/7382], D Loss: 1.3770, G Loss: 0.7354\n",
            "Epoch [46/100], Step [7100/7382], D Loss: 1.3852, G Loss: 0.7328\n",
            "Epoch [46/100], Step [7200/7382], D Loss: 1.3494, G Loss: 0.7407\n",
            "Epoch [46/100], Step [7300/7382], D Loss: 1.4433, G Loss: 0.7801\n",
            "Epoch [47/100], Step [100/7382], D Loss: 1.3690, G Loss: 0.7625\n",
            "Epoch [47/100], Step [200/7382], D Loss: 1.4111, G Loss: 0.6895\n",
            "Epoch [47/100], Step [300/7382], D Loss: 1.3510, G Loss: 0.7581\n",
            "Epoch [47/100], Step [400/7382], D Loss: 1.3376, G Loss: 0.7540\n",
            "Epoch [47/100], Step [500/7382], D Loss: 1.3403, G Loss: 0.7311\n",
            "Epoch [47/100], Step [600/7382], D Loss: 1.3435, G Loss: 0.7597\n",
            "Epoch [47/100], Step [700/7382], D Loss: 1.4163, G Loss: 0.6792\n",
            "Epoch [47/100], Step [800/7382], D Loss: 1.3294, G Loss: 0.7500\n",
            "Epoch [47/100], Step [900/7382], D Loss: 1.3516, G Loss: 0.7586\n",
            "Epoch [47/100], Step [1000/7382], D Loss: 1.3398, G Loss: 0.8138\n",
            "Epoch [47/100], Step [1100/7382], D Loss: 1.3349, G Loss: 0.7758\n",
            "Epoch [47/100], Step [1200/7382], D Loss: 1.3360, G Loss: 0.7438\n",
            "Epoch [47/100], Step [1300/7382], D Loss: 1.3927, G Loss: 0.7514\n",
            "Epoch [47/100], Step [1400/7382], D Loss: 1.3323, G Loss: 0.7332\n",
            "Epoch [47/100], Step [1500/7382], D Loss: 1.3108, G Loss: 0.7621\n",
            "Epoch [47/100], Step [1600/7382], D Loss: 1.3873, G Loss: 0.7538\n",
            "Epoch [47/100], Step [1700/7382], D Loss: 1.3343, G Loss: 0.7122\n",
            "Epoch [47/100], Step [1800/7382], D Loss: 1.3195, G Loss: 0.8328\n",
            "Epoch [47/100], Step [1900/7382], D Loss: 1.3843, G Loss: 0.7583\n",
            "Epoch [47/100], Step [2000/7382], D Loss: 1.3958, G Loss: 0.7514\n",
            "Epoch [47/100], Step [2100/7382], D Loss: 1.3408, G Loss: 0.7414\n",
            "Epoch [47/100], Step [2200/7382], D Loss: 1.3246, G Loss: 0.7969\n",
            "Epoch [47/100], Step [2300/7382], D Loss: 1.3615, G Loss: 0.7303\n",
            "Epoch [47/100], Step [2400/7382], D Loss: 1.2519, G Loss: 0.9553\n",
            "Epoch [47/100], Step [2500/7382], D Loss: 1.3690, G Loss: 0.7731\n",
            "Epoch [47/100], Step [2600/7382], D Loss: 1.3614, G Loss: 0.7223\n",
            "Epoch [47/100], Step [2700/7382], D Loss: 1.3138, G Loss: 0.7609\n",
            "Epoch [47/100], Step [2800/7382], D Loss: 1.3631, G Loss: 0.7244\n",
            "Epoch [47/100], Step [2900/7382], D Loss: 1.3619, G Loss: 0.7471\n",
            "Epoch [47/100], Step [3000/7382], D Loss: 1.3642, G Loss: 0.7813\n",
            "Epoch [47/100], Step [3100/7382], D Loss: 1.3531, G Loss: 0.7255\n",
            "Epoch [47/100], Step [3200/7382], D Loss: 1.3266, G Loss: 0.7424\n",
            "Epoch [47/100], Step [3300/7382], D Loss: 1.4015, G Loss: 0.6986\n",
            "Epoch [47/100], Step [3400/7382], D Loss: 1.3608, G Loss: 0.8064\n",
            "Epoch [47/100], Step [3500/7382], D Loss: 1.3594, G Loss: 0.7623\n",
            "Epoch [47/100], Step [3600/7382], D Loss: 1.3017, G Loss: 0.7463\n",
            "Epoch [47/100], Step [3700/7382], D Loss: 1.3719, G Loss: 0.7102\n",
            "Epoch [47/100], Step [3800/7382], D Loss: 1.3582, G Loss: 0.7177\n",
            "Epoch [47/100], Step [3900/7382], D Loss: 1.3624, G Loss: 0.7902\n",
            "Epoch [47/100], Step [4000/7382], D Loss: 1.3419, G Loss: 0.8014\n",
            "Epoch [47/100], Step [4100/7382], D Loss: 1.3726, G Loss: 0.6997\n",
            "Epoch [47/100], Step [4200/7382], D Loss: 1.3398, G Loss: 0.7574\n",
            "Epoch [47/100], Step [4300/7382], D Loss: 1.3730, G Loss: 0.7507\n",
            "Epoch [47/100], Step [4400/7382], D Loss: 1.3293, G Loss: 0.7606\n",
            "Epoch [47/100], Step [4500/7382], D Loss: 1.3103, G Loss: 0.7442\n",
            "Epoch [47/100], Step [4600/7382], D Loss: 1.3598, G Loss: 0.7480\n",
            "Epoch [47/100], Step [4700/7382], D Loss: 1.3276, G Loss: 0.7368\n",
            "Epoch [47/100], Step [4800/7382], D Loss: 1.4759, G Loss: 0.7102\n",
            "Epoch [47/100], Step [4900/7382], D Loss: 1.3303, G Loss: 0.8164\n",
            "Epoch [47/100], Step [5000/7382], D Loss: 1.3377, G Loss: 0.7576\n",
            "Epoch [47/100], Step [5100/7382], D Loss: 1.3377, G Loss: 0.7218\n",
            "Epoch [47/100], Step [5200/7382], D Loss: 1.4013, G Loss: 0.7187\n",
            "Epoch [47/100], Step [5300/7382], D Loss: 1.3259, G Loss: 0.8169\n",
            "Epoch [47/100], Step [5400/7382], D Loss: 1.3186, G Loss: 0.8149\n",
            "Epoch [47/100], Step [5500/7382], D Loss: 1.3009, G Loss: 0.7856\n",
            "Epoch [47/100], Step [5600/7382], D Loss: 1.3479, G Loss: 0.7720\n",
            "Epoch [47/100], Step [5700/7382], D Loss: 1.3336, G Loss: 0.7695\n",
            "Epoch [47/100], Step [5800/7382], D Loss: 1.2929, G Loss: 0.8079\n",
            "Epoch [47/100], Step [5900/7382], D Loss: 1.3765, G Loss: 0.7540\n",
            "Epoch [47/100], Step [6000/7382], D Loss: 1.3802, G Loss: 0.8054\n",
            "Epoch [47/100], Step [6100/7382], D Loss: 1.3184, G Loss: 0.7648\n",
            "Epoch [47/100], Step [6200/7382], D Loss: 1.3454, G Loss: 0.7559\n",
            "Epoch [47/100], Step [6300/7382], D Loss: 1.3897, G Loss: 0.7225\n",
            "Epoch [47/100], Step [6400/7382], D Loss: 1.3418, G Loss: 0.7985\n",
            "Epoch [47/100], Step [6500/7382], D Loss: 1.2347, G Loss: 0.8562\n",
            "Epoch [47/100], Step [6600/7382], D Loss: 1.3923, G Loss: 0.7459\n",
            "Epoch [47/100], Step [6700/7382], D Loss: 1.2689, G Loss: 0.8564\n",
            "Epoch [47/100], Step [6800/7382], D Loss: 1.3170, G Loss: 0.7795\n",
            "Epoch [47/100], Step [6900/7382], D Loss: 1.3071, G Loss: 0.8353\n",
            "Epoch [47/100], Step [7000/7382], D Loss: 1.3467, G Loss: 0.7854\n",
            "Epoch [47/100], Step [7100/7382], D Loss: 1.2535, G Loss: 0.8466\n",
            "Epoch [47/100], Step [7200/7382], D Loss: 1.2936, G Loss: 0.7965\n",
            "Epoch [47/100], Step [7300/7382], D Loss: 1.2928, G Loss: 0.8214\n",
            "Epoch [48/100], Step [100/7382], D Loss: 1.2759, G Loss: 0.8646\n",
            "Epoch [48/100], Step [200/7382], D Loss: 1.3483, G Loss: 0.7525\n",
            "Epoch [48/100], Step [300/7382], D Loss: 1.2772, G Loss: 0.8505\n",
            "Epoch [48/100], Step [400/7382], D Loss: 1.2325, G Loss: 0.9774\n",
            "Epoch [48/100], Step [500/7382], D Loss: 1.2825, G Loss: 0.8093\n",
            "Epoch [48/100], Step [600/7382], D Loss: 1.3180, G Loss: 0.7931\n",
            "Epoch [48/100], Step [700/7382], D Loss: 1.2455, G Loss: 0.9243\n",
            "Epoch [48/100], Step [800/7382], D Loss: 1.3191, G Loss: 0.8345\n",
            "Epoch [48/100], Step [900/7382], D Loss: 1.3096, G Loss: 0.8057\n",
            "Epoch [48/100], Step [1000/7382], D Loss: 1.2939, G Loss: 0.8818\n",
            "Epoch [48/100], Step [1100/7382], D Loss: 1.3239, G Loss: 0.9215\n",
            "Epoch [48/100], Step [1200/7382], D Loss: 1.2877, G Loss: 0.8136\n",
            "Epoch [48/100], Step [1300/7382], D Loss: 1.3223, G Loss: 0.8234\n",
            "Epoch [48/100], Step [1400/7382], D Loss: 1.3102, G Loss: 0.7663\n",
            "Epoch [48/100], Step [1500/7382], D Loss: 1.3323, G Loss: 0.7489\n",
            "Epoch [48/100], Step [1600/7382], D Loss: 1.3707, G Loss: 0.8115\n",
            "Epoch [48/100], Step [1700/7382], D Loss: 1.3204, G Loss: 0.8191\n",
            "Epoch [48/100], Step [1800/7382], D Loss: 1.2824, G Loss: 0.9137\n",
            "Epoch [48/100], Step [1900/7382], D Loss: 1.2862, G Loss: 0.8472\n",
            "Epoch [48/100], Step [2000/7382], D Loss: 1.4453, G Loss: 0.7914\n",
            "Epoch [48/100], Step [2100/7382], D Loss: 1.3193, G Loss: 0.7996\n",
            "Epoch [48/100], Step [2200/7382], D Loss: 1.3337, G Loss: 0.8613\n",
            "Epoch [48/100], Step [2300/7382], D Loss: 1.2288, G Loss: 0.8627\n",
            "Epoch [48/100], Step [2400/7382], D Loss: 1.2682, G Loss: 0.8598\n",
            "Epoch [48/100], Step [2500/7382], D Loss: 1.3661, G Loss: 0.8467\n",
            "Epoch [48/100], Step [2600/7382], D Loss: 1.3253, G Loss: 0.8633\n",
            "Epoch [48/100], Step [2700/7382], D Loss: 1.2293, G Loss: 1.0265\n",
            "Epoch [48/100], Step [2800/7382], D Loss: 1.3763, G Loss: 0.7574\n",
            "Epoch [48/100], Step [2900/7382], D Loss: 1.3675, G Loss: 0.8570\n",
            "Epoch [48/100], Step [3000/7382], D Loss: 1.2602, G Loss: 0.8786\n",
            "Epoch [48/100], Step [3100/7382], D Loss: 1.3616, G Loss: 0.7605\n",
            "Epoch [48/100], Step [3200/7382], D Loss: 1.2918, G Loss: 0.8256\n",
            "Epoch [48/100], Step [3300/7382], D Loss: 1.3359, G Loss: 0.8959\n",
            "Epoch [48/100], Step [3400/7382], D Loss: 1.3215, G Loss: 0.8042\n",
            "Epoch [48/100], Step [3500/7382], D Loss: 1.3068, G Loss: 0.8663\n",
            "Epoch [48/100], Step [3600/7382], D Loss: 1.2896, G Loss: 0.8390\n",
            "Epoch [48/100], Step [3700/7382], D Loss: 1.2525, G Loss: 0.9688\n",
            "Epoch [48/100], Step [3800/7382], D Loss: 1.3244, G Loss: 0.8174\n",
            "Epoch [48/100], Step [3900/7382], D Loss: 1.1912, G Loss: 0.9108\n",
            "Epoch [48/100], Step [4000/7382], D Loss: 1.2599, G Loss: 0.8446\n",
            "Epoch [48/100], Step [4100/7382], D Loss: 1.2945, G Loss: 0.8485\n",
            "Epoch [48/100], Step [4200/7382], D Loss: 1.2323, G Loss: 0.9376\n",
            "Epoch [48/100], Step [4300/7382], D Loss: 1.3595, G Loss: 0.8497\n",
            "Epoch [48/100], Step [4400/7382], D Loss: 1.2271, G Loss: 0.9239\n",
            "Epoch [48/100], Step [4500/7382], D Loss: 1.2274, G Loss: 0.8696\n",
            "Epoch [48/100], Step [4600/7382], D Loss: 1.2426, G Loss: 0.9083\n",
            "Epoch [48/100], Step [4700/7382], D Loss: 1.3041, G Loss: 0.8851\n",
            "Epoch [48/100], Step [4800/7382], D Loss: 1.2945, G Loss: 0.8278\n",
            "Epoch [48/100], Step [4900/7382], D Loss: 1.3087, G Loss: 0.8517\n",
            "Epoch [48/100], Step [5000/7382], D Loss: 1.2353, G Loss: 0.8743\n",
            "Epoch [48/100], Step [5100/7382], D Loss: 1.1950, G Loss: 0.9803\n",
            "Epoch [48/100], Step [5200/7382], D Loss: 1.2773, G Loss: 0.8395\n",
            "Epoch [48/100], Step [5300/7382], D Loss: 1.4277, G Loss: 0.7857\n",
            "Epoch [48/100], Step [5400/7382], D Loss: 1.3291, G Loss: 0.8244\n",
            "Epoch [48/100], Step [5500/7382], D Loss: 1.2968, G Loss: 0.8551\n",
            "Epoch [48/100], Step [5600/7382], D Loss: 1.2591, G Loss: 0.9057\n",
            "Epoch [48/100], Step [5700/7382], D Loss: 1.3697, G Loss: 0.7820\n",
            "Epoch [48/100], Step [5800/7382], D Loss: 1.3523, G Loss: 0.7945\n",
            "Epoch [48/100], Step [5900/7382], D Loss: 1.2050, G Loss: 0.8985\n",
            "Epoch [48/100], Step [6000/7382], D Loss: 1.2386, G Loss: 0.8944\n",
            "Epoch [48/100], Step [6100/7382], D Loss: 1.3150, G Loss: 0.8238\n",
            "Epoch [48/100], Step [6200/7382], D Loss: 1.3234, G Loss: 0.7831\n",
            "Epoch [48/100], Step [6300/7382], D Loss: 1.2429, G Loss: 0.8796\n",
            "Epoch [48/100], Step [6400/7382], D Loss: 1.3687, G Loss: 0.8029\n",
            "Epoch [48/100], Step [6500/7382], D Loss: 1.3335, G Loss: 0.7913\n",
            "Epoch [48/100], Step [6600/7382], D Loss: 1.2201, G Loss: 1.0167\n",
            "Epoch [48/100], Step [6700/7382], D Loss: 1.3426, G Loss: 0.8473\n",
            "Epoch [48/100], Step [6800/7382], D Loss: 1.3204, G Loss: 0.7810\n",
            "Epoch [48/100], Step [6900/7382], D Loss: 1.3140, G Loss: 0.7753\n",
            "Epoch [48/100], Step [7000/7382], D Loss: 1.3423, G Loss: 0.8567\n",
            "Epoch [48/100], Step [7100/7382], D Loss: 1.2716, G Loss: 0.8493\n",
            "Epoch [48/100], Step [7200/7382], D Loss: 1.3470, G Loss: 0.8080\n",
            "Epoch [48/100], Step [7300/7382], D Loss: 1.3421, G Loss: 0.7768\n",
            "Epoch [49/100], Step [100/7382], D Loss: 1.2975, G Loss: 0.8242\n",
            "Epoch [49/100], Step [200/7382], D Loss: 1.3657, G Loss: 0.8216\n",
            "Epoch [49/100], Step [300/7382], D Loss: 1.2465, G Loss: 0.9204\n",
            "Epoch [49/100], Step [400/7382], D Loss: 1.2676, G Loss: 0.8664\n",
            "Epoch [49/100], Step [500/7382], D Loss: 1.3362, G Loss: 0.8115\n",
            "Epoch [49/100], Step [600/7382], D Loss: 1.3758, G Loss: 0.7832\n",
            "Epoch [49/100], Step [700/7382], D Loss: 1.3269, G Loss: 0.7818\n",
            "Epoch [49/100], Step [800/7382], D Loss: 1.2194, G Loss: 0.9440\n",
            "Epoch [49/100], Step [900/7382], D Loss: 1.3503, G Loss: 0.8062\n",
            "Epoch [49/100], Step [1000/7382], D Loss: 1.2612, G Loss: 0.9054\n",
            "Epoch [49/100], Step [1100/7382], D Loss: 1.3497, G Loss: 0.7472\n",
            "Epoch [49/100], Step [1200/7382], D Loss: 1.3188, G Loss: 0.9072\n",
            "Epoch [49/100], Step [1300/7382], D Loss: 1.2805, G Loss: 0.7778\n",
            "Epoch [49/100], Step [1400/7382], D Loss: 1.2240, G Loss: 0.8869\n",
            "Epoch [49/100], Step [1500/7382], D Loss: 1.3826, G Loss: 0.7474\n",
            "Epoch [49/100], Step [1600/7382], D Loss: 1.2286, G Loss: 0.9026\n",
            "Epoch [49/100], Step [1700/7382], D Loss: 1.3259, G Loss: 0.7765\n",
            "Epoch [49/100], Step [1800/7382], D Loss: 1.2209, G Loss: 0.9314\n",
            "Epoch [49/100], Step [1900/7382], D Loss: 1.3229, G Loss: 0.8504\n",
            "Epoch [49/100], Step [2000/7382], D Loss: 1.2640, G Loss: 0.7936\n",
            "Epoch [49/100], Step [2100/7382], D Loss: 1.3835, G Loss: 0.8020\n",
            "Epoch [49/100], Step [2200/7382], D Loss: 1.3329, G Loss: 0.9266\n",
            "Epoch [49/100], Step [2300/7382], D Loss: 1.2868, G Loss: 0.7825\n",
            "Epoch [49/100], Step [2400/7382], D Loss: 1.2394, G Loss: 0.8771\n",
            "Epoch [49/100], Step [2500/7382], D Loss: 1.2671, G Loss: 0.8417\n",
            "Epoch [49/100], Step [2600/7382], D Loss: 1.3719, G Loss: 0.8021\n",
            "Epoch [49/100], Step [2700/7382], D Loss: 1.2242, G Loss: 0.8580\n",
            "Epoch [49/100], Step [2800/7382], D Loss: 1.3142, G Loss: 0.8083\n",
            "Epoch [49/100], Step [2900/7382], D Loss: 1.2505, G Loss: 0.8379\n",
            "Epoch [49/100], Step [3000/7382], D Loss: 1.3488, G Loss: 0.8204\n",
            "Epoch [49/100], Step [3100/7382], D Loss: 1.1610, G Loss: 1.0428\n",
            "Epoch [49/100], Step [3200/7382], D Loss: 1.3422, G Loss: 0.8253\n",
            "Epoch [49/100], Step [3300/7382], D Loss: 1.2812, G Loss: 0.8853\n",
            "Epoch [49/100], Step [3400/7382], D Loss: 1.2930, G Loss: 0.9518\n",
            "Epoch [49/100], Step [3500/7382], D Loss: 1.2367, G Loss: 0.8514\n",
            "Epoch [49/100], Step [3600/7382], D Loss: 1.2700, G Loss: 0.8560\n",
            "Epoch [49/100], Step [3700/7382], D Loss: 1.3094, G Loss: 0.8377\n",
            "Epoch [49/100], Step [3800/7382], D Loss: 1.2956, G Loss: 0.8275\n",
            "Epoch [49/100], Step [3900/7382], D Loss: 1.4150, G Loss: 0.7948\n",
            "Epoch [49/100], Step [4000/7382], D Loss: 1.3765, G Loss: 0.7943\n",
            "Epoch [49/100], Step [4100/7382], D Loss: 1.2754, G Loss: 0.7885\n",
            "Epoch [49/100], Step [4200/7382], D Loss: 1.2088, G Loss: 0.9436\n",
            "Epoch [49/100], Step [4300/7382], D Loss: 1.3151, G Loss: 0.7803\n",
            "Epoch [49/100], Step [4400/7382], D Loss: 1.3078, G Loss: 0.7799\n",
            "Epoch [49/100], Step [4500/7382], D Loss: 1.3194, G Loss: 0.8041\n",
            "Epoch [49/100], Step [4600/7382], D Loss: 1.3052, G Loss: 0.8217\n",
            "Epoch [49/100], Step [4700/7382], D Loss: 1.3030, G Loss: 0.8305\n",
            "Epoch [49/100], Step [4800/7382], D Loss: 1.3122, G Loss: 0.8234\n",
            "Epoch [49/100], Step [4900/7382], D Loss: 1.3146, G Loss: 0.7972\n",
            "Epoch [49/100], Step [5000/7382], D Loss: 1.3466, G Loss: 0.8132\n",
            "Epoch [49/100], Step [5100/7382], D Loss: 1.3194, G Loss: 0.9039\n",
            "Epoch [49/100], Step [5200/7382], D Loss: 1.2591, G Loss: 0.9204\n",
            "Epoch [49/100], Step [5300/7382], D Loss: 1.2708, G Loss: 0.8409\n",
            "Epoch [49/100], Step [5400/7382], D Loss: 1.2637, G Loss: 0.8253\n",
            "Epoch [49/100], Step [5500/7382], D Loss: 1.2773, G Loss: 0.8582\n",
            "Epoch [49/100], Step [5600/7382], D Loss: 1.3159, G Loss: 0.8965\n",
            "Epoch [49/100], Step [5700/7382], D Loss: 1.3293, G Loss: 0.8190\n",
            "Epoch [49/100], Step [5800/7382], D Loss: 1.3268, G Loss: 0.8498\n",
            "Epoch [49/100], Step [5900/7382], D Loss: 1.1355, G Loss: 1.0155\n",
            "Epoch [49/100], Step [6000/7382], D Loss: 1.2555, G Loss: 0.9107\n",
            "Epoch [49/100], Step [6100/7382], D Loss: 1.3089, G Loss: 0.8567\n",
            "Epoch [49/100], Step [6200/7382], D Loss: 1.2753, G Loss: 0.8116\n",
            "Epoch [49/100], Step [6300/7382], D Loss: 1.4052, G Loss: 0.8119\n",
            "Epoch [49/100], Step [6400/7382], D Loss: 1.3877, G Loss: 0.7627\n",
            "Epoch [49/100], Step [6500/7382], D Loss: 1.3349, G Loss: 0.7457\n",
            "Epoch [49/100], Step [6600/7382], D Loss: 1.2413, G Loss: 0.8532\n",
            "Epoch [49/100], Step [6700/7382], D Loss: 1.3135, G Loss: 0.8231\n",
            "Epoch [49/100], Step [6800/7382], D Loss: 1.4104, G Loss: 0.7774\n",
            "Epoch [49/100], Step [6900/7382], D Loss: 1.2724, G Loss: 0.8418\n",
            "Epoch [49/100], Step [7000/7382], D Loss: 1.2703, G Loss: 0.8690\n",
            "Epoch [49/100], Step [7100/7382], D Loss: 1.3675, G Loss: 0.7486\n",
            "Epoch [49/100], Step [7200/7382], D Loss: 1.3440, G Loss: 0.7825\n",
            "Epoch [49/100], Step [7300/7382], D Loss: 1.3631, G Loss: 0.7509\n",
            "Epoch [50/100], Step [100/7382], D Loss: 1.3045, G Loss: 0.7995\n",
            "Epoch [50/100], Step [200/7382], D Loss: 1.3969, G Loss: 0.7307\n",
            "Epoch [50/100], Step [300/7382], D Loss: 1.2732, G Loss: 0.8497\n",
            "Epoch [50/100], Step [400/7382], D Loss: 1.3249, G Loss: 0.7991\n",
            "Epoch [50/100], Step [500/7382], D Loss: 1.3100, G Loss: 0.7656\n",
            "Epoch [50/100], Step [600/7382], D Loss: 1.2757, G Loss: 0.8295\n",
            "Epoch [50/100], Step [700/7382], D Loss: 1.3540, G Loss: 0.7359\n",
            "Epoch [50/100], Step [800/7382], D Loss: 1.3169, G Loss: 0.7940\n",
            "Epoch [50/100], Step [900/7382], D Loss: 1.2537, G Loss: 0.8692\n",
            "Epoch [50/100], Step [1000/7382], D Loss: 1.3993, G Loss: 0.7552\n",
            "Epoch [50/100], Step [1100/7382], D Loss: 1.2572, G Loss: 0.8452\n",
            "Epoch [50/100], Step [1200/7382], D Loss: 1.2813, G Loss: 0.8298\n",
            "Epoch [50/100], Step [1300/7382], D Loss: 1.3720, G Loss: 0.7831\n",
            "Epoch [50/100], Step [1400/7382], D Loss: 1.4054, G Loss: 0.7886\n",
            "Epoch [50/100], Step [1500/7382], D Loss: 1.2248, G Loss: 0.9704\n",
            "Epoch [50/100], Step [1600/7382], D Loss: 1.2846, G Loss: 0.8297\n",
            "Epoch [50/100], Step [1700/7382], D Loss: 1.2966, G Loss: 0.8526\n",
            "Epoch [50/100], Step [1800/7382], D Loss: 1.4318, G Loss: 0.7862\n",
            "Epoch [50/100], Step [1900/7382], D Loss: 1.4441, G Loss: 0.7230\n",
            "Epoch [50/100], Step [2000/7382], D Loss: 1.4562, G Loss: 0.7410\n",
            "Epoch [50/100], Step [2100/7382], D Loss: 1.3173, G Loss: 0.8539\n",
            "Epoch [50/100], Step [2200/7382], D Loss: 1.2885, G Loss: 0.8271\n",
            "Epoch [50/100], Step [2300/7382], D Loss: 1.3248, G Loss: 0.8132\n",
            "Epoch [50/100], Step [2400/7382], D Loss: 1.2447, G Loss: 0.8509\n",
            "Epoch [50/100], Step [2500/7382], D Loss: 1.3937, G Loss: 0.8063\n",
            "Epoch [50/100], Step [2600/7382], D Loss: 1.2955, G Loss: 0.8135\n",
            "Epoch [50/100], Step [2700/7382], D Loss: 1.2717, G Loss: 0.8628\n",
            "Epoch [50/100], Step [2800/7382], D Loss: 1.2530, G Loss: 0.8140\n",
            "Epoch [50/100], Step [2900/7382], D Loss: 1.2900, G Loss: 0.8464\n",
            "Epoch [50/100], Step [3000/7382], D Loss: 1.3709, G Loss: 0.7830\n",
            "Epoch [50/100], Step [3100/7382], D Loss: 1.3139, G Loss: 0.8878\n",
            "Epoch [50/100], Step [3200/7382], D Loss: 1.3760, G Loss: 0.8266\n",
            "Epoch [50/100], Step [3300/7382], D Loss: 1.3464, G Loss: 1.0648\n",
            "Epoch [50/100], Step [3400/7382], D Loss: 1.3645, G Loss: 0.7476\n",
            "Epoch [50/100], Step [3500/7382], D Loss: 1.3372, G Loss: 0.8049\n",
            "Epoch [50/100], Step [3600/7382], D Loss: 1.3507, G Loss: 0.7647\n",
            "Epoch [50/100], Step [3700/7382], D Loss: 1.3196, G Loss: 0.8442\n",
            "Epoch [50/100], Step [3800/7382], D Loss: 1.3305, G Loss: 0.7994\n",
            "Epoch [50/100], Step [3900/7382], D Loss: 1.3415, G Loss: 0.8060\n",
            "Epoch [50/100], Step [4000/7382], D Loss: 1.3263, G Loss: 0.7651\n",
            "Epoch [50/100], Step [4100/7382], D Loss: 1.2305, G Loss: 0.9521\n",
            "Epoch [50/100], Step [4200/7382], D Loss: 1.2965, G Loss: 0.8463\n",
            "Epoch [50/100], Step [4300/7382], D Loss: 1.3720, G Loss: 0.7530\n",
            "Epoch [50/100], Step [4400/7382], D Loss: 1.2621, G Loss: 0.8664\n",
            "Epoch [50/100], Step [4500/7382], D Loss: 1.2806, G Loss: 0.8747\n",
            "Epoch [50/100], Step [4600/7382], D Loss: 1.2925, G Loss: 0.8021\n",
            "Epoch [50/100], Step [4700/7382], D Loss: 1.3060, G Loss: 0.7790\n",
            "Epoch [50/100], Step [4800/7382], D Loss: 1.2823, G Loss: 0.8411\n",
            "Epoch [50/100], Step [4900/7382], D Loss: 1.2740, G Loss: 0.8563\n",
            "Epoch [50/100], Step [5000/7382], D Loss: 1.3792, G Loss: 0.7362\n",
            "Epoch [50/100], Step [5100/7382], D Loss: 1.3865, G Loss: 0.7836\n",
            "Epoch [50/100], Step [5200/7382], D Loss: 1.3369, G Loss: 0.7691\n",
            "Epoch [50/100], Step [5300/7382], D Loss: 1.3736, G Loss: 0.7641\n",
            "Epoch [50/100], Step [5400/7382], D Loss: 1.4392, G Loss: 0.7063\n",
            "Epoch [50/100], Step [5500/7382], D Loss: 1.2762, G Loss: 0.8247\n",
            "Epoch [50/100], Step [5600/7382], D Loss: 1.2710, G Loss: 0.8493\n",
            "Epoch [50/100], Step [5700/7382], D Loss: 1.2915, G Loss: 0.9094\n",
            "Epoch [50/100], Step [5800/7382], D Loss: 1.3287, G Loss: 0.8021\n",
            "Epoch [50/100], Step [5900/7382], D Loss: 1.3495, G Loss: 0.8525\n",
            "Epoch [50/100], Step [6000/7382], D Loss: 1.2726, G Loss: 0.8797\n",
            "Epoch [50/100], Step [6100/7382], D Loss: 1.2960, G Loss: 0.9340\n",
            "Epoch [50/100], Step [6200/7382], D Loss: 1.2678, G Loss: 0.8218\n",
            "Epoch [50/100], Step [6300/7382], D Loss: 1.2656, G Loss: 0.8801\n",
            "Epoch [50/100], Step [6400/7382], D Loss: 1.3766, G Loss: 0.7462\n",
            "Epoch [50/100], Step [6500/7382], D Loss: 1.3546, G Loss: 0.8035\n",
            "Epoch [50/100], Step [6600/7382], D Loss: 1.3510, G Loss: 0.8150\n",
            "Epoch [50/100], Step [6700/7382], D Loss: 1.3481, G Loss: 0.7952\n",
            "Epoch [50/100], Step [6800/7382], D Loss: 1.3642, G Loss: 0.7901\n",
            "Epoch [50/100], Step [6900/7382], D Loss: 1.3549, G Loss: 0.7768\n",
            "Epoch [50/100], Step [7000/7382], D Loss: 1.2547, G Loss: 0.9854\n",
            "Epoch [50/100], Step [7100/7382], D Loss: 1.3584, G Loss: 0.7781\n",
            "Epoch [50/100], Step [7200/7382], D Loss: 1.2911, G Loss: 0.8301\n",
            "Epoch [50/100], Step [7300/7382], D Loss: 1.2680, G Loss: 0.8851\n",
            "Epoch [51/100], Step [100/7382], D Loss: 1.2790, G Loss: 0.9841\n",
            "Epoch [51/100], Step [200/7382], D Loss: 1.2713, G Loss: 0.8288\n",
            "Epoch [51/100], Step [300/7382], D Loss: 1.3666, G Loss: 0.7790\n",
            "Epoch [51/100], Step [400/7382], D Loss: 1.2791, G Loss: 0.8909\n",
            "Epoch [51/100], Step [500/7382], D Loss: 1.3253, G Loss: 0.8076\n",
            "Epoch [51/100], Step [600/7382], D Loss: 1.2654, G Loss: 0.8052\n",
            "Epoch [51/100], Step [700/7382], D Loss: 1.4225, G Loss: 0.7232\n",
            "Epoch [51/100], Step [800/7382], D Loss: 1.2645, G Loss: 0.8187\n",
            "Epoch [51/100], Step [900/7382], D Loss: 1.3703, G Loss: 0.7351\n",
            "Epoch [51/100], Step [1000/7382], D Loss: 1.3976, G Loss: 0.7783\n",
            "Epoch [51/100], Step [1100/7382], D Loss: 1.2693, G Loss: 0.8730\n",
            "Epoch [51/100], Step [1200/7382], D Loss: 1.3379, G Loss: 0.8073\n",
            "Epoch [51/100], Step [1300/7382], D Loss: 1.3552, G Loss: 0.7648\n",
            "Epoch [51/100], Step [1400/7382], D Loss: 1.3818, G Loss: 0.8213\n",
            "Epoch [51/100], Step [1500/7382], D Loss: 1.2098, G Loss: 0.8730\n",
            "Epoch [51/100], Step [1600/7382], D Loss: 1.2731, G Loss: 0.9936\n",
            "Epoch [51/100], Step [1700/7382], D Loss: 1.3250, G Loss: 0.7728\n",
            "Epoch [51/100], Step [1800/7382], D Loss: 1.2871, G Loss: 0.8734\n",
            "Epoch [51/100], Step [1900/7382], D Loss: 1.3774, G Loss: 0.7831\n",
            "Epoch [51/100], Step [2000/7382], D Loss: 1.2289, G Loss: 0.8809\n",
            "Epoch [51/100], Step [2100/7382], D Loss: 1.2771, G Loss: 0.8185\n",
            "Epoch [51/100], Step [2200/7382], D Loss: 1.3439, G Loss: 0.8238\n",
            "Epoch [51/100], Step [2300/7382], D Loss: 1.3067, G Loss: 0.8435\n",
            "Epoch [51/100], Step [2400/7382], D Loss: 1.2980, G Loss: 0.8396\n",
            "Epoch [51/100], Step [2500/7382], D Loss: 1.3107, G Loss: 0.8723\n",
            "Epoch [51/100], Step [2600/7382], D Loss: 1.3695, G Loss: 0.7481\n",
            "Epoch [51/100], Step [2700/7382], D Loss: 1.2797, G Loss: 0.8801\n",
            "Epoch [51/100], Step [2800/7382], D Loss: 1.2788, G Loss: 0.8025\n",
            "Epoch [51/100], Step [2900/7382], D Loss: 1.3432, G Loss: 0.7659\n",
            "Epoch [51/100], Step [3000/7382], D Loss: 1.3068, G Loss: 0.8802\n",
            "Epoch [51/100], Step [3100/7382], D Loss: 1.1774, G Loss: 1.0538\n",
            "Epoch [51/100], Step [3200/7382], D Loss: 1.3480, G Loss: 0.7847\n",
            "Epoch [51/100], Step [3300/7382], D Loss: 1.2766, G Loss: 0.8511\n",
            "Epoch [51/100], Step [3400/7382], D Loss: 1.2681, G Loss: 0.8478\n",
            "Epoch [51/100], Step [3500/7382], D Loss: 1.2800, G Loss: 0.8397\n",
            "Epoch [51/100], Step [3600/7382], D Loss: 1.2625, G Loss: 0.8362\n",
            "Epoch [51/100], Step [3700/7382], D Loss: 1.3294, G Loss: 0.7816\n",
            "Epoch [51/100], Step [3800/7382], D Loss: 1.3626, G Loss: 0.7869\n",
            "Epoch [51/100], Step [3900/7382], D Loss: 1.2260, G Loss: 0.8581\n",
            "Epoch [51/100], Step [4000/7382], D Loss: 1.2513, G Loss: 0.8713\n",
            "Epoch [51/100], Step [4100/7382], D Loss: 1.2712, G Loss: 0.8179\n",
            "Epoch [51/100], Step [4200/7382], D Loss: 1.3450, G Loss: 0.7858\n",
            "Epoch [51/100], Step [4300/7382], D Loss: 1.2823, G Loss: 0.8627\n",
            "Epoch [51/100], Step [4400/7382], D Loss: 1.3237, G Loss: 0.8162\n",
            "Epoch [51/100], Step [4500/7382], D Loss: 1.4200, G Loss: 0.7334\n",
            "Epoch [51/100], Step [4600/7382], D Loss: 1.3249, G Loss: 0.7771\n",
            "Epoch [51/100], Step [4700/7382], D Loss: 1.2970, G Loss: 0.8375\n",
            "Epoch [51/100], Step [4800/7382], D Loss: 1.2839, G Loss: 0.8398\n",
            "Epoch [51/100], Step [4900/7382], D Loss: 1.3598, G Loss: 0.7967\n",
            "Epoch [51/100], Step [5000/7382], D Loss: 1.3639, G Loss: 0.7908\n",
            "Epoch [51/100], Step [5100/7382], D Loss: 1.3356, G Loss: 0.7697\n",
            "Epoch [51/100], Step [5200/7382], D Loss: 1.3519, G Loss: 0.7860\n",
            "Epoch [51/100], Step [5300/7382], D Loss: 1.2164, G Loss: 0.8698\n",
            "Epoch [51/100], Step [5400/7382], D Loss: 1.2617, G Loss: 0.8463\n",
            "Epoch [51/100], Step [5500/7382], D Loss: 1.2423, G Loss: 0.9213\n",
            "Epoch [51/100], Step [5600/7382], D Loss: 1.4058, G Loss: 0.8182\n",
            "Epoch [51/100], Step [5700/7382], D Loss: 1.2008, G Loss: 0.8685\n",
            "Epoch [51/100], Step [5800/7382], D Loss: 1.2946, G Loss: 0.8719\n",
            "Epoch [51/100], Step [5900/7382], D Loss: 1.4012, G Loss: 0.7687\n",
            "Epoch [51/100], Step [6000/7382], D Loss: 1.1974, G Loss: 0.9092\n",
            "Epoch [51/100], Step [6100/7382], D Loss: 1.2625, G Loss: 0.8494\n",
            "Epoch [51/100], Step [6200/7382], D Loss: 1.2882, G Loss: 0.8295\n",
            "Epoch [51/100], Step [6300/7382], D Loss: 1.3220, G Loss: 0.7765\n",
            "Epoch [51/100], Step [6400/7382], D Loss: 1.2597, G Loss: 0.8704\n",
            "Epoch [51/100], Step [6500/7382], D Loss: 1.3392, G Loss: 0.8702\n",
            "Epoch [51/100], Step [6600/7382], D Loss: 1.3144, G Loss: 0.8122\n",
            "Epoch [51/100], Step [6700/7382], D Loss: 1.2429, G Loss: 0.8845\n",
            "Epoch [51/100], Step [6800/7382], D Loss: 1.2849, G Loss: 0.8483\n",
            "Epoch [51/100], Step [6900/7382], D Loss: 1.2971, G Loss: 0.8219\n",
            "Epoch [51/100], Step [7000/7382], D Loss: 1.2592, G Loss: 0.8286\n",
            "Epoch [51/100], Step [7100/7382], D Loss: 1.2957, G Loss: 0.7751\n",
            "Epoch [51/100], Step [7200/7382], D Loss: 1.3436, G Loss: 0.8178\n",
            "Epoch [51/100], Step [7300/7382], D Loss: 1.2842, G Loss: 0.7504\n",
            "Epoch [52/100], Step [100/7382], D Loss: 1.2942, G Loss: 0.8560\n",
            "Epoch [52/100], Step [200/7382], D Loss: 1.3759, G Loss: 0.8886\n",
            "Epoch [52/100], Step [300/7382], D Loss: 1.2668, G Loss: 0.8090\n",
            "Epoch [52/100], Step [400/7382], D Loss: 1.2887, G Loss: 0.8034\n",
            "Epoch [52/100], Step [500/7382], D Loss: 1.2791, G Loss: 0.8349\n",
            "Epoch [52/100], Step [600/7382], D Loss: 1.3745, G Loss: 0.8194\n",
            "Epoch [52/100], Step [700/7382], D Loss: 1.2929, G Loss: 0.8459\n",
            "Epoch [52/100], Step [800/7382], D Loss: 1.3713, G Loss: 0.8206\n",
            "Epoch [52/100], Step [900/7382], D Loss: 1.2867, G Loss: 0.8446\n",
            "Epoch [52/100], Step [1000/7382], D Loss: 1.3777, G Loss: 0.7839\n",
            "Epoch [52/100], Step [1100/7382], D Loss: 1.3345, G Loss: 0.7606\n",
            "Epoch [52/100], Step [1200/7382], D Loss: 1.3523, G Loss: 0.7714\n",
            "Epoch [52/100], Step [1300/7382], D Loss: 1.2650, G Loss: 0.8998\n",
            "Epoch [52/100], Step [1400/7382], D Loss: 1.2732, G Loss: 0.8612\n",
            "Epoch [52/100], Step [1500/7382], D Loss: 1.2955, G Loss: 0.9339\n",
            "Epoch [52/100], Step [1600/7382], D Loss: 1.2328, G Loss: 0.9017\n",
            "Epoch [52/100], Step [1700/7382], D Loss: 1.3022, G Loss: 0.9028\n",
            "Epoch [52/100], Step [1800/7382], D Loss: 1.3074, G Loss: 0.8940\n",
            "Epoch [52/100], Step [1900/7382], D Loss: 1.3006, G Loss: 0.8819\n",
            "Epoch [52/100], Step [2000/7382], D Loss: 1.3348, G Loss: 0.7987\n",
            "Epoch [52/100], Step [2100/7382], D Loss: 1.3069, G Loss: 0.7932\n",
            "Epoch [52/100], Step [2200/7382], D Loss: 1.2752, G Loss: 0.8668\n",
            "Epoch [52/100], Step [2300/7382], D Loss: 1.3270, G Loss: 0.7491\n",
            "Epoch [52/100], Step [2400/7382], D Loss: 1.3343, G Loss: 0.8097\n",
            "Epoch [52/100], Step [2500/7382], D Loss: 1.3182, G Loss: 0.7517\n",
            "Epoch [52/100], Step [2600/7382], D Loss: 1.3423, G Loss: 0.7468\n",
            "Epoch [52/100], Step [2700/7382], D Loss: 1.3522, G Loss: 0.7797\n",
            "Epoch [52/100], Step [2800/7382], D Loss: 1.3184, G Loss: 0.7658\n",
            "Epoch [52/100], Step [2900/7382], D Loss: 1.3068, G Loss: 0.7909\n",
            "Epoch [52/100], Step [3000/7382], D Loss: 1.3535, G Loss: 0.7696\n",
            "Epoch [52/100], Step [3100/7382], D Loss: 1.2865, G Loss: 0.8476\n",
            "Epoch [52/100], Step [3200/7382], D Loss: 1.3149, G Loss: 0.8154\n",
            "Epoch [52/100], Step [3300/7382], D Loss: 1.3132, G Loss: 0.7921\n",
            "Epoch [52/100], Step [3400/7382], D Loss: 1.3605, G Loss: 0.7902\n",
            "Epoch [52/100], Step [3500/7382], D Loss: 1.2717, G Loss: 0.8636\n",
            "Epoch [52/100], Step [3600/7382], D Loss: 1.2677, G Loss: 0.7906\n",
            "Epoch [52/100], Step [3700/7382], D Loss: 1.3821, G Loss: 0.7609\n",
            "Epoch [52/100], Step [3800/7382], D Loss: 1.3625, G Loss: 0.7808\n",
            "Epoch [52/100], Step [3900/7382], D Loss: 1.3546, G Loss: 0.7753\n",
            "Epoch [52/100], Step [4000/7382], D Loss: 1.3798, G Loss: 0.8260\n",
            "Epoch [52/100], Step [4100/7382], D Loss: 1.3636, G Loss: 0.7410\n",
            "Epoch [52/100], Step [4200/7382], D Loss: 1.3584, G Loss: 0.7532\n",
            "Epoch [52/100], Step [4300/7382], D Loss: 1.3788, G Loss: 0.7604\n",
            "Epoch [52/100], Step [4400/7382], D Loss: 1.3084, G Loss: 0.7945\n",
            "Epoch [52/100], Step [4500/7382], D Loss: 1.3079, G Loss: 0.8135\n",
            "Epoch [52/100], Step [4600/7382], D Loss: 1.3412, G Loss: 0.7967\n",
            "Epoch [52/100], Step [4700/7382], D Loss: 1.3273, G Loss: 0.7878\n",
            "Epoch [52/100], Step [4800/7382], D Loss: 1.3321, G Loss: 0.8413\n",
            "Epoch [52/100], Step [4900/7382], D Loss: 1.3226, G Loss: 0.9154\n",
            "Epoch [52/100], Step [5000/7382], D Loss: 1.3314, G Loss: 0.8990\n",
            "Epoch [52/100], Step [5100/7382], D Loss: 1.2587, G Loss: 0.8588\n",
            "Epoch [52/100], Step [5200/7382], D Loss: 1.4169, G Loss: 0.7410\n",
            "Epoch [52/100], Step [5300/7382], D Loss: 1.3556, G Loss: 0.7346\n",
            "Epoch [52/100], Step [5400/7382], D Loss: 1.3431, G Loss: 0.7400\n",
            "Epoch [52/100], Step [5500/7382], D Loss: 1.2992, G Loss: 0.8231\n",
            "Epoch [52/100], Step [5600/7382], D Loss: 1.3114, G Loss: 0.8073\n",
            "Epoch [52/100], Step [5700/7382], D Loss: 1.3391, G Loss: 0.7786\n",
            "Epoch [52/100], Step [5800/7382], D Loss: 1.4021, G Loss: 0.7735\n",
            "Epoch [52/100], Step [5900/7382], D Loss: 1.2989, G Loss: 0.8762\n",
            "Epoch [52/100], Step [6000/7382], D Loss: 1.3839, G Loss: 0.7625\n",
            "Epoch [52/100], Step [6100/7382], D Loss: 1.3118, G Loss: 0.7372\n",
            "Epoch [52/100], Step [6200/7382], D Loss: 1.3342, G Loss: 0.8314\n",
            "Epoch [52/100], Step [6300/7382], D Loss: 1.3813, G Loss: 0.7746\n",
            "Epoch [52/100], Step [6400/7382], D Loss: 1.3568, G Loss: 0.7713\n",
            "Epoch [52/100], Step [6500/7382], D Loss: 1.2063, G Loss: 0.9657\n",
            "Epoch [52/100], Step [6600/7382], D Loss: 1.3583, G Loss: 0.7410\n",
            "Epoch [52/100], Step [6700/7382], D Loss: 1.3184, G Loss: 0.8173\n",
            "Epoch [52/100], Step [6800/7382], D Loss: 1.2832, G Loss: 0.8612\n",
            "Epoch [52/100], Step [6900/7382], D Loss: 1.2851, G Loss: 0.8896\n",
            "Epoch [52/100], Step [7000/7382], D Loss: 1.3280, G Loss: 0.8402\n",
            "Epoch [52/100], Step [7100/7382], D Loss: 1.3615, G Loss: 0.7284\n",
            "Epoch [52/100], Step [7200/7382], D Loss: 1.3766, G Loss: 0.7530\n",
            "Epoch [52/100], Step [7300/7382], D Loss: 1.3244, G Loss: 0.8941\n",
            "Epoch [53/100], Step [100/7382], D Loss: 1.4105, G Loss: 0.8052\n",
            "Epoch [53/100], Step [200/7382], D Loss: 1.3034, G Loss: 0.7799\n",
            "Epoch [53/100], Step [300/7382], D Loss: 1.3081, G Loss: 0.8220\n",
            "Epoch [53/100], Step [400/7382], D Loss: 1.3047, G Loss: 0.7971\n",
            "Epoch [53/100], Step [500/7382], D Loss: 1.2945, G Loss: 0.8862\n",
            "Epoch [53/100], Step [600/7382], D Loss: 1.3742, G Loss: 0.7895\n",
            "Epoch [53/100], Step [700/7382], D Loss: 1.3915, G Loss: 0.7713\n",
            "Epoch [53/100], Step [800/7382], D Loss: 1.2948, G Loss: 0.7861\n",
            "Epoch [53/100], Step [900/7382], D Loss: 1.3686, G Loss: 0.7444\n",
            "Epoch [53/100], Step [1000/7382], D Loss: 1.3178, G Loss: 0.7778\n",
            "Epoch [53/100], Step [1100/7382], D Loss: 1.2751, G Loss: 0.7807\n",
            "Epoch [53/100], Step [1200/7382], D Loss: 1.2999, G Loss: 0.8305\n",
            "Epoch [53/100], Step [1300/7382], D Loss: 1.3791, G Loss: 0.7259\n",
            "Epoch [53/100], Step [1400/7382], D Loss: 1.3648, G Loss: 0.7637\n",
            "Epoch [53/100], Step [1500/7382], D Loss: 1.3222, G Loss: 0.7868\n",
            "Epoch [53/100], Step [1600/7382], D Loss: 1.2928, G Loss: 0.7850\n",
            "Epoch [53/100], Step [1700/7382], D Loss: 1.3538, G Loss: 0.7877\n",
            "Epoch [53/100], Step [1800/7382], D Loss: 1.3327, G Loss: 0.8049\n",
            "Epoch [53/100], Step [1900/7382], D Loss: 1.3240, G Loss: 0.7778\n",
            "Epoch [53/100], Step [2000/7382], D Loss: 1.2993, G Loss: 0.7818\n",
            "Epoch [53/100], Step [2100/7382], D Loss: 1.2681, G Loss: 0.8525\n",
            "Epoch [53/100], Step [2200/7382], D Loss: 1.3283, G Loss: 0.7760\n",
            "Epoch [53/100], Step [2300/7382], D Loss: 1.3808, G Loss: 0.7443\n",
            "Epoch [53/100], Step [2400/7382], D Loss: 1.3260, G Loss: 0.7934\n",
            "Epoch [53/100], Step [2500/7382], D Loss: 1.3855, G Loss: 0.7621\n",
            "Epoch [53/100], Step [2600/7382], D Loss: 1.3427, G Loss: 0.7562\n",
            "Epoch [53/100], Step [2700/7382], D Loss: 1.4258, G Loss: 0.7411\n",
            "Epoch [53/100], Step [2800/7382], D Loss: 1.3140, G Loss: 0.8018\n",
            "Epoch [53/100], Step [2900/7382], D Loss: 1.3839, G Loss: 0.8080\n",
            "Epoch [53/100], Step [3000/7382], D Loss: 1.4026, G Loss: 0.7627\n",
            "Epoch [53/100], Step [3100/7382], D Loss: 1.3446, G Loss: 0.7913\n",
            "Epoch [53/100], Step [3200/7382], D Loss: 1.3193, G Loss: 0.7750\n",
            "Epoch [53/100], Step [3300/7382], D Loss: 1.3367, G Loss: 0.7739\n",
            "Epoch [53/100], Step [3400/7382], D Loss: 1.3494, G Loss: 0.7427\n",
            "Epoch [53/100], Step [3500/7382], D Loss: 1.3405, G Loss: 0.7258\n",
            "Epoch [53/100], Step [3600/7382], D Loss: 1.3595, G Loss: 0.7286\n",
            "Epoch [53/100], Step [3700/7382], D Loss: 1.3140, G Loss: 0.8348\n",
            "Epoch [53/100], Step [3800/7382], D Loss: 1.3397, G Loss: 0.7597\n",
            "Epoch [53/100], Step [3900/7382], D Loss: 1.3362, G Loss: 0.7629\n",
            "Epoch [53/100], Step [4000/7382], D Loss: 1.3520, G Loss: 0.7236\n",
            "Epoch [53/100], Step [4100/7382], D Loss: 1.4006, G Loss: 0.7181\n",
            "Epoch [53/100], Step [4200/7382], D Loss: 1.3093, G Loss: 0.7785\n",
            "Epoch [53/100], Step [4300/7382], D Loss: 1.3934, G Loss: 0.7917\n",
            "Epoch [53/100], Step [4400/7382], D Loss: 1.3354, G Loss: 0.8048\n",
            "Epoch [53/100], Step [4500/7382], D Loss: 1.3244, G Loss: 0.7769\n",
            "Epoch [53/100], Step [4600/7382], D Loss: 1.3575, G Loss: 0.7382\n",
            "Epoch [53/100], Step [4700/7382], D Loss: 1.3154, G Loss: 0.7370\n",
            "Epoch [53/100], Step [4800/7382], D Loss: 1.3549, G Loss: 0.7488\n",
            "Epoch [53/100], Step [4900/7382], D Loss: 1.3537, G Loss: 0.8126\n",
            "Epoch [53/100], Step [5000/7382], D Loss: 1.3805, G Loss: 0.7177\n",
            "Epoch [53/100], Step [5100/7382], D Loss: 1.3683, G Loss: 0.7277\n",
            "Epoch [53/100], Step [5200/7382], D Loss: 1.3510, G Loss: 0.7387\n",
            "Epoch [53/100], Step [5300/7382], D Loss: 1.3633, G Loss: 0.7577\n",
            "Epoch [53/100], Step [5400/7382], D Loss: 1.3800, G Loss: 0.7465\n",
            "Epoch [53/100], Step [5500/7382], D Loss: 1.3138, G Loss: 0.7743\n",
            "Epoch [53/100], Step [5600/7382], D Loss: 1.2871, G Loss: 0.7688\n",
            "Epoch [53/100], Step [5700/7382], D Loss: 1.3484, G Loss: 0.8171\n",
            "Epoch [53/100], Step [5800/7382], D Loss: 1.3396, G Loss: 0.8454\n",
            "Epoch [53/100], Step [5900/7382], D Loss: 1.3011, G Loss: 0.7925\n",
            "Epoch [53/100], Step [6000/7382], D Loss: 1.3519, G Loss: 0.7384\n",
            "Epoch [53/100], Step [6100/7382], D Loss: 1.3706, G Loss: 0.7309\n",
            "Epoch [53/100], Step [6200/7382], D Loss: 1.3579, G Loss: 0.7482\n",
            "Epoch [53/100], Step [6300/7382], D Loss: 1.3414, G Loss: 0.7632\n",
            "Epoch [53/100], Step [6400/7382], D Loss: 1.3607, G Loss: 0.7448\n",
            "Epoch [53/100], Step [6500/7382], D Loss: 1.3753, G Loss: 0.7462\n",
            "Epoch [53/100], Step [6600/7382], D Loss: 1.3181, G Loss: 0.7719\n",
            "Epoch [53/100], Step [6700/7382], D Loss: 1.3553, G Loss: 0.7677\n",
            "Epoch [53/100], Step [6800/7382], D Loss: 1.3284, G Loss: 0.7354\n",
            "Epoch [53/100], Step [6900/7382], D Loss: 1.3435, G Loss: 0.7433\n",
            "Epoch [53/100], Step [7000/7382], D Loss: 1.3339, G Loss: 0.8101\n",
            "Epoch [53/100], Step [7100/7382], D Loss: 1.3848, G Loss: 0.7073\n",
            "Epoch [53/100], Step [7200/7382], D Loss: 1.4027, G Loss: 0.7165\n",
            "Epoch [53/100], Step [7300/7382], D Loss: 1.3433, G Loss: 0.7807\n",
            "Epoch [54/100], Step [100/7382], D Loss: 1.3661, G Loss: 0.8135\n",
            "Epoch [54/100], Step [200/7382], D Loss: 1.3856, G Loss: 0.7230\n",
            "Epoch [54/100], Step [300/7382], D Loss: 1.3410, G Loss: 0.7940\n",
            "Epoch [54/100], Step [400/7382], D Loss: 1.3636, G Loss: 0.7426\n",
            "Epoch [54/100], Step [500/7382], D Loss: 1.3681, G Loss: 0.7293\n",
            "Epoch [54/100], Step [600/7382], D Loss: 1.3434, G Loss: 0.7526\n",
            "Epoch [54/100], Step [700/7382], D Loss: 1.3642, G Loss: 0.7419\n",
            "Epoch [54/100], Step [800/7382], D Loss: 1.3755, G Loss: 0.7187\n",
            "Epoch [54/100], Step [900/7382], D Loss: 1.3374, G Loss: 0.7435\n",
            "Epoch [54/100], Step [1000/7382], D Loss: 1.3729, G Loss: 0.7252\n",
            "Epoch [54/100], Step [1100/7382], D Loss: 1.3797, G Loss: 0.7267\n",
            "Epoch [54/100], Step [1200/7382], D Loss: 1.3557, G Loss: 0.7348\n",
            "Epoch [54/100], Step [1300/7382], D Loss: 1.3871, G Loss: 0.7114\n",
            "Epoch [54/100], Step [1400/7382], D Loss: 1.3899, G Loss: 0.7212\n",
            "Epoch [54/100], Step [1500/7382], D Loss: 1.3176, G Loss: 0.8346\n",
            "Epoch [54/100], Step [1600/7382], D Loss: 1.3803, G Loss: 0.7653\n",
            "Epoch [54/100], Step [1700/7382], D Loss: 1.3454, G Loss: 0.7866\n",
            "Epoch [54/100], Step [1800/7382], D Loss: 1.3921, G Loss: 0.7137\n",
            "Epoch [54/100], Step [1900/7382], D Loss: 1.3835, G Loss: 0.6876\n",
            "Epoch [54/100], Step [2000/7382], D Loss: 1.4005, G Loss: 0.7109\n",
            "Epoch [54/100], Step [2100/7382], D Loss: 1.4063, G Loss: 0.6842\n",
            "Epoch [54/100], Step [2200/7382], D Loss: 1.3405, G Loss: 0.7933\n",
            "Epoch [54/100], Step [2300/7382], D Loss: 1.3756, G Loss: 0.7027\n",
            "Epoch [54/100], Step [2400/7382], D Loss: 1.3572, G Loss: 0.7363\n",
            "Epoch [54/100], Step [2500/7382], D Loss: 1.3656, G Loss: 0.6993\n",
            "Epoch [54/100], Step [2600/7382], D Loss: 1.4228, G Loss: 0.7961\n",
            "Epoch [54/100], Step [2700/7382], D Loss: 1.3407, G Loss: 0.7440\n",
            "Epoch [54/100], Step [2800/7382], D Loss: 1.3712, G Loss: 0.7519\n",
            "Epoch [54/100], Step [2900/7382], D Loss: 1.3992, G Loss: 0.7060\n",
            "Epoch [54/100], Step [3000/7382], D Loss: 1.3807, G Loss: 0.7142\n",
            "Epoch [54/100], Step [3100/7382], D Loss: 1.3714, G Loss: 0.7656\n",
            "Epoch [54/100], Step [3200/7382], D Loss: 1.4210, G Loss: 0.8213\n",
            "Epoch [54/100], Step [3300/7382], D Loss: 1.3772, G Loss: 0.6943\n",
            "Epoch [54/100], Step [3400/7382], D Loss: 1.3895, G Loss: 0.7303\n",
            "Epoch [54/100], Step [3500/7382], D Loss: 1.3695, G Loss: 0.7129\n",
            "Epoch [54/100], Step [3600/7382], D Loss: 1.4050, G Loss: 0.7250\n",
            "Epoch [54/100], Step [3700/7382], D Loss: 1.3619, G Loss: 0.7451\n",
            "Epoch [54/100], Step [3800/7382], D Loss: 1.3591, G Loss: 0.7646\n",
            "Epoch [54/100], Step [3900/7382], D Loss: 1.3364, G Loss: 0.8005\n",
            "Epoch [54/100], Step [4000/7382], D Loss: 1.3150, G Loss: 0.7670\n",
            "Epoch [54/100], Step [4100/7382], D Loss: 1.3072, G Loss: 0.7786\n",
            "Epoch [54/100], Step [4200/7382], D Loss: 1.3126, G Loss: 0.8392\n",
            "Epoch [54/100], Step [4300/7382], D Loss: 1.3703, G Loss: 0.7165\n",
            "Epoch [54/100], Step [4400/7382], D Loss: 1.3755, G Loss: 0.7829\n",
            "Epoch [54/100], Step [4500/7382], D Loss: 1.3453, G Loss: 0.8199\n",
            "Epoch [54/100], Step [4600/7382], D Loss: 1.3641, G Loss: 0.7819\n",
            "Epoch [54/100], Step [4700/7382], D Loss: 1.3209, G Loss: 0.7753\n",
            "Epoch [54/100], Step [4800/7382], D Loss: 1.3487, G Loss: 0.7575\n",
            "Epoch [54/100], Step [4900/7382], D Loss: 1.3616, G Loss: 0.7424\n",
            "Epoch [54/100], Step [5000/7382], D Loss: 1.3608, G Loss: 0.7936\n",
            "Epoch [54/100], Step [5100/7382], D Loss: 1.4034, G Loss: 0.6918\n",
            "Epoch [54/100], Step [5200/7382], D Loss: 1.3403, G Loss: 0.8201\n",
            "Epoch [54/100], Step [5300/7382], D Loss: 1.3477, G Loss: 0.7219\n",
            "Epoch [54/100], Step [5400/7382], D Loss: 1.3701, G Loss: 0.7430\n",
            "Epoch [54/100], Step [5500/7382], D Loss: 1.4059, G Loss: 0.7124\n",
            "Epoch [54/100], Step [5600/7382], D Loss: 1.3799, G Loss: 0.7260\n",
            "Epoch [54/100], Step [5700/7382], D Loss: 1.4004, G Loss: 0.7286\n",
            "Epoch [54/100], Step [5800/7382], D Loss: 1.3562, G Loss: 0.7703\n",
            "Epoch [54/100], Step [5900/7382], D Loss: 1.3767, G Loss: 0.7435\n",
            "Epoch [54/100], Step [6000/7382], D Loss: 1.3925, G Loss: 0.7438\n",
            "Epoch [54/100], Step [6100/7382], D Loss: 1.4091, G Loss: 0.6991\n",
            "Epoch [54/100], Step [6200/7382], D Loss: 1.3697, G Loss: 0.7129\n",
            "Epoch [54/100], Step [6300/7382], D Loss: 1.3467, G Loss: 0.7277\n",
            "Epoch [54/100], Step [6400/7382], D Loss: 1.3653, G Loss: 0.7707\n",
            "Epoch [54/100], Step [6500/7382], D Loss: 1.4041, G Loss: 0.7300\n",
            "Epoch [54/100], Step [6600/7382], D Loss: 1.3379, G Loss: 0.7689\n",
            "Epoch [54/100], Step [6700/7382], D Loss: 1.3665, G Loss: 0.7304\n",
            "Epoch [54/100], Step [6800/7382], D Loss: 1.3298, G Loss: 0.7770\n",
            "Epoch [54/100], Step [6900/7382], D Loss: 1.3190, G Loss: 0.8269\n",
            "Epoch [54/100], Step [7000/7382], D Loss: 1.4064, G Loss: 0.7002\n",
            "Epoch [54/100], Step [7100/7382], D Loss: 1.3589, G Loss: 0.7741\n",
            "Epoch [54/100], Step [7200/7382], D Loss: 1.3528, G Loss: 0.8020\n",
            "Epoch [54/100], Step [7300/7382], D Loss: 1.3673, G Loss: 0.7230\n",
            "Epoch [55/100], Step [100/7382], D Loss: 1.3582, G Loss: 0.7382\n",
            "Epoch [55/100], Step [200/7382], D Loss: 1.3793, G Loss: 0.7154\n",
            "Epoch [55/100], Step [300/7382], D Loss: 1.3429, G Loss: 0.8043\n",
            "Epoch [55/100], Step [400/7382], D Loss: 1.3529, G Loss: 0.7172\n",
            "Epoch [55/100], Step [500/7382], D Loss: 1.3552, G Loss: 0.7753\n",
            "Epoch [55/100], Step [600/7382], D Loss: 1.3558, G Loss: 0.7364\n",
            "Epoch [55/100], Step [700/7382], D Loss: 1.3658, G Loss: 0.7240\n",
            "Epoch [55/100], Step [800/7382], D Loss: 1.3482, G Loss: 0.7475\n",
            "Epoch [55/100], Step [900/7382], D Loss: 1.3371, G Loss: 0.7550\n",
            "Epoch [55/100], Step [1000/7382], D Loss: 1.3614, G Loss: 0.8380\n",
            "Epoch [55/100], Step [1100/7382], D Loss: 1.3925, G Loss: 0.7254\n",
            "Epoch [55/100], Step [1200/7382], D Loss: 1.3308, G Loss: 0.7832\n",
            "Epoch [55/100], Step [1300/7382], D Loss: 1.3784, G Loss: 0.7447\n",
            "Epoch [55/100], Step [1400/7382], D Loss: 1.3552, G Loss: 0.7681\n",
            "Epoch [55/100], Step [1500/7382], D Loss: 1.3659, G Loss: 0.8005\n",
            "Epoch [55/100], Step [1600/7382], D Loss: 1.3688, G Loss: 0.7942\n",
            "Epoch [55/100], Step [1700/7382], D Loss: 1.3313, G Loss: 0.8021\n",
            "Epoch [55/100], Step [1800/7382], D Loss: 1.3671, G Loss: 0.7364\n",
            "Epoch [55/100], Step [1900/7382], D Loss: 1.3224, G Loss: 0.7426\n",
            "Epoch [55/100], Step [2000/7382], D Loss: 1.2947, G Loss: 0.7652\n",
            "Epoch [55/100], Step [2100/7382], D Loss: 1.3744, G Loss: 0.7508\n",
            "Epoch [55/100], Step [2200/7382], D Loss: 1.3713, G Loss: 0.7440\n",
            "Epoch [55/100], Step [2300/7382], D Loss: 1.3303, G Loss: 0.7414\n",
            "Epoch [55/100], Step [2400/7382], D Loss: 1.3415, G Loss: 0.7910\n",
            "Epoch [55/100], Step [2500/7382], D Loss: 1.3679, G Loss: 0.7892\n",
            "Epoch [55/100], Step [2600/7382], D Loss: 1.2994, G Loss: 0.8371\n",
            "Epoch [55/100], Step [2700/7382], D Loss: 1.3372, G Loss: 0.7686\n",
            "Epoch [55/100], Step [2800/7382], D Loss: 1.3467, G Loss: 0.7555\n",
            "Epoch [55/100], Step [2900/7382], D Loss: 1.3362, G Loss: 0.7805\n",
            "Epoch [55/100], Step [3000/7382], D Loss: 1.3529, G Loss: 0.7732\n",
            "Epoch [55/100], Step [3100/7382], D Loss: 1.3822, G Loss: 0.7746\n",
            "Epoch [55/100], Step [3200/7382], D Loss: 1.3763, G Loss: 0.7069\n",
            "Epoch [55/100], Step [3300/7382], D Loss: 1.3119, G Loss: 0.8106\n",
            "Epoch [55/100], Step [3400/7382], D Loss: 1.3786, G Loss: 0.7149\n",
            "Epoch [55/100], Step [3500/7382], D Loss: 1.3510, G Loss: 0.7492\n",
            "Epoch [55/100], Step [3600/7382], D Loss: 1.3679, G Loss: 0.7154\n",
            "Epoch [55/100], Step [3700/7382], D Loss: 1.4069, G Loss: 0.7289\n",
            "Epoch [55/100], Step [3800/7382], D Loss: 1.3939, G Loss: 0.6983\n",
            "Epoch [55/100], Step [3900/7382], D Loss: 1.3517, G Loss: 0.8353\n",
            "Epoch [55/100], Step [4000/7382], D Loss: 1.3617, G Loss: 0.7823\n",
            "Epoch [55/100], Step [4100/7382], D Loss: 1.3298, G Loss: 0.8275\n",
            "Epoch [55/100], Step [4200/7382], D Loss: 1.3446, G Loss: 0.7512\n",
            "Epoch [55/100], Step [4300/7382], D Loss: 1.3371, G Loss: 0.8127\n",
            "Epoch [55/100], Step [4400/7382], D Loss: 1.3521, G Loss: 0.8522\n",
            "Epoch [55/100], Step [4500/7382], D Loss: 1.4510, G Loss: 0.7350\n",
            "Epoch [55/100], Step [4600/7382], D Loss: 1.3283, G Loss: 0.7915\n",
            "Epoch [55/100], Step [4700/7382], D Loss: 1.3552, G Loss: 0.7415\n",
            "Epoch [55/100], Step [4800/7382], D Loss: 1.3407, G Loss: 0.7352\n",
            "Epoch [55/100], Step [4900/7382], D Loss: 1.3849, G Loss: 0.6953\n",
            "Epoch [55/100], Step [5000/7382], D Loss: 1.3877, G Loss: 0.7307\n",
            "Epoch [55/100], Step [5100/7382], D Loss: 1.3833, G Loss: 0.7902\n",
            "Epoch [55/100], Step [5200/7382], D Loss: 1.3570, G Loss: 0.7272\n",
            "Epoch [55/100], Step [5300/7382], D Loss: 1.2981, G Loss: 0.7949\n",
            "Epoch [55/100], Step [5400/7382], D Loss: 1.3795, G Loss: 0.7329\n",
            "Epoch [55/100], Step [5500/7382], D Loss: 1.2923, G Loss: 0.8110\n",
            "Epoch [55/100], Step [5600/7382], D Loss: 1.3883, G Loss: 0.7005\n",
            "Epoch [55/100], Step [5700/7382], D Loss: 1.3448, G Loss: 0.7760\n",
            "Epoch [55/100], Step [5800/7382], D Loss: 1.3943, G Loss: 0.7937\n",
            "Epoch [55/100], Step [5900/7382], D Loss: 1.3709, G Loss: 0.7322\n",
            "Epoch [55/100], Step [6000/7382], D Loss: 1.3413, G Loss: 0.7665\n",
            "Epoch [55/100], Step [6100/7382], D Loss: 1.3115, G Loss: 0.8340\n",
            "Epoch [55/100], Step [6200/7382], D Loss: 1.4094, G Loss: 0.7643\n",
            "Epoch [55/100], Step [6300/7382], D Loss: 1.4346, G Loss: 0.8214\n",
            "Epoch [55/100], Step [6400/7382], D Loss: 1.3709, G Loss: 0.7073\n",
            "Epoch [55/100], Step [6500/7382], D Loss: 1.3493, G Loss: 0.7340\n",
            "Epoch [55/100], Step [6600/7382], D Loss: 1.2807, G Loss: 0.8430\n",
            "Epoch [55/100], Step [6700/7382], D Loss: 1.3677, G Loss: 0.7363\n",
            "Epoch [55/100], Step [6800/7382], D Loss: 1.3434, G Loss: 0.8387\n",
            "Epoch [55/100], Step [6900/7382], D Loss: 1.3514, G Loss: 0.7828\n",
            "Epoch [55/100], Step [7000/7382], D Loss: 1.3453, G Loss: 0.7650\n",
            "Epoch [55/100], Step [7100/7382], D Loss: 1.3284, G Loss: 0.8125\n",
            "Epoch [55/100], Step [7200/7382], D Loss: 1.3159, G Loss: 0.7585\n",
            "Epoch [55/100], Step [7300/7382], D Loss: 1.3827, G Loss: 0.7968\n",
            "Epoch [56/100], Step [100/7382], D Loss: 1.3496, G Loss: 0.7605\n",
            "Epoch [56/100], Step [200/7382], D Loss: 1.3551, G Loss: 0.8532\n",
            "Epoch [56/100], Step [300/7382], D Loss: 1.3584, G Loss: 0.7287\n",
            "Epoch [56/100], Step [400/7382], D Loss: 1.3804, G Loss: 0.7492\n",
            "Epoch [56/100], Step [500/7382], D Loss: 1.3347, G Loss: 0.7866\n",
            "Epoch [56/100], Step [600/7382], D Loss: 1.3462, G Loss: 0.7448\n",
            "Epoch [56/100], Step [700/7382], D Loss: 1.3544, G Loss: 0.7350\n",
            "Epoch [56/100], Step [800/7382], D Loss: 1.3794, G Loss: 0.7664\n",
            "Epoch [56/100], Step [900/7382], D Loss: 1.3600, G Loss: 0.7839\n",
            "Epoch [56/100], Step [1000/7382], D Loss: 1.3704, G Loss: 0.7877\n",
            "Epoch [56/100], Step [1100/7382], D Loss: 1.3374, G Loss: 0.7551\n",
            "Epoch [56/100], Step [1200/7382], D Loss: 1.3567, G Loss: 0.8233\n",
            "Epoch [56/100], Step [1300/7382], D Loss: 1.2815, G Loss: 0.8717\n",
            "Epoch [56/100], Step [1400/7382], D Loss: 1.3471, G Loss: 0.8991\n",
            "Epoch [56/100], Step [1500/7382], D Loss: 1.3205, G Loss: 0.8479\n",
            "Epoch [56/100], Step [1600/7382], D Loss: 1.3791, G Loss: 0.7483\n",
            "Epoch [56/100], Step [1700/7382], D Loss: 1.3128, G Loss: 0.8477\n",
            "Epoch [56/100], Step [1800/7382], D Loss: 1.3693, G Loss: 0.8129\n",
            "Epoch [56/100], Step [1900/7382], D Loss: 1.3733, G Loss: 0.7308\n",
            "Epoch [56/100], Step [2000/7382], D Loss: 1.3431, G Loss: 0.7901\n",
            "Epoch [56/100], Step [2100/7382], D Loss: 1.3995, G Loss: 0.7557\n",
            "Epoch [56/100], Step [2200/7382], D Loss: 1.4393, G Loss: 0.7361\n",
            "Epoch [56/100], Step [2300/7382], D Loss: 1.3584, G Loss: 0.7508\n",
            "Epoch [56/100], Step [2400/7382], D Loss: 1.3837, G Loss: 0.7381\n",
            "Epoch [56/100], Step [2500/7382], D Loss: 1.3972, G Loss: 0.8030\n",
            "Epoch [56/100], Step [2600/7382], D Loss: 1.3474, G Loss: 0.7301\n",
            "Epoch [56/100], Step [2700/7382], D Loss: 1.3340, G Loss: 0.7638\n",
            "Epoch [56/100], Step [2800/7382], D Loss: 1.3011, G Loss: 0.8377\n",
            "Epoch [56/100], Step [2900/7382], D Loss: 1.4027, G Loss: 0.7028\n",
            "Epoch [56/100], Step [3000/7382], D Loss: 1.2936, G Loss: 0.7640\n",
            "Epoch [56/100], Step [3100/7382], D Loss: 1.3467, G Loss: 0.7530\n",
            "Epoch [56/100], Step [3200/7382], D Loss: 1.3504, G Loss: 0.7263\n",
            "Epoch [56/100], Step [3300/7382], D Loss: 1.3563, G Loss: 0.7251\n",
            "Epoch [56/100], Step [3400/7382], D Loss: 1.3426, G Loss: 0.7679\n",
            "Epoch [56/100], Step [3500/7382], D Loss: 1.3794, G Loss: 0.7794\n",
            "Epoch [56/100], Step [3600/7382], D Loss: 1.3385, G Loss: 0.7848\n",
            "Epoch [56/100], Step [3700/7382], D Loss: 1.3707, G Loss: 0.7320\n",
            "Epoch [56/100], Step [3800/7382], D Loss: 1.3508, G Loss: 0.7124\n",
            "Epoch [56/100], Step [3900/7382], D Loss: 1.3501, G Loss: 0.7391\n",
            "Epoch [56/100], Step [4000/7382], D Loss: 1.3337, G Loss: 0.7485\n",
            "Epoch [56/100], Step [4100/7382], D Loss: 1.4166, G Loss: 0.7225\n",
            "Epoch [56/100], Step [4200/7382], D Loss: 1.3315, G Loss: 0.7435\n",
            "Epoch [56/100], Step [4300/7382], D Loss: 1.3913, G Loss: 0.7246\n",
            "Epoch [56/100], Step [4400/7382], D Loss: 1.3540, G Loss: 0.7740\n",
            "Epoch [56/100], Step [4500/7382], D Loss: 1.3408, G Loss: 0.7209\n",
            "Epoch [56/100], Step [4600/7382], D Loss: 1.3775, G Loss: 0.8028\n",
            "Epoch [56/100], Step [4700/7382], D Loss: 1.3499, G Loss: 0.7445\n",
            "Epoch [56/100], Step [4800/7382], D Loss: 1.2985, G Loss: 0.9554\n",
            "Epoch [56/100], Step [4900/7382], D Loss: 1.3452, G Loss: 0.8576\n",
            "Epoch [56/100], Step [5000/7382], D Loss: 1.3769, G Loss: 0.7505\n",
            "Epoch [56/100], Step [5100/7382], D Loss: 1.3095, G Loss: 0.8258\n",
            "Epoch [56/100], Step [5200/7382], D Loss: 1.3314, G Loss: 0.7760\n",
            "Epoch [56/100], Step [5300/7382], D Loss: 1.3016, G Loss: 0.8591\n",
            "Epoch [56/100], Step [5400/7382], D Loss: 1.3453, G Loss: 0.8865\n",
            "Epoch [56/100], Step [5500/7382], D Loss: 1.3554, G Loss: 0.8000\n",
            "Epoch [56/100], Step [5600/7382], D Loss: 1.4305, G Loss: 0.7187\n",
            "Epoch [56/100], Step [5700/7382], D Loss: 1.3263, G Loss: 0.8347\n",
            "Epoch [56/100], Step [5800/7382], D Loss: 1.3497, G Loss: 0.7616\n",
            "Epoch [56/100], Step [5900/7382], D Loss: 1.3656, G Loss: 0.7602\n",
            "Epoch [56/100], Step [6000/7382], D Loss: 1.3504, G Loss: 0.7255\n",
            "Epoch [56/100], Step [6100/7382], D Loss: 1.4527, G Loss: 0.7419\n",
            "Epoch [56/100], Step [6200/7382], D Loss: 1.3883, G Loss: 0.7900\n",
            "Epoch [56/100], Step [6300/7382], D Loss: 1.4023, G Loss: 0.6815\n",
            "Epoch [56/100], Step [6400/7382], D Loss: 1.3726, G Loss: 0.7275\n",
            "Epoch [56/100], Step [6500/7382], D Loss: 1.4241, G Loss: 0.6874\n",
            "Epoch [56/100], Step [6600/7382], D Loss: 1.3149, G Loss: 0.7972\n",
            "Epoch [56/100], Step [6700/7382], D Loss: 1.3868, G Loss: 0.7083\n",
            "Epoch [56/100], Step [6800/7382], D Loss: 1.3375, G Loss: 0.7750\n",
            "Epoch [56/100], Step [6900/7382], D Loss: 1.3700, G Loss: 0.7294\n",
            "Epoch [56/100], Step [7000/7382], D Loss: 1.3850, G Loss: 0.7177\n",
            "Epoch [56/100], Step [7100/7382], D Loss: 1.3048, G Loss: 0.8811\n",
            "Epoch [56/100], Step [7200/7382], D Loss: 1.3778, G Loss: 0.7714\n",
            "Epoch [56/100], Step [7300/7382], D Loss: 1.3321, G Loss: 0.7668\n",
            "Epoch [57/100], Step [100/7382], D Loss: 1.3587, G Loss: 0.7462\n",
            "Epoch [57/100], Step [200/7382], D Loss: 1.3580, G Loss: 0.7532\n",
            "Epoch [57/100], Step [300/7382], D Loss: 1.3677, G Loss: 0.7247\n",
            "Epoch [57/100], Step [400/7382], D Loss: 1.3494, G Loss: 0.7222\n",
            "Epoch [57/100], Step [500/7382], D Loss: 1.3568, G Loss: 0.7443\n",
            "Epoch [57/100], Step [600/7382], D Loss: 1.3952, G Loss: 0.6807\n",
            "Epoch [57/100], Step [700/7382], D Loss: 1.3691, G Loss: 0.7405\n",
            "Epoch [57/100], Step [800/7382], D Loss: 1.3392, G Loss: 0.8264\n",
            "Epoch [57/100], Step [900/7382], D Loss: 1.3915, G Loss: 0.6968\n",
            "Epoch [57/100], Step [1000/7382], D Loss: 1.3722, G Loss: 0.7141\n",
            "Epoch [57/100], Step [1100/7382], D Loss: 1.3556, G Loss: 0.7354\n",
            "Epoch [57/100], Step [1200/7382], D Loss: 1.3540, G Loss: 0.8266\n",
            "Epoch [57/100], Step [1300/7382], D Loss: 1.3498, G Loss: 0.7184\n",
            "Epoch [57/100], Step [1400/7382], D Loss: 1.3750, G Loss: 0.7237\n",
            "Epoch [57/100], Step [1500/7382], D Loss: 1.3653, G Loss: 0.7398\n",
            "Epoch [57/100], Step [1600/7382], D Loss: 1.3676, G Loss: 0.7535\n",
            "Epoch [57/100], Step [1700/7382], D Loss: 1.3653, G Loss: 0.7165\n",
            "Epoch [57/100], Step [1800/7382], D Loss: 1.3638, G Loss: 0.7256\n",
            "Epoch [57/100], Step [1900/7382], D Loss: 1.3359, G Loss: 0.7916\n",
            "Epoch [57/100], Step [2000/7382], D Loss: 1.3848, G Loss: 0.7106\n",
            "Epoch [57/100], Step [2100/7382], D Loss: 1.3435, G Loss: 0.7844\n",
            "Epoch [57/100], Step [2200/7382], D Loss: 1.3697, G Loss: 0.7336\n",
            "Epoch [57/100], Step [2300/7382], D Loss: 1.3570, G Loss: 0.7457\n",
            "Epoch [57/100], Step [2400/7382], D Loss: 1.3371, G Loss: 0.7838\n",
            "Epoch [57/100], Step [2500/7382], D Loss: 1.3348, G Loss: 0.8068\n",
            "Epoch [57/100], Step [2600/7382], D Loss: 1.4271, G Loss: 0.7116\n",
            "Epoch [57/100], Step [2700/7382], D Loss: 1.3493, G Loss: 0.7227\n",
            "Epoch [57/100], Step [2800/7382], D Loss: 1.3877, G Loss: 0.7121\n",
            "Epoch [57/100], Step [2900/7382], D Loss: 1.3676, G Loss: 0.7362\n",
            "Epoch [57/100], Step [3000/7382], D Loss: 1.3655, G Loss: 0.7383\n",
            "Epoch [57/100], Step [3100/7382], D Loss: 1.3365, G Loss: 0.9694\n",
            "Epoch [57/100], Step [3200/7382], D Loss: 1.3175, G Loss: 0.7700\n",
            "Epoch [57/100], Step [3300/7382], D Loss: 1.3752, G Loss: 0.8382\n",
            "Epoch [57/100], Step [3400/7382], D Loss: 1.3635, G Loss: 0.7384\n",
            "Epoch [57/100], Step [3500/7382], D Loss: 1.3687, G Loss: 0.7179\n",
            "Epoch [57/100], Step [3600/7382], D Loss: 1.3499, G Loss: 0.7115\n",
            "Epoch [57/100], Step [3700/7382], D Loss: 1.3478, G Loss: 0.7376\n",
            "Epoch [57/100], Step [3800/7382], D Loss: 1.3440, G Loss: 0.8460\n",
            "Epoch [57/100], Step [3900/7382], D Loss: 1.4395, G Loss: 0.6925\n",
            "Epoch [57/100], Step [4000/7382], D Loss: 1.3472, G Loss: 0.7434\n",
            "Epoch [57/100], Step [4100/7382], D Loss: 1.3864, G Loss: 0.7104\n",
            "Epoch [57/100], Step [4200/7382], D Loss: 1.3560, G Loss: 0.7479\n",
            "Epoch [57/100], Step [4300/7382], D Loss: 1.3090, G Loss: 0.9334\n",
            "Epoch [57/100], Step [4400/7382], D Loss: 1.3810, G Loss: 0.7887\n",
            "Epoch [57/100], Step [4500/7382], D Loss: 1.3826, G Loss: 0.7225\n",
            "Epoch [57/100], Step [4600/7382], D Loss: 1.3216, G Loss: 0.9233\n",
            "Epoch [57/100], Step [4700/7382], D Loss: 1.3968, G Loss: 0.7741\n",
            "Epoch [57/100], Step [4800/7382], D Loss: 1.3584, G Loss: 0.7542\n",
            "Epoch [57/100], Step [4900/7382], D Loss: 1.3536, G Loss: 0.7113\n",
            "Epoch [57/100], Step [5000/7382], D Loss: 1.3796, G Loss: 0.6892\n",
            "Epoch [57/100], Step [5100/7382], D Loss: 1.3549, G Loss: 0.7216\n",
            "Epoch [57/100], Step [5200/7382], D Loss: 1.3349, G Loss: 0.8189\n",
            "Epoch [57/100], Step [5300/7382], D Loss: 1.3816, G Loss: 0.7228\n",
            "Epoch [57/100], Step [5400/7382], D Loss: 1.3806, G Loss: 0.7087\n",
            "Epoch [57/100], Step [5500/7382], D Loss: 1.3298, G Loss: 0.8708\n",
            "Epoch [57/100], Step [5600/7382], D Loss: 1.4328, G Loss: 0.7581\n",
            "Epoch [57/100], Step [5700/7382], D Loss: 1.3599, G Loss: 0.7676\n",
            "Epoch [57/100], Step [5800/7382], D Loss: 1.3804, G Loss: 0.7248\n",
            "Epoch [57/100], Step [5900/7382], D Loss: 1.3763, G Loss: 0.6993\n",
            "Epoch [57/100], Step [6000/7382], D Loss: 1.3759, G Loss: 0.7477\n",
            "Epoch [57/100], Step [6100/7382], D Loss: 1.3108, G Loss: 0.7846\n",
            "Epoch [57/100], Step [6200/7382], D Loss: 1.3507, G Loss: 0.7662\n",
            "Epoch [57/100], Step [6300/7382], D Loss: 1.3253, G Loss: 0.7614\n",
            "Epoch [57/100], Step [6400/7382], D Loss: 1.3544, G Loss: 0.8113\n",
            "Epoch [57/100], Step [6500/7382], D Loss: 1.3679, G Loss: 0.8675\n",
            "Epoch [57/100], Step [6600/7382], D Loss: 1.3507, G Loss: 0.8389\n",
            "Epoch [57/100], Step [6700/7382], D Loss: 1.3581, G Loss: 0.7626\n",
            "Epoch [57/100], Step [6800/7382], D Loss: 1.3643, G Loss: 0.7713\n",
            "Epoch [57/100], Step [6900/7382], D Loss: 1.3558, G Loss: 0.7376\n",
            "Epoch [57/100], Step [7000/7382], D Loss: 1.3647, G Loss: 0.7788\n",
            "Epoch [57/100], Step [7100/7382], D Loss: 1.3500, G Loss: 0.7321\n",
            "Epoch [57/100], Step [7200/7382], D Loss: 1.3803, G Loss: 0.7422\n",
            "Epoch [57/100], Step [7300/7382], D Loss: 1.4081, G Loss: 0.7660\n",
            "Epoch [58/100], Step [100/7382], D Loss: 1.3537, G Loss: 0.7627\n",
            "Epoch [58/100], Step [200/7382], D Loss: 1.3639, G Loss: 0.7994\n",
            "Epoch [58/100], Step [300/7382], D Loss: 1.3793, G Loss: 0.7056\n",
            "Epoch [58/100], Step [400/7382], D Loss: 1.3107, G Loss: 0.7955\n",
            "Epoch [58/100], Step [500/7382], D Loss: 1.3618, G Loss: 0.7194\n",
            "Epoch [58/100], Step [600/7382], D Loss: 1.3025, G Loss: 0.7615\n",
            "Epoch [58/100], Step [700/7382], D Loss: 1.3604, G Loss: 0.7577\n",
            "Epoch [58/100], Step [800/7382], D Loss: 1.3366, G Loss: 0.7610\n",
            "Epoch [58/100], Step [900/7382], D Loss: 1.2925, G Loss: 0.8171\n",
            "Epoch [58/100], Step [1000/7382], D Loss: 1.3540, G Loss: 0.7532\n",
            "Epoch [58/100], Step [1100/7382], D Loss: 1.3641, G Loss: 0.7539\n",
            "Epoch [58/100], Step [1200/7382], D Loss: 1.3218, G Loss: 0.7678\n",
            "Epoch [58/100], Step [1300/7382], D Loss: 1.3435, G Loss: 0.7775\n",
            "Epoch [58/100], Step [1400/7382], D Loss: 1.3564, G Loss: 0.7664\n",
            "Epoch [58/100], Step [1500/7382], D Loss: 1.2916, G Loss: 0.8026\n",
            "Epoch [58/100], Step [1600/7382], D Loss: 1.3685, G Loss: 0.7338\n",
            "Epoch [58/100], Step [1700/7382], D Loss: 1.4114, G Loss: 0.7818\n",
            "Epoch [58/100], Step [1800/7382], D Loss: 1.3454, G Loss: 0.7730\n",
            "Epoch [58/100], Step [1900/7382], D Loss: 1.3278, G Loss: 0.7547\n",
            "Epoch [58/100], Step [2000/7382], D Loss: 1.3288, G Loss: 0.8179\n",
            "Epoch [58/100], Step [2100/7382], D Loss: 1.3521, G Loss: 0.7272\n",
            "Epoch [58/100], Step [2200/7382], D Loss: 1.3712, G Loss: 0.7488\n",
            "Epoch [58/100], Step [2300/7382], D Loss: 1.4182, G Loss: 0.7260\n",
            "Epoch [58/100], Step [2400/7382], D Loss: 1.3433, G Loss: 0.7231\n",
            "Epoch [58/100], Step [2500/7382], D Loss: 1.3482, G Loss: 0.7865\n",
            "Epoch [58/100], Step [2600/7382], D Loss: 1.3111, G Loss: 0.8316\n",
            "Epoch [58/100], Step [2700/7382], D Loss: 1.3329, G Loss: 0.7884\n",
            "Epoch [58/100], Step [2800/7382], D Loss: 1.3661, G Loss: 0.7505\n",
            "Epoch [58/100], Step [2900/7382], D Loss: 1.4130, G Loss: 0.7630\n",
            "Epoch [58/100], Step [3000/7382], D Loss: 1.3756, G Loss: 0.7154\n",
            "Epoch [58/100], Step [3100/7382], D Loss: 1.3591, G Loss: 0.7225\n",
            "Epoch [58/100], Step [3200/7382], D Loss: 1.2799, G Loss: 0.8429\n",
            "Epoch [58/100], Step [3300/7382], D Loss: 1.3400, G Loss: 0.7728\n",
            "Epoch [58/100], Step [3400/7382], D Loss: 1.3636, G Loss: 0.7602\n",
            "Epoch [58/100], Step [3500/7382], D Loss: 1.3937, G Loss: 0.7164\n",
            "Epoch [58/100], Step [3600/7382], D Loss: 1.3418, G Loss: 0.7679\n",
            "Epoch [58/100], Step [3700/7382], D Loss: 1.3669, G Loss: 0.7788\n",
            "Epoch [58/100], Step [3800/7382], D Loss: 1.3961, G Loss: 0.7437\n",
            "Epoch [58/100], Step [3900/7382], D Loss: 1.3808, G Loss: 0.7092\n",
            "Epoch [58/100], Step [4000/7382], D Loss: 1.3189, G Loss: 0.7972\n",
            "Epoch [58/100], Step [4100/7382], D Loss: 1.3185, G Loss: 0.7887\n",
            "Epoch [58/100], Step [4200/7382], D Loss: 1.3827, G Loss: 0.7361\n",
            "Epoch [58/100], Step [4300/7382], D Loss: 1.3565, G Loss: 0.7484\n",
            "Epoch [58/100], Step [4400/7382], D Loss: 1.3460, G Loss: 0.7308\n",
            "Epoch [58/100], Step [4500/7382], D Loss: 1.3133, G Loss: 0.8052\n",
            "Epoch [58/100], Step [4600/7382], D Loss: 1.3793, G Loss: 0.7396\n",
            "Epoch [58/100], Step [4700/7382], D Loss: 1.3295, G Loss: 0.8444\n",
            "Epoch [58/100], Step [4800/7382], D Loss: 1.3653, G Loss: 0.7775\n",
            "Epoch [58/100], Step [4900/7382], D Loss: 1.3185, G Loss: 0.7567\n",
            "Epoch [58/100], Step [5000/7382], D Loss: 1.3623, G Loss: 0.7822\n",
            "Epoch [58/100], Step [5100/7382], D Loss: 1.2820, G Loss: 0.8435\n",
            "Epoch [58/100], Step [5200/7382], D Loss: 1.3206, G Loss: 0.7683\n",
            "Epoch [58/100], Step [5300/7382], D Loss: 1.3535, G Loss: 0.7930\n",
            "Epoch [58/100], Step [5400/7382], D Loss: 1.3216, G Loss: 0.7926\n",
            "Epoch [58/100], Step [5500/7382], D Loss: 1.3585, G Loss: 0.7400\n",
            "Epoch [58/100], Step [5600/7382], D Loss: 1.3643, G Loss: 0.7531\n",
            "Epoch [58/100], Step [5700/7382], D Loss: 1.3480, G Loss: 0.8258\n",
            "Epoch [58/100], Step [5800/7382], D Loss: 1.3562, G Loss: 0.7155\n",
            "Epoch [58/100], Step [5900/7382], D Loss: 1.3418, G Loss: 0.8025\n",
            "Epoch [58/100], Step [6000/7382], D Loss: 1.3684, G Loss: 0.7903\n",
            "Epoch [58/100], Step [6100/7382], D Loss: 1.3418, G Loss: 0.7523\n",
            "Epoch [58/100], Step [6200/7382], D Loss: 1.3050, G Loss: 0.8007\n",
            "Epoch [58/100], Step [6300/7382], D Loss: 1.3074, G Loss: 0.7628\n",
            "Epoch [58/100], Step [6400/7382], D Loss: 1.3416, G Loss: 0.7919\n",
            "Epoch [58/100], Step [6500/7382], D Loss: 1.3803, G Loss: 0.7245\n",
            "Epoch [58/100], Step [6600/7382], D Loss: 1.2536, G Loss: 0.8403\n",
            "Epoch [58/100], Step [6700/7382], D Loss: 1.3810, G Loss: 0.8706\n",
            "Epoch [58/100], Step [6800/7382], D Loss: 1.3225, G Loss: 0.7748\n",
            "Epoch [58/100], Step [6900/7382], D Loss: 1.3408, G Loss: 0.7298\n",
            "Epoch [58/100], Step [7000/7382], D Loss: 1.3959, G Loss: 0.7301\n",
            "Epoch [58/100], Step [7100/7382], D Loss: 1.3529, G Loss: 0.7541\n",
            "Epoch [58/100], Step [7200/7382], D Loss: 1.4042, G Loss: 0.7080\n",
            "Epoch [58/100], Step [7300/7382], D Loss: 1.3171, G Loss: 0.8127\n",
            "Epoch [59/100], Step [100/7382], D Loss: 1.4481, G Loss: 0.6981\n",
            "Epoch [59/100], Step [200/7382], D Loss: 1.3846, G Loss: 0.7112\n",
            "Epoch [59/100], Step [300/7382], D Loss: 1.3683, G Loss: 0.7338\n",
            "Epoch [59/100], Step [400/7382], D Loss: 1.3710, G Loss: 0.7503\n",
            "Epoch [59/100], Step [500/7382], D Loss: 1.3700, G Loss: 0.7420\n",
            "Epoch [59/100], Step [600/7382], D Loss: 1.3887, G Loss: 0.7635\n",
            "Epoch [59/100], Step [700/7382], D Loss: 1.3942, G Loss: 0.7209\n",
            "Epoch [59/100], Step [800/7382], D Loss: 1.3352, G Loss: 0.8177\n",
            "Epoch [59/100], Step [900/7382], D Loss: 1.3467, G Loss: 0.7954\n",
            "Epoch [59/100], Step [1000/7382], D Loss: 1.3343, G Loss: 0.7803\n",
            "Epoch [59/100], Step [1100/7382], D Loss: 1.3532, G Loss: 0.7369\n",
            "Epoch [59/100], Step [1200/7382], D Loss: 1.3642, G Loss: 0.7844\n",
            "Epoch [59/100], Step [1300/7382], D Loss: 1.3089, G Loss: 0.8113\n",
            "Epoch [59/100], Step [1400/7382], D Loss: 1.3982, G Loss: 0.6995\n",
            "Epoch [59/100], Step [1500/7382], D Loss: 1.3548, G Loss: 0.7436\n",
            "Epoch [59/100], Step [1600/7382], D Loss: 1.3613, G Loss: 0.7346\n",
            "Epoch [59/100], Step [1700/7382], D Loss: 1.3356, G Loss: 0.8066\n",
            "Epoch [59/100], Step [1800/7382], D Loss: 1.4013, G Loss: 0.7405\n",
            "Epoch [59/100], Step [1900/7382], D Loss: 1.3223, G Loss: 0.7885\n",
            "Epoch [59/100], Step [2000/7382], D Loss: 1.3649, G Loss: 0.7468\n",
            "Epoch [59/100], Step [2100/7382], D Loss: 1.3662, G Loss: 0.7451\n",
            "Epoch [59/100], Step [2200/7382], D Loss: 1.3865, G Loss: 0.7377\n",
            "Epoch [59/100], Step [2300/7382], D Loss: 1.3396, G Loss: 0.7784\n",
            "Epoch [59/100], Step [2400/7382], D Loss: 1.3308, G Loss: 0.7468\n",
            "Epoch [59/100], Step [2500/7382], D Loss: 1.3224, G Loss: 0.8270\n",
            "Epoch [59/100], Step [2600/7382], D Loss: 1.3962, G Loss: 0.7261\n",
            "Epoch [59/100], Step [2700/7382], D Loss: 1.2729, G Loss: 0.8017\n",
            "Epoch [59/100], Step [2800/7382], D Loss: 1.3461, G Loss: 0.7316\n",
            "Epoch [59/100], Step [2900/7382], D Loss: 1.3732, G Loss: 0.8215\n",
            "Epoch [59/100], Step [3000/7382], D Loss: 1.3896, G Loss: 0.7442\n",
            "Epoch [59/100], Step [3100/7382], D Loss: 1.3694, G Loss: 0.7889\n",
            "Epoch [59/100], Step [3200/7382], D Loss: 1.3524, G Loss: 0.7539\n",
            "Epoch [59/100], Step [3300/7382], D Loss: 1.3555, G Loss: 0.7457\n",
            "Epoch [59/100], Step [3400/7382], D Loss: 1.3430, G Loss: 0.7526\n",
            "Epoch [59/100], Step [3500/7382], D Loss: 1.3234, G Loss: 0.7765\n",
            "Epoch [59/100], Step [3600/7382], D Loss: 1.3725, G Loss: 0.7209\n",
            "Epoch [59/100], Step [3700/7382], D Loss: 1.3725, G Loss: 0.7188\n",
            "Epoch [59/100], Step [3800/7382], D Loss: 1.4134, G Loss: 0.7427\n",
            "Epoch [59/100], Step [3900/7382], D Loss: 1.3908, G Loss: 0.7604\n",
            "Epoch [59/100], Step [4000/7382], D Loss: 1.3623, G Loss: 0.7152\n",
            "Epoch [59/100], Step [4100/7382], D Loss: 1.3983, G Loss: 0.7188\n",
            "Epoch [59/100], Step [4200/7382], D Loss: 1.3609, G Loss: 0.7807\n",
            "Epoch [59/100], Step [4300/7382], D Loss: 1.3441, G Loss: 0.7355\n",
            "Epoch [59/100], Step [4400/7382], D Loss: 1.4074, G Loss: 0.7212\n",
            "Epoch [59/100], Step [4500/7382], D Loss: 1.3803, G Loss: 0.7521\n",
            "Epoch [59/100], Step [4600/7382], D Loss: 1.3849, G Loss: 0.7267\n",
            "Epoch [59/100], Step [4700/7382], D Loss: 1.3778, G Loss: 0.6776\n",
            "Epoch [59/100], Step [4800/7382], D Loss: 1.3204, G Loss: 0.7619\n",
            "Epoch [59/100], Step [4900/7382], D Loss: 1.3493, G Loss: 0.7462\n",
            "Epoch [59/100], Step [5000/7382], D Loss: 1.3596, G Loss: 0.7651\n",
            "Epoch [59/100], Step [5100/7382], D Loss: 1.3669, G Loss: 0.7286\n",
            "Epoch [59/100], Step [5200/7382], D Loss: 1.3412, G Loss: 0.7510\n",
            "Epoch [59/100], Step [5300/7382], D Loss: 1.3541, G Loss: 0.7284\n",
            "Epoch [59/100], Step [5400/7382], D Loss: 1.3734, G Loss: 0.7294\n",
            "Epoch [59/100], Step [5500/7382], D Loss: 1.3762, G Loss: 0.7212\n",
            "Epoch [59/100], Step [5600/7382], D Loss: 1.3485, G Loss: 0.7133\n",
            "Epoch [59/100], Step [5700/7382], D Loss: 1.3695, G Loss: 0.7835\n",
            "Epoch [59/100], Step [5800/7382], D Loss: 1.3585, G Loss: 0.7765\n",
            "Epoch [59/100], Step [5900/7382], D Loss: 1.3838, G Loss: 0.7108\n",
            "Epoch [59/100], Step [6000/7382], D Loss: 1.3870, G Loss: 0.7899\n",
            "Epoch [59/100], Step [6100/7382], D Loss: 1.3427, G Loss: 0.8142\n",
            "Epoch [59/100], Step [6200/7382], D Loss: 1.3353, G Loss: 0.7806\n",
            "Epoch [59/100], Step [6300/7382], D Loss: 1.3866, G Loss: 0.7371\n",
            "Epoch [59/100], Step [6400/7382], D Loss: 1.3837, G Loss: 0.7808\n",
            "Epoch [59/100], Step [6500/7382], D Loss: 1.3155, G Loss: 0.7447\n",
            "Epoch [59/100], Step [6600/7382], D Loss: 1.3422, G Loss: 0.7565\n",
            "Epoch [59/100], Step [6700/7382], D Loss: 1.3436, G Loss: 0.8024\n",
            "Epoch [59/100], Step [6800/7382], D Loss: 1.3641, G Loss: 0.7208\n",
            "Epoch [59/100], Step [6900/7382], D Loss: 1.3986, G Loss: 0.7731\n",
            "Epoch [59/100], Step [7000/7382], D Loss: 1.3081, G Loss: 0.7676\n",
            "Epoch [59/100], Step [7100/7382], D Loss: 1.3858, G Loss: 0.7031\n",
            "Epoch [59/100], Step [7200/7382], D Loss: 1.3859, G Loss: 0.7132\n",
            "Epoch [59/100], Step [7300/7382], D Loss: 1.3692, G Loss: 0.6935\n",
            "Epoch [60/100], Step [100/7382], D Loss: 1.3491, G Loss: 0.8084\n",
            "Epoch [60/100], Step [200/7382], D Loss: 1.3408, G Loss: 0.7519\n",
            "Epoch [60/100], Step [300/7382], D Loss: 1.4132, G Loss: 0.7916\n",
            "Epoch [60/100], Step [400/7382], D Loss: 1.3322, G Loss: 0.8281\n",
            "Epoch [60/100], Step [500/7382], D Loss: 1.3535, G Loss: 0.7360\n",
            "Epoch [60/100], Step [600/7382], D Loss: 1.3541, G Loss: 0.7589\n",
            "Epoch [60/100], Step [700/7382], D Loss: 1.3354, G Loss: 0.7982\n",
            "Epoch [60/100], Step [800/7382], D Loss: 1.3599, G Loss: 0.6921\n",
            "Epoch [60/100], Step [900/7382], D Loss: 1.3966, G Loss: 0.6987\n",
            "Epoch [60/100], Step [1000/7382], D Loss: 1.3507, G Loss: 0.7432\n",
            "Epoch [60/100], Step [1100/7382], D Loss: 1.4118, G Loss: 0.7208\n",
            "Epoch [60/100], Step [1200/7382], D Loss: 1.3508, G Loss: 0.7954\n",
            "Epoch [60/100], Step [1300/7382], D Loss: 1.3853, G Loss: 0.8069\n",
            "Epoch [60/100], Step [1400/7382], D Loss: 1.3648, G Loss: 0.7933\n",
            "Epoch [60/100], Step [1500/7382], D Loss: 1.3942, G Loss: 0.6841\n",
            "Epoch [60/100], Step [1600/7382], D Loss: 1.3298, G Loss: 0.7487\n",
            "Epoch [60/100], Step [1700/7382], D Loss: 1.3211, G Loss: 0.7669\n",
            "Epoch [60/100], Step [1800/7382], D Loss: 1.3836, G Loss: 0.7194\n",
            "Epoch [60/100], Step [1900/7382], D Loss: 1.3492, G Loss: 0.7653\n",
            "Epoch [60/100], Step [2000/7382], D Loss: 1.4077, G Loss: 0.7040\n",
            "Epoch [60/100], Step [2100/7382], D Loss: 1.3647, G Loss: 0.7657\n",
            "Epoch [60/100], Step [2200/7382], D Loss: 1.4325, G Loss: 0.7002\n",
            "Epoch [60/100], Step [2300/7382], D Loss: 1.3864, G Loss: 0.7265\n",
            "Epoch [60/100], Step [2400/7382], D Loss: 1.3294, G Loss: 0.8018\n",
            "Epoch [60/100], Step [2500/7382], D Loss: 1.3749, G Loss: 0.7642\n",
            "Epoch [60/100], Step [2600/7382], D Loss: 1.3735, G Loss: 0.8031\n",
            "Epoch [60/100], Step [2700/7382], D Loss: 1.3537, G Loss: 0.7724\n",
            "Epoch [60/100], Step [2800/7382], D Loss: 1.3831, G Loss: 0.7484\n",
            "Epoch [60/100], Step [2900/7382], D Loss: 1.3474, G Loss: 0.7974\n",
            "Epoch [60/100], Step [3000/7382], D Loss: 1.3571, G Loss: 0.7314\n",
            "Epoch [60/100], Step [3100/7382], D Loss: 1.3258, G Loss: 0.7347\n",
            "Epoch [60/100], Step [3200/7382], D Loss: 1.2908, G Loss: 0.8228\n",
            "Epoch [60/100], Step [3300/7382], D Loss: 1.3286, G Loss: 0.7625\n",
            "Epoch [60/100], Step [3400/7382], D Loss: 1.3736, G Loss: 0.8352\n",
            "Epoch [60/100], Step [3500/7382], D Loss: 1.3817, G Loss: 0.7266\n",
            "Epoch [60/100], Step [3600/7382], D Loss: 1.3785, G Loss: 0.7249\n",
            "Epoch [60/100], Step [3700/7382], D Loss: 1.3840, G Loss: 0.7456\n",
            "Epoch [60/100], Step [3800/7382], D Loss: 1.3211, G Loss: 0.7609\n",
            "Epoch [60/100], Step [3900/7382], D Loss: 1.3204, G Loss: 0.7405\n",
            "Epoch [60/100], Step [4000/7382], D Loss: 1.3433, G Loss: 0.7546\n",
            "Epoch [60/100], Step [4100/7382], D Loss: 1.3150, G Loss: 0.8364\n",
            "Epoch [60/100], Step [4200/7382], D Loss: 1.3643, G Loss: 0.7405\n",
            "Epoch [60/100], Step [4300/7382], D Loss: 1.3662, G Loss: 0.7673\n",
            "Epoch [60/100], Step [4400/7382], D Loss: 1.3616, G Loss: 0.7718\n",
            "Epoch [60/100], Step [4500/7382], D Loss: 1.3375, G Loss: 0.7393\n",
            "Epoch [60/100], Step [4600/7382], D Loss: 1.4097, G Loss: 0.7201\n",
            "Epoch [60/100], Step [4700/7382], D Loss: 1.3398, G Loss: 0.7550\n",
            "Epoch [60/100], Step [4800/7382], D Loss: 1.3235, G Loss: 0.7585\n",
            "Epoch [60/100], Step [4900/7382], D Loss: 1.3029, G Loss: 0.8299\n",
            "Epoch [60/100], Step [5000/7382], D Loss: 1.2847, G Loss: 0.8282\n",
            "Epoch [60/100], Step [5100/7382], D Loss: 1.3071, G Loss: 0.7845\n",
            "Epoch [60/100], Step [5200/7382], D Loss: 1.4156, G Loss: 0.7348\n",
            "Epoch [60/100], Step [5300/7382], D Loss: 1.3305, G Loss: 0.7729\n",
            "Epoch [60/100], Step [5400/7382], D Loss: 1.2301, G Loss: 0.8861\n",
            "Epoch [60/100], Step [5500/7382], D Loss: 1.3526, G Loss: 0.7917\n",
            "Epoch [60/100], Step [5600/7382], D Loss: 1.3179, G Loss: 0.7535\n",
            "Epoch [60/100], Step [5700/7382], D Loss: 1.3869, G Loss: 0.8234\n",
            "Epoch [60/100], Step [5800/7382], D Loss: 1.3908, G Loss: 0.7335\n",
            "Epoch [60/100], Step [5900/7382], D Loss: 1.3863, G Loss: 0.8033\n",
            "Epoch [60/100], Step [6000/7382], D Loss: 1.3288, G Loss: 0.7678\n",
            "Epoch [60/100], Step [6100/7382], D Loss: 1.3219, G Loss: 0.8296\n",
            "Epoch [60/100], Step [6200/7382], D Loss: 1.3554, G Loss: 0.7513\n",
            "Epoch [60/100], Step [6300/7382], D Loss: 1.3365, G Loss: 0.8249\n",
            "Epoch [60/100], Step [6400/7382], D Loss: 1.3533, G Loss: 0.7403\n",
            "Epoch [60/100], Step [6500/7382], D Loss: 1.3670, G Loss: 0.7804\n",
            "Epoch [60/100], Step [6600/7382], D Loss: 1.4112, G Loss: 0.7124\n",
            "Epoch [60/100], Step [6700/7382], D Loss: 1.3560, G Loss: 0.7776\n",
            "Epoch [60/100], Step [6800/7382], D Loss: 1.3704, G Loss: 0.7505\n",
            "Epoch [60/100], Step [6900/7382], D Loss: 1.3845, G Loss: 0.7175\n",
            "Epoch [60/100], Step [7000/7382], D Loss: 1.3276, G Loss: 0.7503\n",
            "Epoch [60/100], Step [7100/7382], D Loss: 1.4366, G Loss: 0.6959\n",
            "Epoch [60/100], Step [7200/7382], D Loss: 1.3552, G Loss: 0.7549\n",
            "Epoch [60/100], Step [7300/7382], D Loss: 1.3588, G Loss: 0.7203\n",
            "Epoch [61/100], Step [100/7382], D Loss: 1.3509, G Loss: 0.7557\n",
            "Epoch [61/100], Step [200/7382], D Loss: 1.3513, G Loss: 0.7530\n",
            "Epoch [61/100], Step [300/7382], D Loss: 1.3798, G Loss: 0.7463\n",
            "Epoch [61/100], Step [400/7382], D Loss: 1.3313, G Loss: 0.8093\n",
            "Epoch [61/100], Step [500/7382], D Loss: 1.3748, G Loss: 0.7371\n",
            "Epoch [61/100], Step [600/7382], D Loss: 1.3632, G Loss: 0.7345\n",
            "Epoch [61/100], Step [700/7382], D Loss: 1.3389, G Loss: 0.7784\n",
            "Epoch [61/100], Step [800/7382], D Loss: 1.3541, G Loss: 0.7645\n",
            "Epoch [61/100], Step [900/7382], D Loss: 1.3149, G Loss: 0.8001\n",
            "Epoch [61/100], Step [1000/7382], D Loss: 1.3457, G Loss: 0.7483\n",
            "Epoch [61/100], Step [1100/7382], D Loss: 1.3417, G Loss: 0.7455\n",
            "Epoch [61/100], Step [1200/7382], D Loss: 1.3382, G Loss: 0.6799\n",
            "Epoch [61/100], Step [1300/7382], D Loss: 1.3347, G Loss: 0.8019\n",
            "Epoch [61/100], Step [1400/7382], D Loss: 1.3329, G Loss: 0.7775\n",
            "Epoch [61/100], Step [1500/7382], D Loss: 1.3439, G Loss: 0.7629\n",
            "Epoch [61/100], Step [1600/7382], D Loss: 1.3140, G Loss: 0.7819\n",
            "Epoch [61/100], Step [1700/7382], D Loss: 1.3324, G Loss: 0.8340\n",
            "Epoch [61/100], Step [1800/7382], D Loss: 1.4046, G Loss: 0.7540\n",
            "Epoch [61/100], Step [1900/7382], D Loss: 1.3243, G Loss: 0.8134\n",
            "Epoch [61/100], Step [2000/7382], D Loss: 1.3039, G Loss: 0.8017\n",
            "Epoch [61/100], Step [2100/7382], D Loss: 1.3979, G Loss: 0.7815\n",
            "Epoch [61/100], Step [2200/7382], D Loss: 1.3388, G Loss: 0.7502\n",
            "Epoch [61/100], Step [2300/7382], D Loss: 1.3789, G Loss: 0.7730\n",
            "Epoch [61/100], Step [2400/7382], D Loss: 1.3194, G Loss: 0.7599\n",
            "Epoch [61/100], Step [2500/7382], D Loss: 1.4058, G Loss: 0.7240\n",
            "Epoch [61/100], Step [2600/7382], D Loss: 1.2844, G Loss: 0.7805\n",
            "Epoch [61/100], Step [2700/7382], D Loss: 1.4234, G Loss: 0.7555\n",
            "Epoch [61/100], Step [2800/7382], D Loss: 1.2928, G Loss: 0.7990\n",
            "Epoch [61/100], Step [2900/7382], D Loss: 1.3717, G Loss: 0.7421\n",
            "Epoch [61/100], Step [3000/7382], D Loss: 1.3202, G Loss: 0.8414\n",
            "Epoch [61/100], Step [3100/7382], D Loss: 1.3525, G Loss: 0.7622\n",
            "Epoch [61/100], Step [3200/7382], D Loss: 1.2713, G Loss: 0.7947\n",
            "Epoch [61/100], Step [3300/7382], D Loss: 1.3547, G Loss: 0.7648\n",
            "Epoch [61/100], Step [3400/7382], D Loss: 1.2847, G Loss: 0.7884\n",
            "Epoch [61/100], Step [3500/7382], D Loss: 1.3127, G Loss: 0.8697\n",
            "Epoch [61/100], Step [3600/7382], D Loss: 1.3364, G Loss: 0.7849\n",
            "Epoch [61/100], Step [3700/7382], D Loss: 1.3636, G Loss: 0.7513\n",
            "Epoch [61/100], Step [3800/7382], D Loss: 1.3288, G Loss: 0.7690\n",
            "Epoch [61/100], Step [3900/7382], D Loss: 1.3437, G Loss: 0.7470\n",
            "Epoch [61/100], Step [4000/7382], D Loss: 1.3485, G Loss: 0.8155\n",
            "Epoch [61/100], Step [4100/7382], D Loss: 1.2901, G Loss: 0.8213\n",
            "Epoch [61/100], Step [4200/7382], D Loss: 1.3677, G Loss: 0.7919\n",
            "Epoch [61/100], Step [4300/7382], D Loss: 1.3721, G Loss: 0.7753\n",
            "Epoch [61/100], Step [4400/7382], D Loss: 1.3664, G Loss: 0.7547\n",
            "Epoch [61/100], Step [4500/7382], D Loss: 1.3461, G Loss: 0.7549\n",
            "Epoch [61/100], Step [4600/7382], D Loss: 1.3826, G Loss: 0.8275\n",
            "Epoch [61/100], Step [4700/7382], D Loss: 1.3718, G Loss: 0.8063\n",
            "Epoch [61/100], Step [4800/7382], D Loss: 1.4036, G Loss: 0.7380\n",
            "Epoch [61/100], Step [4900/7382], D Loss: 1.3209, G Loss: 0.7688\n",
            "Epoch [61/100], Step [5000/7382], D Loss: 1.2998, G Loss: 0.8157\n",
            "Epoch [61/100], Step [5100/7382], D Loss: 1.3137, G Loss: 0.7930\n",
            "Epoch [61/100], Step [5200/7382], D Loss: 1.3256, G Loss: 0.8387\n",
            "Epoch [61/100], Step [5300/7382], D Loss: 1.3304, G Loss: 0.8133\n",
            "Epoch [61/100], Step [5400/7382], D Loss: 1.2959, G Loss: 0.8004\n",
            "Epoch [61/100], Step [5500/7382], D Loss: 1.3144, G Loss: 0.8412\n",
            "Epoch [61/100], Step [5600/7382], D Loss: 1.3018, G Loss: 0.7580\n",
            "Epoch [61/100], Step [5700/7382], D Loss: 1.3709, G Loss: 0.7664\n",
            "Epoch [61/100], Step [5800/7382], D Loss: 1.3802, G Loss: 0.7739\n",
            "Epoch [61/100], Step [5900/7382], D Loss: 1.3241, G Loss: 0.7507\n",
            "Epoch [61/100], Step [6000/7382], D Loss: 1.3725, G Loss: 0.7640\n",
            "Epoch [61/100], Step [6100/7382], D Loss: 1.3268, G Loss: 0.7731\n",
            "Epoch [61/100], Step [6200/7382], D Loss: 1.3434, G Loss: 0.7654\n",
            "Epoch [61/100], Step [6300/7382], D Loss: 1.3343, G Loss: 0.7860\n",
            "Epoch [61/100], Step [6400/7382], D Loss: 1.3377, G Loss: 0.7301\n",
            "Epoch [61/100], Step [6500/7382], D Loss: 1.3254, G Loss: 0.9150\n",
            "Epoch [61/100], Step [6600/7382], D Loss: 1.3872, G Loss: 0.7576\n",
            "Epoch [61/100], Step [6700/7382], D Loss: 1.3333, G Loss: 0.8079\n",
            "Epoch [61/100], Step [6800/7382], D Loss: 1.3715, G Loss: 0.7467\n",
            "Epoch [61/100], Step [6900/7382], D Loss: 1.3387, G Loss: 0.7459\n",
            "Epoch [61/100], Step [7000/7382], D Loss: 1.3314, G Loss: 0.8076\n",
            "Epoch [61/100], Step [7100/7382], D Loss: 1.3528, G Loss: 0.7280\n",
            "Epoch [61/100], Step [7200/7382], D Loss: 1.3064, G Loss: 0.8680\n",
            "Epoch [61/100], Step [7300/7382], D Loss: 1.3422, G Loss: 0.7345\n",
            "Epoch [62/100], Step [100/7382], D Loss: 1.3509, G Loss: 0.7405\n",
            "Epoch [62/100], Step [200/7382], D Loss: 1.3945, G Loss: 0.7318\n",
            "Epoch [62/100], Step [300/7382], D Loss: 1.3056, G Loss: 0.7835\n",
            "Epoch [62/100], Step [400/7382], D Loss: 1.3899, G Loss: 0.6922\n",
            "Epoch [62/100], Step [500/7382], D Loss: 1.3389, G Loss: 0.7773\n",
            "Epoch [62/100], Step [600/7382], D Loss: 1.3223, G Loss: 0.7693\n",
            "Epoch [62/100], Step [700/7382], D Loss: 1.3496, G Loss: 0.8191\n",
            "Epoch [62/100], Step [800/7382], D Loss: 1.4057, G Loss: 0.7168\n",
            "Epoch [62/100], Step [900/7382], D Loss: 1.3597, G Loss: 0.7648\n",
            "Epoch [62/100], Step [1000/7382], D Loss: 1.3790, G Loss: 0.7335\n",
            "Epoch [62/100], Step [1100/7382], D Loss: 1.3643, G Loss: 0.7448\n",
            "Epoch [62/100], Step [1200/7382], D Loss: 1.3651, G Loss: 0.8328\n",
            "Epoch [62/100], Step [1300/7382], D Loss: 1.3363, G Loss: 0.7629\n",
            "Epoch [62/100], Step [1400/7382], D Loss: 1.3125, G Loss: 0.7676\n",
            "Epoch [62/100], Step [1500/7382], D Loss: 1.2958, G Loss: 0.8078\n",
            "Epoch [62/100], Step [1600/7382], D Loss: 1.3483, G Loss: 0.7382\n",
            "Epoch [62/100], Step [1700/7382], D Loss: 1.3468, G Loss: 0.7592\n",
            "Epoch [62/100], Step [1800/7382], D Loss: 1.3979, G Loss: 0.7529\n",
            "Epoch [62/100], Step [1900/7382], D Loss: 1.3513, G Loss: 0.7193\n",
            "Epoch [62/100], Step [2000/7382], D Loss: 1.3627, G Loss: 0.7255\n",
            "Epoch [62/100], Step [2100/7382], D Loss: 1.3583, G Loss: 0.7487\n",
            "Epoch [62/100], Step [2200/7382], D Loss: 1.3613, G Loss: 0.7142\n",
            "Epoch [62/100], Step [2300/7382], D Loss: 1.3653, G Loss: 0.8002\n",
            "Epoch [62/100], Step [2400/7382], D Loss: 1.4100, G Loss: 0.7296\n",
            "Epoch [62/100], Step [2500/7382], D Loss: 1.3947, G Loss: 0.7277\n",
            "Epoch [62/100], Step [2600/7382], D Loss: 1.3414, G Loss: 0.7733\n",
            "Epoch [62/100], Step [2700/7382], D Loss: 1.3213, G Loss: 0.7679\n",
            "Epoch [62/100], Step [2800/7382], D Loss: 1.3258, G Loss: 0.7462\n",
            "Epoch [62/100], Step [2900/7382], D Loss: 1.3050, G Loss: 0.8893\n",
            "Epoch [62/100], Step [3000/7382], D Loss: 1.3284, G Loss: 0.7599\n",
            "Epoch [62/100], Step [3100/7382], D Loss: 1.3700, G Loss: 0.8052\n",
            "Epoch [62/100], Step [3200/7382], D Loss: 1.2724, G Loss: 0.7831\n",
            "Epoch [62/100], Step [3300/7382], D Loss: 1.3075, G Loss: 0.7786\n",
            "Epoch [62/100], Step [3400/7382], D Loss: 1.3382, G Loss: 0.7603\n",
            "Epoch [62/100], Step [3500/7382], D Loss: 1.3937, G Loss: 0.7571\n",
            "Epoch [62/100], Step [3600/7382], D Loss: 1.3642, G Loss: 0.7644\n",
            "Epoch [62/100], Step [3700/7382], D Loss: 1.3259, G Loss: 0.7565\n",
            "Epoch [62/100], Step [3800/7382], D Loss: 1.2997, G Loss: 0.7754\n",
            "Epoch [62/100], Step [3900/7382], D Loss: 1.4481, G Loss: 0.7204\n",
            "Epoch [62/100], Step [4000/7382], D Loss: 1.2928, G Loss: 0.8045\n",
            "Epoch [62/100], Step [4100/7382], D Loss: 1.3404, G Loss: 0.7298\n",
            "Epoch [62/100], Step [4200/7382], D Loss: 1.3192, G Loss: 0.7309\n",
            "Epoch [62/100], Step [4300/7382], D Loss: 1.3884, G Loss: 0.6887\n",
            "Epoch [62/100], Step [4400/7382], D Loss: 1.3274, G Loss: 0.8379\n",
            "Epoch [62/100], Step [4500/7382], D Loss: 1.3383, G Loss: 0.7436\n",
            "Epoch [62/100], Step [4600/7382], D Loss: 1.3596, G Loss: 0.7939\n",
            "Epoch [62/100], Step [4700/7382], D Loss: 1.3177, G Loss: 0.8006\n",
            "Epoch [62/100], Step [4800/7382], D Loss: 1.3519, G Loss: 0.7384\n",
            "Epoch [62/100], Step [4900/7382], D Loss: 1.3128, G Loss: 0.8868\n",
            "Epoch [62/100], Step [5000/7382], D Loss: 1.3170, G Loss: 0.7597\n",
            "Epoch [62/100], Step [5100/7382], D Loss: 1.3300, G Loss: 0.7824\n",
            "Epoch [62/100], Step [5200/7382], D Loss: 1.3771, G Loss: 0.7823\n",
            "Epoch [62/100], Step [5300/7382], D Loss: 1.3444, G Loss: 0.7356\n",
            "Epoch [62/100], Step [5400/7382], D Loss: 1.3499, G Loss: 0.7460\n",
            "Epoch [62/100], Step [5500/7382], D Loss: 1.3023, G Loss: 0.8026\n",
            "Epoch [62/100], Step [5600/7382], D Loss: 1.3123, G Loss: 0.8099\n",
            "Epoch [62/100], Step [5700/7382], D Loss: 1.3907, G Loss: 0.6957\n",
            "Epoch [62/100], Step [5800/7382], D Loss: 1.3684, G Loss: 0.7482\n",
            "Epoch [62/100], Step [5900/7382], D Loss: 1.3361, G Loss: 0.8134\n",
            "Epoch [62/100], Step [6000/7382], D Loss: 1.3302, G Loss: 0.7488\n",
            "Epoch [62/100], Step [6100/7382], D Loss: 1.3157, G Loss: 0.7712\n",
            "Epoch [62/100], Step [6200/7382], D Loss: 1.3426, G Loss: 0.7465\n",
            "Epoch [62/100], Step [6300/7382], D Loss: 1.3283, G Loss: 0.7670\n",
            "Epoch [62/100], Step [6400/7382], D Loss: 1.3727, G Loss: 0.7279\n",
            "Epoch [62/100], Step [6500/7382], D Loss: 1.3499, G Loss: 0.7201\n",
            "Epoch [62/100], Step [6600/7382], D Loss: 1.3851, G Loss: 0.7477\n",
            "Epoch [62/100], Step [6700/7382], D Loss: 1.3443, G Loss: 0.7973\n",
            "Epoch [62/100], Step [6800/7382], D Loss: 1.3290, G Loss: 0.7971\n",
            "Epoch [62/100], Step [6900/7382], D Loss: 1.3660, G Loss: 0.7321\n",
            "Epoch [62/100], Step [7000/7382], D Loss: 1.3712, G Loss: 0.7507\n",
            "Epoch [62/100], Step [7100/7382], D Loss: 1.3861, G Loss: 0.7301\n",
            "Epoch [62/100], Step [7200/7382], D Loss: 1.4310, G Loss: 0.7229\n",
            "Epoch [62/100], Step [7300/7382], D Loss: 1.3116, G Loss: 0.7631\n",
            "Epoch [63/100], Step [100/7382], D Loss: 1.3745, G Loss: 0.7405\n",
            "Epoch [63/100], Step [200/7382], D Loss: 1.3453, G Loss: 0.7874\n",
            "Epoch [63/100], Step [300/7382], D Loss: 1.3811, G Loss: 0.7187\n",
            "Epoch [63/100], Step [400/7382], D Loss: 1.4373, G Loss: 0.7922\n",
            "Epoch [63/100], Step [500/7382], D Loss: 1.3625, G Loss: 0.7221\n",
            "Epoch [63/100], Step [600/7382], D Loss: 1.3759, G Loss: 0.7392\n",
            "Epoch [63/100], Step [700/7382], D Loss: 1.3678, G Loss: 0.7416\n",
            "Epoch [63/100], Step [800/7382], D Loss: 1.2892, G Loss: 0.9020\n",
            "Epoch [63/100], Step [900/7382], D Loss: 1.3596, G Loss: 0.7628\n",
            "Epoch [63/100], Step [1000/7382], D Loss: 1.2785, G Loss: 0.7995\n",
            "Epoch [63/100], Step [1100/7382], D Loss: 1.3509, G Loss: 0.7429\n",
            "Epoch [63/100], Step [1200/7382], D Loss: 1.3594, G Loss: 0.7328\n",
            "Epoch [63/100], Step [1300/7382], D Loss: 1.3070, G Loss: 0.8025\n",
            "Epoch [63/100], Step [1400/7382], D Loss: 1.2945, G Loss: 0.8191\n",
            "Epoch [63/100], Step [1500/7382], D Loss: 1.3727, G Loss: 0.7451\n",
            "Epoch [63/100], Step [1600/7382], D Loss: 1.3393, G Loss: 0.7732\n",
            "Epoch [63/100], Step [1700/7382], D Loss: 1.3607, G Loss: 0.7703\n",
            "Epoch [63/100], Step [1800/7382], D Loss: 1.3826, G Loss: 0.7299\n",
            "Epoch [63/100], Step [1900/7382], D Loss: 1.3160, G Loss: 0.8244\n",
            "Epoch [63/100], Step [2000/7382], D Loss: 1.4123, G Loss: 0.7285\n",
            "Epoch [63/100], Step [2100/7382], D Loss: 1.3658, G Loss: 0.7569\n",
            "Epoch [63/100], Step [2200/7382], D Loss: 1.3525, G Loss: 0.8021\n",
            "Epoch [63/100], Step [2300/7382], D Loss: 1.3255, G Loss: 0.7939\n",
            "Epoch [63/100], Step [2400/7382], D Loss: 1.3286, G Loss: 0.8118\n",
            "Epoch [63/100], Step [2500/7382], D Loss: 1.3807, G Loss: 0.7915\n",
            "Epoch [63/100], Step [2600/7382], D Loss: 1.3773, G Loss: 0.8018\n",
            "Epoch [63/100], Step [2700/7382], D Loss: 1.3725, G Loss: 0.7808\n",
            "Epoch [63/100], Step [2800/7382], D Loss: 1.3740, G Loss: 0.7557\n",
            "Epoch [63/100], Step [2900/7382], D Loss: 1.3529, G Loss: 0.7985\n",
            "Epoch [63/100], Step [3000/7382], D Loss: 1.3278, G Loss: 0.8078\n",
            "Epoch [63/100], Step [3100/7382], D Loss: 1.3531, G Loss: 0.7528\n",
            "Epoch [63/100], Step [3200/7382], D Loss: 1.3061, G Loss: 0.7763\n",
            "Epoch [63/100], Step [3300/7382], D Loss: 1.3243, G Loss: 0.7776\n",
            "Epoch [63/100], Step [3400/7382], D Loss: 1.2793, G Loss: 0.7986\n",
            "Epoch [63/100], Step [3500/7382], D Loss: 1.2776, G Loss: 0.8340\n",
            "Epoch [63/100], Step [3600/7382], D Loss: 1.2361, G Loss: 0.9318\n",
            "Epoch [63/100], Step [3700/7382], D Loss: 1.2851, G Loss: 0.8241\n",
            "Epoch [63/100], Step [3800/7382], D Loss: 1.3344, G Loss: 0.8187\n",
            "Epoch [63/100], Step [3900/7382], D Loss: 1.3176, G Loss: 0.8383\n",
            "Epoch [63/100], Step [4000/7382], D Loss: 1.3141, G Loss: 0.7957\n",
            "Epoch [63/100], Step [4100/7382], D Loss: 1.3556, G Loss: 0.8032\n",
            "Epoch [63/100], Step [4200/7382], D Loss: 1.3111, G Loss: 0.8633\n",
            "Epoch [63/100], Step [4300/7382], D Loss: 1.3742, G Loss: 0.7875\n",
            "Epoch [63/100], Step [4400/7382], D Loss: 1.3244, G Loss: 0.7922\n",
            "Epoch [63/100], Step [4500/7382], D Loss: 1.3168, G Loss: 0.7677\n",
            "Epoch [63/100], Step [4600/7382], D Loss: 1.3354, G Loss: 0.8236\n",
            "Epoch [63/100], Step [4700/7382], D Loss: 1.2598, G Loss: 0.8739\n",
            "Epoch [63/100], Step [4800/7382], D Loss: 1.2509, G Loss: 0.8828\n",
            "Epoch [63/100], Step [4900/7382], D Loss: 1.2618, G Loss: 0.8968\n",
            "Epoch [63/100], Step [5000/7382], D Loss: 1.2783, G Loss: 0.9705\n",
            "Epoch [63/100], Step [5100/7382], D Loss: 1.3830, G Loss: 0.7893\n",
            "Epoch [63/100], Step [5200/7382], D Loss: 1.3590, G Loss: 0.8204\n",
            "Epoch [63/100], Step [5300/7382], D Loss: 1.3869, G Loss: 0.7003\n",
            "Epoch [63/100], Step [5400/7382], D Loss: 1.4385, G Loss: 0.8689\n",
            "Epoch [63/100], Step [5500/7382], D Loss: 1.1581, G Loss: 0.9253\n",
            "Epoch [63/100], Step [5600/7382], D Loss: 1.2803, G Loss: 0.8619\n",
            "Epoch [63/100], Step [5700/7382], D Loss: 1.2502, G Loss: 0.9440\n",
            "Epoch [63/100], Step [5800/7382], D Loss: 1.2636, G Loss: 0.9249\n",
            "Epoch [63/100], Step [5900/7382], D Loss: 1.2634, G Loss: 0.8465\n",
            "Epoch [63/100], Step [6000/7382], D Loss: 1.2169, G Loss: 0.9030\n",
            "Epoch [63/100], Step [6100/7382], D Loss: 1.3332, G Loss: 0.8034\n",
            "Epoch [63/100], Step [6200/7382], D Loss: 1.2699, G Loss: 0.8618\n",
            "Epoch [63/100], Step [6300/7382], D Loss: 1.2729, G Loss: 0.8682\n",
            "Epoch [63/100], Step [6400/7382], D Loss: 1.2488, G Loss: 0.9008\n",
            "Epoch [63/100], Step [6500/7382], D Loss: 1.3280, G Loss: 0.8976\n",
            "Epoch [63/100], Step [6600/7382], D Loss: 1.2405, G Loss: 0.8793\n",
            "Epoch [63/100], Step [6700/7382], D Loss: 1.3096, G Loss: 0.7583\n",
            "Epoch [63/100], Step [6800/7382], D Loss: 1.2942, G Loss: 0.8853\n",
            "Epoch [63/100], Step [6900/7382], D Loss: 1.2161, G Loss: 0.8926\n",
            "Epoch [63/100], Step [7000/7382], D Loss: 1.2672, G Loss: 0.8999\n",
            "Epoch [63/100], Step [7100/7382], D Loss: 1.3906, G Loss: 0.8578\n",
            "Epoch [63/100], Step [7200/7382], D Loss: 1.2239, G Loss: 0.9037\n",
            "Epoch [63/100], Step [7300/7382], D Loss: 1.3359, G Loss: 0.7620\n",
            "Epoch [64/100], Step [100/7382], D Loss: 1.3218, G Loss: 0.8791\n",
            "Epoch [64/100], Step [200/7382], D Loss: 1.3170, G Loss: 0.8776\n",
            "Epoch [64/100], Step [300/7382], D Loss: 1.3219, G Loss: 0.8161\n",
            "Epoch [64/100], Step [400/7382], D Loss: 1.3418, G Loss: 0.8504\n",
            "Epoch [64/100], Step [500/7382], D Loss: 1.3152, G Loss: 0.7545\n",
            "Epoch [64/100], Step [600/7382], D Loss: 1.3148, G Loss: 0.8004\n",
            "Epoch [64/100], Step [700/7382], D Loss: 1.2420, G Loss: 0.8213\n",
            "Epoch [64/100], Step [800/7382], D Loss: 1.3147, G Loss: 0.8098\n",
            "Epoch [64/100], Step [900/7382], D Loss: 1.3695, G Loss: 0.7962\n",
            "Epoch [64/100], Step [1000/7382], D Loss: 1.3173, G Loss: 0.8033\n",
            "Epoch [64/100], Step [1100/7382], D Loss: 1.3098, G Loss: 0.8120\n",
            "Epoch [64/100], Step [1200/7382], D Loss: 1.2810, G Loss: 0.8766\n",
            "Epoch [64/100], Step [1300/7382], D Loss: 1.3229, G Loss: 0.7732\n",
            "Epoch [64/100], Step [1400/7382], D Loss: 1.3030, G Loss: 0.8043\n",
            "Epoch [64/100], Step [1500/7382], D Loss: 1.3329, G Loss: 0.7652\n",
            "Epoch [64/100], Step [1600/7382], D Loss: 1.3749, G Loss: 0.7231\n",
            "Epoch [64/100], Step [1700/7382], D Loss: 1.3584, G Loss: 0.7703\n",
            "Epoch [64/100], Step [1800/7382], D Loss: 1.3186, G Loss: 0.8433\n",
            "Epoch [64/100], Step [1900/7382], D Loss: 1.3142, G Loss: 0.7754\n",
            "Epoch [64/100], Step [2000/7382], D Loss: 1.3057, G Loss: 0.7555\n",
            "Epoch [64/100], Step [2100/7382], D Loss: 1.3184, G Loss: 0.8087\n",
            "Epoch [64/100], Step [2200/7382], D Loss: 1.3140, G Loss: 0.8085\n",
            "Epoch [64/100], Step [2300/7382], D Loss: 1.2603, G Loss: 0.9231\n",
            "Epoch [64/100], Step [2400/7382], D Loss: 1.2871, G Loss: 0.8863\n",
            "Epoch [64/100], Step [2500/7382], D Loss: 1.2922, G Loss: 0.8232\n",
            "Epoch [64/100], Step [2600/7382], D Loss: 1.3679, G Loss: 0.7735\n",
            "Epoch [64/100], Step [2700/7382], D Loss: 1.2941, G Loss: 0.8970\n",
            "Epoch [64/100], Step [2800/7382], D Loss: 1.3275, G Loss: 0.8176\n",
            "Epoch [64/100], Step [2900/7382], D Loss: 1.2352, G Loss: 0.8480\n",
            "Epoch [64/100], Step [3000/7382], D Loss: 1.3890, G Loss: 0.7320\n",
            "Epoch [64/100], Step [3100/7382], D Loss: 1.3868, G Loss: 0.8047\n",
            "Epoch [64/100], Step [3200/7382], D Loss: 1.3178, G Loss: 0.8023\n",
            "Epoch [64/100], Step [3300/7382], D Loss: 1.3263, G Loss: 0.8345\n",
            "Epoch [64/100], Step [3400/7382], D Loss: 1.3010, G Loss: 0.8106\n",
            "Epoch [64/100], Step [3500/7382], D Loss: 1.3896, G Loss: 0.7681\n",
            "Epoch [64/100], Step [3600/7382], D Loss: 1.4200, G Loss: 0.8020\n",
            "Epoch [64/100], Step [3700/7382], D Loss: 1.3659, G Loss: 0.7394\n",
            "Epoch [64/100], Step [3800/7382], D Loss: 1.3464, G Loss: 0.7616\n",
            "Epoch [64/100], Step [3900/7382], D Loss: 1.3110, G Loss: 0.7957\n",
            "Epoch [64/100], Step [4000/7382], D Loss: 1.3666, G Loss: 0.7643\n",
            "Epoch [64/100], Step [4100/7382], D Loss: 1.3483, G Loss: 0.8316\n",
            "Epoch [64/100], Step [4200/7382], D Loss: 1.3287, G Loss: 0.8070\n",
            "Epoch [64/100], Step [4300/7382], D Loss: 1.3314, G Loss: 0.7215\n",
            "Epoch [64/100], Step [4400/7382], D Loss: 1.3307, G Loss: 0.7626\n",
            "Epoch [64/100], Step [4500/7382], D Loss: 1.3083, G Loss: 0.7755\n",
            "Epoch [64/100], Step [4600/7382], D Loss: 1.3930, G Loss: 0.7332\n",
            "Epoch [64/100], Step [4700/7382], D Loss: 1.2227, G Loss: 0.9797\n",
            "Epoch [64/100], Step [4800/7382], D Loss: 1.4060, G Loss: 0.6941\n",
            "Epoch [64/100], Step [4900/7382], D Loss: 1.2972, G Loss: 0.8969\n",
            "Epoch [64/100], Step [5000/7382], D Loss: 1.4038, G Loss: 0.7235\n",
            "Epoch [64/100], Step [5100/7382], D Loss: 1.3376, G Loss: 0.7652\n",
            "Epoch [64/100], Step [5200/7382], D Loss: 1.4161, G Loss: 0.7568\n",
            "Epoch [64/100], Step [5300/7382], D Loss: 1.4264, G Loss: 0.7911\n",
            "Epoch [64/100], Step [5400/7382], D Loss: 1.3522, G Loss: 0.8436\n",
            "Epoch [64/100], Step [5500/7382], D Loss: 1.3921, G Loss: 0.7252\n",
            "Epoch [64/100], Step [5600/7382], D Loss: 1.3695, G Loss: 0.7976\n",
            "Epoch [64/100], Step [5700/7382], D Loss: 1.3603, G Loss: 0.7810\n",
            "Epoch [64/100], Step [5800/7382], D Loss: 1.3462, G Loss: 0.7971\n",
            "Epoch [64/100], Step [5900/7382], D Loss: 1.3255, G Loss: 0.8116\n",
            "Epoch [64/100], Step [6000/7382], D Loss: 1.3401, G Loss: 0.7933\n",
            "Epoch [64/100], Step [6100/7382], D Loss: 1.2749, G Loss: 0.8009\n",
            "Epoch [64/100], Step [6200/7382], D Loss: 1.3167, G Loss: 0.8270\n",
            "Epoch [64/100], Step [6300/7382], D Loss: 1.3886, G Loss: 0.8083\n",
            "Epoch [64/100], Step [6400/7382], D Loss: 1.3184, G Loss: 0.8277\n",
            "Epoch [64/100], Step [6500/7382], D Loss: 1.3043, G Loss: 0.7840\n",
            "Epoch [64/100], Step [6600/7382], D Loss: 1.3545, G Loss: 0.7418\n",
            "Epoch [64/100], Step [6700/7382], D Loss: 1.3062, G Loss: 0.7975\n",
            "Epoch [64/100], Step [6800/7382], D Loss: 1.2845, G Loss: 0.8581\n",
            "Epoch [64/100], Step [6900/7382], D Loss: 1.3533, G Loss: 0.7710\n",
            "Epoch [64/100], Step [7000/7382], D Loss: 1.3393, G Loss: 0.7524\n",
            "Epoch [64/100], Step [7100/7382], D Loss: 1.3326, G Loss: 0.7689\n",
            "Epoch [64/100], Step [7200/7382], D Loss: 1.3534, G Loss: 0.8480\n",
            "Epoch [64/100], Step [7300/7382], D Loss: 1.2575, G Loss: 0.8277\n",
            "Epoch [65/100], Step [100/7382], D Loss: 1.3654, G Loss: 0.7715\n",
            "Epoch [65/100], Step [200/7382], D Loss: 1.3104, G Loss: 0.8598\n",
            "Epoch [65/100], Step [300/7382], D Loss: 1.3363, G Loss: 0.7506\n",
            "Epoch [65/100], Step [400/7382], D Loss: 1.4693, G Loss: 0.7845\n",
            "Epoch [65/100], Step [500/7382], D Loss: 1.2282, G Loss: 0.9397\n",
            "Epoch [65/100], Step [600/7382], D Loss: 1.3693, G Loss: 0.8764\n",
            "Epoch [65/100], Step [700/7382], D Loss: 1.3352, G Loss: 0.7756\n",
            "Epoch [65/100], Step [800/7382], D Loss: 1.3566, G Loss: 0.7924\n",
            "Epoch [65/100], Step [900/7382], D Loss: 1.3323, G Loss: 0.8264\n",
            "Epoch [65/100], Step [1000/7382], D Loss: 1.3125, G Loss: 0.7740\n",
            "Epoch [65/100], Step [1100/7382], D Loss: 1.3263, G Loss: 0.7615\n",
            "Epoch [65/100], Step [1200/7382], D Loss: 1.3016, G Loss: 0.8667\n",
            "Epoch [65/100], Step [1300/7382], D Loss: 1.2947, G Loss: 0.8311\n",
            "Epoch [65/100], Step [1400/7382], D Loss: 1.3208, G Loss: 0.7917\n",
            "Epoch [65/100], Step [1500/7382], D Loss: 1.2887, G Loss: 0.8742\n",
            "Epoch [65/100], Step [1600/7382], D Loss: 1.2648, G Loss: 0.8947\n",
            "Epoch [65/100], Step [1700/7382], D Loss: 1.3049, G Loss: 0.8287\n",
            "Epoch [65/100], Step [1800/7382], D Loss: 1.3670, G Loss: 0.7152\n",
            "Epoch [65/100], Step [1900/7382], D Loss: 1.2795, G Loss: 0.7984\n",
            "Epoch [65/100], Step [2000/7382], D Loss: 1.3416, G Loss: 0.7562\n",
            "Epoch [65/100], Step [2100/7382], D Loss: 1.2696, G Loss: 0.8746\n",
            "Epoch [65/100], Step [2200/7382], D Loss: 1.3434, G Loss: 0.7589\n",
            "Epoch [65/100], Step [2300/7382], D Loss: 1.2801, G Loss: 0.8008\n",
            "Epoch [65/100], Step [2400/7382], D Loss: 1.3259, G Loss: 0.7669\n",
            "Epoch [65/100], Step [2500/7382], D Loss: 1.2805, G Loss: 0.7948\n",
            "Epoch [65/100], Step [2600/7382], D Loss: 1.3738, G Loss: 0.7237\n",
            "Epoch [65/100], Step [2700/7382], D Loss: 1.3520, G Loss: 0.7930\n",
            "Epoch [65/100], Step [2800/7382], D Loss: 1.3644, G Loss: 0.7566\n",
            "Epoch [65/100], Step [2900/7382], D Loss: 1.3001, G Loss: 0.9146\n",
            "Epoch [65/100], Step [3000/7382], D Loss: 1.4021, G Loss: 0.7524\n",
            "Epoch [65/100], Step [3100/7382], D Loss: 1.3523, G Loss: 0.7586\n",
            "Epoch [65/100], Step [3200/7382], D Loss: 1.2917, G Loss: 0.8073\n",
            "Epoch [65/100], Step [3300/7382], D Loss: 1.3387, G Loss: 0.7876\n",
            "Epoch [65/100], Step [3400/7382], D Loss: 1.3429, G Loss: 0.7305\n",
            "Epoch [65/100], Step [3500/7382], D Loss: 1.2977, G Loss: 0.8401\n",
            "Epoch [65/100], Step [3600/7382], D Loss: 1.3596, G Loss: 0.7547\n",
            "Epoch [65/100], Step [3700/7382], D Loss: 1.3039, G Loss: 0.7952\n",
            "Epoch [65/100], Step [3800/7382], D Loss: 1.2795, G Loss: 0.7818\n",
            "Epoch [65/100], Step [3900/7382], D Loss: 1.3565, G Loss: 0.7456\n",
            "Epoch [65/100], Step [4000/7382], D Loss: 1.3114, G Loss: 0.8542\n",
            "Epoch [65/100], Step [4100/7382], D Loss: 1.3051, G Loss: 0.7707\n",
            "Epoch [65/100], Step [4200/7382], D Loss: 1.2699, G Loss: 0.8144\n",
            "Epoch [65/100], Step [4300/7382], D Loss: 1.3986, G Loss: 0.7540\n",
            "Epoch [65/100], Step [4400/7382], D Loss: 1.4190, G Loss: 0.7560\n",
            "Epoch [65/100], Step [4500/7382], D Loss: 1.3092, G Loss: 0.7989\n",
            "Epoch [65/100], Step [4600/7382], D Loss: 1.2774, G Loss: 0.8868\n",
            "Epoch [65/100], Step [4700/7382], D Loss: 1.3569, G Loss: 0.7348\n",
            "Epoch [65/100], Step [4800/7382], D Loss: 1.3334, G Loss: 0.8564\n",
            "Epoch [65/100], Step [4900/7382], D Loss: 1.3421, G Loss: 0.8124\n",
            "Epoch [65/100], Step [5000/7382], D Loss: 1.3411, G Loss: 0.8438\n",
            "Epoch [65/100], Step [5100/7382], D Loss: 1.3818, G Loss: 0.7598\n",
            "Epoch [65/100], Step [5200/7382], D Loss: 1.2737, G Loss: 0.8039\n",
            "Epoch [65/100], Step [5300/7382], D Loss: 1.3620, G Loss: 0.7266\n",
            "Epoch [65/100], Step [5400/7382], D Loss: 1.3529, G Loss: 0.8364\n",
            "Epoch [65/100], Step [5500/7382], D Loss: 1.2911, G Loss: 0.8499\n",
            "Epoch [65/100], Step [5600/7382], D Loss: 1.3700, G Loss: 0.7599\n",
            "Epoch [65/100], Step [5700/7382], D Loss: 1.3237, G Loss: 0.7975\n",
            "Epoch [65/100], Step [5800/7382], D Loss: 1.3186, G Loss: 0.7386\n",
            "Epoch [65/100], Step [5900/7382], D Loss: 1.2899, G Loss: 0.8261\n",
            "Epoch [65/100], Step [6000/7382], D Loss: 1.3163, G Loss: 0.7385\n",
            "Epoch [65/100], Step [6100/7382], D Loss: 1.3028, G Loss: 0.8307\n",
            "Epoch [65/100], Step [6200/7382], D Loss: 1.3861, G Loss: 0.7520\n",
            "Epoch [65/100], Step [6300/7382], D Loss: 1.4108, G Loss: 0.7613\n",
            "Epoch [65/100], Step [6400/7382], D Loss: 1.3395, G Loss: 0.8160\n",
            "Epoch [65/100], Step [6500/7382], D Loss: 1.3034, G Loss: 0.8184\n",
            "Epoch [65/100], Step [6600/7382], D Loss: 1.3311, G Loss: 0.8619\n",
            "Epoch [65/100], Step [6700/7382], D Loss: 1.3242, G Loss: 0.8266\n",
            "Epoch [65/100], Step [6800/7382], D Loss: 1.3782, G Loss: 0.7261\n",
            "Epoch [65/100], Step [6900/7382], D Loss: 1.2980, G Loss: 0.8081\n",
            "Epoch [65/100], Step [7000/7382], D Loss: 1.3242, G Loss: 0.8345\n",
            "Epoch [65/100], Step [7100/7382], D Loss: 1.3592, G Loss: 0.7639\n",
            "Epoch [65/100], Step [7200/7382], D Loss: 1.3962, G Loss: 0.7517\n",
            "Epoch [65/100], Step [7300/7382], D Loss: 1.3263, G Loss: 0.7599\n",
            "Epoch [66/100], Step [100/7382], D Loss: 1.3969, G Loss: 0.7745\n",
            "Epoch [66/100], Step [200/7382], D Loss: 1.2963, G Loss: 0.8445\n",
            "Epoch [66/100], Step [300/7382], D Loss: 1.3464, G Loss: 0.7767\n",
            "Epoch [66/100], Step [400/7382], D Loss: 1.2789, G Loss: 0.8052\n",
            "Epoch [66/100], Step [500/7382], D Loss: 1.2458, G Loss: 0.7965\n",
            "Epoch [66/100], Step [600/7382], D Loss: 1.2527, G Loss: 0.8917\n",
            "Epoch [66/100], Step [700/7382], D Loss: 1.3393, G Loss: 0.8730\n",
            "Epoch [66/100], Step [800/7382], D Loss: 1.3457, G Loss: 0.7933\n",
            "Epoch [66/100], Step [900/7382], D Loss: 1.3818, G Loss: 0.7625\n",
            "Epoch [66/100], Step [1000/7382], D Loss: 1.3201, G Loss: 0.8403\n",
            "Epoch [66/100], Step [1100/7382], D Loss: 1.2862, G Loss: 0.8377\n",
            "Epoch [66/100], Step [1200/7382], D Loss: 1.3193, G Loss: 0.7686\n",
            "Epoch [66/100], Step [1300/7382], D Loss: 1.2551, G Loss: 0.8101\n",
            "Epoch [66/100], Step [1400/7382], D Loss: 1.4021, G Loss: 0.7704\n",
            "Epoch [66/100], Step [1500/7382], D Loss: 1.3830, G Loss: 0.7399\n",
            "Epoch [66/100], Step [1600/7382], D Loss: 1.2999, G Loss: 0.8196\n",
            "Epoch [66/100], Step [1700/7382], D Loss: 1.3810, G Loss: 0.7399\n",
            "Epoch [66/100], Step [1800/7382], D Loss: 1.3180, G Loss: 0.8701\n",
            "Epoch [66/100], Step [1900/7382], D Loss: 1.2958, G Loss: 0.8296\n",
            "Epoch [66/100], Step [2000/7382], D Loss: 1.3931, G Loss: 0.7411\n",
            "Epoch [66/100], Step [2100/7382], D Loss: 1.3711, G Loss: 0.7565\n",
            "Epoch [66/100], Step [2200/7382], D Loss: 1.3401, G Loss: 0.7503\n",
            "Epoch [66/100], Step [2300/7382], D Loss: 1.3927, G Loss: 0.7612\n",
            "Epoch [66/100], Step [2400/7382], D Loss: 1.3037, G Loss: 0.7926\n",
            "Epoch [66/100], Step [2500/7382], D Loss: 1.3426, G Loss: 0.7638\n",
            "Epoch [66/100], Step [2600/7382], D Loss: 1.3334, G Loss: 0.7649\n",
            "Epoch [66/100], Step [2700/7382], D Loss: 1.3495, G Loss: 0.7253\n",
            "Epoch [66/100], Step [2800/7382], D Loss: 1.2684, G Loss: 0.7905\n",
            "Epoch [66/100], Step [2900/7382], D Loss: 1.2930, G Loss: 0.7975\n",
            "Epoch [66/100], Step [3000/7382], D Loss: 1.3871, G Loss: 0.8500\n",
            "Epoch [66/100], Step [3100/7382], D Loss: 1.3515, G Loss: 0.9277\n",
            "Epoch [66/100], Step [3200/7382], D Loss: 1.2166, G Loss: 0.9812\n",
            "Epoch [66/100], Step [3300/7382], D Loss: 1.3548, G Loss: 0.8400\n",
            "Epoch [66/100], Step [3400/7382], D Loss: 1.3028, G Loss: 0.8034\n",
            "Epoch [66/100], Step [3500/7382], D Loss: 1.3069, G Loss: 0.8225\n",
            "Epoch [66/100], Step [3600/7382], D Loss: 1.3024, G Loss: 0.8233\n",
            "Epoch [66/100], Step [3700/7382], D Loss: 1.2931, G Loss: 0.8720\n",
            "Epoch [66/100], Step [3800/7382], D Loss: 1.2689, G Loss: 0.8096\n",
            "Epoch [66/100], Step [3900/7382], D Loss: 1.2460, G Loss: 0.8429\n",
            "Epoch [66/100], Step [4000/7382], D Loss: 1.2596, G Loss: 0.8731\n",
            "Epoch [66/100], Step [4100/7382], D Loss: 1.3397, G Loss: 0.8055\n",
            "Epoch [66/100], Step [4200/7382], D Loss: 1.3371, G Loss: 0.8245\n",
            "Epoch [66/100], Step [4300/7382], D Loss: 1.3134, G Loss: 0.8275\n",
            "Epoch [66/100], Step [4400/7382], D Loss: 1.2974, G Loss: 0.7847\n",
            "Epoch [66/100], Step [4500/7382], D Loss: 1.3805, G Loss: 0.7464\n",
            "Epoch [66/100], Step [4600/7382], D Loss: 1.3682, G Loss: 0.7751\n",
            "Epoch [66/100], Step [4700/7382], D Loss: 1.3625, G Loss: 0.7230\n",
            "Epoch [66/100], Step [4800/7382], D Loss: 1.3365, G Loss: 0.7622\n",
            "Epoch [66/100], Step [4900/7382], D Loss: 1.3016, G Loss: 0.8615\n",
            "Epoch [66/100], Step [5000/7382], D Loss: 1.2770, G Loss: 0.8942\n",
            "Epoch [66/100], Step [5100/7382], D Loss: 1.3070, G Loss: 0.8118\n",
            "Epoch [66/100], Step [5200/7382], D Loss: 1.3005, G Loss: 0.8027\n",
            "Epoch [66/100], Step [5300/7382], D Loss: 1.2508, G Loss: 0.8548\n",
            "Epoch [66/100], Step [5400/7382], D Loss: 1.2887, G Loss: 0.8509\n",
            "Epoch [66/100], Step [5500/7382], D Loss: 1.4146, G Loss: 0.7833\n",
            "Epoch [66/100], Step [5600/7382], D Loss: 1.3164, G Loss: 0.8628\n",
            "Epoch [66/100], Step [5700/7382], D Loss: 1.3486, G Loss: 0.7826\n",
            "Epoch [66/100], Step [5800/7382], D Loss: 1.3568, G Loss: 0.7862\n",
            "Epoch [66/100], Step [5900/7382], D Loss: 1.3215, G Loss: 0.8627\n",
            "Epoch [66/100], Step [6000/7382], D Loss: 1.2832, G Loss: 0.8657\n",
            "Epoch [66/100], Step [6100/7382], D Loss: 1.4409, G Loss: 0.8551\n",
            "Epoch [66/100], Step [6200/7382], D Loss: 1.2915, G Loss: 0.9271\n",
            "Epoch [66/100], Step [6300/7382], D Loss: 1.3178, G Loss: 0.7840\n",
            "Epoch [66/100], Step [6400/7382], D Loss: 1.3550, G Loss: 0.7977\n",
            "Epoch [66/100], Step [6500/7382], D Loss: 1.3808, G Loss: 0.7112\n",
            "Epoch [66/100], Step [6600/7382], D Loss: 1.3435, G Loss: 0.7637\n",
            "Epoch [66/100], Step [6700/7382], D Loss: 1.3188, G Loss: 0.7791\n",
            "Epoch [66/100], Step [6800/7382], D Loss: 1.3596, G Loss: 0.7810\n",
            "Epoch [66/100], Step [6900/7382], D Loss: 1.3599, G Loss: 0.7680\n",
            "Epoch [66/100], Step [7000/7382], D Loss: 1.3131, G Loss: 0.8022\n",
            "Epoch [66/100], Step [7100/7382], D Loss: 1.3092, G Loss: 0.8733\n",
            "Epoch [66/100], Step [7200/7382], D Loss: 1.2824, G Loss: 0.8513\n",
            "Epoch [66/100], Step [7300/7382], D Loss: 1.3281, G Loss: 0.8498\n",
            "Epoch [67/100], Step [100/7382], D Loss: 1.3618, G Loss: 0.7443\n",
            "Epoch [67/100], Step [200/7382], D Loss: 1.2376, G Loss: 0.9014\n",
            "Epoch [67/100], Step [300/7382], D Loss: 1.2496, G Loss: 0.8398\n",
            "Epoch [67/100], Step [400/7382], D Loss: 1.2037, G Loss: 0.9196\n",
            "Epoch [67/100], Step [500/7382], D Loss: 1.3343, G Loss: 0.8732\n",
            "Epoch [67/100], Step [600/7382], D Loss: 1.3476, G Loss: 0.8298\n",
            "Epoch [67/100], Step [700/7382], D Loss: 1.2311, G Loss: 0.9362\n",
            "Epoch [67/100], Step [800/7382], D Loss: 1.3250, G Loss: 0.8155\n",
            "Epoch [67/100], Step [900/7382], D Loss: 1.3119, G Loss: 0.7869\n",
            "Epoch [67/100], Step [1000/7382], D Loss: 1.3313, G Loss: 0.7800\n",
            "Epoch [67/100], Step [1100/7382], D Loss: 1.3462, G Loss: 0.7551\n",
            "Epoch [67/100], Step [1200/7382], D Loss: 1.3936, G Loss: 0.7535\n",
            "Epoch [67/100], Step [1300/7382], D Loss: 1.2516, G Loss: 0.8857\n",
            "Epoch [67/100], Step [1400/7382], D Loss: 1.3715, G Loss: 0.8153\n",
            "Epoch [67/100], Step [1500/7382], D Loss: 1.2897, G Loss: 0.8681\n",
            "Epoch [67/100], Step [1600/7382], D Loss: 1.2712, G Loss: 0.8072\n",
            "Epoch [67/100], Step [1700/7382], D Loss: 1.2898, G Loss: 0.7913\n",
            "Epoch [67/100], Step [1800/7382], D Loss: 1.3210, G Loss: 0.7172\n",
            "Epoch [67/100], Step [1900/7382], D Loss: 1.2901, G Loss: 0.8268\n",
            "Epoch [67/100], Step [2000/7382], D Loss: 1.3318, G Loss: 0.7898\n",
            "Epoch [67/100], Step [2100/7382], D Loss: 1.3006, G Loss: 0.8346\n",
            "Epoch [67/100], Step [2200/7382], D Loss: 1.3745, G Loss: 0.7642\n",
            "Epoch [67/100], Step [2300/7382], D Loss: 1.3463, G Loss: 0.7191\n",
            "Epoch [67/100], Step [2400/7382], D Loss: 1.3053, G Loss: 0.8864\n",
            "Epoch [67/100], Step [2500/7382], D Loss: 1.3608, G Loss: 0.7489\n",
            "Epoch [67/100], Step [2600/7382], D Loss: 1.3424, G Loss: 0.7428\n",
            "Epoch [67/100], Step [2700/7382], D Loss: 1.2967, G Loss: 0.8153\n",
            "Epoch [67/100], Step [2800/7382], D Loss: 1.3068, G Loss: 0.8015\n",
            "Epoch [67/100], Step [2900/7382], D Loss: 1.2489, G Loss: 0.9177\n",
            "Epoch [67/100], Step [3000/7382], D Loss: 1.2897, G Loss: 0.8306\n",
            "Epoch [67/100], Step [3100/7382], D Loss: 1.3317, G Loss: 0.7594\n",
            "Epoch [67/100], Step [3200/7382], D Loss: 1.3091, G Loss: 0.8254\n",
            "Epoch [67/100], Step [3300/7382], D Loss: 1.3444, G Loss: 0.7798\n",
            "Epoch [67/100], Step [3400/7382], D Loss: 1.3259, G Loss: 0.8193\n",
            "Epoch [67/100], Step [3500/7382], D Loss: 1.2958, G Loss: 0.7842\n",
            "Epoch [67/100], Step [3600/7382], D Loss: 1.2517, G Loss: 0.8073\n",
            "Epoch [67/100], Step [3700/7382], D Loss: 1.2811, G Loss: 0.8101\n",
            "Epoch [67/100], Step [3800/7382], D Loss: 1.3956, G Loss: 0.7763\n",
            "Epoch [67/100], Step [3900/7382], D Loss: 1.4252, G Loss: 0.7612\n",
            "Epoch [67/100], Step [4000/7382], D Loss: 1.4283, G Loss: 0.7274\n",
            "Epoch [67/100], Step [4100/7382], D Loss: 1.3851, G Loss: 0.7941\n",
            "Epoch [67/100], Step [4200/7382], D Loss: 1.3415, G Loss: 0.7985\n",
            "Epoch [67/100], Step [4300/7382], D Loss: 1.3822, G Loss: 0.7821\n",
            "Epoch [67/100], Step [4400/7382], D Loss: 1.3007, G Loss: 0.8149\n",
            "Epoch [67/100], Step [4500/7382], D Loss: 1.3624, G Loss: 0.8558\n",
            "Epoch [67/100], Step [4600/7382], D Loss: 1.2640, G Loss: 0.7807\n",
            "Epoch [67/100], Step [4700/7382], D Loss: 1.3965, G Loss: 0.7622\n",
            "Epoch [67/100], Step [4800/7382], D Loss: 1.3029, G Loss: 0.8222\n",
            "Epoch [67/100], Step [4900/7382], D Loss: 1.3610, G Loss: 0.7542\n",
            "Epoch [67/100], Step [5000/7382], D Loss: 1.3577, G Loss: 0.7477\n",
            "Epoch [67/100], Step [5100/7382], D Loss: 1.3329, G Loss: 0.7455\n",
            "Epoch [67/100], Step [5200/7382], D Loss: 1.2766, G Loss: 0.9277\n",
            "Epoch [67/100], Step [5300/7382], D Loss: 1.3238, G Loss: 0.8238\n",
            "Epoch [67/100], Step [5400/7382], D Loss: 1.3403, G Loss: 0.8035\n",
            "Epoch [67/100], Step [5500/7382], D Loss: 1.2754, G Loss: 0.8104\n",
            "Epoch [67/100], Step [5600/7382], D Loss: 1.2869, G Loss: 0.7952\n",
            "Epoch [67/100], Step [5700/7382], D Loss: 1.3316, G Loss: 0.7656\n",
            "Epoch [67/100], Step [5800/7382], D Loss: 1.3526, G Loss: 0.7858\n",
            "Epoch [67/100], Step [5900/7382], D Loss: 1.3208, G Loss: 0.7607\n",
            "Epoch [67/100], Step [6000/7382], D Loss: 1.3369, G Loss: 0.7966\n",
            "Epoch [67/100], Step [6100/7382], D Loss: 1.3458, G Loss: 0.7895\n",
            "Epoch [67/100], Step [6200/7382], D Loss: 1.4262, G Loss: 0.7436\n",
            "Epoch [67/100], Step [6300/7382], D Loss: 1.1838, G Loss: 1.0765\n",
            "Epoch [67/100], Step [6400/7382], D Loss: 1.2883, G Loss: 0.7735\n",
            "Epoch [67/100], Step [6500/7382], D Loss: 1.3596, G Loss: 0.7411\n",
            "Epoch [67/100], Step [6600/7382], D Loss: 1.3788, G Loss: 0.7411\n",
            "Epoch [67/100], Step [6700/7382], D Loss: 1.3362, G Loss: 0.7673\n",
            "Epoch [67/100], Step [6800/7382], D Loss: 1.3846, G Loss: 0.8185\n",
            "Epoch [67/100], Step [6900/7382], D Loss: 1.2813, G Loss: 0.7977\n",
            "Epoch [67/100], Step [7000/7382], D Loss: 1.2957, G Loss: 0.9421\n",
            "Epoch [67/100], Step [7100/7382], D Loss: 1.4096, G Loss: 0.7395\n",
            "Epoch [67/100], Step [7200/7382], D Loss: 1.3330, G Loss: 0.8043\n",
            "Epoch [67/100], Step [7300/7382], D Loss: 1.4155, G Loss: 0.7096\n",
            "Epoch [68/100], Step [100/7382], D Loss: 1.2764, G Loss: 0.8315\n",
            "Epoch [68/100], Step [200/7382], D Loss: 1.2721, G Loss: 0.7529\n",
            "Epoch [68/100], Step [300/7382], D Loss: 1.3649, G Loss: 0.7681\n",
            "Epoch [68/100], Step [400/7382], D Loss: 1.2656, G Loss: 0.8338\n",
            "Epoch [68/100], Step [500/7382], D Loss: 1.2774, G Loss: 0.8588\n",
            "Epoch [68/100], Step [600/7382], D Loss: 1.2749, G Loss: 0.9307\n",
            "Epoch [68/100], Step [700/7382], D Loss: 1.3109, G Loss: 0.7835\n",
            "Epoch [68/100], Step [800/7382], D Loss: 1.3342, G Loss: 0.7940\n",
            "Epoch [68/100], Step [900/7382], D Loss: 1.3559, G Loss: 0.8480\n",
            "Epoch [68/100], Step [1000/7382], D Loss: 1.2963, G Loss: 0.9215\n",
            "Epoch [68/100], Step [1100/7382], D Loss: 1.3167, G Loss: 0.7972\n",
            "Epoch [68/100], Step [1200/7382], D Loss: 1.3472, G Loss: 0.8153\n",
            "Epoch [68/100], Step [1300/7382], D Loss: 1.2890, G Loss: 0.7938\n",
            "Epoch [68/100], Step [1400/7382], D Loss: 1.3648, G Loss: 0.8427\n",
            "Epoch [68/100], Step [1500/7382], D Loss: 1.3551, G Loss: 0.7852\n",
            "Epoch [68/100], Step [1600/7382], D Loss: 1.3009, G Loss: 0.8247\n",
            "Epoch [68/100], Step [1700/7382], D Loss: 1.3369, G Loss: 0.7858\n",
            "Epoch [68/100], Step [1800/7382], D Loss: 1.4159, G Loss: 0.7508\n",
            "Epoch [68/100], Step [1900/7382], D Loss: 1.3093, G Loss: 0.7907\n",
            "Epoch [68/100], Step [2000/7382], D Loss: 1.3342, G Loss: 0.7759\n",
            "Epoch [68/100], Step [2100/7382], D Loss: 1.3137, G Loss: 0.7990\n",
            "Epoch [68/100], Step [2200/7382], D Loss: 1.3320, G Loss: 0.8151\n",
            "Epoch [68/100], Step [2300/7382], D Loss: 1.3620, G Loss: 0.7333\n",
            "Epoch [68/100], Step [2400/7382], D Loss: 1.3203, G Loss: 0.8041\n",
            "Epoch [68/100], Step [2500/7382], D Loss: 1.3262, G Loss: 0.8066\n",
            "Epoch [68/100], Step [2600/7382], D Loss: 1.2619, G Loss: 0.8476\n",
            "Epoch [68/100], Step [2700/7382], D Loss: 1.3135, G Loss: 0.8037\n",
            "Epoch [68/100], Step [2800/7382], D Loss: 1.2700, G Loss: 0.8201\n",
            "Epoch [68/100], Step [2900/7382], D Loss: 1.3487, G Loss: 0.8259\n",
            "Epoch [68/100], Step [3000/7382], D Loss: 1.3282, G Loss: 0.7811\n",
            "Epoch [68/100], Step [3100/7382], D Loss: 1.3636, G Loss: 0.7780\n",
            "Epoch [68/100], Step [3200/7382], D Loss: 1.2615, G Loss: 0.8196\n",
            "Epoch [68/100], Step [3300/7382], D Loss: 1.2304, G Loss: 0.9647\n",
            "Epoch [68/100], Step [3400/7382], D Loss: 1.4446, G Loss: 0.8000\n",
            "Epoch [68/100], Step [3500/7382], D Loss: 1.2951, G Loss: 0.8136\n",
            "Epoch [68/100], Step [3600/7382], D Loss: 1.2825, G Loss: 0.7935\n",
            "Epoch [68/100], Step [3700/7382], D Loss: 1.3294, G Loss: 0.8373\n",
            "Epoch [68/100], Step [3800/7382], D Loss: 1.3004, G Loss: 0.8410\n",
            "Epoch [68/100], Step [3900/7382], D Loss: 1.3016, G Loss: 0.7815\n",
            "Epoch [68/100], Step [4000/7382], D Loss: 1.2710, G Loss: 0.8426\n",
            "Epoch [68/100], Step [4100/7382], D Loss: 1.4007, G Loss: 0.7612\n",
            "Epoch [68/100], Step [4200/7382], D Loss: 1.3195, G Loss: 0.7785\n",
            "Epoch [68/100], Step [4300/7382], D Loss: 1.3604, G Loss: 0.8608\n",
            "Epoch [68/100], Step [4400/7382], D Loss: 1.3907, G Loss: 0.8014\n",
            "Epoch [68/100], Step [4500/7382], D Loss: 1.3146, G Loss: 0.7864\n",
            "Epoch [68/100], Step [4600/7382], D Loss: 1.2988, G Loss: 0.8433\n",
            "Epoch [68/100], Step [4700/7382], D Loss: 1.3298, G Loss: 0.7520\n",
            "Epoch [68/100], Step [4800/7382], D Loss: 1.1955, G Loss: 0.8629\n",
            "Epoch [68/100], Step [4900/7382], D Loss: 1.4293, G Loss: 0.7426\n",
            "Epoch [68/100], Step [5000/7382], D Loss: 1.3108, G Loss: 0.8125\n",
            "Epoch [68/100], Step [5100/7382], D Loss: 1.2529, G Loss: 0.8373\n",
            "Epoch [68/100], Step [5200/7382], D Loss: 1.2305, G Loss: 0.9393\n",
            "Epoch [68/100], Step [5300/7382], D Loss: 1.3454, G Loss: 0.7963\n",
            "Epoch [68/100], Step [5400/7382], D Loss: 1.3986, G Loss: 0.8183\n",
            "Epoch [68/100], Step [5500/7382], D Loss: 1.3022, G Loss: 0.8370\n",
            "Epoch [68/100], Step [5600/7382], D Loss: 1.3145, G Loss: 0.7566\n",
            "Epoch [68/100], Step [5700/7382], D Loss: 1.1785, G Loss: 0.8942\n",
            "Epoch [68/100], Step [5800/7382], D Loss: 1.4329, G Loss: 0.8013\n",
            "Epoch [68/100], Step [5900/7382], D Loss: 1.3290, G Loss: 0.8369\n",
            "Epoch [68/100], Step [6000/7382], D Loss: 1.3637, G Loss: 0.7978\n",
            "Epoch [68/100], Step [6100/7382], D Loss: 1.3209, G Loss: 0.7998\n",
            "Epoch [68/100], Step [6200/7382], D Loss: 1.3219, G Loss: 0.8217\n",
            "Epoch [68/100], Step [6300/7382], D Loss: 1.2654, G Loss: 0.8495\n",
            "Epoch [68/100], Step [6400/7382], D Loss: 1.2536, G Loss: 0.8768\n",
            "Epoch [68/100], Step [6500/7382], D Loss: 1.2985, G Loss: 0.7867\n",
            "Epoch [68/100], Step [6600/7382], D Loss: 1.4498, G Loss: 0.7914\n",
            "Epoch [68/100], Step [6700/7382], D Loss: 1.3646, G Loss: 0.7875\n",
            "Epoch [68/100], Step [6800/7382], D Loss: 1.2963, G Loss: 0.7963\n",
            "Epoch [68/100], Step [6900/7382], D Loss: 1.2314, G Loss: 0.8025\n",
            "Epoch [68/100], Step [7000/7382], D Loss: 1.4170, G Loss: 0.7609\n",
            "Epoch [68/100], Step [7100/7382], D Loss: 1.3519, G Loss: 0.8500\n",
            "Epoch [68/100], Step [7200/7382], D Loss: 1.2247, G Loss: 0.8761\n",
            "Epoch [68/100], Step [7300/7382], D Loss: 1.3199, G Loss: 0.7879\n",
            "Epoch [69/100], Step [100/7382], D Loss: 1.3169, G Loss: 0.7692\n",
            "Epoch [69/100], Step [200/7382], D Loss: 1.3645, G Loss: 0.7529\n",
            "Epoch [69/100], Step [300/7382], D Loss: 1.2856, G Loss: 0.8219\n",
            "Epoch [69/100], Step [400/7382], D Loss: 1.2535, G Loss: 0.8185\n",
            "Epoch [69/100], Step [500/7382], D Loss: 1.1742, G Loss: 1.0225\n",
            "Epoch [69/100], Step [600/7382], D Loss: 1.2995, G Loss: 0.9264\n",
            "Epoch [69/100], Step [700/7382], D Loss: 1.2727, G Loss: 0.8592\n",
            "Epoch [69/100], Step [800/7382], D Loss: 1.3797, G Loss: 0.9013\n",
            "Epoch [69/100], Step [900/7382], D Loss: 1.3390, G Loss: 0.8000\n",
            "Epoch [69/100], Step [1000/7382], D Loss: 1.3620, G Loss: 0.7719\n",
            "Epoch [69/100], Step [1100/7382], D Loss: 1.3798, G Loss: 0.7822\n",
            "Epoch [69/100], Step [1200/7382], D Loss: 1.3000, G Loss: 0.8744\n",
            "Epoch [69/100], Step [1300/7382], D Loss: 1.3640, G Loss: 0.7951\n",
            "Epoch [69/100], Step [1400/7382], D Loss: 1.3414, G Loss: 0.7650\n",
            "Epoch [69/100], Step [1500/7382], D Loss: 1.3600, G Loss: 0.7911\n",
            "Epoch [69/100], Step [1600/7382], D Loss: 1.3162, G Loss: 0.8264\n",
            "Epoch [69/100], Step [1700/7382], D Loss: 1.2954, G Loss: 0.8068\n",
            "Epoch [69/100], Step [1800/7382], D Loss: 1.3344, G Loss: 0.7725\n",
            "Epoch [69/100], Step [1900/7382], D Loss: 1.1762, G Loss: 0.9786\n",
            "Epoch [69/100], Step [2000/7382], D Loss: 1.3492, G Loss: 0.8216\n",
            "Epoch [69/100], Step [2100/7382], D Loss: 1.2805, G Loss: 0.8956\n",
            "Epoch [69/100], Step [2200/7382], D Loss: 1.3807, G Loss: 0.8297\n",
            "Epoch [69/100], Step [2300/7382], D Loss: 1.3710, G Loss: 0.7614\n",
            "Epoch [69/100], Step [2400/7382], D Loss: 1.2829, G Loss: 0.8420\n",
            "Epoch [69/100], Step [2500/7382], D Loss: 1.2936, G Loss: 0.8112\n",
            "Epoch [69/100], Step [2600/7382], D Loss: 1.3349, G Loss: 0.9112\n",
            "Epoch [69/100], Step [2700/7382], D Loss: 1.2797, G Loss: 0.8268\n",
            "Epoch [69/100], Step [2800/7382], D Loss: 1.3033, G Loss: 0.8049\n",
            "Epoch [69/100], Step [2900/7382], D Loss: 1.3544, G Loss: 0.7954\n",
            "Epoch [69/100], Step [3000/7382], D Loss: 1.2275, G Loss: 0.8752\n",
            "Epoch [69/100], Step [3100/7382], D Loss: 1.4380, G Loss: 0.7343\n",
            "Epoch [69/100], Step [3200/7382], D Loss: 1.2590, G Loss: 0.9462\n",
            "Epoch [69/100], Step [3300/7382], D Loss: 1.3111, G Loss: 0.8578\n",
            "Epoch [69/100], Step [3400/7382], D Loss: 1.4183, G Loss: 0.7482\n",
            "Epoch [69/100], Step [3500/7382], D Loss: 1.3153, G Loss: 0.8112\n",
            "Epoch [69/100], Step [3600/7382], D Loss: 1.3175, G Loss: 0.7665\n",
            "Epoch [69/100], Step [3700/7382], D Loss: 1.2947, G Loss: 0.7941\n",
            "Epoch [69/100], Step [3800/7382], D Loss: 1.2604, G Loss: 0.8950\n",
            "Epoch [69/100], Step [3900/7382], D Loss: 1.2881, G Loss: 0.7977\n",
            "Epoch [69/100], Step [4000/7382], D Loss: 1.4042, G Loss: 0.7923\n",
            "Epoch [69/100], Step [4100/7382], D Loss: 1.3243, G Loss: 0.9758\n",
            "Epoch [69/100], Step [4200/7382], D Loss: 1.3665, G Loss: 0.8847\n",
            "Epoch [69/100], Step [4300/7382], D Loss: 1.3002, G Loss: 0.8468\n",
            "Epoch [69/100], Step [4400/7382], D Loss: 1.2923, G Loss: 0.8009\n",
            "Epoch [69/100], Step [4500/7382], D Loss: 1.3092, G Loss: 0.8284\n",
            "Epoch [69/100], Step [4600/7382], D Loss: 1.3473, G Loss: 0.7660\n",
            "Epoch [69/100], Step [4700/7382], D Loss: 1.3013, G Loss: 0.8744\n",
            "Epoch [69/100], Step [4800/7382], D Loss: 1.2786, G Loss: 0.9319\n",
            "Epoch [69/100], Step [4900/7382], D Loss: 1.2409, G Loss: 0.9286\n",
            "Epoch [69/100], Step [5000/7382], D Loss: 1.3043, G Loss: 0.9837\n",
            "Epoch [69/100], Step [5100/7382], D Loss: 1.3087, G Loss: 0.8046\n",
            "Epoch [69/100], Step [5200/7382], D Loss: 1.2593, G Loss: 0.9020\n",
            "Epoch [69/100], Step [5300/7382], D Loss: 1.2924, G Loss: 0.8644\n",
            "Epoch [69/100], Step [5400/7382], D Loss: 1.2399, G Loss: 0.9654\n",
            "Epoch [69/100], Step [5500/7382], D Loss: 1.2960, G Loss: 0.8147\n",
            "Epoch [69/100], Step [5600/7382], D Loss: 1.2179, G Loss: 0.8879\n",
            "Epoch [69/100], Step [5700/7382], D Loss: 1.2796, G Loss: 0.8676\n",
            "Epoch [69/100], Step [5800/7382], D Loss: 1.3242, G Loss: 0.8455\n",
            "Epoch [69/100], Step [5900/7382], D Loss: 1.2567, G Loss: 0.8168\n",
            "Epoch [69/100], Step [6000/7382], D Loss: 1.3499, G Loss: 0.9101\n",
            "Epoch [69/100], Step [6100/7382], D Loss: 1.2955, G Loss: 0.8719\n",
            "Epoch [69/100], Step [6200/7382], D Loss: 1.2726, G Loss: 0.8412\n",
            "Epoch [69/100], Step [6300/7382], D Loss: 1.2235, G Loss: 0.8824\n",
            "Epoch [69/100], Step [6400/7382], D Loss: 1.2451, G Loss: 0.8373\n",
            "Epoch [69/100], Step [6500/7382], D Loss: 1.3366, G Loss: 0.8216\n",
            "Epoch [69/100], Step [6600/7382], D Loss: 1.3060, G Loss: 0.8274\n",
            "Epoch [69/100], Step [6700/7382], D Loss: 1.2557, G Loss: 0.8479\n",
            "Epoch [69/100], Step [6800/7382], D Loss: 1.3519, G Loss: 0.8831\n",
            "Epoch [69/100], Step [6900/7382], D Loss: 1.2782, G Loss: 0.8246\n",
            "Epoch [69/100], Step [7000/7382], D Loss: 1.2018, G Loss: 0.9872\n",
            "Epoch [69/100], Step [7100/7382], D Loss: 1.2173, G Loss: 0.9801\n",
            "Epoch [69/100], Step [7200/7382], D Loss: 1.2496, G Loss: 0.8581\n",
            "Epoch [69/100], Step [7300/7382], D Loss: 1.2288, G Loss: 0.9217\n",
            "Epoch [70/100], Step [100/7382], D Loss: 1.3600, G Loss: 0.9386\n",
            "Epoch [70/100], Step [200/7382], D Loss: 1.2839, G Loss: 0.9386\n",
            "Epoch [70/100], Step [300/7382], D Loss: 1.3009, G Loss: 0.8672\n",
            "Epoch [70/100], Step [400/7382], D Loss: 1.2444, G Loss: 1.0000\n",
            "Epoch [70/100], Step [500/7382], D Loss: 1.2391, G Loss: 0.8945\n",
            "Epoch [70/100], Step [600/7382], D Loss: 1.3152, G Loss: 0.9399\n",
            "Epoch [70/100], Step [700/7382], D Loss: 1.2208, G Loss: 0.9240\n",
            "Epoch [70/100], Step [800/7382], D Loss: 1.3854, G Loss: 0.9152\n",
            "Epoch [70/100], Step [900/7382], D Loss: 1.2006, G Loss: 0.8835\n",
            "Epoch [70/100], Step [1000/7382], D Loss: 1.2585, G Loss: 0.8788\n",
            "Epoch [70/100], Step [1100/7382], D Loss: 1.3100, G Loss: 0.7915\n",
            "Epoch [70/100], Step [1200/7382], D Loss: 1.2309, G Loss: 0.9429\n",
            "Epoch [70/100], Step [1300/7382], D Loss: 1.3041, G Loss: 0.9115\n",
            "Epoch [70/100], Step [1400/7382], D Loss: 1.3643, G Loss: 0.8840\n",
            "Epoch [70/100], Step [1500/7382], D Loss: 1.2434, G Loss: 0.9229\n",
            "Epoch [70/100], Step [1600/7382], D Loss: 1.2086, G Loss: 0.8481\n",
            "Epoch [70/100], Step [1700/7382], D Loss: 1.4031, G Loss: 0.8896\n",
            "Epoch [70/100], Step [1800/7382], D Loss: 1.3531, G Loss: 0.8681\n",
            "Epoch [70/100], Step [1900/7382], D Loss: 1.3203, G Loss: 0.8181\n",
            "Epoch [70/100], Step [2000/7382], D Loss: 1.3526, G Loss: 0.8287\n",
            "Epoch [70/100], Step [2100/7382], D Loss: 1.2615, G Loss: 0.9058\n",
            "Epoch [70/100], Step [2200/7382], D Loss: 1.2022, G Loss: 0.8854\n",
            "Epoch [70/100], Step [2300/7382], D Loss: 1.3061, G Loss: 0.8292\n",
            "Epoch [70/100], Step [2400/7382], D Loss: 1.2857, G Loss: 0.8261\n",
            "Epoch [70/100], Step [2500/7382], D Loss: 1.3229, G Loss: 0.7817\n",
            "Epoch [70/100], Step [2600/7382], D Loss: 1.1785, G Loss: 0.8823\n",
            "Epoch [70/100], Step [2700/7382], D Loss: 1.1835, G Loss: 0.8926\n",
            "Epoch [70/100], Step [2800/7382], D Loss: 1.1814, G Loss: 0.9488\n",
            "Epoch [70/100], Step [2900/7382], D Loss: 1.1795, G Loss: 0.9094\n",
            "Epoch [70/100], Step [3000/7382], D Loss: 1.1958, G Loss: 0.8946\n",
            "Epoch [70/100], Step [3100/7382], D Loss: 1.2125, G Loss: 0.9398\n",
            "Epoch [70/100], Step [3200/7382], D Loss: 1.2620, G Loss: 0.8933\n",
            "Epoch [70/100], Step [3300/7382], D Loss: 1.3606, G Loss: 0.8008\n",
            "Epoch [70/100], Step [3400/7382], D Loss: 1.3650, G Loss: 0.8182\n",
            "Epoch [70/100], Step [3500/7382], D Loss: 1.2701, G Loss: 0.8074\n",
            "Epoch [70/100], Step [3600/7382], D Loss: 1.2952, G Loss: 0.8678\n",
            "Epoch [70/100], Step [3700/7382], D Loss: 1.2971, G Loss: 0.8698\n",
            "Epoch [70/100], Step [3800/7382], D Loss: 1.2407, G Loss: 0.9346\n",
            "Epoch [70/100], Step [3900/7382], D Loss: 1.1796, G Loss: 0.9696\n",
            "Epoch [70/100], Step [4000/7382], D Loss: 1.2168, G Loss: 0.9058\n",
            "Epoch [70/100], Step [4100/7382], D Loss: 1.4419, G Loss: 0.7566\n",
            "Epoch [70/100], Step [4200/7382], D Loss: 1.3147, G Loss: 0.8619\n",
            "Epoch [70/100], Step [4300/7382], D Loss: 1.1907, G Loss: 0.9758\n",
            "Epoch [70/100], Step [4400/7382], D Loss: 1.3119, G Loss: 0.8858\n",
            "Epoch [70/100], Step [4500/7382], D Loss: 1.2548, G Loss: 0.9012\n",
            "Epoch [70/100], Step [4600/7382], D Loss: 1.2861, G Loss: 0.8772\n",
            "Epoch [70/100], Step [4700/7382], D Loss: 1.2859, G Loss: 0.8300\n",
            "Epoch [70/100], Step [4800/7382], D Loss: 1.2583, G Loss: 0.8929\n",
            "Epoch [70/100], Step [4900/7382], D Loss: 1.3021, G Loss: 0.9520\n",
            "Epoch [70/100], Step [5000/7382], D Loss: 1.2983, G Loss: 0.9163\n",
            "Epoch [70/100], Step [5100/7382], D Loss: 1.2849, G Loss: 0.8786\n",
            "Epoch [70/100], Step [5200/7382], D Loss: 1.3196, G Loss: 0.9136\n",
            "Epoch [70/100], Step [5300/7382], D Loss: 1.3131, G Loss: 0.9090\n",
            "Epoch [70/100], Step [5400/7382], D Loss: 1.3155, G Loss: 1.0065\n",
            "Epoch [70/100], Step [5500/7382], D Loss: 1.2690, G Loss: 0.8990\n",
            "Epoch [70/100], Step [5600/7382], D Loss: 1.2812, G Loss: 0.9088\n",
            "Epoch [70/100], Step [5700/7382], D Loss: 1.1979, G Loss: 0.9579\n",
            "Epoch [70/100], Step [5800/7382], D Loss: 1.2674, G Loss: 0.8606\n",
            "Epoch [70/100], Step [5900/7382], D Loss: 1.2197, G Loss: 0.8302\n",
            "Epoch [70/100], Step [6000/7382], D Loss: 1.3651, G Loss: 0.8467\n",
            "Epoch [70/100], Step [6100/7382], D Loss: 1.3060, G Loss: 0.9280\n",
            "Epoch [70/100], Step [6200/7382], D Loss: 1.2467, G Loss: 0.9430\n",
            "Epoch [70/100], Step [6300/7382], D Loss: 1.0749, G Loss: 1.1159\n",
            "Epoch [70/100], Step [6400/7382], D Loss: 1.3442, G Loss: 0.8437\n",
            "Epoch [70/100], Step [6500/7382], D Loss: 1.1919, G Loss: 0.9380\n",
            "Epoch [70/100], Step [6600/7382], D Loss: 1.2617, G Loss: 0.8112\n",
            "Epoch [70/100], Step [6700/7382], D Loss: 1.1365, G Loss: 0.9667\n",
            "Epoch [70/100], Step [6800/7382], D Loss: 1.4749, G Loss: 0.7838\n",
            "Epoch [70/100], Step [6900/7382], D Loss: 1.2761, G Loss: 0.9026\n",
            "Epoch [70/100], Step [7000/7382], D Loss: 1.2484, G Loss: 0.9298\n",
            "Epoch [70/100], Step [7100/7382], D Loss: 1.3487, G Loss: 0.8305\n",
            "Epoch [70/100], Step [7200/7382], D Loss: 1.1587, G Loss: 0.9546\n",
            "Epoch [70/100], Step [7300/7382], D Loss: 1.2662, G Loss: 0.9449\n",
            "Epoch [71/100], Step [100/7382], D Loss: 1.1832, G Loss: 0.9226\n",
            "Epoch [71/100], Step [200/7382], D Loss: 1.3475, G Loss: 0.8148\n",
            "Epoch [71/100], Step [300/7382], D Loss: 1.2306, G Loss: 0.8620\n",
            "Epoch [71/100], Step [400/7382], D Loss: 1.3119, G Loss: 0.8829\n",
            "Epoch [71/100], Step [500/7382], D Loss: 1.1895, G Loss: 0.9361\n",
            "Epoch [71/100], Step [600/7382], D Loss: 1.1828, G Loss: 0.9448\n",
            "Epoch [71/100], Step [700/7382], D Loss: 1.2279, G Loss: 0.9101\n",
            "Epoch [71/100], Step [800/7382], D Loss: 1.1828, G Loss: 0.9144\n",
            "Epoch [71/100], Step [900/7382], D Loss: 1.2547, G Loss: 0.8895\n",
            "Epoch [71/100], Step [1000/7382], D Loss: 1.2796, G Loss: 0.8963\n",
            "Epoch [71/100], Step [1100/7382], D Loss: 1.2791, G Loss: 0.7981\n",
            "Epoch [71/100], Step [1200/7382], D Loss: 1.3595, G Loss: 0.8612\n",
            "Epoch [71/100], Step [1300/7382], D Loss: 1.2533, G Loss: 0.8706\n",
            "Epoch [71/100], Step [1400/7382], D Loss: 1.1995, G Loss: 0.9191\n",
            "Epoch [71/100], Step [1500/7382], D Loss: 1.1612, G Loss: 1.0363\n",
            "Epoch [71/100], Step [1600/7382], D Loss: 1.2806, G Loss: 0.8571\n",
            "Epoch [71/100], Step [1700/7382], D Loss: 1.3352, G Loss: 0.8376\n",
            "Epoch [71/100], Step [1800/7382], D Loss: 1.3307, G Loss: 0.7970\n",
            "Epoch [71/100], Step [1900/7382], D Loss: 1.3019, G Loss: 0.8516\n",
            "Epoch [71/100], Step [2000/7382], D Loss: 1.2665, G Loss: 0.8259\n",
            "Epoch [71/100], Step [2100/7382], D Loss: 1.2308, G Loss: 0.9614\n",
            "Epoch [71/100], Step [2200/7382], D Loss: 1.2664, G Loss: 0.8120\n",
            "Epoch [71/100], Step [2300/7382], D Loss: 1.3212, G Loss: 0.8673\n",
            "Epoch [71/100], Step [2400/7382], D Loss: 1.2709, G Loss: 0.8917\n",
            "Epoch [71/100], Step [2500/7382], D Loss: 1.1370, G Loss: 1.0664\n",
            "Epoch [71/100], Step [2600/7382], D Loss: 1.2917, G Loss: 0.9073\n",
            "Epoch [71/100], Step [2700/7382], D Loss: 1.2615, G Loss: 0.8235\n",
            "Epoch [71/100], Step [2800/7382], D Loss: 1.1858, G Loss: 1.0184\n",
            "Epoch [71/100], Step [2900/7382], D Loss: 1.2035, G Loss: 0.9707\n",
            "Epoch [71/100], Step [3000/7382], D Loss: 1.1989, G Loss: 0.8951\n",
            "Epoch [71/100], Step [3100/7382], D Loss: 1.2159, G Loss: 0.8947\n",
            "Epoch [71/100], Step [3200/7382], D Loss: 1.3141, G Loss: 0.8292\n",
            "Epoch [71/100], Step [3300/7382], D Loss: 1.3253, G Loss: 0.8942\n",
            "Epoch [71/100], Step [3400/7382], D Loss: 1.2627, G Loss: 0.8350\n",
            "Epoch [71/100], Step [3500/7382], D Loss: 1.3228, G Loss: 0.8329\n",
            "Epoch [71/100], Step [3600/7382], D Loss: 1.3507, G Loss: 0.8159\n",
            "Epoch [71/100], Step [3700/7382], D Loss: 1.2217, G Loss: 0.9388\n",
            "Epoch [71/100], Step [3800/7382], D Loss: 1.2360, G Loss: 0.8058\n",
            "Epoch [71/100], Step [3900/7382], D Loss: 1.3202, G Loss: 0.8693\n",
            "Epoch [71/100], Step [4000/7382], D Loss: 1.3100, G Loss: 0.8061\n",
            "Epoch [71/100], Step [4100/7382], D Loss: 1.2605, G Loss: 0.8471\n",
            "Epoch [71/100], Step [4200/7382], D Loss: 1.2114, G Loss: 0.9104\n",
            "Epoch [71/100], Step [4300/7382], D Loss: 1.3004, G Loss: 0.8059\n",
            "Epoch [71/100], Step [4400/7382], D Loss: 1.3334, G Loss: 0.8433\n",
            "Epoch [71/100], Step [4500/7382], D Loss: 1.3221, G Loss: 0.8738\n",
            "Epoch [71/100], Step [4600/7382], D Loss: 1.3023, G Loss: 0.8070\n",
            "Epoch [71/100], Step [4700/7382], D Loss: 1.2889, G Loss: 0.8587\n",
            "Epoch [71/100], Step [4800/7382], D Loss: 1.3324, G Loss: 0.7726\n",
            "Epoch [71/100], Step [4900/7382], D Loss: 1.3205, G Loss: 0.7639\n",
            "Epoch [71/100], Step [5000/7382], D Loss: 1.3452, G Loss: 0.8408\n",
            "Epoch [71/100], Step [5100/7382], D Loss: 1.2794, G Loss: 0.8315\n",
            "Epoch [71/100], Step [5200/7382], D Loss: 1.2770, G Loss: 0.8338\n",
            "Epoch [71/100], Step [5300/7382], D Loss: 1.2583, G Loss: 0.8105\n",
            "Epoch [71/100], Step [5400/7382], D Loss: 1.2511, G Loss: 0.8955\n",
            "Epoch [71/100], Step [5500/7382], D Loss: 1.2083, G Loss: 0.8571\n",
            "Epoch [71/100], Step [5600/7382], D Loss: 1.2344, G Loss: 0.9002\n",
            "Epoch [71/100], Step [5700/7382], D Loss: 1.3692, G Loss: 0.7899\n",
            "Epoch [71/100], Step [5800/7382], D Loss: 1.2912, G Loss: 0.8985\n",
            "Epoch [71/100], Step [5900/7382], D Loss: 1.3256, G Loss: 0.8596\n",
            "Epoch [71/100], Step [6000/7382], D Loss: 1.2089, G Loss: 0.9943\n",
            "Epoch [71/100], Step [6100/7382], D Loss: 1.3364, G Loss: 0.9146\n",
            "Epoch [71/100], Step [6200/7382], D Loss: 1.1864, G Loss: 0.9022\n",
            "Epoch [71/100], Step [6300/7382], D Loss: 1.3128, G Loss: 0.9493\n",
            "Epoch [71/100], Step [6400/7382], D Loss: 1.3221, G Loss: 0.8868\n",
            "Epoch [71/100], Step [6500/7382], D Loss: 1.2639, G Loss: 0.9073\n",
            "Epoch [71/100], Step [6600/7382], D Loss: 1.2464, G Loss: 0.9444\n",
            "Epoch [71/100], Step [6700/7382], D Loss: 1.2284, G Loss: 0.9446\n",
            "Epoch [71/100], Step [6800/7382], D Loss: 1.1823, G Loss: 1.0899\n",
            "Epoch [71/100], Step [6900/7382], D Loss: 1.2092, G Loss: 0.8592\n",
            "Epoch [71/100], Step [7000/7382], D Loss: 1.2736, G Loss: 0.9264\n",
            "Epoch [71/100], Step [7100/7382], D Loss: 1.2679, G Loss: 0.8109\n",
            "Epoch [71/100], Step [7200/7382], D Loss: 1.2712, G Loss: 0.8927\n",
            "Epoch [71/100], Step [7300/7382], D Loss: 1.2948, G Loss: 0.8858\n",
            "Epoch [72/100], Step [100/7382], D Loss: 1.2328, G Loss: 0.9297\n",
            "Epoch [72/100], Step [200/7382], D Loss: 1.2991, G Loss: 0.8283\n",
            "Epoch [72/100], Step [300/7382], D Loss: 1.2705, G Loss: 0.9436\n",
            "Epoch [72/100], Step [400/7382], D Loss: 1.2680, G Loss: 0.8016\n",
            "Epoch [72/100], Step [500/7382], D Loss: 1.3334, G Loss: 0.8535\n",
            "Epoch [72/100], Step [600/7382], D Loss: 1.2816, G Loss: 0.8172\n",
            "Epoch [72/100], Step [700/7382], D Loss: 1.3099, G Loss: 0.9038\n",
            "Epoch [72/100], Step [800/7382], D Loss: 1.2264, G Loss: 0.8917\n",
            "Epoch [72/100], Step [900/7382], D Loss: 1.3603, G Loss: 0.8798\n",
            "Epoch [72/100], Step [1000/7382], D Loss: 1.2635, G Loss: 0.8781\n",
            "Epoch [72/100], Step [1100/7382], D Loss: 1.2864, G Loss: 0.8542\n",
            "Epoch [72/100], Step [1200/7382], D Loss: 1.3207, G Loss: 0.8493\n",
            "Epoch [72/100], Step [1300/7382], D Loss: 1.3299, G Loss: 0.8547\n",
            "Epoch [72/100], Step [1400/7382], D Loss: 1.3623, G Loss: 0.8320\n",
            "Epoch [72/100], Step [1500/7382], D Loss: 1.2597, G Loss: 0.8325\n",
            "Epoch [72/100], Step [1600/7382], D Loss: 1.2942, G Loss: 0.7903\n",
            "Epoch [72/100], Step [1700/7382], D Loss: 1.1014, G Loss: 0.9810\n",
            "Epoch [72/100], Step [1800/7382], D Loss: 1.2755, G Loss: 0.8585\n",
            "Epoch [72/100], Step [1900/7382], D Loss: 1.2778, G Loss: 0.9124\n",
            "Epoch [72/100], Step [2000/7382], D Loss: 1.2324, G Loss: 1.0053\n",
            "Epoch [72/100], Step [2100/7382], D Loss: 1.1827, G Loss: 0.9340\n",
            "Epoch [72/100], Step [2200/7382], D Loss: 1.3262, G Loss: 0.8448\n",
            "Epoch [72/100], Step [2300/7382], D Loss: 1.3795, G Loss: 0.9009\n",
            "Epoch [72/100], Step [2400/7382], D Loss: 1.2859, G Loss: 0.9643\n",
            "Epoch [72/100], Step [2500/7382], D Loss: 1.2510, G Loss: 0.9073\n",
            "Epoch [72/100], Step [2600/7382], D Loss: 1.2591, G Loss: 0.9006\n",
            "Epoch [72/100], Step [2700/7382], D Loss: 1.2355, G Loss: 0.8979\n",
            "Epoch [72/100], Step [2800/7382], D Loss: 1.2598, G Loss: 0.8709\n",
            "Epoch [72/100], Step [2900/7382], D Loss: 1.1519, G Loss: 0.9748\n",
            "Epoch [72/100], Step [3000/7382], D Loss: 1.2864, G Loss: 0.8423\n",
            "Epoch [72/100], Step [3100/7382], D Loss: 1.2002, G Loss: 0.9016\n",
            "Epoch [72/100], Step [3200/7382], D Loss: 1.2467, G Loss: 0.9342\n",
            "Epoch [72/100], Step [3300/7382], D Loss: 1.2464, G Loss: 0.8519\n",
            "Epoch [72/100], Step [3400/7382], D Loss: 1.1870, G Loss: 0.8944\n",
            "Epoch [72/100], Step [3500/7382], D Loss: 1.2021, G Loss: 0.9413\n",
            "Epoch [72/100], Step [3600/7382], D Loss: 1.3162, G Loss: 0.7975\n",
            "Epoch [72/100], Step [3700/7382], D Loss: 1.1275, G Loss: 0.9483\n",
            "Epoch [72/100], Step [3800/7382], D Loss: 1.3351, G Loss: 0.8380\n",
            "Epoch [72/100], Step [3900/7382], D Loss: 1.1434, G Loss: 1.0205\n",
            "Epoch [72/100], Step [4000/7382], D Loss: 1.2569, G Loss: 0.9469\n",
            "Epoch [72/100], Step [4100/7382], D Loss: 1.2812, G Loss: 0.9140\n",
            "Epoch [72/100], Step [4200/7382], D Loss: 1.2298, G Loss: 0.9880\n",
            "Epoch [72/100], Step [4300/7382], D Loss: 1.2524, G Loss: 0.8470\n",
            "Epoch [72/100], Step [4400/7382], D Loss: 1.2403, G Loss: 0.8792\n",
            "Epoch [72/100], Step [4500/7382], D Loss: 1.2261, G Loss: 0.8902\n",
            "Epoch [72/100], Step [4600/7382], D Loss: 1.2114, G Loss: 1.0661\n",
            "Epoch [72/100], Step [4700/7382], D Loss: 1.2483, G Loss: 0.9325\n",
            "Epoch [72/100], Step [4800/7382], D Loss: 1.2594, G Loss: 0.9022\n",
            "Epoch [72/100], Step [4900/7382], D Loss: 1.2266, G Loss: 0.9930\n",
            "Epoch [72/100], Step [5000/7382], D Loss: 1.2837, G Loss: 0.8114\n",
            "Epoch [72/100], Step [5100/7382], D Loss: 1.2087, G Loss: 1.0112\n",
            "Epoch [72/100], Step [5200/7382], D Loss: 1.2324, G Loss: 0.9355\n",
            "Epoch [72/100], Step [5300/7382], D Loss: 1.2345, G Loss: 0.8861\n",
            "Epoch [72/100], Step [5400/7382], D Loss: 1.2731, G Loss: 0.8838\n",
            "Epoch [72/100], Step [5500/7382], D Loss: 1.2262, G Loss: 0.9659\n",
            "Epoch [72/100], Step [5600/7382], D Loss: 1.3593, G Loss: 0.8501\n",
            "Epoch [72/100], Step [5700/7382], D Loss: 1.2392, G Loss: 0.8598\n",
            "Epoch [72/100], Step [5800/7382], D Loss: 1.2956, G Loss: 0.7956\n",
            "Epoch [72/100], Step [5900/7382], D Loss: 1.2359, G Loss: 0.9823\n",
            "Epoch [72/100], Step [6000/7382], D Loss: 1.2765, G Loss: 0.8446\n",
            "Epoch [72/100], Step [6100/7382], D Loss: 1.2627, G Loss: 0.9101\n",
            "Epoch [72/100], Step [6200/7382], D Loss: 1.1715, G Loss: 0.9480\n",
            "Epoch [72/100], Step [6300/7382], D Loss: 1.2654, G Loss: 1.0017\n",
            "Epoch [72/100], Step [6400/7382], D Loss: 1.1570, G Loss: 0.9463\n",
            "Epoch [72/100], Step [6500/7382], D Loss: 1.0292, G Loss: 1.1583\n",
            "Epoch [72/100], Step [6600/7382], D Loss: 1.2283, G Loss: 0.9140\n",
            "Epoch [72/100], Step [6700/7382], D Loss: 1.3807, G Loss: 0.8289\n",
            "Epoch [72/100], Step [6800/7382], D Loss: 1.2154, G Loss: 0.9789\n",
            "Epoch [72/100], Step [6900/7382], D Loss: 1.2506, G Loss: 0.8946\n",
            "Epoch [72/100], Step [7000/7382], D Loss: 1.1432, G Loss: 0.9795\n",
            "Epoch [72/100], Step [7100/7382], D Loss: 1.2438, G Loss: 0.9235\n",
            "Epoch [72/100], Step [7200/7382], D Loss: 1.2365, G Loss: 0.9312\n",
            "Epoch [72/100], Step [7300/7382], D Loss: 1.3009, G Loss: 0.8341\n",
            "Epoch [73/100], Step [100/7382], D Loss: 1.2842, G Loss: 0.9292\n",
            "Epoch [73/100], Step [200/7382], D Loss: 1.2922, G Loss: 0.8667\n",
            "Epoch [73/100], Step [300/7382], D Loss: 1.3314, G Loss: 0.9113\n",
            "Epoch [73/100], Step [400/7382], D Loss: 1.4277, G Loss: 0.9252\n",
            "Epoch [73/100], Step [500/7382], D Loss: 1.2084, G Loss: 1.0138\n",
            "Epoch [73/100], Step [600/7382], D Loss: 1.2873, G Loss: 0.8691\n",
            "Epoch [73/100], Step [700/7382], D Loss: 1.2840, G Loss: 0.8387\n",
            "Epoch [73/100], Step [800/7382], D Loss: 1.3554, G Loss: 0.7734\n",
            "Epoch [73/100], Step [900/7382], D Loss: 1.2089, G Loss: 0.9605\n",
            "Epoch [73/100], Step [1000/7382], D Loss: 1.3208, G Loss: 0.8935\n",
            "Epoch [73/100], Step [1100/7382], D Loss: 1.3854, G Loss: 0.8451\n",
            "Epoch [73/100], Step [1200/7382], D Loss: 1.2497, G Loss: 0.9024\n",
            "Epoch [73/100], Step [1300/7382], D Loss: 1.1936, G Loss: 0.9989\n",
            "Epoch [73/100], Step [1400/7382], D Loss: 1.2813, G Loss: 0.8830\n",
            "Epoch [73/100], Step [1500/7382], D Loss: 1.2124, G Loss: 0.9368\n",
            "Epoch [73/100], Step [1600/7382], D Loss: 1.3119, G Loss: 0.8604\n",
            "Epoch [73/100], Step [1700/7382], D Loss: 1.2081, G Loss: 0.8975\n",
            "Epoch [73/100], Step [1800/7382], D Loss: 1.2345, G Loss: 0.9190\n",
            "Epoch [73/100], Step [1900/7382], D Loss: 1.3498, G Loss: 0.7904\n",
            "Epoch [73/100], Step [2000/7382], D Loss: 1.3265, G Loss: 0.7860\n",
            "Epoch [73/100], Step [2100/7382], D Loss: 1.2572, G Loss: 0.8931\n",
            "Epoch [73/100], Step [2200/7382], D Loss: 1.2386, G Loss: 0.9672\n",
            "Epoch [73/100], Step [2300/7382], D Loss: 1.2641, G Loss: 0.8236\n",
            "Epoch [73/100], Step [2400/7382], D Loss: 1.2810, G Loss: 0.8500\n",
            "Epoch [73/100], Step [2500/7382], D Loss: 1.2807, G Loss: 0.8925\n",
            "Epoch [73/100], Step [2600/7382], D Loss: 1.2614, G Loss: 0.8459\n",
            "Epoch [73/100], Step [2700/7382], D Loss: 1.3838, G Loss: 0.7924\n",
            "Epoch [73/100], Step [2800/7382], D Loss: 1.3706, G Loss: 0.7717\n",
            "Epoch [73/100], Step [2900/7382], D Loss: 1.2767, G Loss: 0.8414\n",
            "Epoch [73/100], Step [3000/7382], D Loss: 1.3095, G Loss: 0.8810\n",
            "Epoch [73/100], Step [3100/7382], D Loss: 1.3348, G Loss: 0.8420\n",
            "Epoch [73/100], Step [3200/7382], D Loss: 1.3021, G Loss: 0.8885\n",
            "Epoch [73/100], Step [3300/7382], D Loss: 1.2965, G Loss: 0.8730\n",
            "Epoch [73/100], Step [3400/7382], D Loss: 1.3021, G Loss: 0.8590\n",
            "Epoch [73/100], Step [3500/7382], D Loss: 1.2909, G Loss: 0.8023\n",
            "Epoch [73/100], Step [3600/7382], D Loss: 1.2806, G Loss: 0.8489\n",
            "Epoch [73/100], Step [3700/7382], D Loss: 1.2825, G Loss: 0.8437\n",
            "Epoch [73/100], Step [3800/7382], D Loss: 1.2826, G Loss: 0.9019\n",
            "Epoch [73/100], Step [3900/7382], D Loss: 1.2537, G Loss: 0.8527\n",
            "Epoch [73/100], Step [4000/7382], D Loss: 1.2897, G Loss: 0.8083\n",
            "Epoch [73/100], Step [4100/7382], D Loss: 1.2603, G Loss: 0.8303\n",
            "Epoch [73/100], Step [4200/7382], D Loss: 1.2588, G Loss: 0.7885\n",
            "Epoch [73/100], Step [4300/7382], D Loss: 1.2942, G Loss: 0.8624\n",
            "Epoch [73/100], Step [4400/7382], D Loss: 1.3529, G Loss: 0.8511\n",
            "Epoch [73/100], Step [4500/7382], D Loss: 1.3065, G Loss: 0.8848\n",
            "Epoch [73/100], Step [4600/7382], D Loss: 1.2571, G Loss: 0.9439\n",
            "Epoch [73/100], Step [4700/7382], D Loss: 1.2909, G Loss: 0.7849\n",
            "Epoch [73/100], Step [4800/7382], D Loss: 1.2046, G Loss: 1.0033\n",
            "Epoch [73/100], Step [4900/7382], D Loss: 1.2892, G Loss: 0.8349\n",
            "Epoch [73/100], Step [5000/7382], D Loss: 1.2944, G Loss: 0.8623\n",
            "Epoch [73/100], Step [5100/7382], D Loss: 1.3041, G Loss: 0.9452\n",
            "Epoch [73/100], Step [5200/7382], D Loss: 1.3552, G Loss: 0.8521\n",
            "Epoch [73/100], Step [5300/7382], D Loss: 1.4041, G Loss: 0.7825\n",
            "Epoch [73/100], Step [5400/7382], D Loss: 1.3284, G Loss: 0.8450\n",
            "Epoch [73/100], Step [5500/7382], D Loss: 1.2466, G Loss: 0.8825\n",
            "Epoch [73/100], Step [5600/7382], D Loss: 1.3052, G Loss: 0.8925\n",
            "Epoch [73/100], Step [5700/7382], D Loss: 1.3312, G Loss: 0.8606\n",
            "Epoch [73/100], Step [5800/7382], D Loss: 1.2026, G Loss: 0.8934\n",
            "Epoch [73/100], Step [5900/7382], D Loss: 1.3381, G Loss: 0.8339\n",
            "Epoch [73/100], Step [6000/7382], D Loss: 1.3132, G Loss: 0.8282\n",
            "Epoch [73/100], Step [6100/7382], D Loss: 1.3136, G Loss: 0.8135\n",
            "Epoch [73/100], Step [6200/7382], D Loss: 1.2491, G Loss: 0.8289\n",
            "Epoch [73/100], Step [6300/7382], D Loss: 1.2600, G Loss: 0.8271\n",
            "Epoch [73/100], Step [6400/7382], D Loss: 1.2288, G Loss: 0.9656\n",
            "Epoch [73/100], Step [6500/7382], D Loss: 1.2337, G Loss: 0.9043\n",
            "Epoch [73/100], Step [6600/7382], D Loss: 1.3793, G Loss: 0.8331\n",
            "Epoch [73/100], Step [6700/7382], D Loss: 1.3112, G Loss: 0.8031\n",
            "Epoch [73/100], Step [6800/7382], D Loss: 1.2802, G Loss: 0.9053\n",
            "Epoch [73/100], Step [6900/7382], D Loss: 1.2224, G Loss: 0.8122\n",
            "Epoch [73/100], Step [7000/7382], D Loss: 1.2750, G Loss: 0.8937\n",
            "Epoch [73/100], Step [7100/7382], D Loss: 1.2505, G Loss: 0.8969\n",
            "Epoch [73/100], Step [7200/7382], D Loss: 1.3404, G Loss: 0.8378\n",
            "Epoch [73/100], Step [7300/7382], D Loss: 1.2488, G Loss: 0.9054\n",
            "Epoch [74/100], Step [100/7382], D Loss: 1.3234, G Loss: 0.9276\n",
            "Epoch [74/100], Step [200/7382], D Loss: 1.2030, G Loss: 0.8972\n",
            "Epoch [74/100], Step [300/7382], D Loss: 1.2480, G Loss: 0.8573\n",
            "Epoch [74/100], Step [400/7382], D Loss: 1.2445, G Loss: 0.8927\n",
            "Epoch [74/100], Step [500/7382], D Loss: 1.2759, G Loss: 0.8685\n",
            "Epoch [74/100], Step [600/7382], D Loss: 1.3209, G Loss: 0.8135\n",
            "Epoch [74/100], Step [700/7382], D Loss: 1.2356, G Loss: 0.9406\n",
            "Epoch [74/100], Step [800/7382], D Loss: 1.1980, G Loss: 0.8913\n",
            "Epoch [74/100], Step [900/7382], D Loss: 1.1854, G Loss: 0.8931\n",
            "Epoch [74/100], Step [1000/7382], D Loss: 1.1766, G Loss: 0.9341\n",
            "Epoch [74/100], Step [1100/7382], D Loss: 1.2106, G Loss: 0.9661\n",
            "Epoch [74/100], Step [1200/7382], D Loss: 1.2967, G Loss: 0.8055\n",
            "Epoch [74/100], Step [1300/7382], D Loss: 1.2760, G Loss: 0.8038\n",
            "Epoch [74/100], Step [1400/7382], D Loss: 1.2128, G Loss: 0.9342\n",
            "Epoch [74/100], Step [1500/7382], D Loss: 1.2467, G Loss: 0.9742\n",
            "Epoch [74/100], Step [1600/7382], D Loss: 1.1291, G Loss: 1.0181\n",
            "Epoch [74/100], Step [1700/7382], D Loss: 1.2324, G Loss: 0.9661\n",
            "Epoch [74/100], Step [1800/7382], D Loss: 1.3592, G Loss: 0.8181\n",
            "Epoch [74/100], Step [1900/7382], D Loss: 1.2365, G Loss: 0.8899\n",
            "Epoch [74/100], Step [2000/7382], D Loss: 1.2427, G Loss: 0.9346\n",
            "Epoch [74/100], Step [2100/7382], D Loss: 1.2123, G Loss: 0.9867\n",
            "Epoch [74/100], Step [2200/7382], D Loss: 1.2603, G Loss: 0.9338\n",
            "Epoch [74/100], Step [2300/7382], D Loss: 1.2566, G Loss: 0.8959\n",
            "Epoch [74/100], Step [2400/7382], D Loss: 1.3151, G Loss: 0.9669\n",
            "Epoch [74/100], Step [2500/7382], D Loss: 1.2606, G Loss: 0.8304\n",
            "Epoch [74/100], Step [2600/7382], D Loss: 1.1500, G Loss: 0.9035\n",
            "Epoch [74/100], Step [2700/7382], D Loss: 1.1539, G Loss: 0.9001\n",
            "Epoch [74/100], Step [2800/7382], D Loss: 1.1693, G Loss: 0.9018\n",
            "Epoch [74/100], Step [2900/7382], D Loss: 1.2811, G Loss: 0.9548\n",
            "Epoch [74/100], Step [3000/7382], D Loss: 1.3130, G Loss: 1.0441\n",
            "Epoch [74/100], Step [3100/7382], D Loss: 1.3127, G Loss: 0.9411\n",
            "Epoch [74/100], Step [3200/7382], D Loss: 1.2416, G Loss: 0.9505\n",
            "Epoch [74/100], Step [3300/7382], D Loss: 1.3136, G Loss: 0.8595\n",
            "Epoch [74/100], Step [3400/7382], D Loss: 1.2714, G Loss: 0.8941\n",
            "Epoch [74/100], Step [3500/7382], D Loss: 1.2667, G Loss: 0.8568\n",
            "Epoch [74/100], Step [3600/7382], D Loss: 1.1469, G Loss: 1.0164\n",
            "Epoch [74/100], Step [3700/7382], D Loss: 1.2676, G Loss: 0.8729\n",
            "Epoch [74/100], Step [3800/7382], D Loss: 1.1562, G Loss: 0.9004\n",
            "Epoch [74/100], Step [3900/7382], D Loss: 1.2497, G Loss: 0.8625\n",
            "Epoch [74/100], Step [4000/7382], D Loss: 1.3150, G Loss: 0.8502\n",
            "Epoch [74/100], Step [4100/7382], D Loss: 1.3190, G Loss: 0.8172\n",
            "Epoch [74/100], Step [4200/7382], D Loss: 1.2452, G Loss: 0.9041\n",
            "Epoch [74/100], Step [4300/7382], D Loss: 1.2184, G Loss: 1.0046\n",
            "Epoch [74/100], Step [4400/7382], D Loss: 1.2843, G Loss: 0.8541\n",
            "Epoch [74/100], Step [4500/7382], D Loss: 1.2461, G Loss: 0.9325\n",
            "Epoch [74/100], Step [4600/7382], D Loss: 1.2992, G Loss: 0.8936\n",
            "Epoch [74/100], Step [4700/7382], D Loss: 1.2314, G Loss: 0.9807\n",
            "Epoch [74/100], Step [4800/7382], D Loss: 1.1890, G Loss: 0.9465\n",
            "Epoch [74/100], Step [4900/7382], D Loss: 1.2744, G Loss: 0.8571\n",
            "Epoch [74/100], Step [5000/7382], D Loss: 1.2981, G Loss: 0.8448\n",
            "Epoch [74/100], Step [5100/7382], D Loss: 1.2802, G Loss: 0.8931\n",
            "Epoch [74/100], Step [5200/7382], D Loss: 1.2523, G Loss: 0.9140\n",
            "Epoch [74/100], Step [5300/7382], D Loss: 1.2752, G Loss: 0.9432\n",
            "Epoch [74/100], Step [5400/7382], D Loss: 1.2727, G Loss: 0.8054\n",
            "Epoch [74/100], Step [5500/7382], D Loss: 1.3922, G Loss: 0.8128\n",
            "Epoch [74/100], Step [5600/7382], D Loss: 1.2194, G Loss: 0.8691\n",
            "Epoch [74/100], Step [5700/7382], D Loss: 1.2914, G Loss: 0.8296\n",
            "Epoch [74/100], Step [5800/7382], D Loss: 1.3246, G Loss: 0.8393\n",
            "Epoch [74/100], Step [5900/7382], D Loss: 1.3750, G Loss: 0.8088\n",
            "Epoch [74/100], Step [6000/7382], D Loss: 1.2887, G Loss: 0.9376\n",
            "Epoch [74/100], Step [6100/7382], D Loss: 1.2766, G Loss: 0.9195\n",
            "Epoch [74/100], Step [6200/7382], D Loss: 1.3068, G Loss: 0.8115\n",
            "Epoch [74/100], Step [6300/7382], D Loss: 1.1584, G Loss: 0.9981\n",
            "Epoch [74/100], Step [6400/7382], D Loss: 1.2423, G Loss: 0.9092\n",
            "Epoch [74/100], Step [6500/7382], D Loss: 1.2762, G Loss: 0.8630\n",
            "Epoch [74/100], Step [6600/7382], D Loss: 1.3496, G Loss: 0.9098\n",
            "Epoch [74/100], Step [6700/7382], D Loss: 1.2180, G Loss: 0.9178\n",
            "Epoch [74/100], Step [6800/7382], D Loss: 1.3152, G Loss: 0.8424\n",
            "Epoch [74/100], Step [6900/7382], D Loss: 1.2832, G Loss: 0.8280\n",
            "Epoch [74/100], Step [7000/7382], D Loss: 1.2483, G Loss: 0.8587\n",
            "Epoch [74/100], Step [7100/7382], D Loss: 1.2820, G Loss: 0.9207\n",
            "Epoch [74/100], Step [7200/7382], D Loss: 1.2586, G Loss: 0.8489\n",
            "Epoch [74/100], Step [7300/7382], D Loss: 1.2039, G Loss: 0.9321\n",
            "Epoch [75/100], Step [100/7382], D Loss: 1.3340, G Loss: 0.8334\n",
            "Epoch [75/100], Step [200/7382], D Loss: 1.2664, G Loss: 0.8884\n",
            "Epoch [75/100], Step [300/7382], D Loss: 1.2513, G Loss: 0.9410\n",
            "Epoch [75/100], Step [400/7382], D Loss: 1.3249, G Loss: 0.8477\n",
            "Epoch [75/100], Step [500/7382], D Loss: 1.2806, G Loss: 0.8757\n",
            "Epoch [75/100], Step [600/7382], D Loss: 1.2274, G Loss: 0.9563\n",
            "Epoch [75/100], Step [700/7382], D Loss: 1.3663, G Loss: 0.7992\n",
            "Epoch [75/100], Step [800/7382], D Loss: 1.2649, G Loss: 0.9584\n",
            "Epoch [75/100], Step [900/7382], D Loss: 1.3052, G Loss: 0.8263\n",
            "Epoch [75/100], Step [1000/7382], D Loss: 1.2686, G Loss: 0.9251\n",
            "Epoch [75/100], Step [1100/7382], D Loss: 1.2400, G Loss: 0.8526\n",
            "Epoch [75/100], Step [1200/7382], D Loss: 1.3059, G Loss: 0.9100\n",
            "Epoch [75/100], Step [1300/7382], D Loss: 1.2621, G Loss: 0.8911\n",
            "Epoch [75/100], Step [1400/7382], D Loss: 1.2775, G Loss: 0.8424\n",
            "Epoch [75/100], Step [1500/7382], D Loss: 1.2714, G Loss: 0.9039\n",
            "Epoch [75/100], Step [1600/7382], D Loss: 1.2585, G Loss: 0.8043\n",
            "Epoch [75/100], Step [1700/7382], D Loss: 1.1841, G Loss: 0.9337\n",
            "Epoch [75/100], Step [1800/7382], D Loss: 1.3207, G Loss: 0.9025\n",
            "Epoch [75/100], Step [1900/7382], D Loss: 1.1742, G Loss: 0.9254\n",
            "Epoch [75/100], Step [2000/7382], D Loss: 1.2657, G Loss: 0.9075\n",
            "Epoch [75/100], Step [2100/7382], D Loss: 1.3112, G Loss: 0.8118\n",
            "Epoch [75/100], Step [2200/7382], D Loss: 1.1838, G Loss: 0.8346\n",
            "Epoch [75/100], Step [2300/7382], D Loss: 1.1939, G Loss: 0.9087\n",
            "Epoch [75/100], Step [2400/7382], D Loss: 1.2253, G Loss: 1.0079\n",
            "Epoch [75/100], Step [2500/7382], D Loss: 1.2076, G Loss: 1.0237\n",
            "Epoch [75/100], Step [2600/7382], D Loss: 1.2409, G Loss: 0.8625\n",
            "Epoch [75/100], Step [2700/7382], D Loss: 1.1472, G Loss: 0.9220\n",
            "Epoch [75/100], Step [2800/7382], D Loss: 1.2064, G Loss: 0.9255\n",
            "Epoch [75/100], Step [2900/7382], D Loss: 1.2303, G Loss: 0.8834\n",
            "Epoch [75/100], Step [3000/7382], D Loss: 1.1970, G Loss: 1.1001\n",
            "Epoch [75/100], Step [3100/7382], D Loss: 1.2907, G Loss: 0.8312\n",
            "Epoch [75/100], Step [3200/7382], D Loss: 1.3515, G Loss: 0.8142\n",
            "Epoch [75/100], Step [3300/7382], D Loss: 1.2854, G Loss: 0.9538\n",
            "Epoch [75/100], Step [3400/7382], D Loss: 1.1594, G Loss: 0.9416\n",
            "Epoch [75/100], Step [3500/7382], D Loss: 1.2710, G Loss: 0.9050\n",
            "Epoch [75/100], Step [3600/7382], D Loss: 1.2931, G Loss: 0.9653\n",
            "Epoch [75/100], Step [3700/7382], D Loss: 1.2557, G Loss: 0.8572\n",
            "Epoch [75/100], Step [3800/7382], D Loss: 1.3008, G Loss: 0.9242\n",
            "Epoch [75/100], Step [3900/7382], D Loss: 1.2718, G Loss: 0.8104\n",
            "Epoch [75/100], Step [4000/7382], D Loss: 1.3134, G Loss: 0.8384\n",
            "Epoch [75/100], Step [4100/7382], D Loss: 1.3228, G Loss: 0.8223\n",
            "Epoch [75/100], Step [4200/7382], D Loss: 1.4375, G Loss: 0.7933\n",
            "Epoch [75/100], Step [4300/7382], D Loss: 1.3192, G Loss: 0.8006\n",
            "Epoch [75/100], Step [4400/7382], D Loss: 1.2669, G Loss: 0.8857\n",
            "Epoch [75/100], Step [4500/7382], D Loss: 1.3602, G Loss: 0.8329\n",
            "Epoch [75/100], Step [4600/7382], D Loss: 1.2001, G Loss: 0.9939\n",
            "Epoch [75/100], Step [4700/7382], D Loss: 1.2974, G Loss: 0.8762\n",
            "Epoch [75/100], Step [4800/7382], D Loss: 1.2714, G Loss: 0.8113\n",
            "Epoch [75/100], Step [4900/7382], D Loss: 1.2514, G Loss: 0.8668\n",
            "Epoch [75/100], Step [5000/7382], D Loss: 1.2877, G Loss: 0.9426\n",
            "Epoch [75/100], Step [5100/7382], D Loss: 1.4146, G Loss: 0.7913\n",
            "Epoch [75/100], Step [5200/7382], D Loss: 1.3360, G Loss: 0.7972\n",
            "Epoch [75/100], Step [5300/7382], D Loss: 1.2520, G Loss: 0.8943\n",
            "Epoch [75/100], Step [5400/7382], D Loss: 1.1877, G Loss: 1.0233\n",
            "Epoch [75/100], Step [5500/7382], D Loss: 1.3924, G Loss: 0.8501\n",
            "Epoch [75/100], Step [5600/7382], D Loss: 1.2148, G Loss: 1.0016\n",
            "Epoch [75/100], Step [5700/7382], D Loss: 1.3042, G Loss: 0.8464\n",
            "Epoch [75/100], Step [5800/7382], D Loss: 1.2528, G Loss: 0.8140\n",
            "Epoch [75/100], Step [5900/7382], D Loss: 1.2560, G Loss: 0.8523\n",
            "Epoch [75/100], Step [6000/7382], D Loss: 1.2372, G Loss: 0.8563\n",
            "Epoch [75/100], Step [6100/7382], D Loss: 1.2223, G Loss: 0.9456\n",
            "Epoch [75/100], Step [6200/7382], D Loss: 1.2680, G Loss: 0.8161\n",
            "Epoch [75/100], Step [6300/7382], D Loss: 1.3068, G Loss: 0.8562\n",
            "Epoch [75/100], Step [6400/7382], D Loss: 1.2920, G Loss: 0.8878\n",
            "Epoch [75/100], Step [6500/7382], D Loss: 1.2340, G Loss: 0.9086\n",
            "Epoch [75/100], Step [6600/7382], D Loss: 1.3251, G Loss: 0.8358\n",
            "Epoch [75/100], Step [6700/7382], D Loss: 1.2931, G Loss: 0.8146\n",
            "Epoch [75/100], Step [6800/7382], D Loss: 1.2854, G Loss: 0.8441\n",
            "Epoch [75/100], Step [6900/7382], D Loss: 1.2949, G Loss: 0.8017\n",
            "Epoch [75/100], Step [7000/7382], D Loss: 1.2137, G Loss: 0.9041\n",
            "Epoch [75/100], Step [7100/7382], D Loss: 1.2755, G Loss: 0.8296\n",
            "Epoch [75/100], Step [7200/7382], D Loss: 1.3289, G Loss: 0.9625\n",
            "Epoch [75/100], Step [7300/7382], D Loss: 1.2352, G Loss: 0.8651\n",
            "Epoch [76/100], Step [100/7382], D Loss: 1.2117, G Loss: 0.8648\n",
            "Epoch [76/100], Step [200/7382], D Loss: 1.2687, G Loss: 0.8255\n",
            "Epoch [76/100], Step [300/7382], D Loss: 1.2926, G Loss: 0.8224\n",
            "Epoch [76/100], Step [400/7382], D Loss: 1.3378, G Loss: 0.7876\n",
            "Epoch [76/100], Step [500/7382], D Loss: 1.2277, G Loss: 0.8172\n",
            "Epoch [76/100], Step [600/7382], D Loss: 1.3009, G Loss: 0.8870\n",
            "Epoch [76/100], Step [700/7382], D Loss: 1.3431, G Loss: 0.8761\n",
            "Epoch [76/100], Step [800/7382], D Loss: 1.2538, G Loss: 0.8781\n",
            "Epoch [76/100], Step [900/7382], D Loss: 1.1848, G Loss: 0.8645\n",
            "Epoch [76/100], Step [1000/7382], D Loss: 1.2568, G Loss: 0.8384\n",
            "Epoch [76/100], Step [1100/7382], D Loss: 1.2960, G Loss: 0.8190\n",
            "Epoch [76/100], Step [1200/7382], D Loss: 1.3333, G Loss: 0.7881\n",
            "Epoch [76/100], Step [1300/7382], D Loss: 1.3293, G Loss: 0.8416\n",
            "Epoch [76/100], Step [1400/7382], D Loss: 1.3417, G Loss: 0.8436\n",
            "Epoch [76/100], Step [1500/7382], D Loss: 1.2261, G Loss: 0.9608\n",
            "Epoch [76/100], Step [1600/7382], D Loss: 1.2787, G Loss: 0.8742\n",
            "Epoch [76/100], Step [1700/7382], D Loss: 1.3173, G Loss: 0.8424\n",
            "Epoch [76/100], Step [1800/7382], D Loss: 1.2153, G Loss: 1.0041\n",
            "Epoch [76/100], Step [1900/7382], D Loss: 1.3619, G Loss: 0.8033\n",
            "Epoch [76/100], Step [2000/7382], D Loss: 1.3058, G Loss: 0.8492\n",
            "Epoch [76/100], Step [2100/7382], D Loss: 1.3082, G Loss: 0.8670\n",
            "Epoch [76/100], Step [2200/7382], D Loss: 1.3559, G Loss: 0.7923\n",
            "Epoch [76/100], Step [2300/7382], D Loss: 1.2985, G Loss: 0.8078\n",
            "Epoch [76/100], Step [2400/7382], D Loss: 1.3577, G Loss: 0.7938\n",
            "Epoch [76/100], Step [2500/7382], D Loss: 1.3333, G Loss: 0.8333\n",
            "Epoch [76/100], Step [2600/7382], D Loss: 1.2887, G Loss: 0.8832\n",
            "Epoch [76/100], Step [2700/7382], D Loss: 1.3175, G Loss: 0.8303\n",
            "Epoch [76/100], Step [2800/7382], D Loss: 1.2438, G Loss: 0.8523\n",
            "Epoch [76/100], Step [2900/7382], D Loss: 1.3608, G Loss: 0.7800\n",
            "Epoch [76/100], Step [3000/7382], D Loss: 1.3188, G Loss: 0.8845\n",
            "Epoch [76/100], Step [3100/7382], D Loss: 1.2868, G Loss: 0.8361\n",
            "Epoch [76/100], Step [3200/7382], D Loss: 1.3097, G Loss: 0.8126\n",
            "Epoch [76/100], Step [3300/7382], D Loss: 1.3380, G Loss: 0.9400\n",
            "Epoch [76/100], Step [3400/7382], D Loss: 1.3206, G Loss: 0.9343\n",
            "Epoch [76/100], Step [3500/7382], D Loss: 1.3338, G Loss: 0.8105\n",
            "Epoch [76/100], Step [3600/7382], D Loss: 1.3293, G Loss: 0.7744\n",
            "Epoch [76/100], Step [3700/7382], D Loss: 1.3229, G Loss: 0.8352\n",
            "Epoch [76/100], Step [3800/7382], D Loss: 1.3092, G Loss: 0.7872\n",
            "Epoch [76/100], Step [3900/7382], D Loss: 1.2869, G Loss: 0.8413\n",
            "Epoch [76/100], Step [4000/7382], D Loss: 1.3366, G Loss: 0.7898\n",
            "Epoch [76/100], Step [4100/7382], D Loss: 1.2984, G Loss: 0.8731\n",
            "Epoch [76/100], Step [4200/7382], D Loss: 1.3080, G Loss: 0.8104\n",
            "Epoch [76/100], Step [4300/7382], D Loss: 1.2163, G Loss: 0.8807\n",
            "Epoch [76/100], Step [4400/7382], D Loss: 1.3113, G Loss: 0.8208\n",
            "Epoch [76/100], Step [4500/7382], D Loss: 1.3542, G Loss: 0.7777\n",
            "Epoch [76/100], Step [4600/7382], D Loss: 1.2690, G Loss: 1.0372\n",
            "Epoch [76/100], Step [4700/7382], D Loss: 1.2545, G Loss: 1.0162\n",
            "Epoch [76/100], Step [4800/7382], D Loss: 1.3796, G Loss: 0.9812\n",
            "Epoch [76/100], Step [4900/7382], D Loss: 1.3615, G Loss: 0.7149\n",
            "Epoch [76/100], Step [5000/7382], D Loss: 1.2845, G Loss: 0.8217\n",
            "Epoch [76/100], Step [5100/7382], D Loss: 1.2888, G Loss: 0.8830\n",
            "Epoch [76/100], Step [5200/7382], D Loss: 1.2187, G Loss: 0.8876\n",
            "Epoch [76/100], Step [5300/7382], D Loss: 1.2666, G Loss: 0.8128\n",
            "Epoch [76/100], Step [5400/7382], D Loss: 1.3140, G Loss: 0.8862\n",
            "Epoch [76/100], Step [5500/7382], D Loss: 1.3696, G Loss: 0.7795\n",
            "Epoch [76/100], Step [5600/7382], D Loss: 1.2949, G Loss: 0.8240\n",
            "Epoch [76/100], Step [5700/7382], D Loss: 1.4318, G Loss: 0.7584\n",
            "Epoch [76/100], Step [5800/7382], D Loss: 1.3546, G Loss: 0.7962\n",
            "Epoch [76/100], Step [5900/7382], D Loss: 1.3413, G Loss: 0.7964\n",
            "Epoch [76/100], Step [6000/7382], D Loss: 1.2662, G Loss: 0.8524\n",
            "Epoch [76/100], Step [6100/7382], D Loss: 1.3158, G Loss: 0.8119\n",
            "Epoch [76/100], Step [6200/7382], D Loss: 1.3858, G Loss: 0.7576\n",
            "Epoch [76/100], Step [6300/7382], D Loss: 1.2618, G Loss: 0.8647\n",
            "Epoch [76/100], Step [6400/7382], D Loss: 1.3059, G Loss: 0.8919\n",
            "Epoch [76/100], Step [6500/7382], D Loss: 1.2985, G Loss: 0.8352\n",
            "Epoch [76/100], Step [6600/7382], D Loss: 1.2835, G Loss: 0.9458\n",
            "Epoch [76/100], Step [6700/7382], D Loss: 1.3686, G Loss: 0.7666\n",
            "Epoch [76/100], Step [6800/7382], D Loss: 1.3179, G Loss: 0.8228\n",
            "Epoch [76/100], Step [6900/7382], D Loss: 1.3549, G Loss: 0.7937\n",
            "Epoch [76/100], Step [7000/7382], D Loss: 1.3209, G Loss: 0.8659\n",
            "Epoch [76/100], Step [7100/7382], D Loss: 1.1898, G Loss: 0.8948\n",
            "Epoch [76/100], Step [7200/7382], D Loss: 1.2915, G Loss: 0.8210\n",
            "Epoch [76/100], Step [7300/7382], D Loss: 1.3314, G Loss: 0.7936\n",
            "Epoch [77/100], Step [100/7382], D Loss: 1.3578, G Loss: 0.7720\n",
            "Epoch [77/100], Step [200/7382], D Loss: 1.3039, G Loss: 0.8242\n",
            "Epoch [77/100], Step [300/7382], D Loss: 1.3237, G Loss: 0.8666\n",
            "Epoch [77/100], Step [400/7382], D Loss: 1.3839, G Loss: 0.8064\n",
            "Epoch [77/100], Step [500/7382], D Loss: 1.3355, G Loss: 0.8819\n",
            "Epoch [77/100], Step [600/7382], D Loss: 1.2946, G Loss: 0.7800\n",
            "Epoch [77/100], Step [700/7382], D Loss: 1.3148, G Loss: 0.8739\n",
            "Epoch [77/100], Step [800/7382], D Loss: 1.3834, G Loss: 0.8024\n",
            "Epoch [77/100], Step [900/7382], D Loss: 1.3780, G Loss: 0.7872\n",
            "Epoch [77/100], Step [1000/7382], D Loss: 1.3539, G Loss: 0.8294\n",
            "Epoch [77/100], Step [1100/7382], D Loss: 1.3086, G Loss: 0.8578\n",
            "Epoch [77/100], Step [1200/7382], D Loss: 1.3030, G Loss: 0.9250\n",
            "Epoch [77/100], Step [1300/7382], D Loss: 1.4024, G Loss: 0.7592\n",
            "Epoch [77/100], Step [1400/7382], D Loss: 1.3443, G Loss: 0.8026\n",
            "Epoch [77/100], Step [1500/7382], D Loss: 1.3354, G Loss: 0.7932\n",
            "Epoch [77/100], Step [1600/7382], D Loss: 1.2676, G Loss: 0.9019\n",
            "Epoch [77/100], Step [1700/7382], D Loss: 1.2891, G Loss: 0.7710\n",
            "Epoch [77/100], Step [1800/7382], D Loss: 1.3461, G Loss: 0.8749\n",
            "Epoch [77/100], Step [1900/7382], D Loss: 1.3586, G Loss: 0.7788\n",
            "Epoch [77/100], Step [2000/7382], D Loss: 1.3160, G Loss: 0.8043\n",
            "Epoch [77/100], Step [2100/7382], D Loss: 1.3085, G Loss: 0.8511\n",
            "Epoch [77/100], Step [2200/7382], D Loss: 1.2282, G Loss: 0.9043\n",
            "Epoch [77/100], Step [2300/7382], D Loss: 1.2531, G Loss: 1.0033\n",
            "Epoch [77/100], Step [2400/7382], D Loss: 1.3255, G Loss: 0.7864\n",
            "Epoch [77/100], Step [2500/7382], D Loss: 1.3551, G Loss: 0.7865\n",
            "Epoch [77/100], Step [2600/7382], D Loss: 1.3580, G Loss: 0.7471\n",
            "Epoch [77/100], Step [2700/7382], D Loss: 1.2708, G Loss: 0.9259\n",
            "Epoch [77/100], Step [2800/7382], D Loss: 1.2923, G Loss: 0.9622\n",
            "Epoch [77/100], Step [2900/7382], D Loss: 1.3843, G Loss: 0.7565\n",
            "Epoch [77/100], Step [3000/7382], D Loss: 1.3218, G Loss: 0.7739\n",
            "Epoch [77/100], Step [3100/7382], D Loss: 1.3241, G Loss: 0.7755\n",
            "Epoch [77/100], Step [3200/7382], D Loss: 1.3023, G Loss: 0.7795\n",
            "Epoch [77/100], Step [3300/7382], D Loss: 1.3794, G Loss: 0.7985\n",
            "Epoch [77/100], Step [3400/7382], D Loss: 1.3883, G Loss: 0.7866\n",
            "Epoch [77/100], Step [3500/7382], D Loss: 1.3862, G Loss: 0.7779\n",
            "Epoch [77/100], Step [3600/7382], D Loss: 1.3997, G Loss: 0.7567\n",
            "Epoch [77/100], Step [3700/7382], D Loss: 1.2997, G Loss: 0.8401\n",
            "Epoch [77/100], Step [3800/7382], D Loss: 1.3297, G Loss: 0.8433\n",
            "Epoch [77/100], Step [3900/7382], D Loss: 1.2882, G Loss: 0.8961\n",
            "Epoch [77/100], Step [4000/7382], D Loss: 1.2446, G Loss: 0.8954\n",
            "Epoch [77/100], Step [4100/7382], D Loss: 1.3186, G Loss: 0.7851\n",
            "Epoch [77/100], Step [4200/7382], D Loss: 1.3312, G Loss: 0.8134\n",
            "Epoch [77/100], Step [4300/7382], D Loss: 1.3187, G Loss: 0.7572\n",
            "Epoch [77/100], Step [4400/7382], D Loss: 1.3419, G Loss: 0.7791\n",
            "Epoch [77/100], Step [4500/7382], D Loss: 1.3353, G Loss: 0.7759\n",
            "Epoch [77/100], Step [4600/7382], D Loss: 1.2614, G Loss: 0.8348\n",
            "Epoch [77/100], Step [4700/7382], D Loss: 1.3675, G Loss: 0.7399\n",
            "Epoch [77/100], Step [4800/7382], D Loss: 1.2504, G Loss: 0.8225\n",
            "Epoch [77/100], Step [4900/7382], D Loss: 1.3184, G Loss: 0.8352\n",
            "Epoch [77/100], Step [5000/7382], D Loss: 1.3261, G Loss: 0.7825\n",
            "Epoch [77/100], Step [5100/7382], D Loss: 1.3828, G Loss: 0.8701\n",
            "Epoch [77/100], Step [5200/7382], D Loss: 1.2836, G Loss: 0.8567\n",
            "Epoch [77/100], Step [5300/7382], D Loss: 1.3216, G Loss: 0.7445\n",
            "Epoch [77/100], Step [5400/7382], D Loss: 1.3070, G Loss: 0.9003\n",
            "Epoch [77/100], Step [5500/7382], D Loss: 1.2560, G Loss: 0.8258\n",
            "Epoch [77/100], Step [5600/7382], D Loss: 1.2973, G Loss: 0.8755\n",
            "Epoch [77/100], Step [5700/7382], D Loss: 1.3336, G Loss: 0.7988\n",
            "Epoch [77/100], Step [5800/7382], D Loss: 1.3598, G Loss: 0.8105\n",
            "Epoch [77/100], Step [5900/7382], D Loss: 1.3418, G Loss: 0.8960\n",
            "Epoch [77/100], Step [6000/7382], D Loss: 1.3111, G Loss: 0.8086\n",
            "Epoch [77/100], Step [6100/7382], D Loss: 1.3219, G Loss: 0.7658\n",
            "Epoch [77/100], Step [6200/7382], D Loss: 1.3421, G Loss: 0.7738\n",
            "Epoch [77/100], Step [6300/7382], D Loss: 1.2784, G Loss: 0.8578\n",
            "Epoch [77/100], Step [6400/7382], D Loss: 1.3596, G Loss: 0.8412\n",
            "Epoch [77/100], Step [6500/7382], D Loss: 1.2641, G Loss: 0.8874\n",
            "Epoch [77/100], Step [6600/7382], D Loss: 1.2905, G Loss: 0.8581\n",
            "Epoch [77/100], Step [6700/7382], D Loss: 1.3494, G Loss: 0.7688\n",
            "Epoch [77/100], Step [6800/7382], D Loss: 1.3297, G Loss: 0.8066\n",
            "Epoch [77/100], Step [6900/7382], D Loss: 1.3935, G Loss: 0.7786\n",
            "Epoch [77/100], Step [7000/7382], D Loss: 1.3521, G Loss: 0.8174\n",
            "Epoch [77/100], Step [7100/7382], D Loss: 1.3135, G Loss: 0.9062\n",
            "Epoch [77/100], Step [7200/7382], D Loss: 1.3322, G Loss: 0.8164\n",
            "Epoch [77/100], Step [7300/7382], D Loss: 1.2966, G Loss: 0.8901\n",
            "Epoch [78/100], Step [100/7382], D Loss: 1.3534, G Loss: 0.7867\n",
            "Epoch [78/100], Step [200/7382], D Loss: 1.3302, G Loss: 0.8984\n",
            "Epoch [78/100], Step [300/7382], D Loss: 1.2644, G Loss: 0.9611\n",
            "Epoch [78/100], Step [400/7382], D Loss: 1.3584, G Loss: 0.7724\n",
            "Epoch [78/100], Step [500/7382], D Loss: 1.2507, G Loss: 0.8576\n",
            "Epoch [78/100], Step [600/7382], D Loss: 1.3033, G Loss: 0.8770\n",
            "Epoch [78/100], Step [700/7382], D Loss: 1.3596, G Loss: 0.7945\n",
            "Epoch [78/100], Step [800/7382], D Loss: 1.4142, G Loss: 0.7650\n",
            "Epoch [78/100], Step [900/7382], D Loss: 1.3885, G Loss: 0.7128\n",
            "Epoch [78/100], Step [1000/7382], D Loss: 1.3249, G Loss: 0.8009\n",
            "Epoch [78/100], Step [1100/7382], D Loss: 1.3978, G Loss: 0.7637\n",
            "Epoch [78/100], Step [1200/7382], D Loss: 1.2917, G Loss: 0.8623\n",
            "Epoch [78/100], Step [1300/7382], D Loss: 1.3134, G Loss: 0.7945\n",
            "Epoch [78/100], Step [1400/7382], D Loss: 1.3611, G Loss: 0.7579\n",
            "Epoch [78/100], Step [1500/7382], D Loss: 1.3518, G Loss: 0.8665\n",
            "Epoch [78/100], Step [1600/7382], D Loss: 1.2881, G Loss: 0.8349\n",
            "Epoch [78/100], Step [1700/7382], D Loss: 1.4317, G Loss: 0.7625\n",
            "Epoch [78/100], Step [1800/7382], D Loss: 1.2328, G Loss: 0.9315\n",
            "Epoch [78/100], Step [1900/7382], D Loss: 1.2706, G Loss: 0.8688\n",
            "Epoch [78/100], Step [2000/7382], D Loss: 1.3190, G Loss: 0.7738\n",
            "Epoch [78/100], Step [2100/7382], D Loss: 1.3406, G Loss: 0.7788\n",
            "Epoch [78/100], Step [2200/7382], D Loss: 1.3491, G Loss: 0.8037\n",
            "Epoch [78/100], Step [2300/7382], D Loss: 1.2905, G Loss: 0.8476\n",
            "Epoch [78/100], Step [2400/7382], D Loss: 1.2854, G Loss: 0.8923\n",
            "Epoch [78/100], Step [2500/7382], D Loss: 1.3620, G Loss: 0.7828\n",
            "Epoch [78/100], Step [2600/7382], D Loss: 1.3360, G Loss: 0.8321\n",
            "Epoch [78/100], Step [2700/7382], D Loss: 1.3757, G Loss: 0.7165\n",
            "Epoch [78/100], Step [2800/7382], D Loss: 1.3416, G Loss: 0.7976\n",
            "Epoch [78/100], Step [2900/7382], D Loss: 1.3595, G Loss: 0.7808\n",
            "Epoch [78/100], Step [3000/7382], D Loss: 1.3440, G Loss: 0.7474\n",
            "Epoch [78/100], Step [3100/7382], D Loss: 1.3533, G Loss: 0.8217\n",
            "Epoch [78/100], Step [3200/7382], D Loss: 1.3277, G Loss: 0.7826\n",
            "Epoch [78/100], Step [3300/7382], D Loss: 1.3532, G Loss: 0.7464\n",
            "Epoch [78/100], Step [3400/7382], D Loss: 1.3281, G Loss: 0.8072\n",
            "Epoch [78/100], Step [3500/7382], D Loss: 1.3609, G Loss: 0.7437\n",
            "Epoch [78/100], Step [3600/7382], D Loss: 1.3196, G Loss: 0.8712\n",
            "Epoch [78/100], Step [3700/7382], D Loss: 1.3366, G Loss: 0.8275\n",
            "Epoch [78/100], Step [3800/7382], D Loss: 1.3827, G Loss: 0.7454\n",
            "Epoch [78/100], Step [3900/7382], D Loss: 1.3541, G Loss: 0.7629\n",
            "Epoch [78/100], Step [4000/7382], D Loss: 1.3488, G Loss: 0.7708\n",
            "Epoch [78/100], Step [4100/7382], D Loss: 1.3596, G Loss: 0.7770\n",
            "Epoch [78/100], Step [4200/7382], D Loss: 1.3974, G Loss: 0.8147\n",
            "Epoch [78/100], Step [4300/7382], D Loss: 1.5045, G Loss: 0.7377\n",
            "Epoch [78/100], Step [4400/7382], D Loss: 1.2617, G Loss: 0.8347\n",
            "Epoch [78/100], Step [4500/7382], D Loss: 1.3302, G Loss: 0.7959\n",
            "Epoch [78/100], Step [4600/7382], D Loss: 1.3327, G Loss: 0.8715\n",
            "Epoch [78/100], Step [4700/7382], D Loss: 1.3952, G Loss: 0.7266\n",
            "Epoch [78/100], Step [4800/7382], D Loss: 1.2992, G Loss: 0.7607\n",
            "Epoch [78/100], Step [4900/7382], D Loss: 1.4036, G Loss: 0.7149\n",
            "Epoch [78/100], Step [5000/7382], D Loss: 1.3148, G Loss: 0.8305\n",
            "Epoch [78/100], Step [5100/7382], D Loss: 1.3249, G Loss: 0.7510\n",
            "Epoch [78/100], Step [5200/7382], D Loss: 1.3237, G Loss: 0.8766\n",
            "Epoch [78/100], Step [5300/7382], D Loss: 1.3201, G Loss: 0.8322\n",
            "Epoch [78/100], Step [5400/7382], D Loss: 1.3042, G Loss: 0.8923\n",
            "Epoch [78/100], Step [5500/7382], D Loss: 1.2705, G Loss: 0.8162\n",
            "Epoch [78/100], Step [5600/7382], D Loss: 1.2923, G Loss: 0.8152\n",
            "Epoch [78/100], Step [5700/7382], D Loss: 1.3424, G Loss: 0.8123\n",
            "Epoch [78/100], Step [5800/7382], D Loss: 1.2698, G Loss: 0.8893\n",
            "Epoch [78/100], Step [5900/7382], D Loss: 1.3340, G Loss: 0.8806\n",
            "Epoch [78/100], Step [6000/7382], D Loss: 1.2711, G Loss: 0.8325\n",
            "Epoch [78/100], Step [6100/7382], D Loss: 1.2865, G Loss: 0.9409\n",
            "Epoch [78/100], Step [6200/7382], D Loss: 1.3081, G Loss: 0.8740\n",
            "Epoch [78/100], Step [6300/7382], D Loss: 1.2952, G Loss: 0.7900\n",
            "Epoch [78/100], Step [6400/7382], D Loss: 1.2439, G Loss: 0.9460\n",
            "Epoch [78/100], Step [6500/7382], D Loss: 1.3417, G Loss: 0.7587\n",
            "Epoch [78/100], Step [6600/7382], D Loss: 1.3585, G Loss: 0.8633\n",
            "Epoch [78/100], Step [6700/7382], D Loss: 1.3764, G Loss: 0.7510\n",
            "Epoch [78/100], Step [6800/7382], D Loss: 1.3194, G Loss: 0.8862\n",
            "Epoch [78/100], Step [6900/7382], D Loss: 1.3544, G Loss: 0.7742\n",
            "Epoch [78/100], Step [7000/7382], D Loss: 1.2645, G Loss: 0.7710\n",
            "Epoch [78/100], Step [7100/7382], D Loss: 1.3642, G Loss: 0.7645\n",
            "Epoch [78/100], Step [7200/7382], D Loss: 1.3160, G Loss: 0.8520\n",
            "Epoch [78/100], Step [7300/7382], D Loss: 1.2828, G Loss: 0.8109\n",
            "Epoch [79/100], Step [100/7382], D Loss: 1.3618, G Loss: 0.7505\n",
            "Epoch [79/100], Step [200/7382], D Loss: 1.3301, G Loss: 0.7493\n",
            "Epoch [79/100], Step [300/7382], D Loss: 1.3696, G Loss: 0.8393\n",
            "Epoch [79/100], Step [400/7382], D Loss: 1.3482, G Loss: 0.8128\n",
            "Epoch [79/100], Step [500/7382], D Loss: 1.4046, G Loss: 0.7825\n",
            "Epoch [79/100], Step [600/7382], D Loss: 1.3172, G Loss: 0.8375\n",
            "Epoch [79/100], Step [700/7382], D Loss: 1.2874, G Loss: 0.8704\n",
            "Epoch [79/100], Step [800/7382], D Loss: 1.3363, G Loss: 0.8410\n",
            "Epoch [79/100], Step [900/7382], D Loss: 1.3515, G Loss: 0.7460\n",
            "Epoch [79/100], Step [1000/7382], D Loss: 1.2405, G Loss: 0.8333\n",
            "Epoch [79/100], Step [1100/7382], D Loss: 1.3396, G Loss: 0.7548\n",
            "Epoch [79/100], Step [1200/7382], D Loss: 1.4065, G Loss: 0.7491\n",
            "Epoch [79/100], Step [1300/7382], D Loss: 1.3101, G Loss: 0.7947\n",
            "Epoch [79/100], Step [1400/7382], D Loss: 1.3981, G Loss: 0.7102\n",
            "Epoch [79/100], Step [1500/7382], D Loss: 1.3481, G Loss: 0.7409\n",
            "Epoch [79/100], Step [1600/7382], D Loss: 1.3716, G Loss: 0.8504\n",
            "Epoch [79/100], Step [1700/7382], D Loss: 1.3234, G Loss: 0.7812\n",
            "Epoch [79/100], Step [1800/7382], D Loss: 1.3080, G Loss: 0.7892\n",
            "Epoch [79/100], Step [1900/7382], D Loss: 1.3461, G Loss: 0.8884\n",
            "Epoch [79/100], Step [2000/7382], D Loss: 1.3229, G Loss: 0.7455\n",
            "Epoch [79/100], Step [2100/7382], D Loss: 1.3620, G Loss: 0.7336\n",
            "Epoch [79/100], Step [2200/7382], D Loss: 1.3802, G Loss: 0.7588\n",
            "Epoch [79/100], Step [2300/7382], D Loss: 1.3134, G Loss: 0.9183\n",
            "Epoch [79/100], Step [2400/7382], D Loss: 1.2999, G Loss: 0.8181\n",
            "Epoch [79/100], Step [2500/7382], D Loss: 1.3192, G Loss: 0.8223\n",
            "Epoch [79/100], Step [2600/7382], D Loss: 1.3127, G Loss: 0.7847\n",
            "Epoch [79/100], Step [2700/7382], D Loss: 1.2871, G Loss: 0.8106\n",
            "Epoch [79/100], Step [2800/7382], D Loss: 1.3248, G Loss: 0.7420\n",
            "Epoch [79/100], Step [2900/7382], D Loss: 1.3362, G Loss: 0.7733\n",
            "Epoch [79/100], Step [3000/7382], D Loss: 1.3725, G Loss: 0.7677\n",
            "Epoch [79/100], Step [3100/7382], D Loss: 1.3277, G Loss: 0.7900\n",
            "Epoch [79/100], Step [3200/7382], D Loss: 1.3494, G Loss: 0.7888\n",
            "Epoch [79/100], Step [3300/7382], D Loss: 1.3228, G Loss: 0.7907\n",
            "Epoch [79/100], Step [3400/7382], D Loss: 1.3874, G Loss: 0.8225\n",
            "Epoch [79/100], Step [3500/7382], D Loss: 1.3420, G Loss: 0.7721\n",
            "Epoch [79/100], Step [3600/7382], D Loss: 1.4035, G Loss: 0.9187\n",
            "Epoch [79/100], Step [3700/7382], D Loss: 1.3255, G Loss: 0.8064\n",
            "Epoch [79/100], Step [3800/7382], D Loss: 1.2682, G Loss: 0.8376\n",
            "Epoch [79/100], Step [3900/7382], D Loss: 1.3210, G Loss: 0.7789\n",
            "Epoch [79/100], Step [4000/7382], D Loss: 1.2849, G Loss: 0.8560\n",
            "Epoch [79/100], Step [4100/7382], D Loss: 1.3862, G Loss: 0.7633\n",
            "Epoch [79/100], Step [4200/7382], D Loss: 1.3650, G Loss: 0.7784\n",
            "Epoch [79/100], Step [4300/7382], D Loss: 1.3691, G Loss: 0.7072\n",
            "Epoch [79/100], Step [4400/7382], D Loss: 1.2620, G Loss: 0.8886\n",
            "Epoch [79/100], Step [4500/7382], D Loss: 1.3658, G Loss: 0.7862\n",
            "Epoch [79/100], Step [4600/7382], D Loss: 1.3500, G Loss: 0.7907\n",
            "Epoch [79/100], Step [4700/7382], D Loss: 1.3639, G Loss: 0.7379\n",
            "Epoch [79/100], Step [4800/7382], D Loss: 1.3133, G Loss: 0.7757\n",
            "Epoch [79/100], Step [4900/7382], D Loss: 1.2810, G Loss: 0.8166\n",
            "Epoch [79/100], Step [5000/7382], D Loss: 1.3143, G Loss: 0.8211\n",
            "Epoch [79/100], Step [5100/7382], D Loss: 1.3023, G Loss: 0.7585\n",
            "Epoch [79/100], Step [5200/7382], D Loss: 1.3233, G Loss: 0.8207\n",
            "Epoch [79/100], Step [5300/7382], D Loss: 1.3401, G Loss: 0.8630\n",
            "Epoch [79/100], Step [5400/7382], D Loss: 1.3430, G Loss: 0.7841\n",
            "Epoch [79/100], Step [5500/7382], D Loss: 1.3643, G Loss: 0.7401\n",
            "Epoch [79/100], Step [5600/7382], D Loss: 1.3388, G Loss: 0.7587\n",
            "Epoch [79/100], Step [5700/7382], D Loss: 1.3481, G Loss: 0.7821\n",
            "Epoch [79/100], Step [5800/7382], D Loss: 1.3090, G Loss: 0.8531\n",
            "Epoch [79/100], Step [5900/7382], D Loss: 1.3783, G Loss: 0.7762\n",
            "Epoch [79/100], Step [6000/7382], D Loss: 1.3472, G Loss: 0.8983\n",
            "Epoch [79/100], Step [6100/7382], D Loss: 1.2827, G Loss: 0.8921\n",
            "Epoch [79/100], Step [6200/7382], D Loss: 1.3222, G Loss: 0.7646\n",
            "Epoch [79/100], Step [6300/7382], D Loss: 1.2896, G Loss: 0.8200\n",
            "Epoch [79/100], Step [6400/7382], D Loss: 1.3757, G Loss: 0.7410\n",
            "Epoch [79/100], Step [6500/7382], D Loss: 1.3373, G Loss: 0.8458\n",
            "Epoch [79/100], Step [6600/7382], D Loss: 1.3749, G Loss: 0.9115\n",
            "Epoch [79/100], Step [6700/7382], D Loss: 1.3434, G Loss: 0.8123\n",
            "Epoch [79/100], Step [6800/7382], D Loss: 1.3312, G Loss: 0.7651\n",
            "Epoch [79/100], Step [6900/7382], D Loss: 1.4211, G Loss: 0.7129\n",
            "Epoch [79/100], Step [7000/7382], D Loss: 1.2724, G Loss: 0.8746\n",
            "Epoch [79/100], Step [7100/7382], D Loss: 1.4021, G Loss: 0.8738\n",
            "Epoch [79/100], Step [7200/7382], D Loss: 1.4072, G Loss: 0.7512\n",
            "Epoch [79/100], Step [7300/7382], D Loss: 1.3668, G Loss: 0.7477\n",
            "Epoch [80/100], Step [100/7382], D Loss: 1.3161, G Loss: 0.8875\n",
            "Epoch [80/100], Step [200/7382], D Loss: 1.3709, G Loss: 0.7705\n",
            "Epoch [80/100], Step [300/7382], D Loss: 1.3748, G Loss: 0.7237\n",
            "Epoch [80/100], Step [400/7382], D Loss: 1.3329, G Loss: 0.7863\n",
            "Epoch [80/100], Step [500/7382], D Loss: 1.3411, G Loss: 0.7751\n",
            "Epoch [80/100], Step [600/7382], D Loss: 1.3984, G Loss: 0.7701\n",
            "Epoch [80/100], Step [700/7382], D Loss: 1.3234, G Loss: 0.8142\n",
            "Epoch [80/100], Step [800/7382], D Loss: 1.4067, G Loss: 0.7505\n",
            "Epoch [80/100], Step [900/7382], D Loss: 1.3694, G Loss: 0.7788\n",
            "Epoch [80/100], Step [1000/7382], D Loss: 1.2718, G Loss: 0.8415\n",
            "Epoch [80/100], Step [1100/7382], D Loss: 1.3224, G Loss: 0.8445\n",
            "Epoch [80/100], Step [1200/7382], D Loss: 1.2747, G Loss: 0.8581\n",
            "Epoch [80/100], Step [1300/7382], D Loss: 1.2823, G Loss: 0.8598\n",
            "Epoch [80/100], Step [1400/7382], D Loss: 1.3848, G Loss: 0.7898\n",
            "Epoch [80/100], Step [1500/7382], D Loss: 1.3653, G Loss: 0.8320\n",
            "Epoch [80/100], Step [1600/7382], D Loss: 1.3385, G Loss: 0.7694\n",
            "Epoch [80/100], Step [1700/7382], D Loss: 1.3052, G Loss: 0.8520\n",
            "Epoch [80/100], Step [1800/7382], D Loss: 1.3676, G Loss: 0.7317\n",
            "Epoch [80/100], Step [1900/7382], D Loss: 1.3030, G Loss: 0.7445\n",
            "Epoch [80/100], Step [2000/7382], D Loss: 1.3145, G Loss: 0.7907\n",
            "Epoch [80/100], Step [2100/7382], D Loss: 1.3012, G Loss: 0.7812\n",
            "Epoch [80/100], Step [2200/7382], D Loss: 1.3014, G Loss: 0.9449\n",
            "Epoch [80/100], Step [2300/7382], D Loss: 1.3818, G Loss: 0.7082\n",
            "Epoch [80/100], Step [2400/7382], D Loss: 1.3105, G Loss: 0.7781\n",
            "Epoch [80/100], Step [2500/7382], D Loss: 1.3129, G Loss: 0.7793\n",
            "Epoch [80/100], Step [2600/7382], D Loss: 1.3164, G Loss: 0.8060\n",
            "Epoch [80/100], Step [2700/7382], D Loss: 1.3477, G Loss: 0.8639\n",
            "Epoch [80/100], Step [2800/7382], D Loss: 1.4004, G Loss: 0.7510\n",
            "Epoch [80/100], Step [2900/7382], D Loss: 1.3562, G Loss: 0.7832\n",
            "Epoch [80/100], Step [3000/7382], D Loss: 1.3254, G Loss: 0.7553\n",
            "Epoch [80/100], Step [3100/7382], D Loss: 1.2992, G Loss: 0.8069\n",
            "Epoch [80/100], Step [3200/7382], D Loss: 1.2857, G Loss: 0.8894\n",
            "Epoch [80/100], Step [3300/7382], D Loss: 1.3400, G Loss: 0.7683\n",
            "Epoch [80/100], Step [3400/7382], D Loss: 1.3538, G Loss: 0.7354\n",
            "Epoch [80/100], Step [3500/7382], D Loss: 1.3269, G Loss: 0.7903\n",
            "Epoch [80/100], Step [3600/7382], D Loss: 1.2942, G Loss: 0.8639\n",
            "Epoch [80/100], Step [3700/7382], D Loss: 1.3361, G Loss: 0.8689\n",
            "Epoch [80/100], Step [3800/7382], D Loss: 1.3437, G Loss: 0.8203\n",
            "Epoch [80/100], Step [3900/7382], D Loss: 1.4116, G Loss: 0.7491\n",
            "Epoch [80/100], Step [4000/7382], D Loss: 1.3167, G Loss: 0.7709\n",
            "Epoch [80/100], Step [4100/7382], D Loss: 1.3601, G Loss: 0.7428\n",
            "Epoch [80/100], Step [4200/7382], D Loss: 1.3554, G Loss: 0.7301\n",
            "Epoch [80/100], Step [4300/7382], D Loss: 1.3336, G Loss: 0.7827\n",
            "Epoch [80/100], Step [4400/7382], D Loss: 1.3110, G Loss: 0.7794\n",
            "Epoch [80/100], Step [4500/7382], D Loss: 1.3591, G Loss: 0.7641\n",
            "Epoch [80/100], Step [4600/7382], D Loss: 1.2690, G Loss: 0.9044\n",
            "Epoch [80/100], Step [4700/7382], D Loss: 1.3463, G Loss: 0.8001\n",
            "Epoch [80/100], Step [4800/7382], D Loss: 1.3041, G Loss: 0.8905\n",
            "Epoch [80/100], Step [4900/7382], D Loss: 1.3526, G Loss: 0.7718\n",
            "Epoch [80/100], Step [5000/7382], D Loss: 1.3224, G Loss: 0.7536\n",
            "Epoch [80/100], Step [5100/7382], D Loss: 1.2882, G Loss: 0.7897\n",
            "Epoch [80/100], Step [5200/7382], D Loss: 1.2194, G Loss: 0.8362\n",
            "Epoch [80/100], Step [5300/7382], D Loss: 1.3202, G Loss: 0.9068\n",
            "Epoch [80/100], Step [5400/7382], D Loss: 1.3450, G Loss: 0.7951\n",
            "Epoch [80/100], Step [5500/7382], D Loss: 1.3213, G Loss: 0.7849\n",
            "Epoch [80/100], Step [5600/7382], D Loss: 1.2755, G Loss: 0.8074\n",
            "Epoch [80/100], Step [5700/7382], D Loss: 1.2677, G Loss: 0.8465\n",
            "Epoch [80/100], Step [5800/7382], D Loss: 1.2763, G Loss: 0.8728\n",
            "Epoch [80/100], Step [5900/7382], D Loss: 1.3417, G Loss: 0.8110\n",
            "Epoch [80/100], Step [6000/7382], D Loss: 1.3743, G Loss: 0.8025\n",
            "Epoch [80/100], Step [6100/7382], D Loss: 1.3399, G Loss: 0.7803\n",
            "Epoch [80/100], Step [6200/7382], D Loss: 1.2810, G Loss: 0.8497\n",
            "Epoch [80/100], Step [6300/7382], D Loss: 1.3438, G Loss: 0.8222\n",
            "Epoch [80/100], Step [6400/7382], D Loss: 1.3331, G Loss: 0.8326\n",
            "Epoch [80/100], Step [6500/7382], D Loss: 1.3789, G Loss: 0.7210\n",
            "Epoch [80/100], Step [6600/7382], D Loss: 1.3314, G Loss: 0.8400\n",
            "Epoch [80/100], Step [6700/7382], D Loss: 1.3110, G Loss: 0.8412\n",
            "Epoch [80/100], Step [6800/7382], D Loss: 1.3720, G Loss: 0.7689\n",
            "Epoch [80/100], Step [6900/7382], D Loss: 1.2514, G Loss: 0.8276\n",
            "Epoch [80/100], Step [7000/7382], D Loss: 1.3689, G Loss: 0.7796\n",
            "Epoch [80/100], Step [7100/7382], D Loss: 1.2816, G Loss: 0.8959\n",
            "Epoch [80/100], Step [7200/7382], D Loss: 1.3702, G Loss: 0.7646\n",
            "Epoch [80/100], Step [7300/7382], D Loss: 1.4188, G Loss: 0.8293\n",
            "Epoch [81/100], Step [100/7382], D Loss: 1.3743, G Loss: 0.8211\n",
            "Epoch [81/100], Step [200/7382], D Loss: 1.3498, G Loss: 0.7642\n",
            "Epoch [81/100], Step [300/7382], D Loss: 1.3231, G Loss: 0.7951\n",
            "Epoch [81/100], Step [400/7382], D Loss: 1.3419, G Loss: 0.8148\n",
            "Epoch [81/100], Step [500/7382], D Loss: 1.3195, G Loss: 0.7674\n",
            "Epoch [81/100], Step [600/7382], D Loss: 1.3099, G Loss: 0.8780\n",
            "Epoch [81/100], Step [700/7382], D Loss: 1.3095, G Loss: 0.8716\n",
            "Epoch [81/100], Step [800/7382], D Loss: 1.3808, G Loss: 0.7460\n",
            "Epoch [81/100], Step [900/7382], D Loss: 1.3156, G Loss: 0.7869\n",
            "Epoch [81/100], Step [1000/7382], D Loss: 1.3124, G Loss: 0.7859\n",
            "Epoch [81/100], Step [1100/7382], D Loss: 1.3342, G Loss: 0.7558\n",
            "Epoch [81/100], Step [1200/7382], D Loss: 1.3167, G Loss: 0.8041\n",
            "Epoch [81/100], Step [1300/7382], D Loss: 1.3709, G Loss: 0.7078\n",
            "Epoch [81/100], Step [1400/7382], D Loss: 1.3088, G Loss: 0.8032\n",
            "Epoch [81/100], Step [1500/7382], D Loss: 1.2980, G Loss: 0.8863\n",
            "Epoch [81/100], Step [1600/7382], D Loss: 1.4360, G Loss: 0.7856\n",
            "Epoch [81/100], Step [1700/7382], D Loss: 1.3290, G Loss: 0.8024\n",
            "Epoch [81/100], Step [1800/7382], D Loss: 1.3625, G Loss: 0.9714\n",
            "Epoch [81/100], Step [1900/7382], D Loss: 1.3264, G Loss: 0.8162\n",
            "Epoch [81/100], Step [2000/7382], D Loss: 1.3510, G Loss: 0.9198\n",
            "Epoch [81/100], Step [2100/7382], D Loss: 1.2796, G Loss: 0.7975\n",
            "Epoch [81/100], Step [2200/7382], D Loss: 1.3158, G Loss: 0.8522\n",
            "Epoch [81/100], Step [2300/7382], D Loss: 1.3349, G Loss: 0.8433\n",
            "Epoch [81/100], Step [2400/7382], D Loss: 1.3011, G Loss: 0.7846\n",
            "Epoch [81/100], Step [2500/7382], D Loss: 1.3254, G Loss: 0.8482\n",
            "Epoch [81/100], Step [2600/7382], D Loss: 1.2730, G Loss: 0.8932\n",
            "Epoch [81/100], Step [2700/7382], D Loss: 1.3665, G Loss: 0.7737\n",
            "Epoch [81/100], Step [2800/7382], D Loss: 1.3359, G Loss: 0.8066\n",
            "Epoch [81/100], Step [2900/7382], D Loss: 1.2718, G Loss: 0.7932\n",
            "Epoch [81/100], Step [3000/7382], D Loss: 1.2566, G Loss: 0.9528\n",
            "Epoch [81/100], Step [3100/7382], D Loss: 1.2665, G Loss: 0.8253\n",
            "Epoch [81/100], Step [3200/7382], D Loss: 1.3025, G Loss: 0.8582\n",
            "Epoch [81/100], Step [3300/7382], D Loss: 1.2964, G Loss: 0.9361\n",
            "Epoch [81/100], Step [3400/7382], D Loss: 1.2395, G Loss: 0.8527\n",
            "Epoch [81/100], Step [3500/7382], D Loss: 1.2055, G Loss: 1.2645\n",
            "Epoch [81/100], Step [3600/7382], D Loss: 1.3806, G Loss: 0.7773\n",
            "Epoch [81/100], Step [3700/7382], D Loss: 1.3840, G Loss: 0.7975\n",
            "Epoch [81/100], Step [3800/7382], D Loss: 1.3188, G Loss: 0.8926\n",
            "Epoch [81/100], Step [3900/7382], D Loss: 1.3386, G Loss: 0.8843\n",
            "Epoch [81/100], Step [4000/7382], D Loss: 1.3750, G Loss: 0.8741\n",
            "Epoch [81/100], Step [4100/7382], D Loss: 1.3234, G Loss: 0.8999\n",
            "Epoch [81/100], Step [4200/7382], D Loss: 1.3302, G Loss: 0.8552\n",
            "Epoch [81/100], Step [4300/7382], D Loss: 1.2829, G Loss: 0.8375\n",
            "Epoch [81/100], Step [4400/7382], D Loss: 1.3108, G Loss: 0.9227\n",
            "Epoch [81/100], Step [4500/7382], D Loss: 1.3201, G Loss: 0.8390\n",
            "Epoch [81/100], Step [4600/7382], D Loss: 1.3093, G Loss: 0.7844\n",
            "Epoch [81/100], Step [4700/7382], D Loss: 1.2917, G Loss: 0.7717\n",
            "Epoch [81/100], Step [4800/7382], D Loss: 1.2905, G Loss: 0.8108\n",
            "Epoch [81/100], Step [4900/7382], D Loss: 1.3055, G Loss: 0.8307\n",
            "Epoch [81/100], Step [5000/7382], D Loss: 1.3626, G Loss: 0.7741\n",
            "Epoch [81/100], Step [5100/7382], D Loss: 1.3880, G Loss: 0.7929\n",
            "Epoch [81/100], Step [5200/7382], D Loss: 1.3275, G Loss: 0.8748\n",
            "Epoch [81/100], Step [5300/7382], D Loss: 1.3531, G Loss: 0.8298\n",
            "Epoch [81/100], Step [5400/7382], D Loss: 1.2646, G Loss: 0.8349\n",
            "Epoch [81/100], Step [5500/7382], D Loss: 1.3191, G Loss: 0.8617\n",
            "Epoch [81/100], Step [5600/7382], D Loss: 1.3427, G Loss: 0.7978\n",
            "Epoch [81/100], Step [5700/7382], D Loss: 1.2806, G Loss: 0.9059\n",
            "Epoch [81/100], Step [5800/7382], D Loss: 1.3783, G Loss: 0.8324\n",
            "Epoch [81/100], Step [5900/7382], D Loss: 1.2385, G Loss: 0.8624\n",
            "Epoch [81/100], Step [6000/7382], D Loss: 1.2557, G Loss: 0.8631\n",
            "Epoch [81/100], Step [6100/7382], D Loss: 1.2537, G Loss: 0.8482\n",
            "Epoch [81/100], Step [6200/7382], D Loss: 1.2958, G Loss: 0.8014\n",
            "Epoch [81/100], Step [6300/7382], D Loss: 1.3662, G Loss: 0.9035\n",
            "Epoch [81/100], Step [6400/7382], D Loss: 1.3040, G Loss: 0.8740\n",
            "Epoch [81/100], Step [6500/7382], D Loss: 1.3585, G Loss: 0.8457\n",
            "Epoch [81/100], Step [6600/7382], D Loss: 1.2956, G Loss: 0.8293\n",
            "Epoch [81/100], Step [6700/7382], D Loss: 1.3050, G Loss: 1.0598\n",
            "Epoch [81/100], Step [6800/7382], D Loss: 1.2938, G Loss: 0.8318\n",
            "Epoch [81/100], Step [6900/7382], D Loss: 1.2625, G Loss: 0.8354\n",
            "Epoch [81/100], Step [7000/7382], D Loss: 1.2787, G Loss: 0.9650\n",
            "Epoch [81/100], Step [7100/7382], D Loss: 1.2586, G Loss: 0.9575\n",
            "Epoch [81/100], Step [7200/7382], D Loss: 1.1739, G Loss: 1.1859\n",
            "Epoch [81/100], Step [7300/7382], D Loss: 1.2837, G Loss: 0.8531\n",
            "Epoch [82/100], Step [100/7382], D Loss: 1.2863, G Loss: 0.9252\n",
            "Epoch [82/100], Step [200/7382], D Loss: 1.3527, G Loss: 0.7523\n",
            "Epoch [82/100], Step [300/7382], D Loss: 1.3605, G Loss: 0.7478\n",
            "Epoch [82/100], Step [400/7382], D Loss: 1.3000, G Loss: 0.9307\n",
            "Epoch [82/100], Step [500/7382], D Loss: 1.2468, G Loss: 0.9962\n",
            "Epoch [82/100], Step [600/7382], D Loss: 1.3037, G Loss: 0.8806\n",
            "Epoch [82/100], Step [700/7382], D Loss: 1.2589, G Loss: 0.8949\n",
            "Epoch [82/100], Step [800/7382], D Loss: 1.2666, G Loss: 0.9031\n",
            "Epoch [82/100], Step [900/7382], D Loss: 1.3489, G Loss: 0.8856\n",
            "Epoch [82/100], Step [1000/7382], D Loss: 1.3288, G Loss: 0.8991\n",
            "Epoch [82/100], Step [1100/7382], D Loss: 1.2864, G Loss: 0.8461\n",
            "Epoch [82/100], Step [1200/7382], D Loss: 1.3243, G Loss: 0.7813\n",
            "Epoch [82/100], Step [1300/7382], D Loss: 1.3510, G Loss: 0.8520\n",
            "Epoch [82/100], Step [1400/7382], D Loss: 1.3164, G Loss: 0.8498\n",
            "Epoch [82/100], Step [1500/7382], D Loss: 1.2595, G Loss: 0.9615\n",
            "Epoch [82/100], Step [1600/7382], D Loss: 1.2818, G Loss: 0.8295\n",
            "Epoch [82/100], Step [1700/7382], D Loss: 1.2978, G Loss: 0.7958\n",
            "Epoch [82/100], Step [1800/7382], D Loss: 1.2925, G Loss: 0.8921\n",
            "Epoch [82/100], Step [1900/7382], D Loss: 1.3228, G Loss: 0.7745\n",
            "Epoch [82/100], Step [2000/7382], D Loss: 1.2641, G Loss: 0.8738\n",
            "Epoch [82/100], Step [2100/7382], D Loss: 1.2754, G Loss: 0.8856\n",
            "Epoch [82/100], Step [2200/7382], D Loss: 1.3271, G Loss: 0.8633\n",
            "Epoch [82/100], Step [2300/7382], D Loss: 1.2253, G Loss: 1.0344\n",
            "Epoch [82/100], Step [2400/7382], D Loss: 1.3368, G Loss: 0.8229\n",
            "Epoch [82/100], Step [2500/7382], D Loss: 1.3576, G Loss: 0.8418\n",
            "Epoch [82/100], Step [2600/7382], D Loss: 1.3515, G Loss: 0.7762\n",
            "Epoch [82/100], Step [2700/7382], D Loss: 1.2361, G Loss: 0.9345\n",
            "Epoch [82/100], Step [2800/7382], D Loss: 1.3016, G Loss: 0.8611\n",
            "Epoch [82/100], Step [2900/7382], D Loss: 1.3254, G Loss: 0.8556\n",
            "Epoch [82/100], Step [3000/7382], D Loss: 1.3389, G Loss: 0.8236\n",
            "Epoch [82/100], Step [3100/7382], D Loss: 1.2886, G Loss: 0.7878\n",
            "Epoch [82/100], Step [3200/7382], D Loss: 1.3451, G Loss: 0.7897\n",
            "Epoch [82/100], Step [3300/7382], D Loss: 1.2813, G Loss: 0.8199\n",
            "Epoch [82/100], Step [3400/7382], D Loss: 1.2175, G Loss: 0.9011\n",
            "Epoch [82/100], Step [3500/7382], D Loss: 1.2598, G Loss: 0.8227\n",
            "Epoch [82/100], Step [3600/7382], D Loss: 1.3937, G Loss: 0.7416\n",
            "Epoch [82/100], Step [3700/7382], D Loss: 1.3812, G Loss: 0.8182\n",
            "Epoch [82/100], Step [3800/7382], D Loss: 1.3592, G Loss: 0.7941\n",
            "Epoch [82/100], Step [3900/7382], D Loss: 1.3725, G Loss: 0.8826\n",
            "Epoch [82/100], Step [4000/7382], D Loss: 1.2833, G Loss: 0.8166\n",
            "Epoch [82/100], Step [4100/7382], D Loss: 1.3931, G Loss: 0.7997\n",
            "Epoch [82/100], Step [4200/7382], D Loss: 1.3443, G Loss: 0.8490\n",
            "Epoch [82/100], Step [4300/7382], D Loss: 1.3879, G Loss: 0.7521\n",
            "Epoch [82/100], Step [4400/7382], D Loss: 1.3073, G Loss: 0.8125\n",
            "Epoch [82/100], Step [4500/7382], D Loss: 1.3006, G Loss: 0.8080\n",
            "Epoch [82/100], Step [4600/7382], D Loss: 1.3561, G Loss: 0.8135\n",
            "Epoch [82/100], Step [4700/7382], D Loss: 1.3637, G Loss: 0.8006\n",
            "Epoch [82/100], Step [4800/7382], D Loss: 1.3480, G Loss: 0.9520\n",
            "Epoch [82/100], Step [4900/7382], D Loss: 1.3830, G Loss: 0.9303\n",
            "Epoch [82/100], Step [5000/7382], D Loss: 1.3168, G Loss: 0.8412\n",
            "Epoch [82/100], Step [5100/7382], D Loss: 1.4193, G Loss: 0.7892\n",
            "Epoch [82/100], Step [5200/7382], D Loss: 1.2834, G Loss: 0.9009\n",
            "Epoch [82/100], Step [5300/7382], D Loss: 1.3582, G Loss: 0.8100\n",
            "Epoch [82/100], Step [5400/7382], D Loss: 1.3346, G Loss: 0.8106\n",
            "Epoch [82/100], Step [5500/7382], D Loss: 1.3458, G Loss: 0.7666\n",
            "Epoch [82/100], Step [5600/7382], D Loss: 1.3616, G Loss: 0.7469\n",
            "Epoch [82/100], Step [5700/7382], D Loss: 1.3123, G Loss: 0.7536\n",
            "Epoch [82/100], Step [5800/7382], D Loss: 1.3546, G Loss: 0.8696\n",
            "Epoch [82/100], Step [5900/7382], D Loss: 1.3276, G Loss: 0.8415\n",
            "Epoch [82/100], Step [6000/7382], D Loss: 1.3899, G Loss: 0.7800\n",
            "Epoch [82/100], Step [6100/7382], D Loss: 1.3059, G Loss: 0.8361\n",
            "Epoch [82/100], Step [6200/7382], D Loss: 1.4071, G Loss: 0.7323\n",
            "Epoch [82/100], Step [6300/7382], D Loss: 1.2931, G Loss: 0.7960\n",
            "Epoch [82/100], Step [6400/7382], D Loss: 1.2762, G Loss: 0.7713\n",
            "Epoch [82/100], Step [6500/7382], D Loss: 1.3256, G Loss: 0.8089\n",
            "Epoch [82/100], Step [6600/7382], D Loss: 1.3431, G Loss: 0.7482\n",
            "Epoch [82/100], Step [6700/7382], D Loss: 1.2992, G Loss: 0.8785\n",
            "Epoch [82/100], Step [6800/7382], D Loss: 1.3264, G Loss: 0.7669\n",
            "Epoch [82/100], Step [6900/7382], D Loss: 1.3010, G Loss: 0.7804\n",
            "Epoch [82/100], Step [7000/7382], D Loss: 1.3741, G Loss: 0.8010\n",
            "Epoch [82/100], Step [7100/7382], D Loss: 1.4228, G Loss: 0.6868\n",
            "Epoch [82/100], Step [7200/7382], D Loss: 1.3227, G Loss: 0.8238\n",
            "Epoch [82/100], Step [7300/7382], D Loss: 1.2955, G Loss: 0.8439\n",
            "Epoch [83/100], Step [100/7382], D Loss: 1.2967, G Loss: 0.7645\n",
            "Epoch [83/100], Step [200/7382], D Loss: 1.3311, G Loss: 0.7896\n",
            "Epoch [83/100], Step [300/7382], D Loss: 1.3230, G Loss: 0.8286\n",
            "Epoch [83/100], Step [400/7382], D Loss: 1.3865, G Loss: 0.7101\n",
            "Epoch [83/100], Step [500/7382], D Loss: 1.3584, G Loss: 0.8250\n",
            "Epoch [83/100], Step [600/7382], D Loss: 1.3167, G Loss: 0.8128\n",
            "Epoch [83/100], Step [700/7382], D Loss: 1.4433, G Loss: 0.8152\n",
            "Epoch [83/100], Step [800/7382], D Loss: 1.3888, G Loss: 0.8058\n",
            "Epoch [83/100], Step [900/7382], D Loss: 1.2384, G Loss: 0.9869\n",
            "Epoch [83/100], Step [1000/7382], D Loss: 1.3780, G Loss: 0.7719\n",
            "Epoch [83/100], Step [1100/7382], D Loss: 1.3610, G Loss: 0.7254\n",
            "Epoch [83/100], Step [1200/7382], D Loss: 1.2769, G Loss: 0.9605\n",
            "Epoch [83/100], Step [1300/7382], D Loss: 1.3625, G Loss: 0.7472\n",
            "Epoch [83/100], Step [1400/7382], D Loss: 1.3656, G Loss: 0.7317\n",
            "Epoch [83/100], Step [1500/7382], D Loss: 1.3870, G Loss: 0.7644\n",
            "Epoch [83/100], Step [1600/7382], D Loss: 1.2634, G Loss: 0.9032\n",
            "Epoch [83/100], Step [1700/7382], D Loss: 1.3150, G Loss: 0.8497\n",
            "Epoch [83/100], Step [1800/7382], D Loss: 1.3057, G Loss: 0.7727\n",
            "Epoch [83/100], Step [1900/7382], D Loss: 1.3799, G Loss: 0.7648\n",
            "Epoch [83/100], Step [2000/7382], D Loss: 1.3689, G Loss: 0.7697\n",
            "Epoch [83/100], Step [2100/7382], D Loss: 1.3319, G Loss: 0.8564\n",
            "Epoch [83/100], Step [2200/7382], D Loss: 1.3956, G Loss: 0.7951\n",
            "Epoch [83/100], Step [2300/7382], D Loss: 1.3235, G Loss: 0.7664\n",
            "Epoch [83/100], Step [2400/7382], D Loss: 1.3111, G Loss: 0.7964\n",
            "Epoch [83/100], Step [2500/7382], D Loss: 1.3290, G Loss: 0.8459\n",
            "Epoch [83/100], Step [2600/7382], D Loss: 1.3050, G Loss: 0.8451\n",
            "Epoch [83/100], Step [2700/7382], D Loss: 1.3142, G Loss: 0.9458\n",
            "Epoch [83/100], Step [2800/7382], D Loss: 1.3846, G Loss: 0.7810\n",
            "Epoch [83/100], Step [2900/7382], D Loss: 1.2723, G Loss: 0.8968\n",
            "Epoch [83/100], Step [3000/7382], D Loss: 1.3656, G Loss: 0.8192\n",
            "Epoch [83/100], Step [3100/7382], D Loss: 1.3723, G Loss: 0.7475\n",
            "Epoch [83/100], Step [3200/7382], D Loss: 1.3175, G Loss: 0.8562\n",
            "Epoch [83/100], Step [3300/7382], D Loss: 1.3320, G Loss: 0.9092\n",
            "Epoch [83/100], Step [3400/7382], D Loss: 1.3394, G Loss: 0.7814\n",
            "Epoch [83/100], Step [3500/7382], D Loss: 1.4165, G Loss: 0.7652\n",
            "Epoch [83/100], Step [3600/7382], D Loss: 1.3751, G Loss: 0.7143\n",
            "Epoch [83/100], Step [3700/7382], D Loss: 1.2976, G Loss: 0.8439\n",
            "Epoch [83/100], Step [3800/7382], D Loss: 1.3825, G Loss: 0.7947\n",
            "Epoch [83/100], Step [3900/7382], D Loss: 1.3262, G Loss: 0.9127\n",
            "Epoch [83/100], Step [4000/7382], D Loss: 1.4139, G Loss: 0.7781\n",
            "Epoch [83/100], Step [4100/7382], D Loss: 1.3241, G Loss: 0.8299\n",
            "Epoch [83/100], Step [4200/7382], D Loss: 1.3341, G Loss: 0.7736\n",
            "Epoch [83/100], Step [4300/7382], D Loss: 1.3580, G Loss: 0.7392\n",
            "Epoch [83/100], Step [4400/7382], D Loss: 1.4562, G Loss: 0.7400\n",
            "Epoch [83/100], Step [4500/7382], D Loss: 1.3289, G Loss: 0.7804\n",
            "Epoch [83/100], Step [4600/7382], D Loss: 1.3353, G Loss: 0.8471\n",
            "Epoch [83/100], Step [4700/7382], D Loss: 1.3558, G Loss: 0.7870\n",
            "Epoch [83/100], Step [4800/7382], D Loss: 1.3229, G Loss: 0.8341\n",
            "Epoch [83/100], Step [4900/7382], D Loss: 1.3348, G Loss: 0.7586\n",
            "Epoch [83/100], Step [5000/7382], D Loss: 1.3583, G Loss: 0.7572\n",
            "Epoch [83/100], Step [5100/7382], D Loss: 1.3465, G Loss: 0.8366\n",
            "Epoch [83/100], Step [5200/7382], D Loss: 1.3491, G Loss: 0.7163\n",
            "Epoch [83/100], Step [5300/7382], D Loss: 1.3205, G Loss: 0.8723\n",
            "Epoch [83/100], Step [5400/7382], D Loss: 1.3328, G Loss: 0.7658\n",
            "Epoch [83/100], Step [5500/7382], D Loss: 1.4031, G Loss: 0.7484\n",
            "Epoch [83/100], Step [5600/7382], D Loss: 1.4021, G Loss: 0.7606\n",
            "Epoch [83/100], Step [5700/7382], D Loss: 1.3825, G Loss: 0.7346\n",
            "Epoch [83/100], Step [5800/7382], D Loss: 1.3363, G Loss: 0.7690\n",
            "Epoch [83/100], Step [5900/7382], D Loss: 1.3214, G Loss: 0.7552\n",
            "Epoch [83/100], Step [6000/7382], D Loss: 1.3143, G Loss: 0.7748\n",
            "Epoch [83/100], Step [6100/7382], D Loss: 1.3400, G Loss: 0.7819\n",
            "Epoch [83/100], Step [6200/7382], D Loss: 1.2993, G Loss: 0.8039\n",
            "Epoch [83/100], Step [6300/7382], D Loss: 1.2982, G Loss: 0.8384\n",
            "Epoch [83/100], Step [6400/7382], D Loss: 1.3385, G Loss: 0.7902\n",
            "Epoch [83/100], Step [6500/7382], D Loss: 1.3369, G Loss: 0.7693\n",
            "Epoch [83/100], Step [6600/7382], D Loss: 1.3800, G Loss: 0.7357\n",
            "Epoch [83/100], Step [6700/7382], D Loss: 1.3238, G Loss: 0.8185\n",
            "Epoch [83/100], Step [6800/7382], D Loss: 1.2982, G Loss: 0.8503\n",
            "Epoch [83/100], Step [6900/7382], D Loss: 1.3577, G Loss: 0.7316\n",
            "Epoch [83/100], Step [7000/7382], D Loss: 1.2835, G Loss: 0.8302\n",
            "Epoch [83/100], Step [7100/7382], D Loss: 1.2163, G Loss: 0.9713\n",
            "Epoch [83/100], Step [7200/7382], D Loss: 1.3901, G Loss: 0.9339\n",
            "Epoch [83/100], Step [7300/7382], D Loss: 1.2621, G Loss: 0.8448\n",
            "Epoch [84/100], Step [100/7382], D Loss: 1.3528, G Loss: 0.7824\n",
            "Epoch [84/100], Step [200/7382], D Loss: 1.3633, G Loss: 0.7343\n",
            "Epoch [84/100], Step [300/7382], D Loss: 1.3700, G Loss: 0.7260\n",
            "Epoch [84/100], Step [400/7382], D Loss: 1.3105, G Loss: 0.8079\n",
            "Epoch [84/100], Step [500/7382], D Loss: 1.3380, G Loss: 0.8546\n",
            "Epoch [84/100], Step [600/7382], D Loss: 1.3155, G Loss: 0.8371\n",
            "Epoch [84/100], Step [700/7382], D Loss: 1.2718, G Loss: 0.8141\n",
            "Epoch [84/100], Step [800/7382], D Loss: 1.3433, G Loss: 0.7860\n",
            "Epoch [84/100], Step [900/7382], D Loss: 1.2711, G Loss: 0.9048\n",
            "Epoch [84/100], Step [1000/7382], D Loss: 1.3434, G Loss: 0.7918\n",
            "Epoch [84/100], Step [1100/7382], D Loss: 1.3067, G Loss: 0.9060\n",
            "Epoch [84/100], Step [1200/7382], D Loss: 1.3199, G Loss: 0.8036\n",
            "Epoch [84/100], Step [1300/7382], D Loss: 1.3485, G Loss: 0.9269\n",
            "Epoch [84/100], Step [1400/7382], D Loss: 1.3909, G Loss: 0.7221\n",
            "Epoch [84/100], Step [1500/7382], D Loss: 1.2918, G Loss: 0.7830\n",
            "Epoch [84/100], Step [1600/7382], D Loss: 1.3415, G Loss: 0.7663\n",
            "Epoch [84/100], Step [1700/7382], D Loss: 1.4066, G Loss: 0.7754\n",
            "Epoch [84/100], Step [1800/7382], D Loss: 1.2221, G Loss: 0.9877\n",
            "Epoch [84/100], Step [1900/7382], D Loss: 1.3044, G Loss: 0.8490\n",
            "Epoch [84/100], Step [2000/7382], D Loss: 1.3451, G Loss: 0.8373\n",
            "Epoch [84/100], Step [2100/7382], D Loss: 1.3046, G Loss: 0.8530\n",
            "Epoch [84/100], Step [2200/7382], D Loss: 1.3836, G Loss: 0.7403\n",
            "Epoch [84/100], Step [2300/7382], D Loss: 1.3089, G Loss: 0.8233\n",
            "Epoch [84/100], Step [2400/7382], D Loss: 1.4006, G Loss: 0.7644\n",
            "Epoch [84/100], Step [2500/7382], D Loss: 1.3061, G Loss: 0.8276\n",
            "Epoch [84/100], Step [2600/7382], D Loss: 1.3171, G Loss: 0.7628\n",
            "Epoch [84/100], Step [2700/7382], D Loss: 1.3068, G Loss: 0.8044\n",
            "Epoch [84/100], Step [2800/7382], D Loss: 1.3056, G Loss: 0.8029\n",
            "Epoch [84/100], Step [2900/7382], D Loss: 1.3231, G Loss: 1.0015\n",
            "Epoch [84/100], Step [3000/7382], D Loss: 1.3481, G Loss: 0.7549\n",
            "Epoch [84/100], Step [3100/7382], D Loss: 1.3147, G Loss: 0.9239\n",
            "Epoch [84/100], Step [3200/7382], D Loss: 1.3077, G Loss: 0.8084\n",
            "Epoch [84/100], Step [3300/7382], D Loss: 1.3629, G Loss: 0.7368\n",
            "Epoch [84/100], Step [3400/7382], D Loss: 1.4205, G Loss: 0.7905\n",
            "Epoch [84/100], Step [3500/7382], D Loss: 1.2786, G Loss: 0.9131\n",
            "Epoch [84/100], Step [3600/7382], D Loss: 1.3058, G Loss: 0.8420\n",
            "Epoch [84/100], Step [3700/7382], D Loss: 1.3507, G Loss: 0.8356\n",
            "Epoch [84/100], Step [3800/7382], D Loss: 1.3294, G Loss: 0.7975\n",
            "Epoch [84/100], Step [3900/7382], D Loss: 1.3274, G Loss: 0.8289\n",
            "Epoch [84/100], Step [4000/7382], D Loss: 1.2793, G Loss: 0.9063\n",
            "Epoch [84/100], Step [4100/7382], D Loss: 1.2485, G Loss: 0.9497\n",
            "Epoch [84/100], Step [4200/7382], D Loss: 1.3239, G Loss: 0.8923\n",
            "Epoch [84/100], Step [4300/7382], D Loss: 1.2922, G Loss: 0.8142\n",
            "Epoch [84/100], Step [4400/7382], D Loss: 1.3003, G Loss: 0.8429\n",
            "Epoch [84/100], Step [4500/7382], D Loss: 1.2661, G Loss: 1.0243\n",
            "Epoch [84/100], Step [4600/7382], D Loss: 1.3357, G Loss: 0.7926\n",
            "Epoch [84/100], Step [4700/7382], D Loss: 1.3347, G Loss: 0.7992\n",
            "Epoch [84/100], Step [4800/7382], D Loss: 1.3075, G Loss: 0.7923\n",
            "Epoch [84/100], Step [4900/7382], D Loss: 1.3387, G Loss: 0.8694\n",
            "Epoch [84/100], Step [5000/7382], D Loss: 1.3220, G Loss: 0.8935\n",
            "Epoch [84/100], Step [5100/7382], D Loss: 1.3693, G Loss: 0.7747\n",
            "Epoch [84/100], Step [5200/7382], D Loss: 1.2165, G Loss: 0.9581\n",
            "Epoch [84/100], Step [5300/7382], D Loss: 1.2575, G Loss: 0.8627\n",
            "Epoch [84/100], Step [5400/7382], D Loss: 1.3601, G Loss: 0.7939\n",
            "Epoch [84/100], Step [5500/7382], D Loss: 1.2732, G Loss: 0.9473\n",
            "Epoch [84/100], Step [5600/7382], D Loss: 1.2297, G Loss: 1.1388\n",
            "Epoch [84/100], Step [5700/7382], D Loss: 1.3144, G Loss: 0.7730\n",
            "Epoch [84/100], Step [5800/7382], D Loss: 1.2107, G Loss: 1.0328\n",
            "Epoch [84/100], Step [5900/7382], D Loss: 1.2998, G Loss: 0.8513\n",
            "Epoch [84/100], Step [6000/7382], D Loss: 1.2067, G Loss: 0.9476\n",
            "Epoch [84/100], Step [6100/7382], D Loss: 1.3069, G Loss: 0.8850\n",
            "Epoch [84/100], Step [6200/7382], D Loss: 1.2580, G Loss: 0.8093\n",
            "Epoch [84/100], Step [6300/7382], D Loss: 1.3989, G Loss: 0.7457\n",
            "Epoch [84/100], Step [6400/7382], D Loss: 1.3525, G Loss: 0.8249\n",
            "Epoch [84/100], Step [6500/7382], D Loss: 1.3370, G Loss: 0.8237\n",
            "Epoch [84/100], Step [6600/7382], D Loss: 1.2386, G Loss: 0.8824\n",
            "Epoch [84/100], Step [6700/7382], D Loss: 1.3191, G Loss: 0.7906\n",
            "Epoch [84/100], Step [6800/7382], D Loss: 1.2775, G Loss: 0.9468\n",
            "Epoch [84/100], Step [6900/7382], D Loss: 1.2270, G Loss: 0.9255\n",
            "Epoch [84/100], Step [7000/7382], D Loss: 1.3055, G Loss: 0.8885\n",
            "Epoch [84/100], Step [7100/7382], D Loss: 1.2608, G Loss: 0.8392\n",
            "Epoch [84/100], Step [7200/7382], D Loss: 1.2321, G Loss: 1.0064\n",
            "Epoch [84/100], Step [7300/7382], D Loss: 1.3582, G Loss: 0.8073\n",
            "Epoch [85/100], Step [100/7382], D Loss: 1.3494, G Loss: 0.8776\n",
            "Epoch [85/100], Step [200/7382], D Loss: 1.3173, G Loss: 0.8355\n",
            "Epoch [85/100], Step [300/7382], D Loss: 1.2365, G Loss: 0.8319\n",
            "Epoch [85/100], Step [400/7382], D Loss: 1.3069, G Loss: 0.8660\n",
            "Epoch [85/100], Step [500/7382], D Loss: 1.3985, G Loss: 0.8003\n",
            "Epoch [85/100], Step [600/7382], D Loss: 1.3510, G Loss: 0.8172\n",
            "Epoch [85/100], Step [700/7382], D Loss: 1.3894, G Loss: 0.7746\n",
            "Epoch [85/100], Step [800/7382], D Loss: 1.2874, G Loss: 0.8282\n",
            "Epoch [85/100], Step [900/7382], D Loss: 1.2945, G Loss: 0.8092\n",
            "Epoch [85/100], Step [1000/7382], D Loss: 1.3668, G Loss: 0.8339\n",
            "Epoch [85/100], Step [1100/7382], D Loss: 1.3346, G Loss: 0.9625\n",
            "Epoch [85/100], Step [1200/7382], D Loss: 1.2428, G Loss: 0.8739\n",
            "Epoch [85/100], Step [1300/7382], D Loss: 1.3398, G Loss: 0.7581\n",
            "Epoch [85/100], Step [1400/7382], D Loss: 1.2487, G Loss: 0.8509\n",
            "Epoch [85/100], Step [1500/7382], D Loss: 1.2387, G Loss: 0.9082\n",
            "Epoch [85/100], Step [1600/7382], D Loss: 1.2764, G Loss: 0.9495\n",
            "Epoch [85/100], Step [1700/7382], D Loss: 1.3389, G Loss: 0.7565\n",
            "Epoch [85/100], Step [1800/7382], D Loss: 1.2764, G Loss: 0.8496\n",
            "Epoch [85/100], Step [1900/7382], D Loss: 1.2461, G Loss: 0.8012\n",
            "Epoch [85/100], Step [2000/7382], D Loss: 1.3997, G Loss: 0.8074\n",
            "Epoch [85/100], Step [2100/7382], D Loss: 1.3040, G Loss: 0.8128\n",
            "Epoch [85/100], Step [2200/7382], D Loss: 1.3336, G Loss: 0.8434\n",
            "Epoch [85/100], Step [2300/7382], D Loss: 1.3266, G Loss: 0.7400\n",
            "Epoch [85/100], Step [2400/7382], D Loss: 1.3439, G Loss: 0.8970\n",
            "Epoch [85/100], Step [2500/7382], D Loss: 1.3168, G Loss: 0.8029\n",
            "Epoch [85/100], Step [2600/7382], D Loss: 1.3485, G Loss: 0.7785\n",
            "Epoch [85/100], Step [2700/7382], D Loss: 1.3027, G Loss: 0.8121\n",
            "Epoch [85/100], Step [2800/7382], D Loss: 1.3351, G Loss: 0.9124\n",
            "Epoch [85/100], Step [2900/7382], D Loss: 1.2918, G Loss: 0.8392\n",
            "Epoch [85/100], Step [3000/7382], D Loss: 1.2888, G Loss: 0.8213\n",
            "Epoch [85/100], Step [3100/7382], D Loss: 1.3331, G Loss: 0.7363\n",
            "Epoch [85/100], Step [3200/7382], D Loss: 1.3629, G Loss: 0.8829\n",
            "Epoch [85/100], Step [3300/7382], D Loss: 1.2695, G Loss: 0.8456\n",
            "Epoch [85/100], Step [3400/7382], D Loss: 1.3021, G Loss: 0.8619\n",
            "Epoch [85/100], Step [3500/7382], D Loss: 1.3528, G Loss: 0.8271\n",
            "Epoch [85/100], Step [3600/7382], D Loss: 1.3778, G Loss: 0.8865\n",
            "Epoch [85/100], Step [3700/7382], D Loss: 1.3482, G Loss: 0.8099\n",
            "Epoch [85/100], Step [3800/7382], D Loss: 1.4170, G Loss: 0.8038\n",
            "Epoch [85/100], Step [3900/7382], D Loss: 1.2091, G Loss: 1.1041\n",
            "Epoch [85/100], Step [4000/7382], D Loss: 1.3156, G Loss: 0.8463\n",
            "Epoch [85/100], Step [4100/7382], D Loss: 1.2605, G Loss: 0.8891\n",
            "Epoch [85/100], Step [4200/7382], D Loss: 1.3722, G Loss: 0.9179\n",
            "Epoch [85/100], Step [4300/7382], D Loss: 1.2555, G Loss: 0.9625\n",
            "Epoch [85/100], Step [4400/7382], D Loss: 1.3209, G Loss: 0.7819\n",
            "Epoch [85/100], Step [4500/7382], D Loss: 1.2418, G Loss: 0.8592\n",
            "Epoch [85/100], Step [4600/7382], D Loss: 1.3158, G Loss: 0.8190\n",
            "Epoch [85/100], Step [4700/7382], D Loss: 1.3638, G Loss: 0.8175\n",
            "Epoch [85/100], Step [4800/7382], D Loss: 1.3460, G Loss: 0.8235\n",
            "Epoch [85/100], Step [4900/7382], D Loss: 1.3533, G Loss: 0.7717\n",
            "Epoch [85/100], Step [5000/7382], D Loss: 1.3110, G Loss: 0.7988\n",
            "Epoch [85/100], Step [5100/7382], D Loss: 1.3637, G Loss: 0.7621\n",
            "Epoch [85/100], Step [5200/7382], D Loss: 1.2995, G Loss: 0.8460\n",
            "Epoch [85/100], Step [5300/7382], D Loss: 1.3968, G Loss: 0.8914\n",
            "Epoch [85/100], Step [5400/7382], D Loss: 1.3062, G Loss: 0.8608\n",
            "Epoch [85/100], Step [5500/7382], D Loss: 1.2960, G Loss: 0.7705\n",
            "Epoch [85/100], Step [5600/7382], D Loss: 1.3680, G Loss: 0.7763\n",
            "Epoch [85/100], Step [5700/7382], D Loss: 1.3511, G Loss: 0.7233\n",
            "Epoch [85/100], Step [5800/7382], D Loss: 1.4149, G Loss: 0.7215\n",
            "Epoch [85/100], Step [5900/7382], D Loss: 1.2864, G Loss: 0.8278\n",
            "Epoch [85/100], Step [6000/7382], D Loss: 1.3311, G Loss: 0.8449\n",
            "Epoch [85/100], Step [6100/7382], D Loss: 1.3832, G Loss: 0.7399\n",
            "Epoch [85/100], Step [6200/7382], D Loss: 1.3480, G Loss: 0.8153\n",
            "Epoch [85/100], Step [6300/7382], D Loss: 1.3775, G Loss: 0.8382\n",
            "Epoch [85/100], Step [6400/7382], D Loss: 1.3501, G Loss: 0.7750\n",
            "Epoch [85/100], Step [6500/7382], D Loss: 1.3021, G Loss: 0.8844\n",
            "Epoch [85/100], Step [6600/7382], D Loss: 1.3463, G Loss: 0.9056\n",
            "Epoch [85/100], Step [6700/7382], D Loss: 1.3706, G Loss: 0.7554\n",
            "Epoch [85/100], Step [6800/7382], D Loss: 1.3796, G Loss: 0.7490\n",
            "Epoch [85/100], Step [6900/7382], D Loss: 1.2377, G Loss: 0.9021\n",
            "Epoch [85/100], Step [7000/7382], D Loss: 1.3056, G Loss: 0.8334\n",
            "Epoch [85/100], Step [7100/7382], D Loss: 1.2908, G Loss: 0.8114\n",
            "Epoch [85/100], Step [7200/7382], D Loss: 1.3286, G Loss: 0.7990\n",
            "Epoch [85/100], Step [7300/7382], D Loss: 1.2610, G Loss: 0.8843\n",
            "Epoch [86/100], Step [100/7382], D Loss: 1.3336, G Loss: 0.8674\n",
            "Epoch [86/100], Step [200/7382], D Loss: 1.3242, G Loss: 0.8677\n",
            "Epoch [86/100], Step [300/7382], D Loss: 1.3768, G Loss: 0.7301\n",
            "Epoch [86/100], Step [400/7382], D Loss: 1.2741, G Loss: 0.7827\n",
            "Epoch [86/100], Step [500/7382], D Loss: 1.3207, G Loss: 0.7669\n",
            "Epoch [86/100], Step [600/7382], D Loss: 1.2704, G Loss: 0.9616\n",
            "Epoch [86/100], Step [700/7382], D Loss: 1.3419, G Loss: 0.7773\n",
            "Epoch [86/100], Step [800/7382], D Loss: 1.2572, G Loss: 0.9144\n",
            "Epoch [86/100], Step [900/7382], D Loss: 1.3116, G Loss: 0.9162\n",
            "Epoch [86/100], Step [1000/7382], D Loss: 1.2351, G Loss: 0.8652\n",
            "Epoch [86/100], Step [1100/7382], D Loss: 1.3085, G Loss: 0.7857\n",
            "Epoch [86/100], Step [1200/7382], D Loss: 1.3605, G Loss: 0.8020\n",
            "Epoch [86/100], Step [1300/7382], D Loss: 1.3587, G Loss: 0.7460\n",
            "Epoch [86/100], Step [1400/7382], D Loss: 1.3481, G Loss: 0.8104\n",
            "Epoch [86/100], Step [1500/7382], D Loss: 1.3382, G Loss: 0.8200\n",
            "Epoch [86/100], Step [1600/7382], D Loss: 1.2856, G Loss: 0.8363\n",
            "Epoch [86/100], Step [1700/7382], D Loss: 1.3307, G Loss: 0.7852\n",
            "Epoch [86/100], Step [1800/7382], D Loss: 1.3524, G Loss: 0.8404\n",
            "Epoch [86/100], Step [1900/7382], D Loss: 1.4145, G Loss: 0.7478\n",
            "Epoch [86/100], Step [2000/7382], D Loss: 1.3158, G Loss: 0.7693\n",
            "Epoch [86/100], Step [2100/7382], D Loss: 1.3584, G Loss: 0.7619\n",
            "Epoch [86/100], Step [2200/7382], D Loss: 1.3639, G Loss: 0.8209\n",
            "Epoch [86/100], Step [2300/7382], D Loss: 1.3384, G Loss: 0.7310\n",
            "Epoch [86/100], Step [2400/7382], D Loss: 1.3205, G Loss: 0.7322\n",
            "Epoch [86/100], Step [2500/7382], D Loss: 1.3170, G Loss: 0.9088\n",
            "Epoch [86/100], Step [2600/7382], D Loss: 1.3608, G Loss: 0.7489\n",
            "Epoch [86/100], Step [2700/7382], D Loss: 1.3974, G Loss: 0.7237\n",
            "Epoch [86/100], Step [2800/7382], D Loss: 1.3068, G Loss: 0.7450\n",
            "Epoch [86/100], Step [2900/7382], D Loss: 1.3226, G Loss: 0.8157\n",
            "Epoch [86/100], Step [3000/7382], D Loss: 1.3625, G Loss: 0.8134\n",
            "Epoch [86/100], Step [3100/7382], D Loss: 1.3612, G Loss: 0.8184\n",
            "Epoch [86/100], Step [3200/7382], D Loss: 1.3666, G Loss: 0.7416\n",
            "Epoch [86/100], Step [3300/7382], D Loss: 1.3564, G Loss: 0.7350\n",
            "Epoch [86/100], Step [3400/7382], D Loss: 1.3457, G Loss: 0.7439\n",
            "Epoch [86/100], Step [3500/7382], D Loss: 1.2633, G Loss: 0.8493\n",
            "Epoch [86/100], Step [3600/7382], D Loss: 1.3276, G Loss: 0.8170\n",
            "Epoch [86/100], Step [3700/7382], D Loss: 1.3065, G Loss: 0.8186\n",
            "Epoch [86/100], Step [3800/7382], D Loss: 1.3233, G Loss: 0.7853\n",
            "Epoch [86/100], Step [3900/7382], D Loss: 1.3440, G Loss: 0.7658\n",
            "Epoch [86/100], Step [4000/7382], D Loss: 1.2720, G Loss: 0.8177\n",
            "Epoch [86/100], Step [4100/7382], D Loss: 1.3119, G Loss: 0.8056\n",
            "Epoch [86/100], Step [4200/7382], D Loss: 1.3172, G Loss: 0.7870\n",
            "Epoch [86/100], Step [4300/7382], D Loss: 1.4572, G Loss: 0.8152\n",
            "Epoch [86/100], Step [4400/7382], D Loss: 1.3639, G Loss: 0.7237\n",
            "Epoch [86/100], Step [4500/7382], D Loss: 1.3280, G Loss: 0.7703\n",
            "Epoch [86/100], Step [4600/7382], D Loss: 1.3325, G Loss: 0.7697\n",
            "Epoch [86/100], Step [4700/7382], D Loss: 1.2436, G Loss: 0.8344\n",
            "Epoch [86/100], Step [4800/7382], D Loss: 1.3680, G Loss: 0.8815\n",
            "Epoch [86/100], Step [4900/7382], D Loss: 1.2995, G Loss: 0.8079\n",
            "Epoch [86/100], Step [5000/7382], D Loss: 1.3396, G Loss: 0.8474\n",
            "Epoch [86/100], Step [5100/7382], D Loss: 1.3207, G Loss: 0.8080\n",
            "Epoch [86/100], Step [5200/7382], D Loss: 1.2753, G Loss: 0.8828\n",
            "Epoch [86/100], Step [5300/7382], D Loss: 1.3573, G Loss: 0.7719\n",
            "Epoch [86/100], Step [5400/7382], D Loss: 1.4133, G Loss: 0.7526\n",
            "Epoch [86/100], Step [5500/7382], D Loss: 1.3726, G Loss: 0.7946\n",
            "Epoch [86/100], Step [5600/7382], D Loss: 1.3323, G Loss: 0.7758\n",
            "Epoch [86/100], Step [5700/7382], D Loss: 1.3377, G Loss: 0.7883\n",
            "Epoch [86/100], Step [5800/7382], D Loss: 1.3207, G Loss: 0.8183\n",
            "Epoch [86/100], Step [5900/7382], D Loss: 1.3227, G Loss: 0.7696\n",
            "Epoch [86/100], Step [6000/7382], D Loss: 1.3195, G Loss: 0.8411\n",
            "Epoch [86/100], Step [6100/7382], D Loss: 1.3106, G Loss: 0.8433\n",
            "Epoch [86/100], Step [6200/7382], D Loss: 1.2747, G Loss: 0.7936\n",
            "Epoch [86/100], Step [6300/7382], D Loss: 1.3046, G Loss: 0.8280\n",
            "Epoch [86/100], Step [6400/7382], D Loss: 1.3644, G Loss: 0.7361\n",
            "Epoch [86/100], Step [6500/7382], D Loss: 1.3770, G Loss: 0.7325\n",
            "Epoch [86/100], Step [6600/7382], D Loss: 1.3554, G Loss: 0.7630\n",
            "Epoch [86/100], Step [6700/7382], D Loss: 1.3070, G Loss: 0.8333\n",
            "Epoch [86/100], Step [6800/7382], D Loss: 1.3402, G Loss: 0.8179\n",
            "Epoch [86/100], Step [6900/7382], D Loss: 1.3356, G Loss: 0.7711\n",
            "Epoch [86/100], Step [7000/7382], D Loss: 1.3457, G Loss: 0.7350\n",
            "Epoch [86/100], Step [7100/7382], D Loss: 1.3188, G Loss: 0.8141\n",
            "Epoch [86/100], Step [7200/7382], D Loss: 1.3167, G Loss: 0.7999\n",
            "Epoch [86/100], Step [7300/7382], D Loss: 1.3911, G Loss: 0.7731\n",
            "Epoch [87/100], Step [100/7382], D Loss: 1.3900, G Loss: 0.8064\n",
            "Epoch [87/100], Step [200/7382], D Loss: 1.3080, G Loss: 0.8239\n",
            "Epoch [87/100], Step [300/7382], D Loss: 1.4018, G Loss: 0.7680\n",
            "Epoch [87/100], Step [400/7382], D Loss: 1.3222, G Loss: 0.7480\n",
            "Epoch [87/100], Step [500/7382], D Loss: 1.2972, G Loss: 0.8340\n",
            "Epoch [87/100], Step [600/7382], D Loss: 1.4140, G Loss: 0.7212\n",
            "Epoch [87/100], Step [700/7382], D Loss: 1.3870, G Loss: 0.7611\n",
            "Epoch [87/100], Step [800/7382], D Loss: 1.3541, G Loss: 0.7924\n",
            "Epoch [87/100], Step [900/7382], D Loss: 1.2995, G Loss: 0.7801\n",
            "Epoch [87/100], Step [1000/7382], D Loss: 1.3527, G Loss: 0.7651\n",
            "Epoch [87/100], Step [1100/7382], D Loss: 1.3143, G Loss: 0.8019\n",
            "Epoch [87/100], Step [1200/7382], D Loss: 1.3524, G Loss: 0.8100\n",
            "Epoch [87/100], Step [1300/7382], D Loss: 1.2756, G Loss: 0.8207\n",
            "Epoch [87/100], Step [1400/7382], D Loss: 1.3500, G Loss: 0.7641\n",
            "Epoch [87/100], Step [1500/7382], D Loss: 1.3283, G Loss: 0.7793\n",
            "Epoch [87/100], Step [1600/7382], D Loss: 1.3336, G Loss: 0.7828\n",
            "Epoch [87/100], Step [1700/7382], D Loss: 1.3550, G Loss: 0.7567\n",
            "Epoch [87/100], Step [1800/7382], D Loss: 1.3761, G Loss: 0.7514\n",
            "Epoch [87/100], Step [1900/7382], D Loss: 1.2390, G Loss: 0.9562\n",
            "Epoch [87/100], Step [2000/7382], D Loss: 1.3300, G Loss: 0.8407\n",
            "Epoch [87/100], Step [2100/7382], D Loss: 1.2915, G Loss: 0.8364\n",
            "Epoch [87/100], Step [2200/7382], D Loss: 1.2983, G Loss: 0.8579\n",
            "Epoch [87/100], Step [2300/7382], D Loss: 1.3506, G Loss: 0.7567\n",
            "Epoch [87/100], Step [2400/7382], D Loss: 1.3714, G Loss: 0.7592\n",
            "Epoch [87/100], Step [2500/7382], D Loss: 1.3463, G Loss: 0.7845\n",
            "Epoch [87/100], Step [2600/7382], D Loss: 1.3612, G Loss: 0.7461\n",
            "Epoch [87/100], Step [2700/7382], D Loss: 1.2787, G Loss: 0.7963\n",
            "Epoch [87/100], Step [2800/7382], D Loss: 1.3898, G Loss: 0.8307\n",
            "Epoch [87/100], Step [2900/7382], D Loss: 1.3636, G Loss: 0.7341\n",
            "Epoch [87/100], Step [3000/7382], D Loss: 1.3133, G Loss: 0.8075\n",
            "Epoch [87/100], Step [3100/7382], D Loss: 1.3723, G Loss: 0.7398\n",
            "Epoch [87/100], Step [3200/7382], D Loss: 1.3539, G Loss: 0.7805\n",
            "Epoch [87/100], Step [3300/7382], D Loss: 1.3802, G Loss: 0.7536\n",
            "Epoch [87/100], Step [3400/7382], D Loss: 1.3016, G Loss: 0.8600\n",
            "Epoch [87/100], Step [3500/7382], D Loss: 1.3161, G Loss: 0.9395\n",
            "Epoch [87/100], Step [3600/7382], D Loss: 1.3626, G Loss: 0.7692\n",
            "Epoch [87/100], Step [3700/7382], D Loss: 1.3463, G Loss: 0.7832\n",
            "Epoch [87/100], Step [3800/7382], D Loss: 1.3635, G Loss: 0.7754\n",
            "Epoch [87/100], Step [3900/7382], D Loss: 1.3835, G Loss: 0.7307\n",
            "Epoch [87/100], Step [4000/7382], D Loss: 1.4108, G Loss: 0.7862\n",
            "Epoch [87/100], Step [4100/7382], D Loss: 1.3288, G Loss: 0.8222\n",
            "Epoch [87/100], Step [4200/7382], D Loss: 1.3880, G Loss: 0.7241\n",
            "Epoch [87/100], Step [4300/7382], D Loss: 1.3462, G Loss: 0.8392\n",
            "Epoch [87/100], Step [4400/7382], D Loss: 1.4095, G Loss: 0.8106\n",
            "Epoch [87/100], Step [4500/7382], D Loss: 1.3548, G Loss: 0.7471\n",
            "Epoch [87/100], Step [4600/7382], D Loss: 1.3614, G Loss: 0.7871\n",
            "Epoch [87/100], Step [4700/7382], D Loss: 1.3121, G Loss: 0.8801\n",
            "Epoch [87/100], Step [4800/7382], D Loss: 1.2680, G Loss: 0.8513\n",
            "Epoch [87/100], Step [4900/7382], D Loss: 1.3835, G Loss: 0.7627\n",
            "Epoch [87/100], Step [5000/7382], D Loss: 1.2971, G Loss: 0.7949\n",
            "Epoch [87/100], Step [5100/7382], D Loss: 1.3435, G Loss: 0.7928\n",
            "Epoch [87/100], Step [5200/7382], D Loss: 1.2796, G Loss: 0.8917\n",
            "Epoch [87/100], Step [5300/7382], D Loss: 1.3780, G Loss: 0.7528\n",
            "Epoch [87/100], Step [5400/7382], D Loss: 1.3007, G Loss: 0.8038\n",
            "Epoch [87/100], Step [5500/7382], D Loss: 1.3189, G Loss: 0.9313\n",
            "Epoch [87/100], Step [5600/7382], D Loss: 1.3048, G Loss: 0.8867\n",
            "Epoch [87/100], Step [5700/7382], D Loss: 1.2564, G Loss: 0.8614\n",
            "Epoch [87/100], Step [5800/7382], D Loss: 1.3962, G Loss: 0.8283\n",
            "Epoch [87/100], Step [5900/7382], D Loss: 1.3862, G Loss: 0.7700\n",
            "Epoch [87/100], Step [6000/7382], D Loss: 1.3560, G Loss: 0.7986\n",
            "Epoch [87/100], Step [6100/7382], D Loss: 1.3663, G Loss: 0.8176\n",
            "Epoch [87/100], Step [6200/7382], D Loss: 1.4094, G Loss: 0.7608\n",
            "Epoch [87/100], Step [6300/7382], D Loss: 1.3538, G Loss: 0.7477\n",
            "Epoch [87/100], Step [6400/7382], D Loss: 1.3395, G Loss: 0.7921\n",
            "Epoch [87/100], Step [6500/7382], D Loss: 1.3188, G Loss: 0.8263\n",
            "Epoch [87/100], Step [6600/7382], D Loss: 1.3672, G Loss: 0.7847\n",
            "Epoch [87/100], Step [6700/7382], D Loss: 1.3429, G Loss: 0.7801\n",
            "Epoch [87/100], Step [6800/7382], D Loss: 1.3188, G Loss: 0.8379\n",
            "Epoch [87/100], Step [6900/7382], D Loss: 1.3120, G Loss: 0.7575\n",
            "Epoch [87/100], Step [7000/7382], D Loss: 1.3293, G Loss: 0.7648\n",
            "Epoch [87/100], Step [7100/7382], D Loss: 1.3328, G Loss: 0.8040\n",
            "Epoch [87/100], Step [7200/7382], D Loss: 1.3789, G Loss: 0.8169\n",
            "Epoch [87/100], Step [7300/7382], D Loss: 1.2224, G Loss: 0.8713\n",
            "Epoch [88/100], Step [100/7382], D Loss: 1.3266, G Loss: 0.9156\n",
            "Epoch [88/100], Step [200/7382], D Loss: 1.2344, G Loss: 0.9655\n",
            "Epoch [88/100], Step [300/7382], D Loss: 1.2400, G Loss: 0.9160\n",
            "Epoch [88/100], Step [400/7382], D Loss: 1.2977, G Loss: 0.9069\n",
            "Epoch [88/100], Step [500/7382], D Loss: 1.3508, G Loss: 0.8349\n",
            "Epoch [88/100], Step [600/7382], D Loss: 1.2893, G Loss: 0.9099\n",
            "Epoch [88/100], Step [700/7382], D Loss: 1.2634, G Loss: 0.9782\n",
            "Epoch [88/100], Step [800/7382], D Loss: 1.2635, G Loss: 0.9413\n",
            "Epoch [88/100], Step [900/7382], D Loss: 1.3652, G Loss: 0.8204\n",
            "Epoch [88/100], Step [1000/7382], D Loss: 1.3396, G Loss: 0.8903\n",
            "Epoch [88/100], Step [1100/7382], D Loss: 1.4444, G Loss: 0.8270\n",
            "Epoch [88/100], Step [1200/7382], D Loss: 1.3858, G Loss: 0.7246\n",
            "Epoch [88/100], Step [1300/7382], D Loss: 1.3081, G Loss: 0.7789\n",
            "Epoch [88/100], Step [1400/7382], D Loss: 1.3127, G Loss: 0.8291\n",
            "Epoch [88/100], Step [1500/7382], D Loss: 1.3618, G Loss: 0.7754\n",
            "Epoch [88/100], Step [1600/7382], D Loss: 1.2938, G Loss: 0.8917\n",
            "Epoch [88/100], Step [1700/7382], D Loss: 1.3421, G Loss: 0.8007\n",
            "Epoch [88/100], Step [1800/7382], D Loss: 1.3667, G Loss: 0.9062\n",
            "Epoch [88/100], Step [1900/7382], D Loss: 1.2773, G Loss: 0.8432\n",
            "Epoch [88/100], Step [2000/7382], D Loss: 1.2732, G Loss: 0.9024\n",
            "Epoch [88/100], Step [2100/7382], D Loss: 1.2844, G Loss: 0.9125\n",
            "Epoch [88/100], Step [2200/7382], D Loss: 1.2935, G Loss: 0.8979\n",
            "Epoch [88/100], Step [2300/7382], D Loss: 1.3151, G Loss: 0.8366\n",
            "Epoch [88/100], Step [2400/7382], D Loss: 1.3188, G Loss: 0.8292\n",
            "Epoch [88/100], Step [2500/7382], D Loss: 1.2893, G Loss: 0.7641\n",
            "Epoch [88/100], Step [2600/7382], D Loss: 1.3164, G Loss: 0.8118\n",
            "Epoch [88/100], Step [2700/7382], D Loss: 1.2482, G Loss: 0.8317\n",
            "Epoch [88/100], Step [2800/7382], D Loss: 1.3786, G Loss: 0.7625\n",
            "Epoch [88/100], Step [2900/7382], D Loss: 1.3414, G Loss: 0.8643\n",
            "Epoch [88/100], Step [3000/7382], D Loss: 1.3318, G Loss: 0.7801\n",
            "Epoch [88/100], Step [3100/7382], D Loss: 1.3154, G Loss: 0.8832\n",
            "Epoch [88/100], Step [3200/7382], D Loss: 1.3501, G Loss: 0.7432\n",
            "Epoch [88/100], Step [3300/7382], D Loss: 1.3679, G Loss: 0.7794\n",
            "Epoch [88/100], Step [3400/7382], D Loss: 1.3400, G Loss: 0.8843\n",
            "Epoch [88/100], Step [3500/7382], D Loss: 1.3671, G Loss: 0.7868\n",
            "Epoch [88/100], Step [3600/7382], D Loss: 1.3019, G Loss: 0.7536\n",
            "Epoch [88/100], Step [3700/7382], D Loss: 1.3686, G Loss: 0.7433\n",
            "Epoch [88/100], Step [3800/7382], D Loss: 1.2931, G Loss: 0.7842\n",
            "Epoch [88/100], Step [3900/7382], D Loss: 1.3747, G Loss: 0.7346\n",
            "Epoch [88/100], Step [4000/7382], D Loss: 1.3533, G Loss: 0.8283\n",
            "Epoch [88/100], Step [4100/7382], D Loss: 1.3166, G Loss: 0.8538\n",
            "Epoch [88/100], Step [4200/7382], D Loss: 1.3659, G Loss: 0.7561\n",
            "Epoch [88/100], Step [4300/7382], D Loss: 1.2970, G Loss: 0.8318\n",
            "Epoch [88/100], Step [4400/7382], D Loss: 1.3317, G Loss: 0.7498\n",
            "Epoch [88/100], Step [4500/7382], D Loss: 1.2738, G Loss: 0.8368\n",
            "Epoch [88/100], Step [4600/7382], D Loss: 1.2957, G Loss: 0.9193\n",
            "Epoch [88/100], Step [4700/7382], D Loss: 1.3319, G Loss: 0.8682\n",
            "Epoch [88/100], Step [4800/7382], D Loss: 1.3598, G Loss: 0.8179\n",
            "Epoch [88/100], Step [4900/7382], D Loss: 1.2328, G Loss: 0.8939\n",
            "Epoch [88/100], Step [5000/7382], D Loss: 1.3302, G Loss: 0.7508\n",
            "Epoch [88/100], Step [5100/7382], D Loss: 1.3460, G Loss: 0.8207\n",
            "Epoch [88/100], Step [5200/7382], D Loss: 1.2989, G Loss: 0.8400\n",
            "Epoch [88/100], Step [5300/7382], D Loss: 1.3486, G Loss: 1.0391\n",
            "Epoch [88/100], Step [5400/7382], D Loss: 1.3854, G Loss: 0.7393\n",
            "Epoch [88/100], Step [5500/7382], D Loss: 1.4735, G Loss: 0.7197\n",
            "Epoch [88/100], Step [5600/7382], D Loss: 1.3203, G Loss: 0.7822\n",
            "Epoch [88/100], Step [5700/7382], D Loss: 1.3566, G Loss: 0.7491\n",
            "Epoch [88/100], Step [5800/7382], D Loss: 1.3420, G Loss: 0.7963\n",
            "Epoch [88/100], Step [5900/7382], D Loss: 1.3548, G Loss: 0.7653\n",
            "Epoch [88/100], Step [6000/7382], D Loss: 1.3044, G Loss: 0.8070\n",
            "Epoch [88/100], Step [6100/7382], D Loss: 1.2920, G Loss: 0.8138\n",
            "Epoch [88/100], Step [6200/7382], D Loss: 1.3066, G Loss: 0.8211\n",
            "Epoch [88/100], Step [6300/7382], D Loss: 1.3475, G Loss: 0.9478\n",
            "Epoch [88/100], Step [6400/7382], D Loss: 1.2504, G Loss: 0.8181\n",
            "Epoch [88/100], Step [6500/7382], D Loss: 1.3573, G Loss: 0.8128\n",
            "Epoch [88/100], Step [6600/7382], D Loss: 1.3750, G Loss: 0.7626\n",
            "Epoch [88/100], Step [6700/7382], D Loss: 1.3272, G Loss: 0.8371\n",
            "Epoch [88/100], Step [6800/7382], D Loss: 1.3159, G Loss: 0.7885\n",
            "Epoch [88/100], Step [6900/7382], D Loss: 1.2474, G Loss: 0.9817\n",
            "Epoch [88/100], Step [7000/7382], D Loss: 1.2718, G Loss: 0.8623\n",
            "Epoch [88/100], Step [7100/7382], D Loss: 1.3558, G Loss: 0.8464\n",
            "Epoch [88/100], Step [7200/7382], D Loss: 1.4678, G Loss: 0.7252\n",
            "Epoch [88/100], Step [7300/7382], D Loss: 1.2447, G Loss: 0.8899\n",
            "Epoch [89/100], Step [100/7382], D Loss: 1.3649, G Loss: 0.8814\n",
            "Epoch [89/100], Step [200/7382], D Loss: 1.2838, G Loss: 0.7740\n",
            "Epoch [89/100], Step [300/7382], D Loss: 1.4634, G Loss: 0.7270\n",
            "Epoch [89/100], Step [400/7382], D Loss: 1.3518, G Loss: 0.7972\n",
            "Epoch [89/100], Step [500/7382], D Loss: 1.2460, G Loss: 0.8743\n",
            "Epoch [89/100], Step [600/7382], D Loss: 1.3228, G Loss: 0.7975\n",
            "Epoch [89/100], Step [700/7382], D Loss: 1.2489, G Loss: 0.9064\n",
            "Epoch [89/100], Step [800/7382], D Loss: 1.2987, G Loss: 0.8754\n",
            "Epoch [89/100], Step [900/7382], D Loss: 1.3151, G Loss: 0.7722\n",
            "Epoch [89/100], Step [1000/7382], D Loss: 1.4089, G Loss: 0.7439\n",
            "Epoch [89/100], Step [1100/7382], D Loss: 1.2804, G Loss: 0.9106\n",
            "Epoch [89/100], Step [1200/7382], D Loss: 1.3744, G Loss: 0.7379\n",
            "Epoch [89/100], Step [1300/7382], D Loss: 1.3475, G Loss: 0.7727\n",
            "Epoch [89/100], Step [1400/7382], D Loss: 1.3671, G Loss: 0.7772\n",
            "Epoch [89/100], Step [1500/7382], D Loss: 1.3476, G Loss: 0.7808\n",
            "Epoch [89/100], Step [1600/7382], D Loss: 1.3739, G Loss: 0.7336\n",
            "Epoch [89/100], Step [1700/7382], D Loss: 1.4047, G Loss: 0.7903\n",
            "Epoch [89/100], Step [1800/7382], D Loss: 1.3207, G Loss: 0.7871\n",
            "Epoch [89/100], Step [1900/7382], D Loss: 1.3942, G Loss: 0.8442\n",
            "Epoch [89/100], Step [2000/7382], D Loss: 1.3559, G Loss: 0.7534\n",
            "Epoch [89/100], Step [2100/7382], D Loss: 1.3002, G Loss: 0.8058\n",
            "Epoch [89/100], Step [2200/7382], D Loss: 1.3418, G Loss: 0.7881\n",
            "Epoch [89/100], Step [2300/7382], D Loss: 1.2282, G Loss: 0.9184\n",
            "Epoch [89/100], Step [2400/7382], D Loss: 1.3481, G Loss: 0.8322\n",
            "Epoch [89/100], Step [2500/7382], D Loss: 1.3360, G Loss: 0.7761\n",
            "Epoch [89/100], Step [2600/7382], D Loss: 1.3502, G Loss: 0.7923\n",
            "Epoch [89/100], Step [2700/7382], D Loss: 1.3021, G Loss: 0.9592\n",
            "Epoch [89/100], Step [2800/7382], D Loss: 1.2719, G Loss: 0.9028\n",
            "Epoch [89/100], Step [2900/7382], D Loss: 1.3739, G Loss: 0.7551\n",
            "Epoch [89/100], Step [3000/7382], D Loss: 1.2846, G Loss: 0.8657\n",
            "Epoch [89/100], Step [3100/7382], D Loss: 1.2797, G Loss: 0.8000\n",
            "Epoch [89/100], Step [3200/7382], D Loss: 1.3339, G Loss: 0.8265\n",
            "Epoch [89/100], Step [3300/7382], D Loss: 1.3209, G Loss: 0.8104\n",
            "Epoch [89/100], Step [3400/7382], D Loss: 1.3631, G Loss: 0.7940\n",
            "Epoch [89/100], Step [3500/7382], D Loss: 1.3091, G Loss: 0.8180\n",
            "Epoch [89/100], Step [3600/7382], D Loss: 1.3420, G Loss: 0.8136\n",
            "Epoch [89/100], Step [3700/7382], D Loss: 1.3776, G Loss: 0.7801\n",
            "Epoch [89/100], Step [3800/7382], D Loss: 1.2898, G Loss: 0.8719\n",
            "Epoch [89/100], Step [3900/7382], D Loss: 1.2775, G Loss: 0.8578\n",
            "Epoch [89/100], Step [4000/7382], D Loss: 1.3347, G Loss: 0.7758\n",
            "Epoch [89/100], Step [4100/7382], D Loss: 1.3418, G Loss: 0.7472\n",
            "Epoch [89/100], Step [4200/7382], D Loss: 1.3255, G Loss: 0.8034\n",
            "Epoch [89/100], Step [4300/7382], D Loss: 1.3599, G Loss: 0.9352\n",
            "Epoch [89/100], Step [4400/7382], D Loss: 1.3512, G Loss: 0.7893\n",
            "Epoch [89/100], Step [4500/7382], D Loss: 1.3680, G Loss: 0.7405\n",
            "Epoch [89/100], Step [4600/7382], D Loss: 1.2609, G Loss: 0.9982\n",
            "Epoch [89/100], Step [4700/7382], D Loss: 1.3210, G Loss: 0.8023\n",
            "Epoch [89/100], Step [4800/7382], D Loss: 1.3140, G Loss: 0.7586\n",
            "Epoch [89/100], Step [4900/7382], D Loss: 1.3237, G Loss: 0.7672\n",
            "Epoch [89/100], Step [5000/7382], D Loss: 1.3581, G Loss: 0.7335\n",
            "Epoch [89/100], Step [5100/7382], D Loss: 1.2930, G Loss: 0.8526\n",
            "Epoch [89/100], Step [5200/7382], D Loss: 1.3202, G Loss: 0.8874\n",
            "Epoch [89/100], Step [5300/7382], D Loss: 1.3556, G Loss: 0.7636\n",
            "Epoch [89/100], Step [5400/7382], D Loss: 1.3647, G Loss: 0.7685\n",
            "Epoch [89/100], Step [5500/7382], D Loss: 1.2969, G Loss: 0.8512\n",
            "Epoch [89/100], Step [5600/7382], D Loss: 1.3632, G Loss: 0.8393\n",
            "Epoch [89/100], Step [5700/7382], D Loss: 1.4051, G Loss: 0.7124\n",
            "Epoch [89/100], Step [5800/7382], D Loss: 1.2489, G Loss: 0.9552\n",
            "Epoch [89/100], Step [5900/7382], D Loss: 1.3575, G Loss: 0.7538\n",
            "Epoch [89/100], Step [6000/7382], D Loss: 1.3450, G Loss: 0.8263\n",
            "Epoch [89/100], Step [6100/7382], D Loss: 1.2548, G Loss: 0.9301\n",
            "Epoch [89/100], Step [6200/7382], D Loss: 1.3609, G Loss: 0.7619\n",
            "Epoch [89/100], Step [6300/7382], D Loss: 1.2458, G Loss: 0.8778\n",
            "Epoch [89/100], Step [6400/7382], D Loss: 1.3992, G Loss: 0.7484\n",
            "Epoch [89/100], Step [6500/7382], D Loss: 1.2969, G Loss: 0.8075\n",
            "Epoch [89/100], Step [6600/7382], D Loss: 1.3133, G Loss: 0.7817\n",
            "Epoch [89/100], Step [6700/7382], D Loss: 1.3829, G Loss: 0.8006\n",
            "Epoch [89/100], Step [6800/7382], D Loss: 1.3155, G Loss: 0.7999\n",
            "Epoch [89/100], Step [6900/7382], D Loss: 1.3274, G Loss: 0.8347\n",
            "Epoch [89/100], Step [7000/7382], D Loss: 1.2467, G Loss: 0.8683\n",
            "Epoch [89/100], Step [7100/7382], D Loss: 1.3383, G Loss: 0.8048\n",
            "Epoch [89/100], Step [7200/7382], D Loss: 1.4220, G Loss: 0.7572\n",
            "Epoch [89/100], Step [7300/7382], D Loss: 1.3236, G Loss: 0.8942\n",
            "Epoch [90/100], Step [100/7382], D Loss: 1.2150, G Loss: 0.8626\n",
            "Epoch [90/100], Step [200/7382], D Loss: 1.2571, G Loss: 0.8540\n",
            "Epoch [90/100], Step [300/7382], D Loss: 1.3687, G Loss: 0.9102\n",
            "Epoch [90/100], Step [400/7382], D Loss: 1.3437, G Loss: 0.9073\n",
            "Epoch [90/100], Step [500/7382], D Loss: 1.3226, G Loss: 0.8385\n",
            "Epoch [90/100], Step [600/7382], D Loss: 1.2813, G Loss: 0.8896\n",
            "Epoch [90/100], Step [700/7382], D Loss: 1.3069, G Loss: 0.8472\n",
            "Epoch [90/100], Step [800/7382], D Loss: 1.2274, G Loss: 0.8489\n",
            "Epoch [90/100], Step [900/7382], D Loss: 1.2954, G Loss: 0.8680\n",
            "Epoch [90/100], Step [1000/7382], D Loss: 1.3609, G Loss: 0.8349\n",
            "Epoch [90/100], Step [1100/7382], D Loss: 1.2957, G Loss: 0.8011\n",
            "Epoch [90/100], Step [1200/7382], D Loss: 1.2570, G Loss: 0.8382\n",
            "Epoch [90/100], Step [1300/7382], D Loss: 1.2801, G Loss: 0.7992\n",
            "Epoch [90/100], Step [1400/7382], D Loss: 1.3020, G Loss: 0.8248\n",
            "Epoch [90/100], Step [1500/7382], D Loss: 1.4169, G Loss: 0.7374\n",
            "Epoch [90/100], Step [1600/7382], D Loss: 1.2823, G Loss: 0.8183\n",
            "Epoch [90/100], Step [1700/7382], D Loss: 1.2968, G Loss: 0.8094\n",
            "Epoch [90/100], Step [1800/7382], D Loss: 1.2492, G Loss: 0.9726\n",
            "Epoch [90/100], Step [1900/7382], D Loss: 1.3047, G Loss: 0.8047\n",
            "Epoch [90/100], Step [2000/7382], D Loss: 1.2863, G Loss: 0.8403\n",
            "Epoch [90/100], Step [2100/7382], D Loss: 1.3195, G Loss: 0.7963\n",
            "Epoch [90/100], Step [2200/7382], D Loss: 1.3873, G Loss: 0.7643\n",
            "Epoch [90/100], Step [2300/7382], D Loss: 1.3061, G Loss: 0.8802\n",
            "Epoch [90/100], Step [2400/7382], D Loss: 1.3718, G Loss: 0.7385\n",
            "Epoch [90/100], Step [2500/7382], D Loss: 1.3598, G Loss: 0.7648\n",
            "Epoch [90/100], Step [2600/7382], D Loss: 1.3579, G Loss: 0.8380\n",
            "Epoch [90/100], Step [2700/7382], D Loss: 1.3584, G Loss: 0.7989\n",
            "Epoch [90/100], Step [2800/7382], D Loss: 1.3450, G Loss: 0.7767\n",
            "Epoch [90/100], Step [2900/7382], D Loss: 1.3593, G Loss: 0.7812\n",
            "Epoch [90/100], Step [3000/7382], D Loss: 1.3590, G Loss: 0.7398\n",
            "Epoch [90/100], Step [3100/7382], D Loss: 1.2370, G Loss: 0.9220\n",
            "Epoch [90/100], Step [3200/7382], D Loss: 1.3387, G Loss: 0.7829\n",
            "Epoch [90/100], Step [3300/7382], D Loss: 1.3588, G Loss: 0.7837\n",
            "Epoch [90/100], Step [3400/7382], D Loss: 1.3451, G Loss: 0.7766\n",
            "Epoch [90/100], Step [3500/7382], D Loss: 1.3409, G Loss: 0.7946\n",
            "Epoch [90/100], Step [3600/7382], D Loss: 1.2768, G Loss: 0.8257\n",
            "Epoch [90/100], Step [3700/7382], D Loss: 1.3796, G Loss: 0.7727\n",
            "Epoch [90/100], Step [3800/7382], D Loss: 1.3237, G Loss: 0.9273\n",
            "Epoch [90/100], Step [3900/7382], D Loss: 1.3682, G Loss: 0.8614\n",
            "Epoch [90/100], Step [4000/7382], D Loss: 1.4041, G Loss: 0.7545\n",
            "Epoch [90/100], Step [4100/7382], D Loss: 1.3117, G Loss: 0.7657\n",
            "Epoch [90/100], Step [4200/7382], D Loss: 1.4081, G Loss: 0.7878\n",
            "Epoch [90/100], Step [4300/7382], D Loss: 1.3222, G Loss: 0.7836\n",
            "Epoch [90/100], Step [4400/7382], D Loss: 1.3351, G Loss: 0.8141\n",
            "Epoch [90/100], Step [4500/7382], D Loss: 1.3343, G Loss: 0.7975\n",
            "Epoch [90/100], Step [4600/7382], D Loss: 1.2999, G Loss: 0.8842\n",
            "Epoch [90/100], Step [4700/7382], D Loss: 1.2892, G Loss: 0.7997\n",
            "Epoch [90/100], Step [4800/7382], D Loss: 1.3546, G Loss: 0.8148\n",
            "Epoch [90/100], Step [4900/7382], D Loss: 1.3365, G Loss: 0.7670\n",
            "Epoch [90/100], Step [5000/7382], D Loss: 1.3074, G Loss: 0.8337\n",
            "Epoch [90/100], Step [5100/7382], D Loss: 1.3272, G Loss: 0.7599\n",
            "Epoch [90/100], Step [5200/7382], D Loss: 1.4067, G Loss: 0.7194\n",
            "Epoch [90/100], Step [5300/7382], D Loss: 1.3902, G Loss: 0.8271\n",
            "Epoch [90/100], Step [5400/7382], D Loss: 1.2904, G Loss: 0.8108\n",
            "Epoch [90/100], Step [5500/7382], D Loss: 1.3328, G Loss: 0.8063\n",
            "Epoch [90/100], Step [5600/7382], D Loss: 1.3180, G Loss: 0.9361\n",
            "Epoch [90/100], Step [5700/7382], D Loss: 1.3804, G Loss: 0.8496\n",
            "Epoch [90/100], Step [5800/7382], D Loss: 1.3523, G Loss: 0.7226\n",
            "Epoch [90/100], Step [5900/7382], D Loss: 1.4198, G Loss: 0.7392\n",
            "Epoch [90/100], Step [6000/7382], D Loss: 1.3787, G Loss: 0.7561\n",
            "Epoch [90/100], Step [6100/7382], D Loss: 1.3264, G Loss: 0.7808\n",
            "Epoch [90/100], Step [6200/7382], D Loss: 1.3471, G Loss: 0.8166\n",
            "Epoch [90/100], Step [6300/7382], D Loss: 1.2677, G Loss: 1.0040\n",
            "Epoch [90/100], Step [6400/7382], D Loss: 1.3080, G Loss: 0.8337\n",
            "Epoch [90/100], Step [6500/7382], D Loss: 1.3549, G Loss: 0.7857\n",
            "Epoch [90/100], Step [6600/7382], D Loss: 1.3675, G Loss: 0.7321\n",
            "Epoch [90/100], Step [6700/7382], D Loss: 1.4032, G Loss: 0.7561\n",
            "Epoch [90/100], Step [6800/7382], D Loss: 1.3280, G Loss: 0.8562\n",
            "Epoch [90/100], Step [6900/7382], D Loss: 1.3093, G Loss: 0.7830\n",
            "Epoch [90/100], Step [7000/7382], D Loss: 1.3380, G Loss: 0.7191\n",
            "Epoch [90/100], Step [7100/7382], D Loss: 1.3716, G Loss: 0.8084\n",
            "Epoch [90/100], Step [7200/7382], D Loss: 1.3728, G Loss: 0.7649\n",
            "Epoch [90/100], Step [7300/7382], D Loss: 1.3049, G Loss: 0.8959\n",
            "Epoch [91/100], Step [100/7382], D Loss: 1.3040, G Loss: 0.7887\n",
            "Epoch [91/100], Step [200/7382], D Loss: 1.3102, G Loss: 0.7791\n",
            "Epoch [91/100], Step [300/7382], D Loss: 1.3388, G Loss: 0.7834\n",
            "Epoch [91/100], Step [400/7382], D Loss: 1.3346, G Loss: 0.8937\n",
            "Epoch [91/100], Step [500/7382], D Loss: 1.3594, G Loss: 0.8053\n",
            "Epoch [91/100], Step [600/7382], D Loss: 1.3891, G Loss: 0.7649\n",
            "Epoch [91/100], Step [700/7382], D Loss: 1.2928, G Loss: 0.9242\n",
            "Epoch [91/100], Step [800/7382], D Loss: 1.3026, G Loss: 0.7840\n",
            "Epoch [91/100], Step [900/7382], D Loss: 1.3351, G Loss: 0.7854\n",
            "Epoch [91/100], Step [1000/7382], D Loss: 1.2385, G Loss: 0.8596\n",
            "Epoch [91/100], Step [1100/7382], D Loss: 1.2298, G Loss: 0.8370\n",
            "Epoch [91/100], Step [1200/7382], D Loss: 1.3388, G Loss: 0.7955\n",
            "Epoch [91/100], Step [1300/7382], D Loss: 1.3601, G Loss: 0.7569\n",
            "Epoch [91/100], Step [1400/7382], D Loss: 1.3261, G Loss: 0.9123\n",
            "Epoch [91/100], Step [1500/7382], D Loss: 1.2849, G Loss: 0.8935\n",
            "Epoch [91/100], Step [1600/7382], D Loss: 1.2832, G Loss: 0.8683\n",
            "Epoch [91/100], Step [1700/7382], D Loss: 1.2987, G Loss: 0.8187\n",
            "Epoch [91/100], Step [1800/7382], D Loss: 1.3300, G Loss: 0.7332\n",
            "Epoch [91/100], Step [1900/7382], D Loss: 1.3381, G Loss: 0.8399\n",
            "Epoch [91/100], Step [2000/7382], D Loss: 1.3714, G Loss: 0.7266\n",
            "Epoch [91/100], Step [2100/7382], D Loss: 1.3230, G Loss: 0.8048\n",
            "Epoch [91/100], Step [2200/7382], D Loss: 1.3257, G Loss: 0.8126\n",
            "Epoch [91/100], Step [2300/7382], D Loss: 1.3422, G Loss: 0.7854\n",
            "Epoch [91/100], Step [2400/7382], D Loss: 1.3600, G Loss: 0.7553\n",
            "Epoch [91/100], Step [2500/7382], D Loss: 1.3454, G Loss: 0.7909\n",
            "Epoch [91/100], Step [2600/7382], D Loss: 1.3114, G Loss: 0.9729\n",
            "Epoch [91/100], Step [2700/7382], D Loss: 1.3772, G Loss: 0.7807\n",
            "Epoch [91/100], Step [2800/7382], D Loss: 1.3267, G Loss: 0.7979\n",
            "Epoch [91/100], Step [2900/7382], D Loss: 1.3677, G Loss: 0.8518\n",
            "Epoch [91/100], Step [3000/7382], D Loss: 1.3196, G Loss: 0.8364\n",
            "Epoch [91/100], Step [3100/7382], D Loss: 1.3426, G Loss: 0.9706\n",
            "Epoch [91/100], Step [3200/7382], D Loss: 1.3384, G Loss: 0.7734\n",
            "Epoch [91/100], Step [3300/7382], D Loss: 1.3076, G Loss: 0.8844\n",
            "Epoch [91/100], Step [3400/7382], D Loss: 1.3169, G Loss: 0.8774\n",
            "Epoch [91/100], Step [3500/7382], D Loss: 1.3466, G Loss: 0.8890\n",
            "Epoch [91/100], Step [3600/7382], D Loss: 1.3602, G Loss: 0.7290\n",
            "Epoch [91/100], Step [3700/7382], D Loss: 1.4043, G Loss: 0.8370\n",
            "Epoch [91/100], Step [3800/7382], D Loss: 1.2660, G Loss: 0.9101\n",
            "Epoch [91/100], Step [3900/7382], D Loss: 1.3534, G Loss: 0.7353\n",
            "Epoch [91/100], Step [4000/7382], D Loss: 1.3548, G Loss: 0.9307\n",
            "Epoch [91/100], Step [4100/7382], D Loss: 1.3048, G Loss: 0.9282\n",
            "Epoch [91/100], Step [4200/7382], D Loss: 1.3275, G Loss: 0.8127\n",
            "Epoch [91/100], Step [4300/7382], D Loss: 1.3867, G Loss: 0.7438\n",
            "Epoch [91/100], Step [4400/7382], D Loss: 1.3390, G Loss: 0.7534\n",
            "Epoch [91/100], Step [4500/7382], D Loss: 1.2914, G Loss: 0.8893\n",
            "Epoch [91/100], Step [4600/7382], D Loss: 1.3003, G Loss: 0.7717\n",
            "Epoch [91/100], Step [4700/7382], D Loss: 1.3472, G Loss: 0.7935\n",
            "Epoch [91/100], Step [4800/7382], D Loss: 1.3993, G Loss: 0.8035\n",
            "Epoch [91/100], Step [4900/7382], D Loss: 1.3379, G Loss: 0.7273\n",
            "Epoch [91/100], Step [5000/7382], D Loss: 1.3631, G Loss: 0.7703\n",
            "Epoch [91/100], Step [5100/7382], D Loss: 1.3286, G Loss: 0.7697\n",
            "Epoch [91/100], Step [5200/7382], D Loss: 1.4028, G Loss: 0.6934\n",
            "Epoch [91/100], Step [5300/7382], D Loss: 1.3846, G Loss: 0.7700\n",
            "Epoch [91/100], Step [5400/7382], D Loss: 1.3422, G Loss: 0.7490\n",
            "Epoch [91/100], Step [5500/7382], D Loss: 1.3470, G Loss: 0.8038\n",
            "Epoch [91/100], Step [5600/7382], D Loss: 1.3165, G Loss: 0.8642\n",
            "Epoch [91/100], Step [5700/7382], D Loss: 1.3801, G Loss: 0.7739\n",
            "Epoch [91/100], Step [5800/7382], D Loss: 1.2787, G Loss: 0.8253\n",
            "Epoch [91/100], Step [5900/7382], D Loss: 1.2753, G Loss: 0.7632\n",
            "Epoch [91/100], Step [6000/7382], D Loss: 1.3822, G Loss: 0.7446\n",
            "Epoch [91/100], Step [6100/7382], D Loss: 1.3600, G Loss: 0.7751\n",
            "Epoch [91/100], Step [6200/7382], D Loss: 1.3493, G Loss: 0.7642\n",
            "Epoch [91/100], Step [6300/7382], D Loss: 1.2955, G Loss: 0.8422\n",
            "Epoch [91/100], Step [6400/7382], D Loss: 1.3643, G Loss: 0.7760\n",
            "Epoch [91/100], Step [6500/7382], D Loss: 1.3919, G Loss: 0.7497\n",
            "Epoch [91/100], Step [6600/7382], D Loss: 1.3261, G Loss: 0.7993\n",
            "Epoch [91/100], Step [6700/7382], D Loss: 1.3136, G Loss: 0.8901\n",
            "Epoch [91/100], Step [6800/7382], D Loss: 1.3197, G Loss: 0.8278\n",
            "Epoch [91/100], Step [6900/7382], D Loss: 1.3362, G Loss: 0.8168\n",
            "Epoch [91/100], Step [7000/7382], D Loss: 1.3298, G Loss: 0.7797\n",
            "Epoch [91/100], Step [7100/7382], D Loss: 1.4242, G Loss: 0.7292\n",
            "Epoch [91/100], Step [7200/7382], D Loss: 1.4106, G Loss: 0.8968\n",
            "Epoch [91/100], Step [7300/7382], D Loss: 1.3446, G Loss: 0.7823\n",
            "Epoch [92/100], Step [100/7382], D Loss: 1.4033, G Loss: 0.7687\n",
            "Epoch [92/100], Step [200/7382], D Loss: 1.3821, G Loss: 0.7415\n",
            "Epoch [92/100], Step [300/7382], D Loss: 1.3924, G Loss: 0.7529\n",
            "Epoch [92/100], Step [400/7382], D Loss: 1.3568, G Loss: 0.7852\n",
            "Epoch [92/100], Step [500/7382], D Loss: 1.3388, G Loss: 0.9234\n",
            "Epoch [92/100], Step [600/7382], D Loss: 1.4143, G Loss: 0.6763\n",
            "Epoch [92/100], Step [700/7382], D Loss: 1.3208, G Loss: 0.8042\n",
            "Epoch [92/100], Step [800/7382], D Loss: 1.2909, G Loss: 0.8157\n",
            "Epoch [92/100], Step [900/7382], D Loss: 1.4001, G Loss: 0.7588\n",
            "Epoch [92/100], Step [1000/7382], D Loss: 1.3173, G Loss: 0.8175\n",
            "Epoch [92/100], Step [1100/7382], D Loss: 1.3024, G Loss: 0.7805\n",
            "Epoch [92/100], Step [1200/7382], D Loss: 1.2983, G Loss: 0.8146\n",
            "Epoch [92/100], Step [1300/7382], D Loss: 1.3580, G Loss: 0.7956\n",
            "Epoch [92/100], Step [1400/7382], D Loss: 1.3318, G Loss: 0.8043\n",
            "Epoch [92/100], Step [1500/7382], D Loss: 1.3459, G Loss: 0.8351\n",
            "Epoch [92/100], Step [1600/7382], D Loss: 1.3712, G Loss: 0.8334\n",
            "Epoch [92/100], Step [1700/7382], D Loss: 1.3968, G Loss: 0.7231\n",
            "Epoch [92/100], Step [1800/7382], D Loss: 1.3067, G Loss: 0.7649\n",
            "Epoch [92/100], Step [1900/7382], D Loss: 1.3415, G Loss: 0.7618\n",
            "Epoch [92/100], Step [2000/7382], D Loss: 1.3344, G Loss: 0.7598\n",
            "Epoch [92/100], Step [2100/7382], D Loss: 1.3872, G Loss: 0.8640\n",
            "Epoch [92/100], Step [2200/7382], D Loss: 1.3642, G Loss: 0.8073\n",
            "Epoch [92/100], Step [2300/7382], D Loss: 1.3274, G Loss: 0.7923\n",
            "Epoch [92/100], Step [2400/7382], D Loss: 1.3150, G Loss: 0.7228\n",
            "Epoch [92/100], Step [2500/7382], D Loss: 1.3119, G Loss: 0.9064\n",
            "Epoch [92/100], Step [2600/7382], D Loss: 1.3270, G Loss: 0.7647\n",
            "Epoch [92/100], Step [2700/7382], D Loss: 1.2839, G Loss: 0.8168\n",
            "Epoch [92/100], Step [2800/7382], D Loss: 1.3081, G Loss: 0.8517\n",
            "Epoch [92/100], Step [2900/7382], D Loss: 1.3488, G Loss: 0.7832\n",
            "Epoch [92/100], Step [3000/7382], D Loss: 1.3432, G Loss: 0.7341\n",
            "Epoch [92/100], Step [3100/7382], D Loss: 1.3395, G Loss: 0.8563\n",
            "Epoch [92/100], Step [3200/7382], D Loss: 1.2915, G Loss: 0.8482\n",
            "Epoch [92/100], Step [3300/7382], D Loss: 1.3905, G Loss: 0.7386\n",
            "Epoch [92/100], Step [3400/7382], D Loss: 1.3444, G Loss: 0.7166\n",
            "Epoch [92/100], Step [3500/7382], D Loss: 1.3954, G Loss: 0.7577\n",
            "Epoch [92/100], Step [3600/7382], D Loss: 1.3404, G Loss: 0.8768\n",
            "Epoch [92/100], Step [3700/7382], D Loss: 1.3553, G Loss: 0.7086\n",
            "Epoch [92/100], Step [3800/7382], D Loss: 1.2748, G Loss: 1.1247\n",
            "Epoch [92/100], Step [3900/7382], D Loss: 1.3788, G Loss: 0.7537\n",
            "Epoch [92/100], Step [4000/7382], D Loss: 1.2861, G Loss: 0.9332\n",
            "Epoch [92/100], Step [4100/7382], D Loss: 1.3533, G Loss: 0.7660\n",
            "Epoch [92/100], Step [4200/7382], D Loss: 1.3384, G Loss: 0.7925\n",
            "Epoch [92/100], Step [4300/7382], D Loss: 1.3278, G Loss: 0.8672\n",
            "Epoch [92/100], Step [4400/7382], D Loss: 1.3241, G Loss: 0.8029\n",
            "Epoch [92/100], Step [4500/7382], D Loss: 1.3535, G Loss: 0.8051\n",
            "Epoch [92/100], Step [4600/7382], D Loss: 1.3420, G Loss: 0.8046\n",
            "Epoch [92/100], Step [4700/7382], D Loss: 1.3289, G Loss: 0.7354\n",
            "Epoch [92/100], Step [4800/7382], D Loss: 1.3359, G Loss: 0.7246\n",
            "Epoch [92/100], Step [4900/7382], D Loss: 1.3633, G Loss: 0.8238\n",
            "Epoch [92/100], Step [5000/7382], D Loss: 1.3882, G Loss: 0.7445\n",
            "Epoch [92/100], Step [5100/7382], D Loss: 1.3941, G Loss: 0.7529\n",
            "Epoch [92/100], Step [5200/7382], D Loss: 1.3403, G Loss: 0.7995\n",
            "Epoch [92/100], Step [5300/7382], D Loss: 1.3824, G Loss: 0.7809\n",
            "Epoch [92/100], Step [5400/7382], D Loss: 1.3730, G Loss: 0.7039\n",
            "Epoch [92/100], Step [5500/7382], D Loss: 1.3510, G Loss: 0.7666\n",
            "Epoch [92/100], Step [5600/7382], D Loss: 1.3864, G Loss: 0.7165\n",
            "Epoch [92/100], Step [5700/7382], D Loss: 1.3472, G Loss: 0.7982\n",
            "Epoch [92/100], Step [5800/7382], D Loss: 1.3230, G Loss: 0.8475\n",
            "Epoch [92/100], Step [5900/7382], D Loss: 1.3306, G Loss: 1.0235\n",
            "Epoch [92/100], Step [6000/7382], D Loss: 1.3730, G Loss: 0.7659\n",
            "Epoch [92/100], Step [6100/7382], D Loss: 1.3401, G Loss: 0.8964\n",
            "Epoch [92/100], Step [6200/7382], D Loss: 1.3664, G Loss: 0.7345\n",
            "Epoch [92/100], Step [6300/7382], D Loss: 1.3636, G Loss: 0.8378\n",
            "Epoch [92/100], Step [6400/7382], D Loss: 1.3453, G Loss: 0.7758\n",
            "Epoch [92/100], Step [6500/7382], D Loss: 1.3707, G Loss: 0.7728\n",
            "Epoch [92/100], Step [6600/7382], D Loss: 1.3935, G Loss: 0.8481\n",
            "Epoch [92/100], Step [6700/7382], D Loss: 1.3170, G Loss: 0.7921\n",
            "Epoch [92/100], Step [6800/7382], D Loss: 1.3645, G Loss: 0.7435\n",
            "Epoch [92/100], Step [6900/7382], D Loss: 1.3264, G Loss: 0.7582\n",
            "Epoch [92/100], Step [7000/7382], D Loss: 1.4016, G Loss: 0.7077\n",
            "Epoch [92/100], Step [7100/7382], D Loss: 1.2925, G Loss: 0.8393\n",
            "Epoch [92/100], Step [7200/7382], D Loss: 1.3218, G Loss: 0.7690\n",
            "Epoch [92/100], Step [7300/7382], D Loss: 1.3668, G Loss: 0.7424\n",
            "Epoch [93/100], Step [100/7382], D Loss: 1.2602, G Loss: 0.9475\n",
            "Epoch [93/100], Step [200/7382], D Loss: 1.3012, G Loss: 1.0186\n",
            "Epoch [93/100], Step [300/7382], D Loss: 1.3088, G Loss: 0.9140\n",
            "Epoch [93/100], Step [400/7382], D Loss: 1.3462, G Loss: 0.7870\n",
            "Epoch [93/100], Step [500/7382], D Loss: 1.3582, G Loss: 0.8241\n",
            "Epoch [93/100], Step [600/7382], D Loss: 1.3323, G Loss: 0.9154\n",
            "Epoch [93/100], Step [700/7382], D Loss: 1.2499, G Loss: 1.0159\n",
            "Epoch [93/100], Step [800/7382], D Loss: 1.4205, G Loss: 0.7134\n",
            "Epoch [93/100], Step [900/7382], D Loss: 1.3096, G Loss: 0.8553\n",
            "Epoch [93/100], Step [1000/7382], D Loss: 1.3656, G Loss: 0.7538\n",
            "Epoch [93/100], Step [1100/7382], D Loss: 1.3535, G Loss: 0.8652\n",
            "Epoch [93/100], Step [1200/7382], D Loss: 1.2966, G Loss: 0.9087\n",
            "Epoch [93/100], Step [1300/7382], D Loss: 1.2988, G Loss: 0.8266\n",
            "Epoch [93/100], Step [1400/7382], D Loss: 1.3698, G Loss: 0.8802\n",
            "Epoch [93/100], Step [1500/7382], D Loss: 1.3315, G Loss: 0.7801\n",
            "Epoch [93/100], Step [1600/7382], D Loss: 1.2760, G Loss: 0.9122\n",
            "Epoch [93/100], Step [1700/7382], D Loss: 1.2926, G Loss: 0.8709\n",
            "Epoch [93/100], Step [1800/7382], D Loss: 1.3650, G Loss: 0.8718\n",
            "Epoch [93/100], Step [1900/7382], D Loss: 1.3058, G Loss: 0.8600\n",
            "Epoch [93/100], Step [2000/7382], D Loss: 1.2486, G Loss: 0.8606\n",
            "Epoch [93/100], Step [2100/7382], D Loss: 1.3549, G Loss: 0.7830\n",
            "Epoch [93/100], Step [2200/7382], D Loss: 1.3063, G Loss: 0.9151\n",
            "Epoch [93/100], Step [2300/7382], D Loss: 1.3876, G Loss: 0.7176\n",
            "Epoch [93/100], Step [2400/7382], D Loss: 1.3826, G Loss: 0.7654\n",
            "Epoch [93/100], Step [2500/7382], D Loss: 1.3183, G Loss: 0.7978\n",
            "Epoch [93/100], Step [2600/7382], D Loss: 1.3731, G Loss: 0.7435\n",
            "Epoch [93/100], Step [2700/7382], D Loss: 1.3520, G Loss: 0.9211\n",
            "Epoch [93/100], Step [2800/7382], D Loss: 1.4157, G Loss: 0.7540\n",
            "Epoch [93/100], Step [2900/7382], D Loss: 1.3320, G Loss: 0.7397\n",
            "Epoch [93/100], Step [3000/7382], D Loss: 1.3098, G Loss: 0.7447\n",
            "Epoch [93/100], Step [3100/7382], D Loss: 1.2653, G Loss: 0.8920\n",
            "Epoch [93/100], Step [3200/7382], D Loss: 1.2826, G Loss: 0.9247\n",
            "Epoch [93/100], Step [3300/7382], D Loss: 1.3786, G Loss: 0.7072\n",
            "Epoch [93/100], Step [3400/7382], D Loss: 1.3700, G Loss: 0.7714\n",
            "Epoch [93/100], Step [3500/7382], D Loss: 1.3547, G Loss: 0.8351\n",
            "Epoch [93/100], Step [3600/7382], D Loss: 1.3624, G Loss: 0.8155\n",
            "Epoch [93/100], Step [3700/7382], D Loss: 1.3596, G Loss: 0.7285\n",
            "Epoch [93/100], Step [3800/7382], D Loss: 1.3457, G Loss: 0.8084\n",
            "Epoch [93/100], Step [3900/7382], D Loss: 1.2900, G Loss: 1.0780\n",
            "Epoch [93/100], Step [4000/7382], D Loss: 1.4867, G Loss: 0.7054\n",
            "Epoch [93/100], Step [4100/7382], D Loss: 1.3320, G Loss: 0.7858\n",
            "Epoch [93/100], Step [4200/7382], D Loss: 1.3505, G Loss: 0.7647\n",
            "Epoch [93/100], Step [4300/7382], D Loss: 1.3959, G Loss: 0.8081\n",
            "Epoch [93/100], Step [4400/7382], D Loss: 1.3496, G Loss: 0.7513\n",
            "Epoch [93/100], Step [4500/7382], D Loss: 1.3018, G Loss: 0.8690\n",
            "Epoch [93/100], Step [4600/7382], D Loss: 1.3212, G Loss: 0.8002\n",
            "Epoch [93/100], Step [4700/7382], D Loss: 1.3752, G Loss: 0.7562\n",
            "Epoch [93/100], Step [4800/7382], D Loss: 1.3388, G Loss: 0.7707\n",
            "Epoch [93/100], Step [4900/7382], D Loss: 1.3219, G Loss: 0.8742\n",
            "Epoch [93/100], Step [5000/7382], D Loss: 1.3593, G Loss: 0.7909\n",
            "Epoch [93/100], Step [5100/7382], D Loss: 1.3439, G Loss: 0.7881\n",
            "Epoch [93/100], Step [5200/7382], D Loss: 1.3402, G Loss: 0.8169\n",
            "Epoch [93/100], Step [5300/7382], D Loss: 1.3227, G Loss: 0.8232\n",
            "Epoch [93/100], Step [5400/7382], D Loss: 1.3471, G Loss: 0.8661\n",
            "Epoch [93/100], Step [5500/7382], D Loss: 1.3635, G Loss: 0.7717\n",
            "Epoch [93/100], Step [5600/7382], D Loss: 1.3749, G Loss: 0.9222\n",
            "Epoch [93/100], Step [5700/7382], D Loss: 1.2860, G Loss: 0.8693\n",
            "Epoch [93/100], Step [5800/7382], D Loss: 1.2689, G Loss: 0.8612\n",
            "Epoch [93/100], Step [5900/7382], D Loss: 1.3318, G Loss: 0.7877\n",
            "Epoch [93/100], Step [6000/7382], D Loss: 1.2609, G Loss: 0.9883\n",
            "Epoch [93/100], Step [6100/7382], D Loss: 1.3006, G Loss: 0.8309\n",
            "Epoch [93/100], Step [6200/7382], D Loss: 1.2971, G Loss: 0.8002\n",
            "Epoch [93/100], Step [6300/7382], D Loss: 1.3372, G Loss: 0.9661\n",
            "Epoch [93/100], Step [6400/7382], D Loss: 1.3336, G Loss: 0.8303\n",
            "Epoch [93/100], Step [6500/7382], D Loss: 1.3683, G Loss: 0.7690\n",
            "Epoch [93/100], Step [6600/7382], D Loss: 1.3038, G Loss: 0.8679\n",
            "Epoch [93/100], Step [6700/7382], D Loss: 1.2681, G Loss: 0.9145\n",
            "Epoch [93/100], Step [6800/7382], D Loss: 1.3207, G Loss: 0.9984\n",
            "Epoch [93/100], Step [6900/7382], D Loss: 1.3241, G Loss: 0.9342\n",
            "Epoch [93/100], Step [7000/7382], D Loss: 1.2877, G Loss: 0.7832\n",
            "Epoch [93/100], Step [7100/7382], D Loss: 1.3844, G Loss: 0.7682\n",
            "Epoch [93/100], Step [7200/7382], D Loss: 1.2932, G Loss: 0.8280\n",
            "Epoch [93/100], Step [7300/7382], D Loss: 1.3157, G Loss: 0.8458\n",
            "Epoch [94/100], Step [100/7382], D Loss: 1.3153, G Loss: 0.8445\n",
            "Epoch [94/100], Step [200/7382], D Loss: 1.3497, G Loss: 0.9076\n",
            "Epoch [94/100], Step [300/7382], D Loss: 1.2842, G Loss: 0.8242\n",
            "Epoch [94/100], Step [400/7382], D Loss: 1.3376, G Loss: 0.8400\n",
            "Epoch [94/100], Step [500/7382], D Loss: 1.2850, G Loss: 0.8962\n",
            "Epoch [94/100], Step [600/7382], D Loss: 1.1911, G Loss: 0.9704\n",
            "Epoch [94/100], Step [700/7382], D Loss: 1.3127, G Loss: 0.9693\n",
            "Epoch [94/100], Step [800/7382], D Loss: 1.3038, G Loss: 0.7910\n",
            "Epoch [94/100], Step [900/7382], D Loss: 1.3374, G Loss: 0.9720\n",
            "Epoch [94/100], Step [1000/7382], D Loss: 1.3847, G Loss: 0.7595\n",
            "Epoch [94/100], Step [1100/7382], D Loss: 1.3522, G Loss: 0.8366\n",
            "Epoch [94/100], Step [1200/7382], D Loss: 1.3472, G Loss: 0.7640\n",
            "Epoch [94/100], Step [1300/7382], D Loss: 1.3277, G Loss: 0.7704\n",
            "Epoch [94/100], Step [1400/7382], D Loss: 1.3273, G Loss: 0.8411\n",
            "Epoch [94/100], Step [1500/7382], D Loss: 1.3489, G Loss: 0.7787\n",
            "Epoch [94/100], Step [1600/7382], D Loss: 1.3248, G Loss: 0.8682\n",
            "Epoch [94/100], Step [1700/7382], D Loss: 1.3467, G Loss: 0.7389\n",
            "Epoch [94/100], Step [1800/7382], D Loss: 1.3151, G Loss: 0.7908\n",
            "Epoch [94/100], Step [1900/7382], D Loss: 1.3610, G Loss: 0.8112\n",
            "Epoch [94/100], Step [2000/7382], D Loss: 1.3200, G Loss: 0.9370\n",
            "Epoch [94/100], Step [2100/7382], D Loss: 1.3634, G Loss: 0.7298\n",
            "Epoch [94/100], Step [2200/7382], D Loss: 1.3379, G Loss: 0.7826\n",
            "Epoch [94/100], Step [2300/7382], D Loss: 1.3327, G Loss: 0.7820\n",
            "Epoch [94/100], Step [2400/7382], D Loss: 1.3343, G Loss: 0.9982\n",
            "Epoch [94/100], Step [2500/7382], D Loss: 1.4191, G Loss: 0.7712\n",
            "Epoch [94/100], Step [2600/7382], D Loss: 1.3496, G Loss: 0.8888\n",
            "Epoch [94/100], Step [2700/7382], D Loss: 1.1752, G Loss: 0.9036\n",
            "Epoch [94/100], Step [2800/7382], D Loss: 1.3461, G Loss: 0.7129\n",
            "Epoch [94/100], Step [2900/7382], D Loss: 1.3240, G Loss: 0.8193\n",
            "Epoch [94/100], Step [3000/7382], D Loss: 1.6004, G Loss: 0.6929\n",
            "Epoch [94/100], Step [3100/7382], D Loss: 1.3082, G Loss: 0.7563\n",
            "Epoch [94/100], Step [3200/7382], D Loss: 1.3856, G Loss: 0.7918\n",
            "Epoch [94/100], Step [3300/7382], D Loss: 1.2882, G Loss: 0.8280\n",
            "Epoch [94/100], Step [3400/7382], D Loss: 1.3320, G Loss: 0.8432\n",
            "Epoch [94/100], Step [3500/7382], D Loss: 1.3780, G Loss: 0.7105\n",
            "Epoch [94/100], Step [3600/7382], D Loss: 1.3408, G Loss: 0.8052\n",
            "Epoch [94/100], Step [3700/7382], D Loss: 1.3670, G Loss: 0.7878\n",
            "Epoch [94/100], Step [3800/7382], D Loss: 1.3406, G Loss: 0.9294\n",
            "Epoch [94/100], Step [3900/7382], D Loss: 1.3582, G Loss: 0.7454\n",
            "Epoch [94/100], Step [4000/7382], D Loss: 1.2521, G Loss: 0.8332\n",
            "Epoch [94/100], Step [4100/7382], D Loss: 1.3253, G Loss: 0.7821\n",
            "Epoch [94/100], Step [4200/7382], D Loss: 1.2785, G Loss: 0.8421\n",
            "Epoch [94/100], Step [4300/7382], D Loss: 1.3555, G Loss: 0.8915\n",
            "Epoch [94/100], Step [4400/7382], D Loss: 1.3778, G Loss: 0.8519\n",
            "Epoch [94/100], Step [4500/7382], D Loss: 1.3601, G Loss: 0.7733\n",
            "Epoch [94/100], Step [4600/7382], D Loss: 1.3817, G Loss: 0.9062\n",
            "Epoch [94/100], Step [4700/7382], D Loss: 1.3423, G Loss: 0.9400\n",
            "Epoch [94/100], Step [4800/7382], D Loss: 1.3470, G Loss: 0.8146\n",
            "Epoch [94/100], Step [4900/7382], D Loss: 1.3668, G Loss: 0.8223\n",
            "Epoch [94/100], Step [5000/7382], D Loss: 1.2815, G Loss: 0.8158\n",
            "Epoch [94/100], Step [5100/7382], D Loss: 1.3843, G Loss: 0.7898\n",
            "Epoch [94/100], Step [5200/7382], D Loss: 1.3185, G Loss: 0.9156\n",
            "Epoch [94/100], Step [5300/7382], D Loss: 1.2976, G Loss: 0.8217\n",
            "Epoch [94/100], Step [5400/7382], D Loss: 1.3148, G Loss: 0.7937\n",
            "Epoch [94/100], Step [5500/7382], D Loss: 1.3452, G Loss: 0.8388\n",
            "Epoch [94/100], Step [5600/7382], D Loss: 1.3914, G Loss: 0.7370\n",
            "Epoch [94/100], Step [5700/7382], D Loss: 1.3669, G Loss: 0.8159\n",
            "Epoch [94/100], Step [5800/7382], D Loss: 1.3025, G Loss: 0.8346\n",
            "Epoch [94/100], Step [5900/7382], D Loss: 1.2961, G Loss: 0.9883\n",
            "Epoch [94/100], Step [6000/7382], D Loss: 1.3848, G Loss: 0.7130\n",
            "Epoch [94/100], Step [6100/7382], D Loss: 1.4020, G Loss: 0.9108\n",
            "Epoch [94/100], Step [6200/7382], D Loss: 1.3279, G Loss: 0.9138\n",
            "Epoch [94/100], Step [6300/7382], D Loss: 1.3241, G Loss: 0.8480\n",
            "Epoch [94/100], Step [6400/7382], D Loss: 1.3915, G Loss: 0.7788\n",
            "Epoch [94/100], Step [6500/7382], D Loss: 1.3334, G Loss: 0.7733\n",
            "Epoch [94/100], Step [6600/7382], D Loss: 1.3393, G Loss: 0.7566\n",
            "Epoch [94/100], Step [6700/7382], D Loss: 1.3964, G Loss: 0.6999\n",
            "Epoch [94/100], Step [6800/7382], D Loss: 1.3803, G Loss: 0.7761\n",
            "Epoch [94/100], Step [6900/7382], D Loss: 1.2629, G Loss: 0.9371\n",
            "Epoch [94/100], Step [7000/7382], D Loss: 1.4062, G Loss: 0.8778\n",
            "Epoch [94/100], Step [7100/7382], D Loss: 1.3257, G Loss: 1.0341\n",
            "Epoch [94/100], Step [7200/7382], D Loss: 1.3404, G Loss: 0.7505\n",
            "Epoch [94/100], Step [7300/7382], D Loss: 1.3486, G Loss: 0.8161\n",
            "Epoch [95/100], Step [100/7382], D Loss: 1.3670, G Loss: 0.7702\n",
            "Epoch [95/100], Step [200/7382], D Loss: 1.3143, G Loss: 0.9468\n",
            "Epoch [95/100], Step [300/7382], D Loss: 1.3348, G Loss: 0.9175\n",
            "Epoch [95/100], Step [400/7382], D Loss: 1.3037, G Loss: 0.8379\n",
            "Epoch [95/100], Step [500/7382], D Loss: 1.3385, G Loss: 0.8949\n",
            "Epoch [95/100], Step [600/7382], D Loss: 1.3662, G Loss: 0.7700\n",
            "Epoch [95/100], Step [700/7382], D Loss: 1.3188, G Loss: 0.7969\n",
            "Epoch [95/100], Step [800/7382], D Loss: 1.2775, G Loss: 0.9002\n",
            "Epoch [95/100], Step [900/7382], D Loss: 1.3445, G Loss: 0.7260\n",
            "Epoch [95/100], Step [1000/7382], D Loss: 1.3453, G Loss: 0.7740\n",
            "Epoch [95/100], Step [1100/7382], D Loss: 1.3614, G Loss: 0.7682\n",
            "Epoch [95/100], Step [1200/7382], D Loss: 1.3880, G Loss: 0.7210\n",
            "Epoch [95/100], Step [1300/7382], D Loss: 1.3607, G Loss: 0.7588\n",
            "Epoch [95/100], Step [1400/7382], D Loss: 1.3608, G Loss: 0.7544\n",
            "Epoch [95/100], Step [1500/7382], D Loss: 1.3043, G Loss: 0.7935\n",
            "Epoch [95/100], Step [1600/7382], D Loss: 1.2920, G Loss: 0.8820\n",
            "Epoch [95/100], Step [1700/7382], D Loss: 1.4662, G Loss: 0.7072\n",
            "Epoch [95/100], Step [1800/7382], D Loss: 1.2887, G Loss: 0.8215\n",
            "Epoch [95/100], Step [1900/7382], D Loss: 1.3887, G Loss: 0.7169\n",
            "Epoch [95/100], Step [2000/7382], D Loss: 1.2927, G Loss: 0.7908\n",
            "Epoch [95/100], Step [2100/7382], D Loss: 1.2714, G Loss: 1.0107\n",
            "Epoch [95/100], Step [2200/7382], D Loss: 1.2916, G Loss: 0.8853\n",
            "Epoch [95/100], Step [2300/7382], D Loss: 1.3601, G Loss: 0.7473\n",
            "Epoch [95/100], Step [2400/7382], D Loss: 1.3556, G Loss: 1.0133\n",
            "Epoch [95/100], Step [2500/7382], D Loss: 1.2910, G Loss: 0.8189\n",
            "Epoch [95/100], Step [2600/7382], D Loss: 1.3433, G Loss: 0.9613\n",
            "Epoch [95/100], Step [2700/7382], D Loss: 1.3604, G Loss: 0.7670\n",
            "Epoch [95/100], Step [2800/7382], D Loss: 1.3263, G Loss: 1.0028\n",
            "Epoch [95/100], Step [2900/7382], D Loss: 1.3363, G Loss: 0.8002\n",
            "Epoch [95/100], Step [3000/7382], D Loss: 1.3153, G Loss: 0.7539\n",
            "Epoch [95/100], Step [3100/7382], D Loss: 1.4031, G Loss: 0.9020\n",
            "Epoch [95/100], Step [3200/7382], D Loss: 1.3595, G Loss: 0.7482\n",
            "Epoch [95/100], Step [3300/7382], D Loss: 1.3821, G Loss: 0.8110\n",
            "Epoch [95/100], Step [3400/7382], D Loss: 1.3452, G Loss: 0.7806\n",
            "Epoch [95/100], Step [3500/7382], D Loss: 1.3366, G Loss: 0.7848\n",
            "Epoch [95/100], Step [3600/7382], D Loss: 1.3036, G Loss: 0.8771\n",
            "Epoch [95/100], Step [3700/7382], D Loss: 1.2445, G Loss: 0.9514\n",
            "Epoch [95/100], Step [3800/7382], D Loss: 1.3192, G Loss: 0.7850\n",
            "Epoch [95/100], Step [3900/7382], D Loss: 1.4584, G Loss: 0.7633\n",
            "Epoch [95/100], Step [4000/7382], D Loss: 1.2888, G Loss: 0.9921\n",
            "Epoch [95/100], Step [4100/7382], D Loss: 1.3585, G Loss: 0.8316\n",
            "Epoch [95/100], Step [4200/7382], D Loss: 1.3398, G Loss: 0.8176\n",
            "Epoch [95/100], Step [4300/7382], D Loss: 1.3008, G Loss: 0.7618\n",
            "Epoch [95/100], Step [4400/7382], D Loss: 1.3238, G Loss: 0.9173\n",
            "Epoch [95/100], Step [4500/7382], D Loss: 1.3071, G Loss: 0.7924\n",
            "Epoch [95/100], Step [4600/7382], D Loss: 1.3232, G Loss: 0.7786\n",
            "Epoch [95/100], Step [4700/7382], D Loss: 1.3667, G Loss: 0.7647\n",
            "Epoch [95/100], Step [4800/7382], D Loss: 1.3501, G Loss: 0.7356\n",
            "Epoch [95/100], Step [4900/7382], D Loss: 1.3531, G Loss: 0.8049\n",
            "Epoch [95/100], Step [5000/7382], D Loss: 1.3544, G Loss: 0.8389\n",
            "Epoch [95/100], Step [5100/7382], D Loss: 1.3159, G Loss: 0.7699\n",
            "Epoch [95/100], Step [5200/7382], D Loss: 1.3343, G Loss: 0.8549\n",
            "Epoch [95/100], Step [5300/7382], D Loss: 1.3413, G Loss: 0.9196\n",
            "Epoch [95/100], Step [5400/7382], D Loss: 1.3808, G Loss: 0.7333\n",
            "Epoch [95/100], Step [5500/7382], D Loss: 1.3310, G Loss: 0.7623\n",
            "Epoch [95/100], Step [5600/7382], D Loss: 1.3720, G Loss: 0.7555\n",
            "Epoch [95/100], Step [5700/7382], D Loss: 1.3783, G Loss: 0.7846\n",
            "Epoch [95/100], Step [5800/7382], D Loss: 1.3278, G Loss: 0.8586\n",
            "Epoch [95/100], Step [5900/7382], D Loss: 1.3422, G Loss: 0.7759\n",
            "Epoch [95/100], Step [6000/7382], D Loss: 1.3589, G Loss: 0.8064\n",
            "Epoch [95/100], Step [6100/7382], D Loss: 1.2336, G Loss: 1.0297\n",
            "Epoch [95/100], Step [6200/7382], D Loss: 1.3205, G Loss: 0.9182\n",
            "Epoch [95/100], Step [6300/7382], D Loss: 1.3773, G Loss: 0.7516\n",
            "Epoch [95/100], Step [6400/7382], D Loss: 1.3676, G Loss: 0.7323\n",
            "Epoch [95/100], Step [6500/7382], D Loss: 1.3205, G Loss: 0.9682\n",
            "Epoch [95/100], Step [6600/7382], D Loss: 1.3563, G Loss: 0.7241\n",
            "Epoch [95/100], Step [6700/7382], D Loss: 1.3804, G Loss: 0.7566\n",
            "Epoch [95/100], Step [6800/7382], D Loss: 1.3511, G Loss: 0.7484\n",
            "Epoch [95/100], Step [6900/7382], D Loss: 1.4030, G Loss: 0.6809\n",
            "Epoch [95/100], Step [7000/7382], D Loss: 1.3263, G Loss: 0.8027\n",
            "Epoch [95/100], Step [7100/7382], D Loss: 1.3411, G Loss: 0.7476\n",
            "Epoch [95/100], Step [7200/7382], D Loss: 1.3666, G Loss: 0.7887\n",
            "Epoch [95/100], Step [7300/7382], D Loss: 1.3394, G Loss: 0.8812\n",
            "Epoch [96/100], Step [100/7382], D Loss: 1.3287, G Loss: 0.7852\n",
            "Epoch [96/100], Step [200/7382], D Loss: 1.3346, G Loss: 0.8317\n",
            "Epoch [96/100], Step [300/7382], D Loss: 1.3391, G Loss: 0.7482\n",
            "Epoch [96/100], Step [400/7382], D Loss: 1.3239, G Loss: 0.8086\n",
            "Epoch [96/100], Step [500/7382], D Loss: 1.3594, G Loss: 0.8294\n",
            "Epoch [96/100], Step [600/7382], D Loss: 1.3419, G Loss: 0.7827\n",
            "Epoch [96/100], Step [700/7382], D Loss: 1.3627, G Loss: 0.7642\n",
            "Epoch [96/100], Step [800/7382], D Loss: 1.4180, G Loss: 0.8385\n",
            "Epoch [96/100], Step [900/7382], D Loss: 1.3605, G Loss: 0.7047\n",
            "Epoch [96/100], Step [1000/7382], D Loss: 1.3619, G Loss: 0.7859\n",
            "Epoch [96/100], Step [1100/7382], D Loss: 1.3628, G Loss: 0.8279\n",
            "Epoch [96/100], Step [1200/7382], D Loss: 1.3645, G Loss: 0.9122\n",
            "Epoch [96/100], Step [1300/7382], D Loss: 1.3500, G Loss: 0.7910\n",
            "Epoch [96/100], Step [1400/7382], D Loss: 1.3446, G Loss: 0.8020\n",
            "Epoch [96/100], Step [1500/7382], D Loss: 1.3302, G Loss: 0.8889\n",
            "Epoch [96/100], Step [1600/7382], D Loss: 1.2794, G Loss: 0.9602\n",
            "Epoch [96/100], Step [1700/7382], D Loss: 1.2590, G Loss: 0.8363\n",
            "Epoch [96/100], Step [1800/7382], D Loss: 1.2271, G Loss: 0.8586\n",
            "Epoch [96/100], Step [1900/7382], D Loss: 1.3061, G Loss: 0.8550\n",
            "Epoch [96/100], Step [2000/7382], D Loss: 1.3983, G Loss: 0.8497\n",
            "Epoch [96/100], Step [2100/7382], D Loss: 1.3626, G Loss: 0.8187\n",
            "Epoch [96/100], Step [2200/7382], D Loss: 1.3029, G Loss: 0.8727\n",
            "Epoch [96/100], Step [2300/7382], D Loss: 1.2574, G Loss: 0.8393\n",
            "Epoch [96/100], Step [2400/7382], D Loss: 1.3817, G Loss: 0.8524\n",
            "Epoch [96/100], Step [2500/7382], D Loss: 1.3107, G Loss: 0.7971\n",
            "Epoch [96/100], Step [2600/7382], D Loss: 1.3675, G Loss: 0.7837\n",
            "Epoch [96/100], Step [2700/7382], D Loss: 1.3583, G Loss: 0.7557\n",
            "Epoch [96/100], Step [2800/7382], D Loss: 1.3052, G Loss: 0.8089\n",
            "Epoch [96/100], Step [2900/7382], D Loss: 1.3683, G Loss: 0.7279\n",
            "Epoch [96/100], Step [3000/7382], D Loss: 1.4132, G Loss: 0.7282\n",
            "Epoch [96/100], Step [3100/7382], D Loss: 1.3195, G Loss: 0.7820\n",
            "Epoch [96/100], Step [3200/7382], D Loss: 1.3329, G Loss: 0.7447\n",
            "Epoch [96/100], Step [3300/7382], D Loss: 1.2830, G Loss: 0.8869\n",
            "Epoch [96/100], Step [3400/7382], D Loss: 1.3410, G Loss: 0.8949\n",
            "Epoch [96/100], Step [3500/7382], D Loss: 1.3645, G Loss: 0.8319\n",
            "Epoch [96/100], Step [3600/7382], D Loss: 1.3935, G Loss: 0.7700\n",
            "Epoch [96/100], Step [3700/7382], D Loss: 1.3420, G Loss: 0.7494\n",
            "Epoch [96/100], Step [3800/7382], D Loss: 1.3754, G Loss: 0.7965\n",
            "Epoch [96/100], Step [3900/7382], D Loss: 1.3431, G Loss: 0.7695\n",
            "Epoch [96/100], Step [4000/7382], D Loss: 1.3581, G Loss: 0.7912\n",
            "Epoch [96/100], Step [4100/7382], D Loss: 1.3018, G Loss: 0.9629\n",
            "Epoch [96/100], Step [4200/7382], D Loss: 1.3822, G Loss: 0.7511\n",
            "Epoch [96/100], Step [4300/7382], D Loss: 1.3045, G Loss: 0.8481\n",
            "Epoch [96/100], Step [4400/7382], D Loss: 1.2965, G Loss: 0.8842\n",
            "Epoch [96/100], Step [4500/7382], D Loss: 1.3659, G Loss: 0.9351\n",
            "Epoch [96/100], Step [4600/7382], D Loss: 1.3656, G Loss: 0.7788\n",
            "Epoch [96/100], Step [4700/7382], D Loss: 1.2950, G Loss: 0.8764\n",
            "Epoch [96/100], Step [4800/7382], D Loss: 1.3327, G Loss: 0.7599\n",
            "Epoch [96/100], Step [4900/7382], D Loss: 1.3183, G Loss: 0.7599\n",
            "Epoch [96/100], Step [5000/7382], D Loss: 1.3174, G Loss: 0.8580\n",
            "Epoch [96/100], Step [5100/7382], D Loss: 1.4086, G Loss: 0.9232\n",
            "Epoch [96/100], Step [5200/7382], D Loss: 1.3051, G Loss: 0.8217\n",
            "Epoch [96/100], Step [5300/7382], D Loss: 1.3045, G Loss: 0.9021\n",
            "Epoch [96/100], Step [5400/7382], D Loss: 1.3271, G Loss: 0.9016\n",
            "Epoch [96/100], Step [5500/7382], D Loss: 1.3730, G Loss: 0.7371\n",
            "Epoch [96/100], Step [5600/7382], D Loss: 1.3244, G Loss: 0.8046\n",
            "Epoch [96/100], Step [5700/7382], D Loss: 1.3011, G Loss: 0.7958\n",
            "Epoch [96/100], Step [5800/7382], D Loss: 1.3590, G Loss: 0.7395\n",
            "Epoch [96/100], Step [5900/7382], D Loss: 1.3053, G Loss: 0.7945\n",
            "Epoch [96/100], Step [6000/7382], D Loss: 1.2391, G Loss: 0.9126\n",
            "Epoch [96/100], Step [6100/7382], D Loss: 1.3489, G Loss: 0.7903\n",
            "Epoch [96/100], Step [6200/7382], D Loss: 1.3270, G Loss: 0.7602\n",
            "Epoch [96/100], Step [6300/7382], D Loss: 1.2935, G Loss: 0.8097\n",
            "Epoch [96/100], Step [6400/7382], D Loss: 1.3039, G Loss: 0.8466\n",
            "Epoch [96/100], Step [6500/7382], D Loss: 1.3621, G Loss: 0.8209\n",
            "Epoch [96/100], Step [6600/7382], D Loss: 1.3664, G Loss: 0.7869\n",
            "Epoch [96/100], Step [6700/7382], D Loss: 1.3049, G Loss: 0.7841\n",
            "Epoch [96/100], Step [6800/7382], D Loss: 1.3758, G Loss: 0.7653\n",
            "Epoch [96/100], Step [6900/7382], D Loss: 1.2620, G Loss: 0.9141\n",
            "Epoch [96/100], Step [7000/7382], D Loss: 1.2647, G Loss: 0.7958\n",
            "Epoch [96/100], Step [7100/7382], D Loss: 1.3091, G Loss: 0.7969\n",
            "Epoch [96/100], Step [7200/7382], D Loss: 1.3028, G Loss: 0.8485\n",
            "Epoch [96/100], Step [7300/7382], D Loss: 1.3145, G Loss: 0.8607\n",
            "Epoch [97/100], Step [100/7382], D Loss: 1.3294, G Loss: 0.7585\n",
            "Epoch [97/100], Step [200/7382], D Loss: 1.4086, G Loss: 0.7433\n",
            "Epoch [97/100], Step [300/7382], D Loss: 1.3500, G Loss: 0.7503\n",
            "Epoch [97/100], Step [400/7382], D Loss: 1.3793, G Loss: 0.7542\n",
            "Epoch [97/100], Step [500/7382], D Loss: 1.3537, G Loss: 0.7855\n",
            "Epoch [97/100], Step [600/7382], D Loss: 1.2820, G Loss: 0.9432\n",
            "Epoch [97/100], Step [700/7382], D Loss: 1.2974, G Loss: 0.8372\n",
            "Epoch [97/100], Step [800/7382], D Loss: 1.3121, G Loss: 0.8225\n",
            "Epoch [97/100], Step [900/7382], D Loss: 1.2961, G Loss: 1.0195\n",
            "Epoch [97/100], Step [1000/7382], D Loss: 1.3811, G Loss: 0.8095\n",
            "Epoch [97/100], Step [1100/7382], D Loss: 1.2668, G Loss: 0.8902\n",
            "Epoch [97/100], Step [1200/7382], D Loss: 1.3259, G Loss: 0.7850\n",
            "Epoch [97/100], Step [1300/7382], D Loss: 1.2937, G Loss: 0.8376\n",
            "Epoch [97/100], Step [1400/7382], D Loss: 1.2561, G Loss: 0.9171\n",
            "Epoch [97/100], Step [1500/7382], D Loss: 1.2605, G Loss: 0.8183\n",
            "Epoch [97/100], Step [1600/7382], D Loss: 1.2632, G Loss: 0.7949\n",
            "Epoch [97/100], Step [1700/7382], D Loss: 1.3298, G Loss: 0.7994\n",
            "Epoch [97/100], Step [1800/7382], D Loss: 1.2785, G Loss: 0.8349\n",
            "Epoch [97/100], Step [1900/7382], D Loss: 1.2997, G Loss: 0.7683\n",
            "Epoch [97/100], Step [2000/7382], D Loss: 1.4260, G Loss: 0.8824\n",
            "Epoch [97/100], Step [2100/7382], D Loss: 1.2199, G Loss: 0.9499\n",
            "Epoch [97/100], Step [2200/7382], D Loss: 1.3016, G Loss: 0.8704\n",
            "Epoch [97/100], Step [2300/7382], D Loss: 1.3698, G Loss: 0.7159\n",
            "Epoch [97/100], Step [2400/7382], D Loss: 1.4320, G Loss: 0.8157\n",
            "Epoch [97/100], Step [2500/7382], D Loss: 1.2834, G Loss: 0.7855\n",
            "Epoch [97/100], Step [2600/7382], D Loss: 1.3587, G Loss: 0.7445\n",
            "Epoch [97/100], Step [2700/7382], D Loss: 1.3375, G Loss: 0.8108\n",
            "Epoch [97/100], Step [2800/7382], D Loss: 1.3123, G Loss: 0.8044\n",
            "Epoch [97/100], Step [2900/7382], D Loss: 1.2551, G Loss: 0.9105\n",
            "Epoch [97/100], Step [3000/7382], D Loss: 1.3619, G Loss: 0.8473\n",
            "Epoch [97/100], Step [3100/7382], D Loss: 1.3621, G Loss: 0.8962\n",
            "Epoch [97/100], Step [3200/7382], D Loss: 1.3601, G Loss: 0.7848\n",
            "Epoch [97/100], Step [3300/7382], D Loss: 1.3190, G Loss: 0.9583\n",
            "Epoch [97/100], Step [3400/7382], D Loss: 1.3325, G Loss: 0.8897\n",
            "Epoch [97/100], Step [3500/7382], D Loss: 1.2263, G Loss: 0.8624\n",
            "Epoch [97/100], Step [3600/7382], D Loss: 1.3512, G Loss: 0.7986\n",
            "Epoch [97/100], Step [3700/7382], D Loss: 1.2521, G Loss: 0.8274\n",
            "Epoch [97/100], Step [3800/7382], D Loss: 1.3279, G Loss: 0.8298\n",
            "Epoch [97/100], Step [3900/7382], D Loss: 1.3010, G Loss: 0.9001\n",
            "Epoch [97/100], Step [4000/7382], D Loss: 1.3757, G Loss: 0.8683\n",
            "Epoch [97/100], Step [4100/7382], D Loss: 1.3301, G Loss: 0.8140\n",
            "Epoch [97/100], Step [4200/7382], D Loss: 1.3456, G Loss: 0.9165\n",
            "Epoch [97/100], Step [4300/7382], D Loss: 1.3673, G Loss: 0.7371\n",
            "Epoch [97/100], Step [4400/7382], D Loss: 1.2671, G Loss: 0.8921\n",
            "Epoch [97/100], Step [4500/7382], D Loss: 1.3234, G Loss: 0.7331\n",
            "Epoch [97/100], Step [4600/7382], D Loss: 1.3766, G Loss: 0.7613\n",
            "Epoch [97/100], Step [4700/7382], D Loss: 1.2472, G Loss: 1.0446\n",
            "Epoch [97/100], Step [4800/7382], D Loss: 1.3350, G Loss: 0.9008\n",
            "Epoch [97/100], Step [4900/7382], D Loss: 1.3634, G Loss: 0.7898\n",
            "Epoch [97/100], Step [5000/7382], D Loss: 1.3019, G Loss: 0.8879\n",
            "Epoch [97/100], Step [5100/7382], D Loss: 1.2904, G Loss: 0.8507\n",
            "Epoch [97/100], Step [5200/7382], D Loss: 1.2340, G Loss: 0.8731\n",
            "Epoch [97/100], Step [5300/7382], D Loss: 1.4149, G Loss: 0.9454\n",
            "Epoch [97/100], Step [5400/7382], D Loss: 1.3468, G Loss: 0.8161\n",
            "Epoch [97/100], Step [5500/7382], D Loss: 1.4046, G Loss: 0.8639\n",
            "Epoch [97/100], Step [5600/7382], D Loss: 1.2779, G Loss: 0.8499\n",
            "Epoch [97/100], Step [5700/7382], D Loss: 1.3415, G Loss: 0.7714\n",
            "Epoch [97/100], Step [5800/7382], D Loss: 1.3231, G Loss: 0.8242\n",
            "Epoch [97/100], Step [5900/7382], D Loss: 1.3176, G Loss: 0.8285\n",
            "Epoch [97/100], Step [6000/7382], D Loss: 1.3815, G Loss: 0.7550\n",
            "Epoch [97/100], Step [6100/7382], D Loss: 1.2682, G Loss: 0.7854\n",
            "Epoch [97/100], Step [6200/7382], D Loss: 1.2153, G Loss: 0.9000\n",
            "Epoch [97/100], Step [6300/7382], D Loss: 1.3107, G Loss: 0.8236\n",
            "Epoch [97/100], Step [6400/7382], D Loss: 1.3807, G Loss: 0.8329\n",
            "Epoch [97/100], Step [6500/7382], D Loss: 1.3766, G Loss: 0.7589\n",
            "Epoch [97/100], Step [6600/7382], D Loss: 1.2832, G Loss: 0.8782\n",
            "Epoch [97/100], Step [6700/7382], D Loss: 1.3340, G Loss: 0.7678\n",
            "Epoch [97/100], Step [6800/7382], D Loss: 1.3133, G Loss: 0.8710\n",
            "Epoch [97/100], Step [6900/7382], D Loss: 1.3301, G Loss: 0.8157\n",
            "Epoch [97/100], Step [7000/7382], D Loss: 1.3385, G Loss: 0.7588\n",
            "Epoch [97/100], Step [7100/7382], D Loss: 1.2885, G Loss: 0.8454\n",
            "Epoch [97/100], Step [7200/7382], D Loss: 1.2929, G Loss: 0.9469\n",
            "Epoch [97/100], Step [7300/7382], D Loss: 1.3694, G Loss: 0.7581\n",
            "Epoch [98/100], Step [100/7382], D Loss: 1.3118, G Loss: 0.8092\n",
            "Epoch [98/100], Step [200/7382], D Loss: 1.3085, G Loss: 0.9429\n",
            "Epoch [98/100], Step [300/7382], D Loss: 1.3686, G Loss: 0.7667\n",
            "Epoch [98/100], Step [400/7382], D Loss: 1.2906, G Loss: 0.7905\n",
            "Epoch [98/100], Step [500/7382], D Loss: 1.2660, G Loss: 0.8315\n",
            "Epoch [98/100], Step [600/7382], D Loss: 1.3514, G Loss: 0.7602\n",
            "Epoch [98/100], Step [700/7382], D Loss: 1.1984, G Loss: 0.9535\n",
            "Epoch [98/100], Step [800/7382], D Loss: 1.3193, G Loss: 0.8438\n",
            "Epoch [98/100], Step [900/7382], D Loss: 1.3310, G Loss: 0.8316\n",
            "Epoch [98/100], Step [1000/7382], D Loss: 1.3232, G Loss: 0.8626\n",
            "Epoch [98/100], Step [1100/7382], D Loss: 1.3068, G Loss: 0.9501\n",
            "Epoch [98/100], Step [1200/7382], D Loss: 1.2528, G Loss: 0.8677\n",
            "Epoch [98/100], Step [1300/7382], D Loss: 1.4074, G Loss: 0.7389\n",
            "Epoch [98/100], Step [1400/7382], D Loss: 1.3033, G Loss: 0.8240\n",
            "Epoch [98/100], Step [1500/7382], D Loss: 1.3477, G Loss: 0.8491\n",
            "Epoch [98/100], Step [1600/7382], D Loss: 1.3644, G Loss: 0.7511\n",
            "Epoch [98/100], Step [1700/7382], D Loss: 1.4307, G Loss: 0.7443\n",
            "Epoch [98/100], Step [1800/7382], D Loss: 1.2709, G Loss: 0.8739\n",
            "Epoch [98/100], Step [1900/7382], D Loss: 1.3334, G Loss: 0.7636\n",
            "Epoch [98/100], Step [2000/7382], D Loss: 1.3703, G Loss: 0.7477\n",
            "Epoch [98/100], Step [2100/7382], D Loss: 1.3824, G Loss: 0.7882\n",
            "Epoch [98/100], Step [2200/7382], D Loss: 1.3787, G Loss: 0.7710\n",
            "Epoch [98/100], Step [2300/7382], D Loss: 1.3072, G Loss: 0.8094\n",
            "Epoch [98/100], Step [2400/7382], D Loss: 1.2982, G Loss: 0.8404\n",
            "Epoch [98/100], Step [2500/7382], D Loss: 1.3709, G Loss: 0.7223\n",
            "Epoch [98/100], Step [2600/7382], D Loss: 1.3144, G Loss: 0.8407\n",
            "Epoch [98/100], Step [2700/7382], D Loss: 1.3892, G Loss: 0.7675\n",
            "Epoch [98/100], Step [2800/7382], D Loss: 1.2827, G Loss: 0.8253\n",
            "Epoch [98/100], Step [2900/7382], D Loss: 1.2687, G Loss: 0.8120\n",
            "Epoch [98/100], Step [3000/7382], D Loss: 1.3701, G Loss: 0.8715\n",
            "Epoch [98/100], Step [3100/7382], D Loss: 1.3136, G Loss: 0.7417\n",
            "Epoch [98/100], Step [3200/7382], D Loss: 1.3399, G Loss: 0.9689\n",
            "Epoch [98/100], Step [3300/7382], D Loss: 1.3478, G Loss: 0.7673\n",
            "Epoch [98/100], Step [3400/7382], D Loss: 1.3029, G Loss: 0.7576\n",
            "Epoch [98/100], Step [3500/7382], D Loss: 1.3128, G Loss: 0.8903\n",
            "Epoch [98/100], Step [3600/7382], D Loss: 1.3808, G Loss: 0.7779\n",
            "Epoch [98/100], Step [3700/7382], D Loss: 1.3440, G Loss: 0.8633\n",
            "Epoch [98/100], Step [3800/7382], D Loss: 1.3744, G Loss: 0.8172\n",
            "Epoch [98/100], Step [3900/7382], D Loss: 1.3378, G Loss: 0.8030\n",
            "Epoch [98/100], Step [4000/7382], D Loss: 1.3798, G Loss: 0.8364\n",
            "Epoch [98/100], Step [4100/7382], D Loss: 1.2398, G Loss: 0.8345\n",
            "Epoch [98/100], Step [4200/7382], D Loss: 1.3048, G Loss: 0.8322\n",
            "Epoch [98/100], Step [4300/7382], D Loss: 1.3240, G Loss: 0.7846\n",
            "Epoch [98/100], Step [4400/7382], D Loss: 1.3033, G Loss: 0.8013\n",
            "Epoch [98/100], Step [4500/7382], D Loss: 1.2606, G Loss: 0.8780\n",
            "Epoch [98/100], Step [4600/7382], D Loss: 1.3781, G Loss: 0.7724\n",
            "Epoch [98/100], Step [4700/7382], D Loss: 1.3299, G Loss: 0.8134\n",
            "Epoch [98/100], Step [4800/7382], D Loss: 1.3644, G Loss: 0.8705\n",
            "Epoch [98/100], Step [4900/7382], D Loss: 1.2943, G Loss: 0.8224\n",
            "Epoch [98/100], Step [5000/7382], D Loss: 1.2341, G Loss: 0.8810\n",
            "Epoch [98/100], Step [5100/7382], D Loss: 1.4684, G Loss: 0.7234\n",
            "Epoch [98/100], Step [5200/7382], D Loss: 1.3423, G Loss: 0.7638\n",
            "Epoch [98/100], Step [5300/7382], D Loss: 1.4058, G Loss: 0.7568\n",
            "Epoch [98/100], Step [5400/7382], D Loss: 1.3054, G Loss: 0.8533\n",
            "Epoch [98/100], Step [5500/7382], D Loss: 1.3243, G Loss: 0.8406\n",
            "Epoch [98/100], Step [5600/7382], D Loss: 1.3136, G Loss: 0.8172\n",
            "Epoch [98/100], Step [5700/7382], D Loss: 1.3293, G Loss: 0.8730\n",
            "Epoch [98/100], Step [5800/7382], D Loss: 1.3888, G Loss: 0.7791\n",
            "Epoch [98/100], Step [5900/7382], D Loss: 1.3857, G Loss: 0.7520\n",
            "Epoch [98/100], Step [6000/7382], D Loss: 1.2969, G Loss: 0.8233\n",
            "Epoch [98/100], Step [6100/7382], D Loss: 1.3303, G Loss: 0.8482\n",
            "Epoch [98/100], Step [6200/7382], D Loss: 1.3983, G Loss: 0.7611\n",
            "Epoch [98/100], Step [6300/7382], D Loss: 1.3418, G Loss: 0.8802\n",
            "Epoch [98/100], Step [6400/7382], D Loss: 1.3188, G Loss: 0.7707\n",
            "Epoch [98/100], Step [6500/7382], D Loss: 1.2833, G Loss: 0.8383\n",
            "Epoch [98/100], Step [6600/7382], D Loss: 1.3125, G Loss: 0.7755\n",
            "Epoch [98/100], Step [6700/7382], D Loss: 1.3237, G Loss: 0.7344\n",
            "Epoch [98/100], Step [6800/7382], D Loss: 1.2391, G Loss: 0.8693\n",
            "Epoch [98/100], Step [6900/7382], D Loss: 1.3589, G Loss: 0.7548\n",
            "Epoch [98/100], Step [7000/7382], D Loss: 1.3121, G Loss: 0.8114\n",
            "Epoch [98/100], Step [7100/7382], D Loss: 1.3465, G Loss: 0.7842\n",
            "Epoch [98/100], Step [7200/7382], D Loss: 1.3888, G Loss: 0.7628\n",
            "Epoch [98/100], Step [7300/7382], D Loss: 1.3618, G Loss: 0.8227\n",
            "Epoch [99/100], Step [100/7382], D Loss: 1.3125, G Loss: 0.8656\n",
            "Epoch [99/100], Step [200/7382], D Loss: 1.3295, G Loss: 0.7938\n",
            "Epoch [99/100], Step [300/7382], D Loss: 1.3173, G Loss: 0.8782\n",
            "Epoch [99/100], Step [400/7382], D Loss: 1.3722, G Loss: 0.7962\n",
            "Epoch [99/100], Step [500/7382], D Loss: 1.2421, G Loss: 0.9929\n",
            "Epoch [99/100], Step [600/7382], D Loss: 1.2863, G Loss: 0.9747\n",
            "Epoch [99/100], Step [700/7382], D Loss: 1.2992, G Loss: 0.8101\n",
            "Epoch [99/100], Step [800/7382], D Loss: 1.3391, G Loss: 0.9049\n",
            "Epoch [99/100], Step [900/7382], D Loss: 1.2766, G Loss: 0.9580\n",
            "Epoch [99/100], Step [1000/7382], D Loss: 1.2479, G Loss: 0.8125\n",
            "Epoch [99/100], Step [1100/7382], D Loss: 1.3046, G Loss: 0.8722\n",
            "Epoch [99/100], Step [1200/7382], D Loss: 1.2996, G Loss: 0.9070\n",
            "Epoch [99/100], Step [1300/7382], D Loss: 1.2778, G Loss: 0.8238\n",
            "Epoch [99/100], Step [1400/7382], D Loss: 1.3613, G Loss: 0.9147\n",
            "Epoch [99/100], Step [1500/7382], D Loss: 1.2903, G Loss: 0.8427\n",
            "Epoch [99/100], Step [1600/7382], D Loss: 1.3481, G Loss: 0.8549\n",
            "Epoch [99/100], Step [1700/7382], D Loss: 1.3234, G Loss: 0.8054\n",
            "Epoch [99/100], Step [1800/7382], D Loss: 1.2997, G Loss: 0.8933\n",
            "Epoch [99/100], Step [1900/7382], D Loss: 1.2465, G Loss: 0.9192\n",
            "Epoch [99/100], Step [2000/7382], D Loss: 1.2990, G Loss: 0.8461\n",
            "Epoch [99/100], Step [2100/7382], D Loss: 1.2584, G Loss: 0.8877\n",
            "Epoch [99/100], Step [2200/7382], D Loss: 1.3707, G Loss: 0.9089\n",
            "Epoch [99/100], Step [2300/7382], D Loss: 1.2844, G Loss: 0.8539\n",
            "Epoch [99/100], Step [2400/7382], D Loss: 1.3549, G Loss: 0.7990\n",
            "Epoch [99/100], Step [2500/7382], D Loss: 1.3874, G Loss: 0.7499\n",
            "Epoch [99/100], Step [2600/7382], D Loss: 1.3460, G Loss: 0.8287\n",
            "Epoch [99/100], Step [2700/7382], D Loss: 1.2979, G Loss: 0.9013\n",
            "Epoch [99/100], Step [2800/7382], D Loss: 1.2479, G Loss: 0.9168\n",
            "Epoch [99/100], Step [2900/7382], D Loss: 1.1942, G Loss: 0.9359\n",
            "Epoch [99/100], Step [3000/7382], D Loss: 1.2298, G Loss: 0.9621\n",
            "Epoch [99/100], Step [3100/7382], D Loss: 1.2689, G Loss: 0.8648\n",
            "Epoch [99/100], Step [3200/7382], D Loss: 1.2499, G Loss: 1.0030\n",
            "Epoch [99/100], Step [3300/7382], D Loss: 1.3129, G Loss: 0.8555\n",
            "Epoch [99/100], Step [3400/7382], D Loss: 1.3026, G Loss: 0.8244\n",
            "Epoch [99/100], Step [3500/7382], D Loss: 1.3197, G Loss: 0.8133\n",
            "Epoch [99/100], Step [3600/7382], D Loss: 1.2928, G Loss: 0.8374\n",
            "Epoch [99/100], Step [3700/7382], D Loss: 1.3211, G Loss: 0.8160\n",
            "Epoch [99/100], Step [3800/7382], D Loss: 1.3367, G Loss: 0.7475\n",
            "Epoch [99/100], Step [3900/7382], D Loss: 1.2970, G Loss: 0.8398\n",
            "Epoch [99/100], Step [4000/7382], D Loss: 1.2728, G Loss: 0.8716\n",
            "Epoch [99/100], Step [4100/7382], D Loss: 1.3237, G Loss: 0.9123\n",
            "Epoch [99/100], Step [4200/7382], D Loss: 1.2690, G Loss: 0.8268\n",
            "Epoch [99/100], Step [4300/7382], D Loss: 1.3284, G Loss: 0.9007\n",
            "Epoch [99/100], Step [4400/7382], D Loss: 1.3636, G Loss: 0.7874\n",
            "Epoch [99/100], Step [4500/7382], D Loss: 1.3101, G Loss: 0.9334\n",
            "Epoch [99/100], Step [4600/7382], D Loss: 1.2745, G Loss: 0.9079\n",
            "Epoch [99/100], Step [4700/7382], D Loss: 1.2887, G Loss: 1.1112\n",
            "Epoch [99/100], Step [4800/7382], D Loss: 1.3287, G Loss: 0.8258\n",
            "Epoch [99/100], Step [4900/7382], D Loss: 1.2798, G Loss: 0.8950\n",
            "Epoch [99/100], Step [5000/7382], D Loss: 1.2768, G Loss: 0.9188\n",
            "Epoch [99/100], Step [5100/7382], D Loss: 1.4183, G Loss: 0.7303\n",
            "Epoch [99/100], Step [5200/7382], D Loss: 1.3312, G Loss: 0.7844\n",
            "Epoch [99/100], Step [5300/7382], D Loss: 1.3215, G Loss: 0.8933\n",
            "Epoch [99/100], Step [5400/7382], D Loss: 1.3021, G Loss: 0.9637\n",
            "Epoch [99/100], Step [5500/7382], D Loss: 1.2837, G Loss: 0.8221\n",
            "Epoch [99/100], Step [5600/7382], D Loss: 1.2501, G Loss: 0.8779\n",
            "Epoch [99/100], Step [5700/7382], D Loss: 1.2849, G Loss: 0.9381\n",
            "Epoch [99/100], Step [5800/7382], D Loss: 1.3236, G Loss: 0.8231\n",
            "Epoch [99/100], Step [5900/7382], D Loss: 1.3575, G Loss: 0.7540\n",
            "Epoch [99/100], Step [6000/7382], D Loss: 1.3488, G Loss: 0.7947\n",
            "Epoch [99/100], Step [6100/7382], D Loss: 1.2280, G Loss: 0.8708\n",
            "Epoch [99/100], Step [6200/7382], D Loss: 1.3812, G Loss: 0.8278\n",
            "Epoch [99/100], Step [6300/7382], D Loss: 1.2808, G Loss: 0.8335\n",
            "Epoch [99/100], Step [6400/7382], D Loss: 1.2838, G Loss: 0.8466\n",
            "Epoch [99/100], Step [6500/7382], D Loss: 1.3058, G Loss: 0.8801\n",
            "Epoch [99/100], Step [6600/7382], D Loss: 1.3635, G Loss: 0.8372\n",
            "Epoch [99/100], Step [6700/7382], D Loss: 1.2901, G Loss: 0.8322\n",
            "Epoch [99/100], Step [6800/7382], D Loss: 1.3197, G Loss: 0.8087\n",
            "Epoch [99/100], Step [6900/7382], D Loss: 1.3432, G Loss: 0.9283\n",
            "Epoch [99/100], Step [7000/7382], D Loss: 1.2910, G Loss: 0.9963\n",
            "Epoch [99/100], Step [7100/7382], D Loss: 1.2706, G Loss: 0.8415\n",
            "Epoch [99/100], Step [7200/7382], D Loss: 1.4344, G Loss: 0.7854\n",
            "Epoch [99/100], Step [7300/7382], D Loss: 1.2162, G Loss: 0.9847\n",
            "Epoch [100/100], Step [100/7382], D Loss: 1.3319, G Loss: 0.7901\n",
            "Epoch [100/100], Step [200/7382], D Loss: 1.3189, G Loss: 0.8043\n",
            "Epoch [100/100], Step [300/7382], D Loss: 1.4098, G Loss: 0.8460\n",
            "Epoch [100/100], Step [400/7382], D Loss: 1.3865, G Loss: 0.8290\n",
            "Epoch [100/100], Step [500/7382], D Loss: 1.2868, G Loss: 1.0461\n",
            "Epoch [100/100], Step [600/7382], D Loss: 1.3425, G Loss: 0.8536\n",
            "Epoch [100/100], Step [700/7382], D Loss: 1.2848, G Loss: 0.8605\n",
            "Epoch [100/100], Step [800/7382], D Loss: 1.3588, G Loss: 0.8558\n",
            "Epoch [100/100], Step [900/7382], D Loss: 1.2135, G Loss: 0.9123\n",
            "Epoch [100/100], Step [1000/7382], D Loss: 1.3050, G Loss: 0.8600\n",
            "Epoch [100/100], Step [1100/7382], D Loss: 1.3506, G Loss: 0.7791\n",
            "Epoch [100/100], Step [1200/7382], D Loss: 1.2833, G Loss: 0.8590\n",
            "Epoch [100/100], Step [1300/7382], D Loss: 1.2404, G Loss: 0.8613\n",
            "Epoch [100/100], Step [1400/7382], D Loss: 1.2035, G Loss: 0.9265\n",
            "Epoch [100/100], Step [1500/7382], D Loss: 1.2601, G Loss: 0.8933\n",
            "Epoch [100/100], Step [1600/7382], D Loss: 1.2988, G Loss: 0.8417\n",
            "Epoch [100/100], Step [1700/7382], D Loss: 1.2729, G Loss: 0.9048\n",
            "Epoch [100/100], Step [1800/7382], D Loss: 1.2888, G Loss: 0.8484\n",
            "Epoch [100/100], Step [1900/7382], D Loss: 1.3294, G Loss: 0.8784\n",
            "Epoch [100/100], Step [2000/7382], D Loss: 1.3802, G Loss: 0.7851\n",
            "Epoch [100/100], Step [2100/7382], D Loss: 1.3657, G Loss: 0.9207\n",
            "Epoch [100/100], Step [2200/7382], D Loss: 1.3299, G Loss: 0.8348\n",
            "Epoch [100/100], Step [2300/7382], D Loss: 1.3199, G Loss: 0.8250\n",
            "Epoch [100/100], Step [2400/7382], D Loss: 1.2453, G Loss: 0.8549\n",
            "Epoch [100/100], Step [2500/7382], D Loss: 1.3155, G Loss: 0.8343\n",
            "Epoch [100/100], Step [2600/7382], D Loss: 1.3657, G Loss: 0.7740\n",
            "Epoch [100/100], Step [2700/7382], D Loss: 1.2760, G Loss: 0.8936\n",
            "Epoch [100/100], Step [2800/7382], D Loss: 1.2476, G Loss: 0.8579\n",
            "Epoch [100/100], Step [2900/7382], D Loss: 1.3304, G Loss: 0.8642\n",
            "Epoch [100/100], Step [3000/7382], D Loss: 1.2869, G Loss: 0.8756\n",
            "Epoch [100/100], Step [3100/7382], D Loss: 1.3256, G Loss: 0.9831\n",
            "Epoch [100/100], Step [3200/7382], D Loss: 1.1081, G Loss: 1.0739\n",
            "Epoch [100/100], Step [3300/7382], D Loss: 1.2928, G Loss: 0.8357\n",
            "Epoch [100/100], Step [3400/7382], D Loss: 1.2012, G Loss: 0.9031\n",
            "Epoch [100/100], Step [3500/7382], D Loss: 1.3332, G Loss: 0.8721\n",
            "Epoch [100/100], Step [3600/7382], D Loss: 1.2652, G Loss: 0.9413\n",
            "Epoch [100/100], Step [3700/7382], D Loss: 1.2893, G Loss: 0.8715\n",
            "Epoch [100/100], Step [3800/7382], D Loss: 1.2852, G Loss: 0.9732\n",
            "Epoch [100/100], Step [3900/7382], D Loss: 1.2949, G Loss: 0.9334\n",
            "Epoch [100/100], Step [4000/7382], D Loss: 1.2519, G Loss: 0.8587\n",
            "Epoch [100/100], Step [4100/7382], D Loss: 1.3490, G Loss: 0.7730\n",
            "Epoch [100/100], Step [4200/7382], D Loss: 1.3374, G Loss: 0.8392\n",
            "Epoch [100/100], Step [4300/7382], D Loss: 1.3219, G Loss: 0.8287\n",
            "Epoch [100/100], Step [4400/7382], D Loss: 1.2859, G Loss: 0.8602\n",
            "Epoch [100/100], Step [4500/7382], D Loss: 1.3085, G Loss: 0.8151\n",
            "Epoch [100/100], Step [4600/7382], D Loss: 1.2856, G Loss: 0.8541\n",
            "Epoch [100/100], Step [4700/7382], D Loss: 1.3458, G Loss: 0.8292\n",
            "Epoch [100/100], Step [4800/7382], D Loss: 1.3350, G Loss: 0.7654\n",
            "Epoch [100/100], Step [4900/7382], D Loss: 1.3166, G Loss: 0.8110\n",
            "Epoch [100/100], Step [5000/7382], D Loss: 1.2675, G Loss: 0.8560\n",
            "Epoch [100/100], Step [5100/7382], D Loss: 1.4247, G Loss: 0.8154\n",
            "Epoch [100/100], Step [5200/7382], D Loss: 1.3409, G Loss: 0.8128\n",
            "Epoch [100/100], Step [5300/7382], D Loss: 1.4027, G Loss: 0.7742\n",
            "Epoch [100/100], Step [5400/7382], D Loss: 1.2997, G Loss: 0.8151\n",
            "Epoch [100/100], Step [5500/7382], D Loss: 1.3248, G Loss: 0.7510\n",
            "Epoch [100/100], Step [5600/7382], D Loss: 1.3026, G Loss: 0.8318\n",
            "Epoch [100/100], Step [5700/7382], D Loss: 1.2203, G Loss: 0.8768\n",
            "Epoch [100/100], Step [5800/7382], D Loss: 1.2646, G Loss: 0.8237\n",
            "Epoch [100/100], Step [5900/7382], D Loss: 1.2526, G Loss: 0.9809\n",
            "Epoch [100/100], Step [6000/7382], D Loss: 1.3377, G Loss: 0.7853\n",
            "Epoch [100/100], Step [6100/7382], D Loss: 1.2907, G Loss: 0.8218\n",
            "Epoch [100/100], Step [6200/7382], D Loss: 1.3264, G Loss: 0.8235\n",
            "Epoch [100/100], Step [6300/7382], D Loss: 1.3926, G Loss: 0.7622\n",
            "Epoch [100/100], Step [6400/7382], D Loss: 1.2984, G Loss: 0.8763\n",
            "Epoch [100/100], Step [6500/7382], D Loss: 1.3286, G Loss: 0.7634\n",
            "Epoch [100/100], Step [6600/7382], D Loss: 1.2723, G Loss: 0.8399\n",
            "Epoch [100/100], Step [6700/7382], D Loss: 1.2714, G Loss: 0.8285\n",
            "Epoch [100/100], Step [6800/7382], D Loss: 1.2802, G Loss: 0.7735\n",
            "Epoch [100/100], Step [6900/7382], D Loss: 1.3451, G Loss: 0.8082\n",
            "Epoch [100/100], Step [7000/7382], D Loss: 1.3357, G Loss: 0.7741\n",
            "Epoch [100/100], Step [7100/7382], D Loss: 1.3491, G Loss: 0.8063\n",
            "Epoch [100/100], Step [7200/7382], D Loss: 1.2916, G Loss: 0.8091\n",
            "Epoch [100/100], Step [7300/7382], D Loss: 1.3645, G Loss: 0.7924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define the Generator network (as you have already trained it)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Load the trained generator model\n",
        "input_dim = 100  # Dimension of the noise vector for the generator\n",
        "output_dim = df.shape[1]  # Dimension of the generated transaction (excluding 'isFraud' and 'isFlaggedFraud')\n",
        "generator = Generator(input_dim, output_dim)\n",
        "generator.load_state_dict(torch.load('generator.pth'))\n",
        "generator.eval()\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "generator = generator.to(device)\n",
        "\n",
        "# Function to generate synthetic samples\n",
        "def generate_synthetic_samples(generator, num_samples, latent_dim, device):\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    with torch.no_grad():\n",
        "        synthetic_samples = generator(z)\n",
        "    return synthetic_samples.cpu().numpy()\n",
        "\n",
        "# Generate synthetic samples\n",
        "num_samples = 1000\n",
        "synthetic_samples = generate_synthetic_samples(generator, num_samples, input_dim, device)\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "columns = df.columns  # Use the same columns as the original dataset\n",
        "synthetic_df = pd.DataFrame(synthetic_samples, columns=columns)\n",
        "\n",
        "# Inverse transform to original scale if you used MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df.values)\n",
        "synthetic_df = pd.DataFrame(scaler.inverse_transform(synthetic_df.values), columns=columns)\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"Statistical Comparison between Real and Synthetic Data\")\n",
        "for column in columns:\n",
        "    print(f\"{column}: Real Mean = {df[column].mean()}, Synthetic Mean = {synthetic_df[column].mean()}\")\n",
        "    print(f\"{column}: Real Std = {df[column].std()}, Synthetic Std = {synthetic_df[column].std()}\")\n",
        "\n",
        "# Visual inspection of a few generated samples\n",
        "print(\"Sample generated transactions:\")\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# Optional: Save synthetic data to a CSV file\n",
        "synthetic_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['amount'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['amount'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Transaction Amount Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['step'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['step'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Step Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OMiv2LJzLZFl",
        "outputId": "50ccb786-28ca-4909-bf30-52f391b67575"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Comparison between Real and Synthetic Data\n",
            "step: Real Mean = 13.593298123432225, Synthetic Mean = 13.803220748901367\n",
            "step: Real Std = 3.598465952326758, Synthetic Std = 3.6236093044281006\n",
            "type: Real Mean = 1.6918703231337517, Synthetic Mean = 1.2849169969558716\n",
            "type: Real Std = 1.3414047498892219, Synthetic Std = 1.4096323251724243\n",
            "amount: Real Mean = 168175.88590332455, Synthetic Mean = 165868.703125\n",
            "amount: Real Std = 275230.54112470045, Synthetic Std = 193222.84375\n",
            "nameOrig: Real Mean = 236179.60862395613, Synthetic Mean = 230909.453125\n",
            "nameOrig: Real Std = 136359.6004262548, Synthetic Std = 133434.65625\n",
            "oldbalanceOrg: Real Mean = 910510.3208010283, Synthetic Mean = 1629250.125\n",
            "oldbalanceOrg: Real Std = 2988086.1268851627, Synthetic Std = 4037280.5\n",
            "newbalanceOrig: Real Mean = 930357.5502715677, Synthetic Mean = 1725265.625\n",
            "newbalanceOrig: Real Std = 3025461.2617613417, Synthetic Std = 4100689.5\n",
            "nameDest: Real Mean = 57752.267531037985, Synthetic Mean = 48216.75390625\n",
            "nameDest: Real Std = 55593.69686684573, Synthetic Std = 46180.32421875\n",
            "oldbalanceDest: Real Mean = 983307.7605816622, Synthetic Mean = 1002999.4375\n",
            "oldbalanceDest: Real Std = 2339876.8723979755, Synthetic Std = 2141202.25\n",
            "newbalanceDest: Real Mean = 1166694.164955536, Synthetic Mean = 1098524.375\n",
            "newbalanceDest: Real Std = 2518074.07113136, Synthetic Std = 2267370.75\n",
            "isFraud: Real Mean = 0.000469935754278638, Synthetic Mean = 2.571045589969123e-12\n",
            "isFraud: Real Std = 0.02167293032732644, Synthetic Std = 4.050527274701565e-11\n",
            "isFlaggedFraud: Real Mean = 0.0, Synthetic Mean = 4.344147112346486e-13\n",
            "isFlaggedFraud: Real Std = 0.0, Synthetic Std = 6.991732713623744e-12\n",
            "Sample generated transactions:\n",
            "        step      type         amount       nameOrig  oldbalanceOrg  \\\n",
            "0  14.589865  0.000000   56250.394531  310076.812500   8.890887e+06   \n",
            "1  16.995428  0.000000  496905.062500  154482.546875   5.455313e+04   \n",
            "2  18.415325  0.000000  109925.039062   80751.757812   8.261609e+03   \n",
            "3  14.576614  3.001229   11268.291992   61587.578125   1.747282e+04   \n",
            "4  12.211649  0.000000  171740.953125  254355.500000   4.106605e+06   \n",
            "\n",
            "   newbalanceOrig       nameDest  oldbalanceDest  newbalanceDest  \\\n",
            "0    8.968365e+06   38895.839844    3.702864e+05    3.425120e+05   \n",
            "1    6.291187e+05   36160.527344    1.310716e+02    3.472656e-05   \n",
            "2    1.106973e+05   28602.287109    3.472774e+06    3.507882e+06   \n",
            "3    1.178973e+04  113024.734375    1.142744e-06    2.650270e-05   \n",
            "4    4.278120e+06   40421.210938    9.458509e+05    7.578920e+05   \n",
            "\n",
            "        isFraud  isFlaggedFraud  \n",
            "0  2.688647e-27    6.770270e-29  \n",
            "1  0.000000e+00    0.000000e+00  \n",
            "2  0.000000e+00    0.000000e+00  \n",
            "3  4.234334e-22    3.741176e-24  \n",
            "4  0.000000e+00    0.000000e+00  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the Discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid()  # Output a probability\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Function to initialize the weights of the networks\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "lr = 0.0002\n",
        "num_epochs = 100\n",
        "input_dim = 100  # Dimension of the noise vector for the generator\n",
        "output_dim = df.shape[1]  # Dimension of the generated transaction (excluding 'isFraud' and 'isFlaggedFraud')\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df.values)\n",
        "dataset = TensorDataset(torch.tensor(df_scaled, dtype=torch.float32))\n",
        "\n",
        "# Handling class imbalance using WeightedRandomSampler\n",
        "labels = df['isFraud'].values  # Assuming 'isFraud' is the label for class imbalance\n",
        "unique_labels = np.unique(labels)\n",
        "class_sample_count = np.array([len(np.where(labels == t)[0]) for t in unique_labels])\n",
        "weight = 1. / class_sample_count\n",
        "\n",
        "# Create a mapping from label values to their corresponding weights\n",
        "label_to_weight = {label: weight[i] for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Use the mapping to create the samples_weight array\n",
        "samples_weight = np.array([label_to_weight[label] for label in labels])\n",
        "\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "# Create instances of the Generator and Discriminator\n",
        "generator = Generator(input_dim, output_dim)\n",
        "discriminator = Discriminator(output_dim)\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# Loss function and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training the GAN\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        # Train Discriminator\n",
        "        real_data = data[0].to(device)\n",
        "        batch_size = real_data.size(0)\n",
        "        labels_real = torch.ones(batch_size, 1).to(device)\n",
        "        labels_fake = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "        # Real data\n",
        "        outputs = discriminator(real_data)\n",
        "        d_loss_real = criterion(outputs, labels_real)\n",
        "\n",
        "        # Fake data\n",
        "        noise = torch.randn(batch_size, input_dim).to(device)\n",
        "        fake_data = generator(noise)\n",
        "        outputs = discriminator(fake_data.detach())\n",
        "        d_loss_fake = criterion(outputs, labels_fake)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator\n",
        "        outputs = discriminator(fake_data)\n",
        "        g_loss = criterion(outputs, labels_real)  # We want the generator to fool the discriminator\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Logging\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
        "\n",
        "# Save the trained models\n",
        "torch.save(generator.state_dict(), 'generator.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pth')\n",
        "\n",
        "# Generate synthetic samples using the trained generator\n",
        "def generate_synthetic_samples(generator, num_samples, latent_dim, device):\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    with torch.no_grad():\n",
        "        synthetic_samples = generator(z)\n",
        "    return synthetic_samples.cpu().numpy()\n",
        "\n",
        "# Generate synthetic samples\n",
        "num_samples = 1000\n",
        "synthetic_samples = generate_synthetic_samples(generator, num_samples, input_dim, device)\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "columns = df.columns  # Use the same columns as the original dataset\n",
        "synthetic_df = pd.DataFrame(synthetic_samples, columns=columns)\n",
        "\n",
        "# Inverse transform to original scale if you used MinMaxScaler\n",
        "synthetic_df = pd.DataFrame(scaler.inverse_transform(synthetic_df.values), columns=columns)\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"Statistical Comparison between Real and Synthetic Data\")\n",
        "for column in columns:\n",
        "    print(f\"{column}: Real Mean = {df[column].mean()}, Synthetic Mean = {synthetic_df[column].mean()}\")\n",
        "    print(f\"{column}: Real Std = {df[column].std()}, Synthetic Std = {synthetic_df[column].std()}\")\n",
        "\n",
        "# Visual inspection of a few generated samples\n",
        "print(\"Sample generated transactions:\")\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# Optional: Save synthetic data to a CSV file\n",
        "synthetic_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['amount'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['amount'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Transaction Amount Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['step'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['step'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Step Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "ylI0Obhtweht",
        "outputId": "ef4c8724-58f7-4635-8507-6d293f0e044e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Step [100/7382], D Loss: 1.3032, G Loss: 0.8073\n",
            "Epoch [1/100], Step [200/7382], D Loss: 1.0335, G Loss: 0.8892\n",
            "Epoch [1/100], Step [300/7382], D Loss: 0.9568, G Loss: 0.9832\n",
            "Epoch [1/100], Step [400/7382], D Loss: 1.1274, G Loss: 0.9427\n",
            "Epoch [1/100], Step [500/7382], D Loss: 0.8373, G Loss: 1.4538\n",
            "Epoch [1/100], Step [600/7382], D Loss: 0.8057, G Loss: 1.2833\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-23e470c78bca>\u001b[0m in \u001b[0;36m<cell line: 98>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0moptimizer_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0moptimizer_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate synthetic samples using the trained generator\n",
        "def generate_synthetic_samples(generator, num_samples, latent_dim, device):\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    with torch.no_grad():\n",
        "        synthetic_samples = generator(z)\n",
        "    return synthetic_samples.cpu().numpy()\n",
        "\n",
        "# Generate synthetic samples\n",
        "num_samples = 1000\n",
        "synthetic_samples = generate_synthetic_samples(generator, num_samples, input_dim, device)\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "columns = df.columns  # Use the same columns as the original dataset\n",
        "synthetic_df = pd.DataFrame(synthetic_samples, columns=columns)\n",
        "\n",
        "# Inverse transform to original scale if you used MinMaxScaler\n",
        "synthetic_df = pd.DataFrame(scaler.inverse_transform(synthetic_df.values), columns=columns)\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"Statistical Comparison between Real and Synthetic Data\")\n",
        "for column in columns:\n",
        "    print(f\"{column}: Real Mean = {df[column].mean()}, Synthetic Mean = {synthetic_df[column].mean()}\")\n",
        "    print(f\"{column}: Real Std = {df[column].std()}, Synthetic Std = {synthetic_df[column].std()}\")\n",
        "\n",
        "# Visual inspection of a few generated samples\n",
        "print(\"Sample generated transactions:\")\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# Optional: Save synthetic data to a CSV file\n",
        "synthetic_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['amount'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['amount'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Transaction Amount Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['step'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['step'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Step Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JCvfOWAS7ByG",
        "outputId": "0f4d1322-3356-4422-bcf9-848c3d435668"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistical Comparison between Real and Synthetic Data\n",
            "step: Real Mean = 13.593298123432225, Synthetic Mean = 16.44501304626465\n",
            "step: Real Std = 3.598465952326758, Synthetic Std = 1.8440096378326416\n",
            "type: Real Mean = 1.6918703231337517, Synthetic Mean = 1.6512657403945923\n",
            "type: Real Std = 1.3414047498892219, Synthetic Std = 0.17276975512504578\n",
            "amount: Real Mean = 168175.88590332455, Synthetic Mean = 45187.16796875\n",
            "amount: Real Std = 275230.54112470045, Synthetic Std = 187005.53125\n",
            "nameOrig: Real Mean = 236179.60862395613, Synthetic Mean = 21274.787109375\n",
            "nameOrig: Real Std = 136359.6004262548, Synthetic Std = 31794.228515625\n",
            "oldbalanceOrg: Real Mean = 910510.3208010283, Synthetic Mean = 69386.2109375\n",
            "oldbalanceOrg: Real Std = 2988086.1268851627, Synthetic Std = 413637.90625\n",
            "newbalanceOrig: Real Mean = 930357.5502715677, Synthetic Mean = 84137.84375\n",
            "newbalanceOrig: Real Std = 3025461.2617613417, Synthetic Std = 463998.0\n",
            "nameDest: Real Mean = 57752.267531037985, Synthetic Mean = 18929.400390625\n",
            "nameDest: Real Std = 55593.69686684573, Synthetic Std = 18766.28515625\n",
            "oldbalanceDest: Real Mean = 983307.7605816622, Synthetic Mean = 144870.296875\n",
            "oldbalanceDest: Real Std = 2339876.8723979755, Synthetic Std = 663712.75\n",
            "newbalanceDest: Real Mean = 1166694.164955536, Synthetic Mean = 98375.96875\n",
            "newbalanceDest: Real Std = 2518074.07113136, Synthetic Std = 526892.125\n",
            "isFraud: Real Mean = 0.000469935754278638, Synthetic Mean = 0.008623845875263214\n",
            "isFraud: Real Std = 0.02167293032732644, Synthetic Std = 0.027249207720160484\n",
            "isFlaggedFraud: Real Mean = 0.0, Synthetic Mean = 0.00020362860232125968\n",
            "isFlaggedFraud: Real Std = 0.0, Synthetic Std = 0.002390343463048339\n",
            "Sample generated transactions:\n",
            "        step      type      amount     nameOrig  oldbalanceOrg  \\\n",
            "0  17.622189  1.598825   10.947174  2428.088135   3.035561e-01   \n",
            "1  18.395613  1.469061    0.187512   382.084747   4.263489e-04   \n",
            "2  16.615065  1.685720  311.113220  8752.842773   2.869800e+01   \n",
            "3  18.775078  1.329976    0.100374    46.275673   2.592724e-07   \n",
            "4  18.683979  1.355468    0.102772    99.784515   3.941710e-06   \n",
            "\n",
            "   newbalanceOrig      nameDest  oldbalanceDest  newbalanceDest       isFraud  \\\n",
            "0        0.972173   6375.725098       13.033056        1.599733  1.987464e-05   \n",
            "1        0.002027   1910.916016        0.067123        0.003930  4.511690e-07   \n",
            "2       68.738159  14301.421875      497.476807      101.782288  2.784724e-04   \n",
            "3        0.000002    482.710632        0.000180        0.000004  6.005572e-09   \n",
            "4        0.000025    795.318481        0.001562        0.000053  2.894710e-08   \n",
            "\n",
            "   isFlaggedFraud  \n",
            "0    1.400742e-15  \n",
            "1    8.390746e-21  \n",
            "2    5.758674e-12  \n",
            "3    1.124371e-26  \n",
            "4    1.647079e-24  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the Generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024, output_dim),\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Define the Discriminator network (WGAN-GP)\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 1024),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Gradient Penalty for WGAN-GP\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    alpha = torch.rand(real_samples.size(0), 1)\n",
        "    alpha = alpha.expand_as(real_samples).to(real_samples.device)\n",
        "    interpolates = alpha * real_samples + ((1 - alpha) * fake_samples)\n",
        "    interpolates = interpolates.requires_grad_(True).to(real_samples.device)\n",
        "\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = torch.ones(real_samples.size(0), 1).to(real_samples.device)\n",
        "\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True\n",
        "    )[0]\n",
        "\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "# Function to initialize the weights of the networks\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "lr = 0.00005\n",
        "num_epochs = 200\n",
        "input_dim = 100  # Dimension of the noise vector for the generator\n",
        "output_dim = df.shape[1] - 2  # Dimension of the generated transaction (excluding 'isFraud' and 'isFlaggedFraud')\n",
        "lambda_gp = 10  # Gradient penalty lambda\n",
        "n_critic = 5  # Number of discriminator updates per generator update\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "scaler = MinMaxScaler()\n",
        "df_scaled = scaler.fit_transform(df.drop(['isFraud', 'isFlaggedFraud'], axis=1).values)\n",
        "dataset = TensorDataset(torch.tensor(df_scaled, dtype=torch.float32))\n",
        "\n",
        "# Handling class imbalance using WeightedRandomSampler\n",
        "labels = df['isFraud'].values  # Assuming 'isFraud' is the label for class imbalance\n",
        "unique_labels = np.unique(labels)\n",
        "class_sample_count = np.array([len(np.where(labels == t)[0]) for t in unique_labels])\n",
        "weight = 1. / class_sample_count\n",
        "\n",
        "# Create a mapping from label values to their corresponding weights\n",
        "label_to_weight = {label: weight[i] for i, label in enumerate(unique_labels)}\n",
        "\n",
        "# Use the mapping to create the samples_weight array\n",
        "samples_weight = np.array([label_to_weight[label] for label in labels])\n",
        "\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
        "\n",
        "# Create instances of the Generator and Discriminator\n",
        "generator = Generator(input_dim, output_dim)\n",
        "discriminator = Discriminator(output_dim)\n",
        "\n",
        "# Initialize weights\n",
        "generator.apply(weights_init)\n",
        "discriminator.apply(weights_init)\n",
        "\n",
        "# Optimizers for WGAN-GP\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "\n",
        "# Training the WGAN-GP\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator.to(device)\n",
        "discriminator.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, data in enumerate(dataloader):\n",
        "        # Train Discriminator\n",
        "        real_data = data[0].to(device)\n",
        "        batch_size = real_data.size(0)\n",
        "\n",
        "        noise = torch.randn(batch_size, input_dim).to(device)\n",
        "        fake_data = generator(noise)\n",
        "\n",
        "        real_validity = discriminator(real_data)\n",
        "        fake_validity = discriminator(fake_data)\n",
        "\n",
        "        # Compute gradient penalty\n",
        "        gradient_penalty = compute_gradient_penalty(discriminator, real_data, fake_data)\n",
        "\n",
        "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + lambda_gp * gradient_penalty\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # Train Generator every n_critic steps\n",
        "        if i % n_critic == 0:\n",
        "            noise = torch.randn(batch_size, input_dim).to(device)\n",
        "            fake_data = generator(noise)\n",
        "            fake_validity = discriminator(fake_data)\n",
        "            g_loss = -torch.mean(fake_validity)\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        # Logging\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
        "\n",
        "# Save the trained models\n",
        "torch.save(generator.state_dict(), 'generator_wgan.pth')\n",
        "torch.save(discriminator.state_dict(), 'discriminator_wgan.pth')\n",
        "\n",
        "# Generate synthetic samples using the trained generator\n",
        "def generate_synthetic_samples(generator, num_samples, latent_dim, device):\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, latent_dim).to(device)\n",
        "    with torch.no_grad():\n",
        "        synthetic_samples = generator(z)\n",
        "    return synthetic_samples.cpu().numpy()\n",
        "\n",
        "# Generate synthetic samples\n",
        "num_samples = 1000\n",
        "synthetic_samples = generate_synthetic_samples(generator, num_samples, input_dim, device)\n",
        "\n",
        "# Convert to DataFrame for easy manipulation\n",
        "columns = df.columns  # Use the same columns as the original dataset\n",
        "synthetic_df = pd.DataFrame(synthetic_samples, columns=columns)\n",
        "\n",
        "# Inverse transform to original scale if you used MinMaxScaler\n",
        "synthetic_df = pd.DataFrame(scaler.inverse_transform(synthetic_df.values), columns=columns)\n",
        "\n",
        "# Statistical comparison\n",
        "print(\"Statistical Comparison between Real and Synthetic Data\")\n",
        "for column in columns:\n",
        "    print(f\"{column}: Real Mean = {df[column].mean()}, Synthetic Mean = {synthetic_df[column].mean()}\")\n",
        "    print(f\"{column}: Real Std = {df[column].std()}, Synthetic Std = {synthetic_df[column].std()}\")\n",
        "\n",
        "# Visual inspection of a few generated samples\n",
        "print(\"Sample generated transactions:\")\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# Optional: Save synthetic data to a CSV file\n",
        "synthetic_df.to_csv('synthetic_transactions.csv', index=False)\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(df['amount'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['amount'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Transaction Amount Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(df['step'], bins=50, alpha=0.7, label='Real Data')\n",
        "plt.hist(synthetic_df['step'], bins=50, alpha=0.7, label='Synthetic Data')\n",
        "plt.title('Step Distribution')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z59CwnIymx-",
        "outputId": "bbe03c41-43af-451f-e76b-c57b22d0cdae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/200], Step [100/119], D Loss: -0.1061, G Loss: 0.0460\n",
            "Epoch [2/200], Step [100/119], D Loss: -0.1410, G Loss: 0.2049\n",
            "Epoch [3/200], Step [100/119], D Loss: -0.4676, G Loss: 0.7784\n",
            "Epoch [4/200], Step [100/119], D Loss: -0.2939, G Loss: 0.8553\n",
            "Epoch [5/200], Step [100/119], D Loss: -0.1274, G Loss: 0.2130\n",
            "Epoch [6/200], Step [100/119], D Loss: -0.2831, G Loss: -0.0371\n",
            "Epoch [7/200], Step [100/119], D Loss: -0.4700, G Loss: 0.5358\n",
            "Epoch [8/200], Step [100/119], D Loss: -0.5452, G Loss: 0.6794\n",
            "Epoch [9/200], Step [100/119], D Loss: -0.5846, G Loss: 0.8079\n",
            "Epoch [10/200], Step [100/119], D Loss: -0.6245, G Loss: 0.8944\n",
            "Epoch [11/200], Step [100/119], D Loss: -0.5915, G Loss: 0.9370\n",
            "Epoch [12/200], Step [100/119], D Loss: -0.6086, G Loss: 0.9691\n",
            "Epoch [13/200], Step [100/119], D Loss: -0.5647, G Loss: 0.9741\n",
            "Epoch [14/200], Step [100/119], D Loss: -0.5572, G Loss: 1.0102\n",
            "Epoch [15/200], Step [100/119], D Loss: -0.5632, G Loss: 1.0388\n",
            "Epoch [16/200], Step [100/119], D Loss: -0.5801, G Loss: 1.0583\n",
            "Epoch [17/200], Step [100/119], D Loss: -0.5278, G Loss: 1.0550\n",
            "Epoch [18/200], Step [100/119], D Loss: -0.5743, G Loss: 1.0571\n",
            "Epoch [19/200], Step [100/119], D Loss: -0.5383, G Loss: 1.1063\n",
            "Epoch [20/200], Step [100/119], D Loss: -0.5164, G Loss: 1.1078\n",
            "Epoch [21/200], Step [100/119], D Loss: -0.5289, G Loss: 1.0306\n",
            "Epoch [22/200], Step [100/119], D Loss: -0.5342, G Loss: 1.0696\n",
            "Epoch [23/200], Step [100/119], D Loss: -0.3673, G Loss: 1.3928\n",
            "Epoch [24/200], Step [100/119], D Loss: -0.3992, G Loss: 0.9713\n",
            "Epoch [25/200], Step [100/119], D Loss: -0.3567, G Loss: 0.7261\n",
            "Epoch [26/200], Step [100/119], D Loss: -0.3518, G Loss: 1.3815\n",
            "Epoch [27/200], Step [100/119], D Loss: -0.4918, G Loss: 0.9194\n",
            "Epoch [28/200], Step [100/119], D Loss: -0.4270, G Loss: 1.0992\n",
            "Epoch [29/200], Step [100/119], D Loss: -0.4317, G Loss: 0.9405\n",
            "Epoch [30/200], Step [100/119], D Loss: -0.3820, G Loss: 1.0380\n",
            "Epoch [31/200], Step [100/119], D Loss: -0.5113, G Loss: 0.9728\n",
            "Epoch [32/200], Step [100/119], D Loss: -0.3020, G Loss: 0.4461\n",
            "Epoch [33/200], Step [100/119], D Loss: -0.4667, G Loss: 1.0160\n",
            "Epoch [34/200], Step [100/119], D Loss: -0.2496, G Loss: 1.4299\n",
            "Epoch [35/200], Step [100/119], D Loss: -0.3824, G Loss: 1.0883\n",
            "Epoch [36/200], Step [100/119], D Loss: -0.4481, G Loss: 1.3357\n",
            "Epoch [37/200], Step [100/119], D Loss: -0.4908, G Loss: 0.9757\n",
            "Epoch [38/200], Step [100/119], D Loss: -0.4915, G Loss: 1.1732\n",
            "Epoch [39/200], Step [100/119], D Loss: -0.3611, G Loss: 1.0101\n",
            "Epoch [40/200], Step [100/119], D Loss: -0.4295, G Loss: 1.5372\n",
            "Epoch [41/200], Step [100/119], D Loss: -0.3831, G Loss: 0.8059\n",
            "Epoch [42/200], Step [100/119], D Loss: -0.4859, G Loss: 1.0135\n",
            "Epoch [43/200], Step [100/119], D Loss: -0.4162, G Loss: 1.5453\n",
            "Epoch [44/200], Step [100/119], D Loss: -0.4600, G Loss: 1.0422\n",
            "Epoch [45/200], Step [100/119], D Loss: -0.3238, G Loss: 1.4378\n",
            "Epoch [46/200], Step [100/119], D Loss: -0.4122, G Loss: 1.1798\n",
            "Epoch [47/200], Step [100/119], D Loss: -0.4003, G Loss: 1.3925\n",
            "Epoch [48/200], Step [100/119], D Loss: -0.3381, G Loss: 1.4688\n",
            "Epoch [49/200], Step [100/119], D Loss: -0.3795, G Loss: 0.9721\n",
            "Epoch [50/200], Step [100/119], D Loss: -0.3958, G Loss: 1.2990\n",
            "Epoch [51/200], Step [100/119], D Loss: -0.3844, G Loss: 1.4369\n",
            "Epoch [52/200], Step [100/119], D Loss: -0.3105, G Loss: 1.4180\n",
            "Epoch [53/200], Step [100/119], D Loss: -0.3629, G Loss: 1.0217\n",
            "Epoch [54/200], Step [100/119], D Loss: -0.3131, G Loss: 1.2547\n",
            "Epoch [55/200], Step [100/119], D Loss: -0.3371, G Loss: 1.0001\n",
            "Epoch [56/200], Step [100/119], D Loss: -0.3591, G Loss: 0.9825\n",
            "Epoch [57/200], Step [100/119], D Loss: -0.3080, G Loss: 1.0584\n",
            "Epoch [58/200], Step [100/119], D Loss: -0.4051, G Loss: 0.7844\n",
            "Epoch [59/200], Step [100/119], D Loss: -0.2882, G Loss: 0.8067\n",
            "Epoch [60/200], Step [100/119], D Loss: -0.2493, G Loss: 0.4765\n",
            "Epoch [61/200], Step [100/119], D Loss: -0.3331, G Loss: 0.4511\n",
            "Epoch [62/200], Step [100/119], D Loss: -0.3402, G Loss: 0.4937\n",
            "Epoch [63/200], Step [100/119], D Loss: -0.3489, G Loss: 0.4595\n",
            "Epoch [64/200], Step [100/119], D Loss: -0.3573, G Loss: 0.4518\n",
            "Epoch [65/200], Step [100/119], D Loss: -0.2523, G Loss: 0.7375\n",
            "Epoch [66/200], Step [100/119], D Loss: -0.2436, G Loss: 0.6778\n",
            "Epoch [67/200], Step [100/119], D Loss: -0.2120, G Loss: 0.7263\n",
            "Epoch [68/200], Step [100/119], D Loss: -0.3264, G Loss: 1.2316\n",
            "Epoch [69/200], Step [100/119], D Loss: -0.3755, G Loss: 1.0055\n",
            "Epoch [70/200], Step [100/119], D Loss: -0.3300, G Loss: 1.1223\n",
            "Epoch [71/200], Step [100/119], D Loss: -0.3309, G Loss: 0.9151\n",
            "Epoch [72/200], Step [100/119], D Loss: -0.3577, G Loss: 1.0277\n",
            "Epoch [73/200], Step [100/119], D Loss: -0.3179, G Loss: 0.9138\n",
            "Epoch [74/200], Step [100/119], D Loss: -0.3141, G Loss: 0.9109\n",
            "Epoch [75/200], Step [100/119], D Loss: -0.2884, G Loss: 0.8326\n",
            "Epoch [76/200], Step [100/119], D Loss: -0.2093, G Loss: 0.5903\n",
            "Epoch [77/200], Step [100/119], D Loss: -0.2702, G Loss: 0.2377\n",
            "Epoch [78/200], Step [100/119], D Loss: -0.3357, G Loss: 0.1482\n",
            "Epoch [79/200], Step [100/119], D Loss: -0.3562, G Loss: 0.2022\n",
            "Epoch [80/200], Step [100/119], D Loss: -0.2776, G Loss: 0.4505\n",
            "Epoch [81/200], Step [100/119], D Loss: -0.2599, G Loss: 0.6249\n",
            "Epoch [82/200], Step [100/119], D Loss: -0.2120, G Loss: 0.6744\n",
            "Epoch [83/200], Step [100/119], D Loss: -0.2825, G Loss: 0.9142\n",
            "Epoch [84/200], Step [100/119], D Loss: -0.2614, G Loss: 0.9067\n",
            "Epoch [85/200], Step [100/119], D Loss: -0.2334, G Loss: 0.6403\n",
            "Epoch [86/200], Step [100/119], D Loss: -0.1930, G Loss: 0.4938\n",
            "Epoch [87/200], Step [100/119], D Loss: -0.2100, G Loss: 0.3160\n",
            "Epoch [88/200], Step [100/119], D Loss: -0.2224, G Loss: 0.5163\n",
            "Epoch [89/200], Step [100/119], D Loss: -0.2740, G Loss: 0.6095\n",
            "Epoch [90/200], Step [100/119], D Loss: -0.2262, G Loss: 0.6034\n",
            "Epoch [91/200], Step [100/119], D Loss: -0.3010, G Loss: 0.6194\n",
            "Epoch [92/200], Step [100/119], D Loss: -0.2760, G Loss: 0.6809\n",
            "Epoch [93/200], Step [100/119], D Loss: -0.2689, G Loss: 0.7392\n",
            "Epoch [94/200], Step [100/119], D Loss: -0.2431, G Loss: 0.6620\n",
            "Epoch [95/200], Step [100/119], D Loss: -0.2680, G Loss: 0.5137\n",
            "Epoch [96/200], Step [100/119], D Loss: -0.3296, G Loss: 0.5029\n",
            "Epoch [97/200], Step [100/119], D Loss: -0.2273, G Loss: 0.5145\n",
            "Epoch [98/200], Step [100/119], D Loss: -0.1313, G Loss: 0.3796\n",
            "Epoch [99/200], Step [100/119], D Loss: -0.1086, G Loss: 0.4671\n",
            "Epoch [100/200], Step [100/119], D Loss: -0.2191, G Loss: 0.7280\n",
            "Epoch [101/200], Step [100/119], D Loss: -0.3118, G Loss: 0.2409\n",
            "Epoch [102/200], Step [100/119], D Loss: -0.3463, G Loss: 0.1680\n",
            "Epoch [103/200], Step [100/119], D Loss: -0.1975, G Loss: 0.3042\n",
            "Epoch [104/200], Step [100/119], D Loss: -0.0736, G Loss: 0.3954\n",
            "Epoch [105/200], Step [100/119], D Loss: -0.0174, G Loss: 0.3977\n",
            "Epoch [106/200], Step [100/119], D Loss: -0.0870, G Loss: 0.4467\n",
            "Epoch [107/200], Step [100/119], D Loss: -0.1554, G Loss: 0.2289\n",
            "Epoch [108/200], Step [100/119], D Loss: -0.2295, G Loss: 0.1175\n",
            "Epoch [109/200], Step [100/119], D Loss: -0.1797, G Loss: 0.1988\n",
            "Epoch [110/200], Step [100/119], D Loss: -0.1922, G Loss: 0.1066\n",
            "Epoch [111/200], Step [100/119], D Loss: -0.1506, G Loss: 0.1895\n",
            "Epoch [112/200], Step [100/119], D Loss: -0.2548, G Loss: 0.4402\n",
            "Epoch [113/200], Step [100/119], D Loss: -0.2419, G Loss: 0.5953\n",
            "Epoch [114/200], Step [100/119], D Loss: -0.2707, G Loss: 0.6631\n",
            "Epoch [115/200], Step [100/119], D Loss: -0.2913, G Loss: 0.1686\n",
            "Epoch [116/200], Step [100/119], D Loss: -0.2363, G Loss: 0.3812\n",
            "Epoch [117/200], Step [100/119], D Loss: -0.2972, G Loss: 0.5737\n",
            "Epoch [118/200], Step [100/119], D Loss: -0.1882, G Loss: 0.1088\n",
            "Epoch [119/200], Step [100/119], D Loss: -0.1765, G Loss: 0.0775\n",
            "Epoch [120/200], Step [100/119], D Loss: -0.1564, G Loss: 0.1214\n",
            "Epoch [121/200], Step [100/119], D Loss: -0.1627, G Loss: 0.0320\n",
            "Epoch [122/200], Step [100/119], D Loss: -0.1940, G Loss: 0.1742\n",
            "Epoch [123/200], Step [100/119], D Loss: -0.2179, G Loss: 0.0415\n",
            "Epoch [124/200], Step [100/119], D Loss: -0.1874, G Loss: 0.1327\n",
            "Epoch [125/200], Step [100/119], D Loss: -0.1641, G Loss: 0.3078\n",
            "Epoch [126/200], Step [100/119], D Loss: -0.2403, G Loss: 0.3511\n",
            "Epoch [127/200], Step [100/119], D Loss: -0.2889, G Loss: 0.4290\n",
            "Epoch [128/200], Step [100/119], D Loss: -0.2032, G Loss: 0.1882\n",
            "Epoch [129/200], Step [100/119], D Loss: -0.1404, G Loss: -0.0549\n",
            "Epoch [130/200], Step [100/119], D Loss: -0.1654, G Loss: 0.0536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hHRsoagi0fja"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "72Nu4LEpL_2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}